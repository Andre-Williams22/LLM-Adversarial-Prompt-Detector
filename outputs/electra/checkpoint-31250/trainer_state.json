{
  "best_global_step": 31250,
  "best_metric": 0.0019,
  "best_model_checkpoint": "./outputs/electra/checkpoint-31250",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 31250,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00032,
      "grad_norm": 0.7916929125785828,
      "learning_rate": 1.9998080000000003e-05,
      "loss": 0.6855,
      "step": 10
    },
    {
      "epoch": 0.00064,
      "grad_norm": 0.6367036700248718,
      "learning_rate": 1.9995946666666668e-05,
      "loss": 0.6777,
      "step": 20
    },
    {
      "epoch": 0.00096,
      "grad_norm": 0.5531640648841858,
      "learning_rate": 1.9993813333333334e-05,
      "loss": 0.6718,
      "step": 30
    },
    {
      "epoch": 0.00128,
      "grad_norm": 0.7439553141593933,
      "learning_rate": 1.9991680000000002e-05,
      "loss": 0.6617,
      "step": 40
    },
    {
      "epoch": 0.0016,
      "grad_norm": 0.6936180591583252,
      "learning_rate": 1.9989546666666668e-05,
      "loss": 0.6527,
      "step": 50
    },
    {
      "epoch": 0.00192,
      "grad_norm": 0.5606865286827087,
      "learning_rate": 1.9987413333333333e-05,
      "loss": 0.6471,
      "step": 60
    },
    {
      "epoch": 0.00224,
      "grad_norm": 0.6535356044769287,
      "learning_rate": 1.9985280000000002e-05,
      "loss": 0.6314,
      "step": 70
    },
    {
      "epoch": 0.00256,
      "grad_norm": 0.7020179033279419,
      "learning_rate": 1.9983146666666667e-05,
      "loss": 0.6232,
      "step": 80
    },
    {
      "epoch": 0.00288,
      "grad_norm": 0.8060786128044128,
      "learning_rate": 1.9981013333333336e-05,
      "loss": 0.6119,
      "step": 90
    },
    {
      "epoch": 0.0032,
      "grad_norm": 0.7023255228996277,
      "learning_rate": 1.997888e-05,
      "loss": 0.6111,
      "step": 100
    },
    {
      "epoch": 0.00352,
      "grad_norm": 1.1846437454223633,
      "learning_rate": 1.997674666666667e-05,
      "loss": 0.5963,
      "step": 110
    },
    {
      "epoch": 0.00384,
      "grad_norm": 0.9604929089546204,
      "learning_rate": 1.9974613333333336e-05,
      "loss": 0.5682,
      "step": 120
    },
    {
      "epoch": 0.00416,
      "grad_norm": 1.0910801887512207,
      "learning_rate": 1.997248e-05,
      "loss": 0.5584,
      "step": 130
    },
    {
      "epoch": 0.00448,
      "grad_norm": 0.8442382216453552,
      "learning_rate": 1.997034666666667e-05,
      "loss": 0.5436,
      "step": 140
    },
    {
      "epoch": 0.0048,
      "grad_norm": 0.8255011439323425,
      "learning_rate": 1.9968213333333335e-05,
      "loss": 0.5112,
      "step": 150
    },
    {
      "epoch": 0.00512,
      "grad_norm": 1.1174322366714478,
      "learning_rate": 1.996608e-05,
      "loss": 0.5038,
      "step": 160
    },
    {
      "epoch": 0.00544,
      "grad_norm": 0.9626955389976501,
      "learning_rate": 1.996394666666667e-05,
      "loss": 0.4792,
      "step": 170
    },
    {
      "epoch": 0.00576,
      "grad_norm": 1.2871685028076172,
      "learning_rate": 1.9961813333333335e-05,
      "loss": 0.4449,
      "step": 180
    },
    {
      "epoch": 0.00608,
      "grad_norm": 1.2564787864685059,
      "learning_rate": 1.995968e-05,
      "loss": 0.4272,
      "step": 190
    },
    {
      "epoch": 0.0064,
      "grad_norm": 1.1323405504226685,
      "learning_rate": 1.995754666666667e-05,
      "loss": 0.4176,
      "step": 200
    },
    {
      "epoch": 0.00672,
      "grad_norm": 1.2523456811904907,
      "learning_rate": 1.9955413333333334e-05,
      "loss": 0.3743,
      "step": 210
    },
    {
      "epoch": 0.00704,
      "grad_norm": 1.2042423486709595,
      "learning_rate": 1.9953280000000003e-05,
      "loss": 0.3543,
      "step": 220
    },
    {
      "epoch": 0.00736,
      "grad_norm": 1.0259288549423218,
      "learning_rate": 1.9951146666666668e-05,
      "loss": 0.3325,
      "step": 230
    },
    {
      "epoch": 0.00768,
      "grad_norm": 1.1664756536483765,
      "learning_rate": 1.9949013333333337e-05,
      "loss": 0.3118,
      "step": 240
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.8863046765327454,
      "learning_rate": 1.9946880000000002e-05,
      "loss": 0.2734,
      "step": 250
    },
    {
      "epoch": 0.00832,
      "grad_norm": 1.117430329322815,
      "learning_rate": 1.9944746666666668e-05,
      "loss": 0.2526,
      "step": 260
    },
    {
      "epoch": 0.00864,
      "grad_norm": 0.8380494713783264,
      "learning_rate": 1.9942613333333337e-05,
      "loss": 0.2308,
      "step": 270
    },
    {
      "epoch": 0.00896,
      "grad_norm": 1.0463247299194336,
      "learning_rate": 1.9940480000000002e-05,
      "loss": 0.2128,
      "step": 280
    },
    {
      "epoch": 0.00928,
      "grad_norm": 1.1021043062210083,
      "learning_rate": 1.9938346666666667e-05,
      "loss": 0.1813,
      "step": 290
    },
    {
      "epoch": 0.0096,
      "grad_norm": 0.8993824124336243,
      "learning_rate": 1.9936213333333333e-05,
      "loss": 0.1628,
      "step": 300
    },
    {
      "epoch": 0.00992,
      "grad_norm": 0.8652257919311523,
      "learning_rate": 1.993408e-05,
      "loss": 0.1503,
      "step": 310
    },
    {
      "epoch": 0.01024,
      "grad_norm": 0.7799456715583801,
      "learning_rate": 1.9931946666666667e-05,
      "loss": 0.1449,
      "step": 320
    },
    {
      "epoch": 0.01056,
      "grad_norm": 1.0566357374191284,
      "learning_rate": 1.9929813333333336e-05,
      "loss": 0.1221,
      "step": 330
    },
    {
      "epoch": 0.01088,
      "grad_norm": 0.9498649835586548,
      "learning_rate": 1.992768e-05,
      "loss": 0.1425,
      "step": 340
    },
    {
      "epoch": 0.0112,
      "grad_norm": 0.6723945140838623,
      "learning_rate": 1.992554666666667e-05,
      "loss": 0.1356,
      "step": 350
    },
    {
      "epoch": 0.01152,
      "grad_norm": 0.6155112385749817,
      "learning_rate": 1.9923413333333335e-05,
      "loss": 0.1074,
      "step": 360
    },
    {
      "epoch": 0.01184,
      "grad_norm": 0.7830743789672852,
      "learning_rate": 1.992128e-05,
      "loss": 0.1123,
      "step": 370
    },
    {
      "epoch": 0.01216,
      "grad_norm": 0.6570001244544983,
      "learning_rate": 1.991914666666667e-05,
      "loss": 0.0707,
      "step": 380
    },
    {
      "epoch": 0.01248,
      "grad_norm": 0.7558070421218872,
      "learning_rate": 1.9917013333333335e-05,
      "loss": 0.1148,
      "step": 390
    },
    {
      "epoch": 0.0128,
      "grad_norm": 1.0655313730239868,
      "learning_rate": 1.991488e-05,
      "loss": 0.0865,
      "step": 400
    },
    {
      "epoch": 0.01312,
      "grad_norm": 0.7005034685134888,
      "learning_rate": 1.991274666666667e-05,
      "loss": 0.0879,
      "step": 410
    },
    {
      "epoch": 0.01344,
      "grad_norm": 0.5084385275840759,
      "learning_rate": 1.9910613333333334e-05,
      "loss": 0.0721,
      "step": 420
    },
    {
      "epoch": 0.01376,
      "grad_norm": 0.5171892046928406,
      "learning_rate": 1.990848e-05,
      "loss": 0.0432,
      "step": 430
    },
    {
      "epoch": 0.01408,
      "grad_norm": 0.4089224338531494,
      "learning_rate": 1.9906346666666668e-05,
      "loss": 0.063,
      "step": 440
    },
    {
      "epoch": 0.0144,
      "grad_norm": 0.6597904562950134,
      "learning_rate": 1.9904213333333337e-05,
      "loss": 0.0657,
      "step": 450
    },
    {
      "epoch": 0.01472,
      "grad_norm": 0.3183935880661011,
      "learning_rate": 1.9902080000000002e-05,
      "loss": 0.0421,
      "step": 460
    },
    {
      "epoch": 0.01504,
      "grad_norm": 1.065425157546997,
      "learning_rate": 1.9899946666666668e-05,
      "loss": 0.0629,
      "step": 470
    },
    {
      "epoch": 0.01536,
      "grad_norm": 0.540303111076355,
      "learning_rate": 1.9897813333333337e-05,
      "loss": 0.0383,
      "step": 480
    },
    {
      "epoch": 0.01568,
      "grad_norm": 0.2927817106246948,
      "learning_rate": 1.9895680000000002e-05,
      "loss": 0.0718,
      "step": 490
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.573326587677002,
      "learning_rate": 1.9893546666666667e-05,
      "loss": 0.0507,
      "step": 500
    },
    {
      "epoch": 0.01632,
      "grad_norm": 0.2342994511127472,
      "learning_rate": 1.9891413333333336e-05,
      "loss": 0.044,
      "step": 510
    },
    {
      "epoch": 0.01664,
      "grad_norm": 0.6105933785438538,
      "learning_rate": 1.988928e-05,
      "loss": 0.0532,
      "step": 520
    },
    {
      "epoch": 0.01696,
      "grad_norm": 0.23890171945095062,
      "learning_rate": 1.9887146666666667e-05,
      "loss": 0.0262,
      "step": 530
    },
    {
      "epoch": 0.01728,
      "grad_norm": 0.38232922554016113,
      "learning_rate": 1.9885013333333336e-05,
      "loss": 0.0331,
      "step": 540
    },
    {
      "epoch": 0.0176,
      "grad_norm": 0.2959619462490082,
      "learning_rate": 1.988288e-05,
      "loss": 0.0372,
      "step": 550
    },
    {
      "epoch": 0.01792,
      "grad_norm": 0.24557681381702423,
      "learning_rate": 1.988074666666667e-05,
      "loss": 0.0352,
      "step": 560
    },
    {
      "epoch": 0.01824,
      "grad_norm": 0.21641962230205536,
      "learning_rate": 1.9878613333333335e-05,
      "loss": 0.0271,
      "step": 570
    },
    {
      "epoch": 0.01856,
      "grad_norm": 0.534761905670166,
      "learning_rate": 1.9876480000000004e-05,
      "loss": 0.0301,
      "step": 580
    },
    {
      "epoch": 0.01888,
      "grad_norm": 0.18481729924678802,
      "learning_rate": 1.987434666666667e-05,
      "loss": 0.0237,
      "step": 590
    },
    {
      "epoch": 0.0192,
      "grad_norm": 0.15710829198360443,
      "learning_rate": 1.9872213333333335e-05,
      "loss": 0.0601,
      "step": 600
    },
    {
      "epoch": 0.01952,
      "grad_norm": 0.21682587265968323,
      "learning_rate": 1.9870080000000003e-05,
      "loss": 0.0893,
      "step": 610
    },
    {
      "epoch": 0.01984,
      "grad_norm": 0.9615607261657715,
      "learning_rate": 1.986794666666667e-05,
      "loss": 0.0311,
      "step": 620
    },
    {
      "epoch": 0.02016,
      "grad_norm": 0.15439552068710327,
      "learning_rate": 1.9865813333333334e-05,
      "loss": 0.0429,
      "step": 630
    },
    {
      "epoch": 0.02048,
      "grad_norm": 0.1854565590620041,
      "learning_rate": 1.986368e-05,
      "loss": 0.0319,
      "step": 640
    },
    {
      "epoch": 0.0208,
      "grad_norm": 0.15710142254829407,
      "learning_rate": 1.9861546666666668e-05,
      "loss": 0.0264,
      "step": 650
    },
    {
      "epoch": 0.02112,
      "grad_norm": 0.14998166263103485,
      "learning_rate": 1.9859413333333334e-05,
      "loss": 0.0485,
      "step": 660
    },
    {
      "epoch": 0.02144,
      "grad_norm": 0.1583578735589981,
      "learning_rate": 1.9857280000000002e-05,
      "loss": 0.0142,
      "step": 670
    },
    {
      "epoch": 0.02176,
      "grad_norm": 0.13278180360794067,
      "learning_rate": 1.9855146666666668e-05,
      "loss": 0.0218,
      "step": 680
    },
    {
      "epoch": 0.02208,
      "grad_norm": 0.5469614863395691,
      "learning_rate": 1.9853013333333337e-05,
      "loss": 0.0506,
      "step": 690
    },
    {
      "epoch": 0.0224,
      "grad_norm": 0.17524629831314087,
      "learning_rate": 1.9850880000000002e-05,
      "loss": 0.0751,
      "step": 700
    },
    {
      "epoch": 0.02272,
      "grad_norm": 0.18082690238952637,
      "learning_rate": 1.9848746666666667e-05,
      "loss": 0.0199,
      "step": 710
    },
    {
      "epoch": 0.02304,
      "grad_norm": 0.10059069842100143,
      "learning_rate": 1.9846613333333336e-05,
      "loss": 0.0222,
      "step": 720
    },
    {
      "epoch": 0.02336,
      "grad_norm": 0.12895303964614868,
      "learning_rate": 1.984448e-05,
      "loss": 0.0239,
      "step": 730
    },
    {
      "epoch": 0.02368,
      "grad_norm": 0.1213865727186203,
      "learning_rate": 1.9842346666666667e-05,
      "loss": 0.02,
      "step": 740
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.11431650817394257,
      "learning_rate": 1.9840213333333336e-05,
      "loss": 0.086,
      "step": 750
    },
    {
      "epoch": 0.02432,
      "grad_norm": 0.16331343352794647,
      "learning_rate": 1.983808e-05,
      "loss": 0.023,
      "step": 760
    },
    {
      "epoch": 0.02464,
      "grad_norm": 0.11230385303497314,
      "learning_rate": 1.9835946666666666e-05,
      "loss": 0.0249,
      "step": 770
    },
    {
      "epoch": 0.02496,
      "grad_norm": 0.11259903758764267,
      "learning_rate": 1.9833813333333335e-05,
      "loss": 0.012,
      "step": 780
    },
    {
      "epoch": 0.02528,
      "grad_norm": 0.14946231245994568,
      "learning_rate": 1.983168e-05,
      "loss": 0.0129,
      "step": 790
    },
    {
      "epoch": 0.0256,
      "grad_norm": 0.11629552394151688,
      "learning_rate": 1.982954666666667e-05,
      "loss": 0.0193,
      "step": 800
    },
    {
      "epoch": 0.02592,
      "grad_norm": 0.10262305289506912,
      "learning_rate": 1.9827413333333335e-05,
      "loss": 0.0171,
      "step": 810
    },
    {
      "epoch": 0.02624,
      "grad_norm": 0.12439712882041931,
      "learning_rate": 1.9825280000000003e-05,
      "loss": 0.0127,
      "step": 820
    },
    {
      "epoch": 0.02656,
      "grad_norm": 1.0495469570159912,
      "learning_rate": 1.982314666666667e-05,
      "loss": 0.0309,
      "step": 830
    },
    {
      "epoch": 0.02688,
      "grad_norm": 0.8894426822662354,
      "learning_rate": 1.9821013333333334e-05,
      "loss": 0.0134,
      "step": 840
    },
    {
      "epoch": 0.0272,
      "grad_norm": 0.10989057272672653,
      "learning_rate": 1.9818880000000003e-05,
      "loss": 0.0093,
      "step": 850
    },
    {
      "epoch": 0.02752,
      "grad_norm": 0.2434721291065216,
      "learning_rate": 1.981674666666667e-05,
      "loss": 0.0108,
      "step": 860
    },
    {
      "epoch": 0.02784,
      "grad_norm": 0.09293822944164276,
      "learning_rate": 1.9814613333333334e-05,
      "loss": 0.0103,
      "step": 870
    },
    {
      "epoch": 0.02816,
      "grad_norm": 0.088924340903759,
      "learning_rate": 1.981248e-05,
      "loss": 0.0112,
      "step": 880
    },
    {
      "epoch": 0.02848,
      "grad_norm": 0.09550101310014725,
      "learning_rate": 1.9810346666666668e-05,
      "loss": 0.0305,
      "step": 890
    },
    {
      "epoch": 0.0288,
      "grad_norm": 2.501784086227417,
      "learning_rate": 1.9808213333333333e-05,
      "loss": 0.0515,
      "step": 900
    },
    {
      "epoch": 0.02912,
      "grad_norm": 0.1589222401380539,
      "learning_rate": 1.9806080000000002e-05,
      "loss": 0.0065,
      "step": 910
    },
    {
      "epoch": 0.02944,
      "grad_norm": 0.10622238367795944,
      "learning_rate": 1.980394666666667e-05,
      "loss": 0.0248,
      "step": 920
    },
    {
      "epoch": 0.02976,
      "grad_norm": 0.867138147354126,
      "learning_rate": 1.9801813333333336e-05,
      "loss": 0.0084,
      "step": 930
    },
    {
      "epoch": 0.03008,
      "grad_norm": 0.07591813057661057,
      "learning_rate": 1.979968e-05,
      "loss": 0.0395,
      "step": 940
    },
    {
      "epoch": 0.0304,
      "grad_norm": 0.09684564173221588,
      "learning_rate": 1.979754666666667e-05,
      "loss": 0.006,
      "step": 950
    },
    {
      "epoch": 0.03072,
      "grad_norm": 0.06338373571634293,
      "learning_rate": 1.9795413333333336e-05,
      "loss": 0.0064,
      "step": 960
    },
    {
      "epoch": 0.03104,
      "grad_norm": 0.08325731754302979,
      "learning_rate": 1.979328e-05,
      "loss": 0.0179,
      "step": 970
    },
    {
      "epoch": 0.03136,
      "grad_norm": 0.16807758808135986,
      "learning_rate": 1.9791146666666666e-05,
      "loss": 0.005,
      "step": 980
    },
    {
      "epoch": 0.03168,
      "grad_norm": 0.05187332257628441,
      "learning_rate": 1.9789013333333335e-05,
      "loss": 0.0069,
      "step": 990
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.06093372777104378,
      "learning_rate": 1.978688e-05,
      "loss": 0.0053,
      "step": 1000
    },
    {
      "epoch": 0.03232,
      "grad_norm": 0.06739725172519684,
      "learning_rate": 1.978474666666667e-05,
      "loss": 0.0367,
      "step": 1010
    },
    {
      "epoch": 0.03264,
      "grad_norm": 0.09026747941970825,
      "learning_rate": 1.9782613333333335e-05,
      "loss": 0.0295,
      "step": 1020
    },
    {
      "epoch": 0.03296,
      "grad_norm": 0.08101535588502884,
      "learning_rate": 1.9780480000000003e-05,
      "loss": 0.0046,
      "step": 1030
    },
    {
      "epoch": 0.03328,
      "grad_norm": 0.136461541056633,
      "learning_rate": 1.977834666666667e-05,
      "loss": 0.006,
      "step": 1040
    },
    {
      "epoch": 0.0336,
      "grad_norm": 0.05358695238828659,
      "learning_rate": 1.9776213333333334e-05,
      "loss": 0.007,
      "step": 1050
    },
    {
      "epoch": 0.03392,
      "grad_norm": 0.16639935970306396,
      "learning_rate": 1.9774080000000003e-05,
      "loss": 0.004,
      "step": 1060
    },
    {
      "epoch": 0.03424,
      "grad_norm": 0.04723183438181877,
      "learning_rate": 1.977194666666667e-05,
      "loss": 0.0068,
      "step": 1070
    },
    {
      "epoch": 0.03456,
      "grad_norm": 0.0643983781337738,
      "learning_rate": 1.9769813333333334e-05,
      "loss": 0.0152,
      "step": 1080
    },
    {
      "epoch": 0.03488,
      "grad_norm": 0.12923018634319305,
      "learning_rate": 1.9767680000000002e-05,
      "loss": 0.009,
      "step": 1090
    },
    {
      "epoch": 0.0352,
      "grad_norm": 0.056507814675569534,
      "learning_rate": 1.9765546666666668e-05,
      "loss": 0.0092,
      "step": 1100
    },
    {
      "epoch": 0.03552,
      "grad_norm": 0.048775576055049896,
      "learning_rate": 1.9763413333333333e-05,
      "loss": 0.0177,
      "step": 1110
    },
    {
      "epoch": 0.03584,
      "grad_norm": 0.06011013686656952,
      "learning_rate": 1.9761280000000002e-05,
      "loss": 0.0113,
      "step": 1120
    },
    {
      "epoch": 0.03616,
      "grad_norm": 0.16646501421928406,
      "learning_rate": 1.9759146666666667e-05,
      "loss": 0.0042,
      "step": 1130
    },
    {
      "epoch": 0.03648,
      "grad_norm": 0.05489866062998772,
      "learning_rate": 1.9757013333333336e-05,
      "loss": 0.0032,
      "step": 1140
    },
    {
      "epoch": 0.0368,
      "grad_norm": 3.0370240211486816,
      "learning_rate": 1.975488e-05,
      "loss": 0.0605,
      "step": 1150
    },
    {
      "epoch": 0.03712,
      "grad_norm": 0.0499749481678009,
      "learning_rate": 1.975274666666667e-05,
      "loss": 0.0324,
      "step": 1160
    },
    {
      "epoch": 0.03744,
      "grad_norm": 0.06240769475698471,
      "learning_rate": 1.9750613333333336e-05,
      "loss": 0.0046,
      "step": 1170
    },
    {
      "epoch": 0.03776,
      "grad_norm": 0.05660512298345566,
      "learning_rate": 1.974848e-05,
      "loss": 0.0129,
      "step": 1180
    },
    {
      "epoch": 0.03808,
      "grad_norm": 0.06467002630233765,
      "learning_rate": 1.974634666666667e-05,
      "loss": 0.0513,
      "step": 1190
    },
    {
      "epoch": 0.0384,
      "grad_norm": 0.030954523012042046,
      "learning_rate": 1.9744213333333335e-05,
      "loss": 0.0138,
      "step": 1200
    },
    {
      "epoch": 0.03872,
      "grad_norm": 0.04721156135201454,
      "learning_rate": 1.974208e-05,
      "loss": 0.0429,
      "step": 1210
    },
    {
      "epoch": 0.03904,
      "grad_norm": 0.04443025961518288,
      "learning_rate": 1.9739946666666666e-05,
      "loss": 0.0134,
      "step": 1220
    },
    {
      "epoch": 0.03936,
      "grad_norm": 0.06255178153514862,
      "learning_rate": 1.9737813333333335e-05,
      "loss": 0.0155,
      "step": 1230
    },
    {
      "epoch": 0.03968,
      "grad_norm": 0.04579856991767883,
      "learning_rate": 1.973568e-05,
      "loss": 0.0602,
      "step": 1240
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10220381617546082,
      "learning_rate": 1.973354666666667e-05,
      "loss": 0.0031,
      "step": 1250
    },
    {
      "epoch": 0.04032,
      "grad_norm": 0.08094366639852524,
      "learning_rate": 1.9731413333333334e-05,
      "loss": 0.0043,
      "step": 1260
    },
    {
      "epoch": 0.04064,
      "grad_norm": 0.3253929316997528,
      "learning_rate": 1.9729280000000003e-05,
      "loss": 0.0039,
      "step": 1270
    },
    {
      "epoch": 0.04096,
      "grad_norm": 0.04276096075773239,
      "learning_rate": 1.972714666666667e-05,
      "loss": 0.0037,
      "step": 1280
    },
    {
      "epoch": 0.04128,
      "grad_norm": 0.03864404186606407,
      "learning_rate": 1.9725013333333337e-05,
      "loss": 0.0328,
      "step": 1290
    },
    {
      "epoch": 0.0416,
      "grad_norm": 0.03268224000930786,
      "learning_rate": 1.9722880000000003e-05,
      "loss": 0.003,
      "step": 1300
    },
    {
      "epoch": 0.04192,
      "grad_norm": 0.03312001749873161,
      "learning_rate": 1.9720746666666668e-05,
      "loss": 0.0817,
      "step": 1310
    },
    {
      "epoch": 0.04224,
      "grad_norm": 0.03155967965722084,
      "learning_rate": 1.9718613333333333e-05,
      "loss": 0.0027,
      "step": 1320
    },
    {
      "epoch": 0.04256,
      "grad_norm": 0.04430381581187248,
      "learning_rate": 1.9716480000000002e-05,
      "loss": 0.0026,
      "step": 1330
    },
    {
      "epoch": 0.04288,
      "grad_norm": 0.027502775192260742,
      "learning_rate": 1.9714346666666667e-05,
      "loss": 0.0607,
      "step": 1340
    },
    {
      "epoch": 0.0432,
      "grad_norm": 0.2147568166255951,
      "learning_rate": 1.9712213333333333e-05,
      "loss": 0.0033,
      "step": 1350
    },
    {
      "epoch": 0.04352,
      "grad_norm": 0.8214404582977295,
      "learning_rate": 1.971008e-05,
      "loss": 0.005,
      "step": 1360
    },
    {
      "epoch": 0.04384,
      "grad_norm": 0.033950988203287125,
      "learning_rate": 1.9707946666666667e-05,
      "loss": 0.0121,
      "step": 1370
    },
    {
      "epoch": 0.04416,
      "grad_norm": 0.04016464576125145,
      "learning_rate": 1.9705813333333336e-05,
      "loss": 0.0026,
      "step": 1380
    },
    {
      "epoch": 0.04448,
      "grad_norm": 0.052217211574316025,
      "learning_rate": 1.970368e-05,
      "loss": 0.0198,
      "step": 1390
    },
    {
      "epoch": 0.0448,
      "grad_norm": 1.4847239255905151,
      "learning_rate": 1.970154666666667e-05,
      "loss": 0.0406,
      "step": 1400
    },
    {
      "epoch": 0.04512,
      "grad_norm": 0.028942754492163658,
      "learning_rate": 1.9699413333333335e-05,
      "loss": 0.0029,
      "step": 1410
    },
    {
      "epoch": 0.04544,
      "grad_norm": 0.0554317831993103,
      "learning_rate": 1.969728e-05,
      "loss": 0.0027,
      "step": 1420
    },
    {
      "epoch": 0.04576,
      "grad_norm": 0.03307592496275902,
      "learning_rate": 1.969514666666667e-05,
      "loss": 0.0025,
      "step": 1430
    },
    {
      "epoch": 0.04608,
      "grad_norm": 0.030631713569164276,
      "learning_rate": 1.9693013333333335e-05,
      "loss": 0.0023,
      "step": 1440
    },
    {
      "epoch": 0.0464,
      "grad_norm": 0.02598468028008938,
      "learning_rate": 1.969088e-05,
      "loss": 0.0041,
      "step": 1450
    },
    {
      "epoch": 0.04672,
      "grad_norm": 0.026790639385581017,
      "learning_rate": 1.968874666666667e-05,
      "loss": 0.0178,
      "step": 1460
    },
    {
      "epoch": 0.04704,
      "grad_norm": 0.028589995577931404,
      "learning_rate": 1.9686613333333334e-05,
      "loss": 0.0022,
      "step": 1470
    },
    {
      "epoch": 0.04736,
      "grad_norm": 1.8557308912277222,
      "learning_rate": 1.9684480000000003e-05,
      "loss": 0.0092,
      "step": 1480
    },
    {
      "epoch": 0.04768,
      "grad_norm": 0.026367047801613808,
      "learning_rate": 1.968234666666667e-05,
      "loss": 0.0037,
      "step": 1490
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.10071670264005661,
      "learning_rate": 1.9680213333333337e-05,
      "loss": 0.0027,
      "step": 1500
    },
    {
      "epoch": 0.04832,
      "grad_norm": 0.1565462052822113,
      "learning_rate": 1.9678080000000003e-05,
      "loss": 0.003,
      "step": 1510
    },
    {
      "epoch": 0.04864,
      "grad_norm": 0.11456327885389328,
      "learning_rate": 1.9675946666666668e-05,
      "loss": 0.0382,
      "step": 1520
    },
    {
      "epoch": 0.04896,
      "grad_norm": 1.3305660486221313,
      "learning_rate": 1.9673813333333337e-05,
      "loss": 0.0441,
      "step": 1530
    },
    {
      "epoch": 0.04928,
      "grad_norm": 0.7329368591308594,
      "learning_rate": 1.9671680000000002e-05,
      "loss": 0.0035,
      "step": 1540
    },
    {
      "epoch": 0.0496,
      "grad_norm": 0.02801179140806198,
      "learning_rate": 1.9669546666666667e-05,
      "loss": 0.0122,
      "step": 1550
    },
    {
      "epoch": 0.04992,
      "grad_norm": 1.0898000001907349,
      "learning_rate": 1.9667413333333333e-05,
      "loss": 0.0262,
      "step": 1560
    },
    {
      "epoch": 0.05024,
      "grad_norm": 0.032045938074588776,
      "learning_rate": 1.966528e-05,
      "loss": 0.0357,
      "step": 1570
    },
    {
      "epoch": 0.05056,
      "grad_norm": 0.028350071981549263,
      "learning_rate": 1.9663146666666667e-05,
      "loss": 0.003,
      "step": 1580
    },
    {
      "epoch": 0.05088,
      "grad_norm": 0.045762646943330765,
      "learning_rate": 1.9661013333333336e-05,
      "loss": 0.0153,
      "step": 1590
    },
    {
      "epoch": 0.0512,
      "grad_norm": 1.8240046501159668,
      "learning_rate": 1.965888e-05,
      "loss": 0.0209,
      "step": 1600
    },
    {
      "epoch": 0.05152,
      "grad_norm": 0.09187998622655869,
      "learning_rate": 1.965674666666667e-05,
      "loss": 0.0451,
      "step": 1610
    },
    {
      "epoch": 0.05184,
      "grad_norm": 0.03587576746940613,
      "learning_rate": 1.9654613333333335e-05,
      "loss": 0.0264,
      "step": 1620
    },
    {
      "epoch": 0.05216,
      "grad_norm": 1.4958360195159912,
      "learning_rate": 1.9652480000000004e-05,
      "loss": 0.0427,
      "step": 1630
    },
    {
      "epoch": 0.05248,
      "grad_norm": 0.03007919155061245,
      "learning_rate": 1.965034666666667e-05,
      "loss": 0.0454,
      "step": 1640
    },
    {
      "epoch": 0.0528,
      "grad_norm": 0.029834292829036713,
      "learning_rate": 1.9648213333333335e-05,
      "loss": 0.0019,
      "step": 1650
    },
    {
      "epoch": 0.05312,
      "grad_norm": 0.026264341548085213,
      "learning_rate": 1.964608e-05,
      "loss": 0.0034,
      "step": 1660
    },
    {
      "epoch": 0.05344,
      "grad_norm": 2.714628219604492,
      "learning_rate": 1.964394666666667e-05,
      "loss": 0.051,
      "step": 1670
    },
    {
      "epoch": 0.05376,
      "grad_norm": 0.03562018647789955,
      "learning_rate": 1.9641813333333334e-05,
      "loss": 0.0018,
      "step": 1680
    },
    {
      "epoch": 0.05408,
      "grad_norm": 0.27320829033851624,
      "learning_rate": 1.963968e-05,
      "loss": 0.0434,
      "step": 1690
    },
    {
      "epoch": 0.0544,
      "grad_norm": 0.024947062134742737,
      "learning_rate": 1.963754666666667e-05,
      "loss": 0.0302,
      "step": 1700
    },
    {
      "epoch": 0.05472,
      "grad_norm": 0.02544686198234558,
      "learning_rate": 1.9635413333333334e-05,
      "loss": 0.0261,
      "step": 1710
    },
    {
      "epoch": 0.05504,
      "grad_norm": 0.10593628138303757,
      "learning_rate": 1.9633280000000003e-05,
      "loss": 0.0146,
      "step": 1720
    },
    {
      "epoch": 0.05536,
      "grad_norm": 0.04619676619768143,
      "learning_rate": 1.9631146666666668e-05,
      "loss": 0.002,
      "step": 1730
    },
    {
      "epoch": 0.05568,
      "grad_norm": 0.03386460244655609,
      "learning_rate": 1.9629013333333337e-05,
      "loss": 0.0035,
      "step": 1740
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.0689447671175003,
      "learning_rate": 1.9626880000000002e-05,
      "loss": 0.0026,
      "step": 1750
    },
    {
      "epoch": 0.05632,
      "grad_norm": 0.03705627843737602,
      "learning_rate": 1.9624746666666667e-05,
      "loss": 0.0017,
      "step": 1760
    },
    {
      "epoch": 0.05664,
      "grad_norm": 0.022571515291929245,
      "learning_rate": 1.9622613333333336e-05,
      "loss": 0.0016,
      "step": 1770
    },
    {
      "epoch": 0.05696,
      "grad_norm": 0.022180834785103798,
      "learning_rate": 1.962048e-05,
      "loss": 0.0019,
      "step": 1780
    },
    {
      "epoch": 0.05728,
      "grad_norm": 0.025813333690166473,
      "learning_rate": 1.9618346666666667e-05,
      "loss": 0.0015,
      "step": 1790
    },
    {
      "epoch": 0.0576,
      "grad_norm": 0.022175097838044167,
      "learning_rate": 1.9616213333333336e-05,
      "loss": 0.0029,
      "step": 1800
    },
    {
      "epoch": 0.05792,
      "grad_norm": 0.03431910276412964,
      "learning_rate": 1.961408e-05,
      "loss": 0.0108,
      "step": 1810
    },
    {
      "epoch": 0.05824,
      "grad_norm": 0.021085456013679504,
      "learning_rate": 1.9611946666666666e-05,
      "loss": 0.0027,
      "step": 1820
    },
    {
      "epoch": 0.05856,
      "grad_norm": 0.020569713786244392,
      "learning_rate": 1.9609813333333335e-05,
      "loss": 0.0092,
      "step": 1830
    },
    {
      "epoch": 0.05888,
      "grad_norm": 0.05730370804667473,
      "learning_rate": 1.960768e-05,
      "loss": 0.0434,
      "step": 1840
    },
    {
      "epoch": 0.0592,
      "grad_norm": 0.03062245436012745,
      "learning_rate": 1.960554666666667e-05,
      "loss": 0.0062,
      "step": 1850
    },
    {
      "epoch": 0.05952,
      "grad_norm": 0.02148696593940258,
      "learning_rate": 1.9603413333333335e-05,
      "loss": 0.0447,
      "step": 1860
    },
    {
      "epoch": 0.05984,
      "grad_norm": 0.0285947285592556,
      "learning_rate": 1.9601280000000004e-05,
      "loss": 0.0251,
      "step": 1870
    },
    {
      "epoch": 0.06016,
      "grad_norm": 0.023342393338680267,
      "learning_rate": 1.959914666666667e-05,
      "loss": 0.0049,
      "step": 1880
    },
    {
      "epoch": 0.06048,
      "grad_norm": 0.02044246345758438,
      "learning_rate": 1.9597013333333334e-05,
      "loss": 0.0256,
      "step": 1890
    },
    {
      "epoch": 0.0608,
      "grad_norm": 0.033173032104969025,
      "learning_rate": 1.959488e-05,
      "loss": 0.0016,
      "step": 1900
    },
    {
      "epoch": 0.06112,
      "grad_norm": 0.022216416895389557,
      "learning_rate": 1.959274666666667e-05,
      "loss": 0.0013,
      "step": 1910
    },
    {
      "epoch": 0.06144,
      "grad_norm": 0.021020453423261642,
      "learning_rate": 1.9590613333333334e-05,
      "loss": 0.0119,
      "step": 1920
    },
    {
      "epoch": 0.06176,
      "grad_norm": 0.02025221660733223,
      "learning_rate": 1.958848e-05,
      "loss": 0.0071,
      "step": 1930
    },
    {
      "epoch": 0.06208,
      "grad_norm": 0.018366200849413872,
      "learning_rate": 1.9586346666666668e-05,
      "loss": 0.0013,
      "step": 1940
    },
    {
      "epoch": 0.0624,
      "grad_norm": 0.48489195108413696,
      "learning_rate": 1.9584213333333337e-05,
      "loss": 0.0025,
      "step": 1950
    },
    {
      "epoch": 0.06272,
      "grad_norm": 0.02514917589724064,
      "learning_rate": 1.9582080000000002e-05,
      "loss": 0.0015,
      "step": 1960
    },
    {
      "epoch": 0.06304,
      "grad_norm": 0.4726954996585846,
      "learning_rate": 1.957994666666667e-05,
      "loss": 0.0287,
      "step": 1970
    },
    {
      "epoch": 0.06336,
      "grad_norm": 0.018649538978934288,
      "learning_rate": 1.9577813333333336e-05,
      "loss": 0.0725,
      "step": 1980
    },
    {
      "epoch": 0.06368,
      "grad_norm": 0.020996803417801857,
      "learning_rate": 1.957568e-05,
      "loss": 0.0014,
      "step": 1990
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.02851143479347229,
      "learning_rate": 1.9573546666666667e-05,
      "loss": 0.0206,
      "step": 2000
    },
    {
      "epoch": 0.06432,
      "grad_norm": 0.020243721082806587,
      "learning_rate": 1.9571413333333336e-05,
      "loss": 0.0158,
      "step": 2010
    },
    {
      "epoch": 0.06464,
      "grad_norm": 0.024271873757243156,
      "learning_rate": 1.956928e-05,
      "loss": 0.0019,
      "step": 2020
    },
    {
      "epoch": 0.06496,
      "grad_norm": 0.02079026959836483,
      "learning_rate": 1.9567146666666667e-05,
      "loss": 0.0354,
      "step": 2030
    },
    {
      "epoch": 0.06528,
      "grad_norm": 3.10703182220459,
      "learning_rate": 1.9565013333333335e-05,
      "loss": 0.008,
      "step": 2040
    },
    {
      "epoch": 0.0656,
      "grad_norm": 0.018805956467986107,
      "learning_rate": 1.956288e-05,
      "loss": 0.0012,
      "step": 2050
    },
    {
      "epoch": 0.06592,
      "grad_norm": 0.2129475474357605,
      "learning_rate": 1.956074666666667e-05,
      "loss": 0.0157,
      "step": 2060
    },
    {
      "epoch": 0.06624,
      "grad_norm": 0.03252488747239113,
      "learning_rate": 1.9558613333333335e-05,
      "loss": 0.0016,
      "step": 2070
    },
    {
      "epoch": 0.06656,
      "grad_norm": 0.019005000591278076,
      "learning_rate": 1.9556480000000004e-05,
      "loss": 0.0015,
      "step": 2080
    },
    {
      "epoch": 0.06688,
      "grad_norm": 0.017800966277718544,
      "learning_rate": 1.955434666666667e-05,
      "loss": 0.0047,
      "step": 2090
    },
    {
      "epoch": 0.0672,
      "grad_norm": 1.3967605829238892,
      "learning_rate": 1.9552213333333334e-05,
      "loss": 0.1294,
      "step": 2100
    },
    {
      "epoch": 0.06752,
      "grad_norm": 0.13879798352718353,
      "learning_rate": 1.9550080000000003e-05,
      "loss": 0.003,
      "step": 2110
    },
    {
      "epoch": 0.06784,
      "grad_norm": 0.029326362535357475,
      "learning_rate": 1.954794666666667e-05,
      "loss": 0.022,
      "step": 2120
    },
    {
      "epoch": 0.06816,
      "grad_norm": 0.015684882178902626,
      "learning_rate": 1.9545813333333334e-05,
      "loss": 0.0153,
      "step": 2130
    },
    {
      "epoch": 0.06848,
      "grad_norm": 0.023718884214758873,
      "learning_rate": 1.9543680000000003e-05,
      "loss": 0.031,
      "step": 2140
    },
    {
      "epoch": 0.0688,
      "grad_norm": 0.027170952409505844,
      "learning_rate": 1.9541546666666668e-05,
      "loss": 0.0013,
      "step": 2150
    },
    {
      "epoch": 0.06912,
      "grad_norm": 0.019600331783294678,
      "learning_rate": 1.9539413333333333e-05,
      "loss": 0.0018,
      "step": 2160
    },
    {
      "epoch": 0.06944,
      "grad_norm": 3.593268394470215,
      "learning_rate": 1.9537280000000002e-05,
      "loss": 0.0375,
      "step": 2170
    },
    {
      "epoch": 0.06976,
      "grad_norm": 2.4364092350006104,
      "learning_rate": 1.9535146666666667e-05,
      "loss": 0.0482,
      "step": 2180
    },
    {
      "epoch": 0.07008,
      "grad_norm": 0.022774280980229378,
      "learning_rate": 1.9533013333333336e-05,
      "loss": 0.0014,
      "step": 2190
    },
    {
      "epoch": 0.0704,
      "grad_norm": 0.01800515130162239,
      "learning_rate": 1.953088e-05,
      "loss": 0.0367,
      "step": 2200
    },
    {
      "epoch": 0.07072,
      "grad_norm": 0.01736893691122532,
      "learning_rate": 1.952874666666667e-05,
      "loss": 0.0438,
      "step": 2210
    },
    {
      "epoch": 0.07104,
      "grad_norm": 0.02732962556183338,
      "learning_rate": 1.9526613333333336e-05,
      "loss": 0.0021,
      "step": 2220
    },
    {
      "epoch": 0.07136,
      "grad_norm": 0.02033153548836708,
      "learning_rate": 1.952448e-05,
      "loss": 0.0031,
      "step": 2230
    },
    {
      "epoch": 0.07168,
      "grad_norm": 0.02399560809135437,
      "learning_rate": 1.9522346666666667e-05,
      "loss": 0.0468,
      "step": 2240
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.041499972343444824,
      "learning_rate": 1.9520213333333335e-05,
      "loss": 0.0014,
      "step": 2250
    },
    {
      "epoch": 0.07232,
      "grad_norm": 0.020224029198288918,
      "learning_rate": 1.951808e-05,
      "loss": 0.0014,
      "step": 2260
    },
    {
      "epoch": 0.07264,
      "grad_norm": 0.024076426401734352,
      "learning_rate": 1.9515946666666666e-05,
      "loss": 0.0021,
      "step": 2270
    },
    {
      "epoch": 0.07296,
      "grad_norm": 0.030600812286138535,
      "learning_rate": 1.9513813333333335e-05,
      "loss": 0.0035,
      "step": 2280
    },
    {
      "epoch": 0.07328,
      "grad_norm": 0.028086500242352486,
      "learning_rate": 1.951168e-05,
      "loss": 0.0114,
      "step": 2290
    },
    {
      "epoch": 0.0736,
      "grad_norm": 0.025126054883003235,
      "learning_rate": 1.950954666666667e-05,
      "loss": 0.0013,
      "step": 2300
    },
    {
      "epoch": 0.07392,
      "grad_norm": 0.01625993475317955,
      "learning_rate": 1.9507413333333334e-05,
      "loss": 0.0021,
      "step": 2310
    },
    {
      "epoch": 0.07424,
      "grad_norm": 0.019603373482823372,
      "learning_rate": 1.9505280000000003e-05,
      "loss": 0.0013,
      "step": 2320
    },
    {
      "epoch": 0.07456,
      "grad_norm": 0.014337198808789253,
      "learning_rate": 1.950314666666667e-05,
      "loss": 0.0116,
      "step": 2330
    },
    {
      "epoch": 0.07488,
      "grad_norm": 0.267394095659256,
      "learning_rate": 1.9501013333333334e-05,
      "loss": 0.0021,
      "step": 2340
    },
    {
      "epoch": 0.0752,
      "grad_norm": 0.01450668927282095,
      "learning_rate": 1.9498880000000003e-05,
      "loss": 0.0012,
      "step": 2350
    },
    {
      "epoch": 0.07552,
      "grad_norm": 0.01691528968513012,
      "learning_rate": 1.9496746666666668e-05,
      "loss": 0.0021,
      "step": 2360
    },
    {
      "epoch": 0.07584,
      "grad_norm": 0.9844909906387329,
      "learning_rate": 1.9494613333333333e-05,
      "loss": 0.0149,
      "step": 2370
    },
    {
      "epoch": 0.07616,
      "grad_norm": 0.014073741622269154,
      "learning_rate": 1.9492480000000002e-05,
      "loss": 0.0078,
      "step": 2380
    },
    {
      "epoch": 0.07648,
      "grad_norm": 0.01599431410431862,
      "learning_rate": 1.9490346666666668e-05,
      "loss": 0.0008,
      "step": 2390
    },
    {
      "epoch": 0.0768,
      "grad_norm": 0.3826262354850769,
      "learning_rate": 1.9488213333333333e-05,
      "loss": 0.0304,
      "step": 2400
    },
    {
      "epoch": 0.07712,
      "grad_norm": 0.020896732807159424,
      "learning_rate": 1.948608e-05,
      "loss": 0.0009,
      "step": 2410
    },
    {
      "epoch": 0.07744,
      "grad_norm": 0.021991008892655373,
      "learning_rate": 1.948394666666667e-05,
      "loss": 0.0014,
      "step": 2420
    },
    {
      "epoch": 0.07776,
      "grad_norm": 0.01794723980128765,
      "learning_rate": 1.9481813333333336e-05,
      "loss": 0.0012,
      "step": 2430
    },
    {
      "epoch": 0.07808,
      "grad_norm": 0.02222856692969799,
      "learning_rate": 1.947968e-05,
      "loss": 0.0478,
      "step": 2440
    },
    {
      "epoch": 0.0784,
      "grad_norm": 0.029876623302698135,
      "learning_rate": 1.947754666666667e-05,
      "loss": 0.0013,
      "step": 2450
    },
    {
      "epoch": 0.07872,
      "grad_norm": 0.019566306844353676,
      "learning_rate": 1.9475413333333335e-05,
      "loss": 0.0072,
      "step": 2460
    },
    {
      "epoch": 0.07904,
      "grad_norm": 0.016232606023550034,
      "learning_rate": 1.947328e-05,
      "loss": 0.0011,
      "step": 2470
    },
    {
      "epoch": 0.07936,
      "grad_norm": 0.019533345475792885,
      "learning_rate": 1.947114666666667e-05,
      "loss": 0.001,
      "step": 2480
    },
    {
      "epoch": 0.07968,
      "grad_norm": 0.014436978846788406,
      "learning_rate": 1.9469013333333335e-05,
      "loss": 0.0814,
      "step": 2490
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.014742105267941952,
      "learning_rate": 1.946688e-05,
      "loss": 0.0014,
      "step": 2500
    },
    {
      "epoch": 0.08032,
      "grad_norm": 0.017053669318556786,
      "learning_rate": 1.946474666666667e-05,
      "loss": 0.0013,
      "step": 2510
    },
    {
      "epoch": 0.08064,
      "grad_norm": 3.3552310466766357,
      "learning_rate": 1.9462613333333334e-05,
      "loss": 0.0406,
      "step": 2520
    },
    {
      "epoch": 0.08096,
      "grad_norm": 0.019815027713775635,
      "learning_rate": 1.9460480000000003e-05,
      "loss": 0.001,
      "step": 2530
    },
    {
      "epoch": 0.08128,
      "grad_norm": 0.016407696530222893,
      "learning_rate": 1.945834666666667e-05,
      "loss": 0.0011,
      "step": 2540
    },
    {
      "epoch": 0.0816,
      "grad_norm": 4.430270195007324,
      "learning_rate": 1.9456213333333337e-05,
      "loss": 0.0492,
      "step": 2550
    },
    {
      "epoch": 0.08192,
      "grad_norm": 0.017054356634616852,
      "learning_rate": 1.9454080000000003e-05,
      "loss": 0.0299,
      "step": 2560
    },
    {
      "epoch": 0.08224,
      "grad_norm": 0.01564926840364933,
      "learning_rate": 1.9451946666666668e-05,
      "loss": 0.001,
      "step": 2570
    },
    {
      "epoch": 0.08256,
      "grad_norm": 0.01211266778409481,
      "learning_rate": 1.9449813333333333e-05,
      "loss": 0.0028,
      "step": 2580
    },
    {
      "epoch": 0.08288,
      "grad_norm": 0.030441977083683014,
      "learning_rate": 1.9447680000000002e-05,
      "loss": 0.0009,
      "step": 2590
    },
    {
      "epoch": 0.0832,
      "grad_norm": 0.014259523712098598,
      "learning_rate": 1.9445546666666668e-05,
      "loss": 0.0019,
      "step": 2600
    },
    {
      "epoch": 0.08352,
      "grad_norm": 0.01486736349761486,
      "learning_rate": 1.9443413333333333e-05,
      "loss": 0.0008,
      "step": 2610
    },
    {
      "epoch": 0.08384,
      "grad_norm": 0.019732998684048653,
      "learning_rate": 1.944128e-05,
      "loss": 0.001,
      "step": 2620
    },
    {
      "epoch": 0.08416,
      "grad_norm": 1.4757492542266846,
      "learning_rate": 1.9439146666666667e-05,
      "loss": 0.0445,
      "step": 2630
    },
    {
      "epoch": 0.08448,
      "grad_norm": 0.029808634892106056,
      "learning_rate": 1.9437013333333336e-05,
      "loss": 0.0017,
      "step": 2640
    },
    {
      "epoch": 0.0848,
      "grad_norm": 0.23286180198192596,
      "learning_rate": 1.943488e-05,
      "loss": 0.0013,
      "step": 2650
    },
    {
      "epoch": 0.08512,
      "grad_norm": 0.011966769583523273,
      "learning_rate": 1.943274666666667e-05,
      "loss": 0.0019,
      "step": 2660
    },
    {
      "epoch": 0.08544,
      "grad_norm": 2.5691494941711426,
      "learning_rate": 1.9430613333333335e-05,
      "loss": 0.0385,
      "step": 2670
    },
    {
      "epoch": 0.08576,
      "grad_norm": 0.02186424657702446,
      "learning_rate": 1.942848e-05,
      "loss": 0.0009,
      "step": 2680
    },
    {
      "epoch": 0.08608,
      "grad_norm": 0.03607962653040886,
      "learning_rate": 1.942634666666667e-05,
      "loss": 0.0011,
      "step": 2690
    },
    {
      "epoch": 0.0864,
      "grad_norm": 0.01252079475671053,
      "learning_rate": 1.9424213333333335e-05,
      "loss": 0.0161,
      "step": 2700
    },
    {
      "epoch": 0.08672,
      "grad_norm": 0.017989100888371468,
      "learning_rate": 1.942208e-05,
      "loss": 0.0009,
      "step": 2710
    },
    {
      "epoch": 0.08704,
      "grad_norm": 3.917572021484375,
      "learning_rate": 1.941994666666667e-05,
      "loss": 0.0382,
      "step": 2720
    },
    {
      "epoch": 0.08736,
      "grad_norm": 0.015097854658961296,
      "learning_rate": 1.9417813333333334e-05,
      "loss": 0.0011,
      "step": 2730
    },
    {
      "epoch": 0.08768,
      "grad_norm": 0.01161735225468874,
      "learning_rate": 1.941568e-05,
      "loss": 0.0568,
      "step": 2740
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.012353873811662197,
      "learning_rate": 1.941354666666667e-05,
      "loss": 0.0008,
      "step": 2750
    },
    {
      "epoch": 0.08832,
      "grad_norm": 0.049385812133550644,
      "learning_rate": 1.9411413333333334e-05,
      "loss": 0.001,
      "step": 2760
    },
    {
      "epoch": 0.08864,
      "grad_norm": 0.01681501418352127,
      "learning_rate": 1.9409280000000003e-05,
      "loss": 0.0778,
      "step": 2770
    },
    {
      "epoch": 0.08896,
      "grad_norm": 0.02983606420457363,
      "learning_rate": 1.9407146666666668e-05,
      "loss": 0.0089,
      "step": 2780
    },
    {
      "epoch": 0.08928,
      "grad_norm": 0.013694224879145622,
      "learning_rate": 1.9405013333333337e-05,
      "loss": 0.0009,
      "step": 2790
    },
    {
      "epoch": 0.0896,
      "grad_norm": 0.25652027130126953,
      "learning_rate": 1.9402880000000002e-05,
      "loss": 0.0014,
      "step": 2800
    },
    {
      "epoch": 0.08992,
      "grad_norm": 0.015488237142562866,
      "learning_rate": 1.9400746666666668e-05,
      "loss": 0.0291,
      "step": 2810
    },
    {
      "epoch": 0.09024,
      "grad_norm": 0.014464844018220901,
      "learning_rate": 1.9398613333333336e-05,
      "loss": 0.0087,
      "step": 2820
    },
    {
      "epoch": 0.09056,
      "grad_norm": 0.01193463709205389,
      "learning_rate": 1.9396480000000002e-05,
      "loss": 0.0009,
      "step": 2830
    },
    {
      "epoch": 0.09088,
      "grad_norm": 0.016522545367479324,
      "learning_rate": 1.9394346666666667e-05,
      "loss": 0.0023,
      "step": 2840
    },
    {
      "epoch": 0.0912,
      "grad_norm": 0.023564953356981277,
      "learning_rate": 1.9392213333333332e-05,
      "loss": 0.0011,
      "step": 2850
    },
    {
      "epoch": 0.09152,
      "grad_norm": 0.08449429273605347,
      "learning_rate": 1.939008e-05,
      "loss": 0.0154,
      "step": 2860
    },
    {
      "epoch": 0.09184,
      "grad_norm": 0.04277126118540764,
      "learning_rate": 1.9387946666666667e-05,
      "loss": 0.0436,
      "step": 2870
    },
    {
      "epoch": 0.09216,
      "grad_norm": 0.019305989146232605,
      "learning_rate": 1.9385813333333335e-05,
      "loss": 0.0012,
      "step": 2880
    },
    {
      "epoch": 0.09248,
      "grad_norm": 0.03153853490948677,
      "learning_rate": 1.9383680000000004e-05,
      "loss": 0.0011,
      "step": 2890
    },
    {
      "epoch": 0.0928,
      "grad_norm": 0.018239088356494904,
      "learning_rate": 1.938154666666667e-05,
      "loss": 0.0157,
      "step": 2900
    },
    {
      "epoch": 0.09312,
      "grad_norm": 0.014986611902713776,
      "learning_rate": 1.9379413333333335e-05,
      "loss": 0.001,
      "step": 2910
    },
    {
      "epoch": 0.09344,
      "grad_norm": 0.012768237851560116,
      "learning_rate": 1.937728e-05,
      "loss": 0.0008,
      "step": 2920
    },
    {
      "epoch": 0.09376,
      "grad_norm": 0.01731283590197563,
      "learning_rate": 1.937514666666667e-05,
      "loss": 0.0351,
      "step": 2930
    },
    {
      "epoch": 0.09408,
      "grad_norm": 0.015671897679567337,
      "learning_rate": 1.9373013333333334e-05,
      "loss": 0.0934,
      "step": 2940
    },
    {
      "epoch": 0.0944,
      "grad_norm": 0.05321209877729416,
      "learning_rate": 1.937088e-05,
      "loss": 0.0801,
      "step": 2950
    },
    {
      "epoch": 0.09472,
      "grad_norm": 0.017692752182483673,
      "learning_rate": 1.936874666666667e-05,
      "loss": 0.0013,
      "step": 2960
    },
    {
      "epoch": 0.09504,
      "grad_norm": 0.09218592196702957,
      "learning_rate": 1.9366613333333334e-05,
      "loss": 0.0152,
      "step": 2970
    },
    {
      "epoch": 0.09536,
      "grad_norm": 0.017870090901851654,
      "learning_rate": 1.9364480000000003e-05,
      "loss": 0.0171,
      "step": 2980
    },
    {
      "epoch": 0.09568,
      "grad_norm": 0.01710447110235691,
      "learning_rate": 1.9362346666666668e-05,
      "loss": 0.0266,
      "step": 2990
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.014733674935996532,
      "learning_rate": 1.9360213333333337e-05,
      "loss": 0.0018,
      "step": 3000
    },
    {
      "epoch": 0.09632,
      "grad_norm": 0.14311084151268005,
      "learning_rate": 1.9358080000000002e-05,
      "loss": 0.0056,
      "step": 3010
    },
    {
      "epoch": 0.09664,
      "grad_norm": 0.017600873485207558,
      "learning_rate": 1.9355946666666668e-05,
      "loss": 0.0044,
      "step": 3020
    },
    {
      "epoch": 0.09696,
      "grad_norm": 0.12305125594139099,
      "learning_rate": 1.9353813333333336e-05,
      "loss": 0.0011,
      "step": 3030
    },
    {
      "epoch": 0.09728,
      "grad_norm": 0.012698938138782978,
      "learning_rate": 1.9351680000000002e-05,
      "loss": 0.0408,
      "step": 3040
    },
    {
      "epoch": 0.0976,
      "grad_norm": 0.02009478025138378,
      "learning_rate": 1.9349546666666667e-05,
      "loss": 0.0012,
      "step": 3050
    },
    {
      "epoch": 0.09792,
      "grad_norm": 0.04575204476714134,
      "learning_rate": 1.9347413333333336e-05,
      "loss": 0.0046,
      "step": 3060
    },
    {
      "epoch": 0.09824,
      "grad_norm": 0.014317670837044716,
      "learning_rate": 1.934528e-05,
      "loss": 0.0009,
      "step": 3070
    },
    {
      "epoch": 0.09856,
      "grad_norm": 0.019528962671756744,
      "learning_rate": 1.9343146666666667e-05,
      "loss": 0.0013,
      "step": 3080
    },
    {
      "epoch": 0.09888,
      "grad_norm": 0.013560838997364044,
      "learning_rate": 1.9341013333333335e-05,
      "loss": 0.0427,
      "step": 3090
    },
    {
      "epoch": 0.0992,
      "grad_norm": 0.012026614509522915,
      "learning_rate": 1.933888e-05,
      "loss": 0.0013,
      "step": 3100
    },
    {
      "epoch": 0.09952,
      "grad_norm": 0.009441059082746506,
      "learning_rate": 1.933674666666667e-05,
      "loss": 0.0017,
      "step": 3110
    },
    {
      "epoch": 0.09984,
      "grad_norm": 0.0209751408547163,
      "learning_rate": 1.9334613333333335e-05,
      "loss": 0.0014,
      "step": 3120
    },
    {
      "epoch": 0.10016,
      "grad_norm": 0.014394662342965603,
      "learning_rate": 1.9332480000000004e-05,
      "loss": 0.011,
      "step": 3130
    },
    {
      "epoch": 0.10048,
      "grad_norm": 0.01588975265622139,
      "learning_rate": 1.933034666666667e-05,
      "loss": 0.0061,
      "step": 3140
    },
    {
      "epoch": 0.1008,
      "grad_norm": 0.012282738462090492,
      "learning_rate": 1.9328213333333334e-05,
      "loss": 0.001,
      "step": 3150
    },
    {
      "epoch": 0.10112,
      "grad_norm": 0.5272453427314758,
      "learning_rate": 1.9326080000000003e-05,
      "loss": 0.0016,
      "step": 3160
    },
    {
      "epoch": 0.10144,
      "grad_norm": 3.2377259731292725,
      "learning_rate": 1.932394666666667e-05,
      "loss": 0.0314,
      "step": 3170
    },
    {
      "epoch": 0.10176,
      "grad_norm": 0.05356232449412346,
      "learning_rate": 1.9321813333333334e-05,
      "loss": 0.0018,
      "step": 3180
    },
    {
      "epoch": 0.10208,
      "grad_norm": 0.010169320739805698,
      "learning_rate": 1.931968e-05,
      "loss": 0.0011,
      "step": 3190
    },
    {
      "epoch": 0.1024,
      "grad_norm": 1.9736777544021606,
      "learning_rate": 1.9317546666666668e-05,
      "loss": 0.0996,
      "step": 3200
    },
    {
      "epoch": 0.10272,
      "grad_norm": 0.6840440630912781,
      "learning_rate": 1.9315413333333333e-05,
      "loss": 0.0288,
      "step": 3210
    },
    {
      "epoch": 0.10304,
      "grad_norm": 0.0148963937535882,
      "learning_rate": 1.9313280000000002e-05,
      "loss": 0.001,
      "step": 3220
    },
    {
      "epoch": 0.10336,
      "grad_norm": 0.015321355313062668,
      "learning_rate": 1.9311146666666668e-05,
      "loss": 0.002,
      "step": 3230
    },
    {
      "epoch": 0.10368,
      "grad_norm": 0.041885700076818466,
      "learning_rate": 1.9309013333333336e-05,
      "loss": 0.002,
      "step": 3240
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.015026849694550037,
      "learning_rate": 1.9306880000000002e-05,
      "loss": 0.0021,
      "step": 3250
    },
    {
      "epoch": 0.10432,
      "grad_norm": 0.02544761635363102,
      "learning_rate": 1.9304746666666667e-05,
      "loss": 0.0484,
      "step": 3260
    },
    {
      "epoch": 0.10464,
      "grad_norm": 2.227743148803711,
      "learning_rate": 1.9302613333333336e-05,
      "loss": 0.0494,
      "step": 3270
    },
    {
      "epoch": 0.10496,
      "grad_norm": 0.09536506235599518,
      "learning_rate": 1.930048e-05,
      "loss": 0.0174,
      "step": 3280
    },
    {
      "epoch": 0.10528,
      "grad_norm": 0.01407875120639801,
      "learning_rate": 1.9298346666666667e-05,
      "loss": 0.0009,
      "step": 3290
    },
    {
      "epoch": 0.1056,
      "grad_norm": 0.017034783959388733,
      "learning_rate": 1.9296213333333335e-05,
      "loss": 0.0056,
      "step": 3300
    },
    {
      "epoch": 0.10592,
      "grad_norm": 0.011828585527837276,
      "learning_rate": 1.929408e-05,
      "loss": 0.0019,
      "step": 3310
    },
    {
      "epoch": 0.10624,
      "grad_norm": 1.084553837776184,
      "learning_rate": 1.9291946666666666e-05,
      "loss": 0.0396,
      "step": 3320
    },
    {
      "epoch": 0.10656,
      "grad_norm": 0.01272534765303135,
      "learning_rate": 1.9289813333333335e-05,
      "loss": 0.0334,
      "step": 3330
    },
    {
      "epoch": 0.10688,
      "grad_norm": 0.01315750740468502,
      "learning_rate": 1.928768e-05,
      "loss": 0.0008,
      "step": 3340
    },
    {
      "epoch": 0.1072,
      "grad_norm": 0.014063986018300056,
      "learning_rate": 1.928554666666667e-05,
      "loss": 0.0009,
      "step": 3350
    },
    {
      "epoch": 0.10752,
      "grad_norm": 0.012583457864820957,
      "learning_rate": 1.9283413333333334e-05,
      "loss": 0.0009,
      "step": 3360
    },
    {
      "epoch": 0.10784,
      "grad_norm": 0.03834505379199982,
      "learning_rate": 1.9281280000000003e-05,
      "loss": 0.0008,
      "step": 3370
    },
    {
      "epoch": 0.10816,
      "grad_norm": 0.015290760435163975,
      "learning_rate": 1.927914666666667e-05,
      "loss": 0.0008,
      "step": 3380
    },
    {
      "epoch": 0.10848,
      "grad_norm": 0.011664429679512978,
      "learning_rate": 1.9277013333333334e-05,
      "loss": 0.0008,
      "step": 3390
    },
    {
      "epoch": 0.1088,
      "grad_norm": 0.013687803409993649,
      "learning_rate": 1.9274880000000003e-05,
      "loss": 0.001,
      "step": 3400
    },
    {
      "epoch": 0.10912,
      "grad_norm": 0.0182949285954237,
      "learning_rate": 1.9272746666666668e-05,
      "loss": 0.0012,
      "step": 3410
    },
    {
      "epoch": 0.10944,
      "grad_norm": 0.021601198241114616,
      "learning_rate": 1.9270613333333333e-05,
      "loss": 0.0444,
      "step": 3420
    },
    {
      "epoch": 0.10976,
      "grad_norm": 0.013630070723593235,
      "learning_rate": 1.926848e-05,
      "loss": 0.0535,
      "step": 3430
    },
    {
      "epoch": 0.11008,
      "grad_norm": 0.012996857054531574,
      "learning_rate": 1.9266346666666668e-05,
      "loss": 0.0422,
      "step": 3440
    },
    {
      "epoch": 0.1104,
      "grad_norm": 0.010983143001794815,
      "learning_rate": 1.9264213333333336e-05,
      "loss": 0.001,
      "step": 3450
    },
    {
      "epoch": 0.11072,
      "grad_norm": 0.02275318093597889,
      "learning_rate": 1.9262080000000002e-05,
      "loss": 0.0391,
      "step": 3460
    },
    {
      "epoch": 0.11104,
      "grad_norm": 0.018055113032460213,
      "learning_rate": 1.925994666666667e-05,
      "loss": 0.0008,
      "step": 3470
    },
    {
      "epoch": 0.11136,
      "grad_norm": 0.013459241949021816,
      "learning_rate": 1.9257813333333336e-05,
      "loss": 0.0009,
      "step": 3480
    },
    {
      "epoch": 0.11168,
      "grad_norm": 0.012654428370296955,
      "learning_rate": 1.925568e-05,
      "loss": 0.0716,
      "step": 3490
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.0442107692360878,
      "learning_rate": 1.925354666666667e-05,
      "loss": 0.0022,
      "step": 3500
    },
    {
      "epoch": 0.11232,
      "grad_norm": 0.014325421303510666,
      "learning_rate": 1.9251413333333335e-05,
      "loss": 0.0315,
      "step": 3510
    },
    {
      "epoch": 0.11264,
      "grad_norm": 0.12585346400737762,
      "learning_rate": 1.924928e-05,
      "loss": 0.0191,
      "step": 3520
    },
    {
      "epoch": 0.11296,
      "grad_norm": 0.013416189700365067,
      "learning_rate": 1.9247146666666666e-05,
      "loss": 0.0008,
      "step": 3530
    },
    {
      "epoch": 0.11328,
      "grad_norm": 0.017522621899843216,
      "learning_rate": 1.9245013333333335e-05,
      "loss": 0.001,
      "step": 3540
    },
    {
      "epoch": 0.1136,
      "grad_norm": 0.01495642401278019,
      "learning_rate": 1.924288e-05,
      "loss": 0.0013,
      "step": 3550
    },
    {
      "epoch": 0.11392,
      "grad_norm": 0.014770668931305408,
      "learning_rate": 1.924074666666667e-05,
      "loss": 0.0009,
      "step": 3560
    },
    {
      "epoch": 0.11424,
      "grad_norm": 0.03951260820031166,
      "learning_rate": 1.9238613333333334e-05,
      "loss": 0.0018,
      "step": 3570
    },
    {
      "epoch": 0.11456,
      "grad_norm": 0.013061142526566982,
      "learning_rate": 1.9236480000000003e-05,
      "loss": 0.001,
      "step": 3580
    },
    {
      "epoch": 0.11488,
      "grad_norm": 0.01886535808444023,
      "learning_rate": 1.923434666666667e-05,
      "loss": 0.0012,
      "step": 3590
    },
    {
      "epoch": 0.1152,
      "grad_norm": 0.012524654157459736,
      "learning_rate": 1.9232213333333334e-05,
      "loss": 0.0403,
      "step": 3600
    },
    {
      "epoch": 0.11552,
      "grad_norm": 0.01056541409343481,
      "learning_rate": 1.9230080000000003e-05,
      "loss": 0.0013,
      "step": 3610
    },
    {
      "epoch": 0.11584,
      "grad_norm": 0.010470299050211906,
      "learning_rate": 1.9227946666666668e-05,
      "loss": 0.0022,
      "step": 3620
    },
    {
      "epoch": 0.11616,
      "grad_norm": 2.6682677268981934,
      "learning_rate": 1.9225813333333334e-05,
      "loss": 0.0411,
      "step": 3630
    },
    {
      "epoch": 0.11648,
      "grad_norm": 0.7591625452041626,
      "learning_rate": 1.9223680000000002e-05,
      "loss": 0.0019,
      "step": 3640
    },
    {
      "epoch": 0.1168,
      "grad_norm": 0.014426324516534805,
      "learning_rate": 1.9221546666666668e-05,
      "loss": 0.0008,
      "step": 3650
    },
    {
      "epoch": 0.11712,
      "grad_norm": 0.019675105810165405,
      "learning_rate": 1.9219413333333333e-05,
      "loss": 0.0009,
      "step": 3660
    },
    {
      "epoch": 0.11744,
      "grad_norm": 0.012126483023166656,
      "learning_rate": 1.9217280000000002e-05,
      "loss": 0.0009,
      "step": 3670
    },
    {
      "epoch": 0.11776,
      "grad_norm": 0.02272062934935093,
      "learning_rate": 1.9215146666666667e-05,
      "loss": 0.0378,
      "step": 3680
    },
    {
      "epoch": 0.11808,
      "grad_norm": 0.012526815757155418,
      "learning_rate": 1.9213013333333336e-05,
      "loss": 0.0009,
      "step": 3690
    },
    {
      "epoch": 0.1184,
      "grad_norm": 0.011790083721280098,
      "learning_rate": 1.921088e-05,
      "loss": 0.0118,
      "step": 3700
    },
    {
      "epoch": 0.11872,
      "grad_norm": 0.016206638887524605,
      "learning_rate": 1.920874666666667e-05,
      "loss": 0.0401,
      "step": 3710
    },
    {
      "epoch": 0.11904,
      "grad_norm": 0.011415896005928516,
      "learning_rate": 1.9206613333333335e-05,
      "loss": 0.0058,
      "step": 3720
    },
    {
      "epoch": 0.11936,
      "grad_norm": 0.014375370927155018,
      "learning_rate": 1.920448e-05,
      "loss": 0.0014,
      "step": 3730
    },
    {
      "epoch": 0.11968,
      "grad_norm": 0.01867886818945408,
      "learning_rate": 1.920234666666667e-05,
      "loss": 0.0011,
      "step": 3740
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.17132313549518585,
      "learning_rate": 1.9200213333333335e-05,
      "loss": 0.0172,
      "step": 3750
    },
    {
      "epoch": 0.12032,
      "grad_norm": 0.009436918422579765,
      "learning_rate": 1.919808e-05,
      "loss": 0.0013,
      "step": 3760
    },
    {
      "epoch": 0.12064,
      "grad_norm": 0.024956367909908295,
      "learning_rate": 1.9195946666666666e-05,
      "loss": 0.0009,
      "step": 3770
    },
    {
      "epoch": 0.12096,
      "grad_norm": 0.015241304412484169,
      "learning_rate": 1.9193813333333334e-05,
      "loss": 0.0035,
      "step": 3780
    },
    {
      "epoch": 0.12128,
      "grad_norm": 0.01376679539680481,
      "learning_rate": 1.919168e-05,
      "loss": 0.0047,
      "step": 3790
    },
    {
      "epoch": 0.1216,
      "grad_norm": 0.0543520413339138,
      "learning_rate": 1.918954666666667e-05,
      "loss": 0.0008,
      "step": 3800
    },
    {
      "epoch": 0.12192,
      "grad_norm": 0.04199269786477089,
      "learning_rate": 1.9187413333333334e-05,
      "loss": 0.0007,
      "step": 3810
    },
    {
      "epoch": 0.12224,
      "grad_norm": 0.009722684510052204,
      "learning_rate": 1.9185280000000003e-05,
      "loss": 0.0008,
      "step": 3820
    },
    {
      "epoch": 0.12256,
      "grad_norm": 0.013754372484982014,
      "learning_rate": 1.9183146666666668e-05,
      "loss": 0.0331,
      "step": 3830
    },
    {
      "epoch": 0.12288,
      "grad_norm": 0.00970597192645073,
      "learning_rate": 1.9181013333333337e-05,
      "loss": 0.0183,
      "step": 3840
    },
    {
      "epoch": 0.1232,
      "grad_norm": 0.01324492134153843,
      "learning_rate": 1.9178880000000002e-05,
      "loss": 0.0007,
      "step": 3850
    },
    {
      "epoch": 0.12352,
      "grad_norm": 0.011564616113901138,
      "learning_rate": 1.9176746666666668e-05,
      "loss": 0.0018,
      "step": 3860
    },
    {
      "epoch": 0.12384,
      "grad_norm": 0.009027182124555111,
      "learning_rate": 1.9174613333333333e-05,
      "loss": 0.0007,
      "step": 3870
    },
    {
      "epoch": 0.12416,
      "grad_norm": 0.009678618051111698,
      "learning_rate": 1.9172480000000002e-05,
      "loss": 0.0012,
      "step": 3880
    },
    {
      "epoch": 0.12448,
      "grad_norm": 0.008538701571524143,
      "learning_rate": 1.9170346666666667e-05,
      "loss": 0.0403,
      "step": 3890
    },
    {
      "epoch": 0.1248,
      "grad_norm": 0.011363436467945576,
      "learning_rate": 1.9168213333333333e-05,
      "loss": 0.0006,
      "step": 3900
    },
    {
      "epoch": 0.12512,
      "grad_norm": 0.2754180133342743,
      "learning_rate": 1.916608e-05,
      "loss": 0.0011,
      "step": 3910
    },
    {
      "epoch": 0.12544,
      "grad_norm": 0.01673790253698826,
      "learning_rate": 1.916394666666667e-05,
      "loss": 0.0356,
      "step": 3920
    },
    {
      "epoch": 0.12576,
      "grad_norm": 0.011110962368547916,
      "learning_rate": 1.9161813333333335e-05,
      "loss": 0.0013,
      "step": 3930
    },
    {
      "epoch": 0.12608,
      "grad_norm": 0.01339410524815321,
      "learning_rate": 1.915968e-05,
      "loss": 0.0203,
      "step": 3940
    },
    {
      "epoch": 0.1264,
      "grad_norm": 0.01309211179614067,
      "learning_rate": 1.915754666666667e-05,
      "loss": 0.0008,
      "step": 3950
    },
    {
      "epoch": 0.12672,
      "grad_norm": 0.010012488812208176,
      "learning_rate": 1.9155413333333335e-05,
      "loss": 0.0007,
      "step": 3960
    },
    {
      "epoch": 0.12704,
      "grad_norm": 0.012013301253318787,
      "learning_rate": 1.915328e-05,
      "loss": 0.0038,
      "step": 3970
    },
    {
      "epoch": 0.12736,
      "grad_norm": 0.010777464136481285,
      "learning_rate": 1.915114666666667e-05,
      "loss": 0.0124,
      "step": 3980
    },
    {
      "epoch": 0.12768,
      "grad_norm": 0.009369203820824623,
      "learning_rate": 1.9149013333333335e-05,
      "loss": 0.0532,
      "step": 3990
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.01418366190046072,
      "learning_rate": 1.914688e-05,
      "loss": 0.0069,
      "step": 4000
    },
    {
      "epoch": 0.12832,
      "grad_norm": 0.1346595585346222,
      "learning_rate": 1.914474666666667e-05,
      "loss": 0.0008,
      "step": 4010
    },
    {
      "epoch": 0.12864,
      "grad_norm": 0.013993201777338982,
      "learning_rate": 1.9142613333333334e-05,
      "loss": 0.0018,
      "step": 4020
    },
    {
      "epoch": 0.12896,
      "grad_norm": 0.01193622499704361,
      "learning_rate": 1.9140480000000003e-05,
      "loss": 0.0007,
      "step": 4030
    },
    {
      "epoch": 0.12928,
      "grad_norm": 0.009360873140394688,
      "learning_rate": 1.9138346666666668e-05,
      "loss": 0.0017,
      "step": 4040
    },
    {
      "epoch": 0.1296,
      "grad_norm": 0.01367641519755125,
      "learning_rate": 1.9136213333333337e-05,
      "loss": 0.0023,
      "step": 4050
    },
    {
      "epoch": 0.12992,
      "grad_norm": 0.008618846535682678,
      "learning_rate": 1.9134080000000002e-05,
      "loss": 0.0007,
      "step": 4060
    },
    {
      "epoch": 0.13024,
      "grad_norm": 0.009142361581325531,
      "learning_rate": 1.9131946666666668e-05,
      "loss": 0.0005,
      "step": 4070
    },
    {
      "epoch": 0.13056,
      "grad_norm": 0.11472068727016449,
      "learning_rate": 1.9129813333333336e-05,
      "loss": 0.0499,
      "step": 4080
    },
    {
      "epoch": 0.13088,
      "grad_norm": 0.009256130084395409,
      "learning_rate": 1.9127680000000002e-05,
      "loss": 0.0326,
      "step": 4090
    },
    {
      "epoch": 0.1312,
      "grad_norm": 0.09868277609348297,
      "learning_rate": 1.9125546666666667e-05,
      "loss": 0.0008,
      "step": 4100
    },
    {
      "epoch": 0.13152,
      "grad_norm": 0.008244799450039864,
      "learning_rate": 1.9123413333333333e-05,
      "loss": 0.0006,
      "step": 4110
    },
    {
      "epoch": 0.13184,
      "grad_norm": 0.008881298825144768,
      "learning_rate": 1.912128e-05,
      "loss": 0.0006,
      "step": 4120
    },
    {
      "epoch": 0.13216,
      "grad_norm": 0.011022304184734821,
      "learning_rate": 1.9119146666666667e-05,
      "loss": 0.0101,
      "step": 4130
    },
    {
      "epoch": 0.13248,
      "grad_norm": 0.009541013278067112,
      "learning_rate": 1.9117013333333335e-05,
      "loss": 0.0006,
      "step": 4140
    },
    {
      "epoch": 0.1328,
      "grad_norm": 0.012051057070493698,
      "learning_rate": 1.911488e-05,
      "loss": 0.0006,
      "step": 4150
    },
    {
      "epoch": 0.13312,
      "grad_norm": 0.07206650823354721,
      "learning_rate": 1.911274666666667e-05,
      "loss": 0.0009,
      "step": 4160
    },
    {
      "epoch": 0.13344,
      "grad_norm": 0.009906981140375137,
      "learning_rate": 1.9110613333333335e-05,
      "loss": 0.0181,
      "step": 4170
    },
    {
      "epoch": 0.13376,
      "grad_norm": 0.009692716412246227,
      "learning_rate": 1.9108480000000004e-05,
      "loss": 0.0865,
      "step": 4180
    },
    {
      "epoch": 0.13408,
      "grad_norm": 0.01656736619770527,
      "learning_rate": 1.910634666666667e-05,
      "loss": 0.0397,
      "step": 4190
    },
    {
      "epoch": 0.1344,
      "grad_norm": 0.016213612630963326,
      "learning_rate": 1.9104213333333335e-05,
      "loss": 0.0009,
      "step": 4200
    },
    {
      "epoch": 0.13472,
      "grad_norm": 0.01378156803548336,
      "learning_rate": 1.910208e-05,
      "loss": 0.1067,
      "step": 4210
    },
    {
      "epoch": 0.13504,
      "grad_norm": 0.011042499914765358,
      "learning_rate": 1.909994666666667e-05,
      "loss": 0.0007,
      "step": 4220
    },
    {
      "epoch": 0.13536,
      "grad_norm": 0.0095926932990551,
      "learning_rate": 1.9097813333333334e-05,
      "loss": 0.0292,
      "step": 4230
    },
    {
      "epoch": 0.13568,
      "grad_norm": 0.02116072177886963,
      "learning_rate": 1.909568e-05,
      "loss": 0.0016,
      "step": 4240
    },
    {
      "epoch": 0.136,
      "grad_norm": 6.92732572555542,
      "learning_rate": 1.9093546666666668e-05,
      "loss": 0.0389,
      "step": 4250
    },
    {
      "epoch": 0.13632,
      "grad_norm": 0.011611947789788246,
      "learning_rate": 1.9091413333333334e-05,
      "loss": 0.0436,
      "step": 4260
    },
    {
      "epoch": 0.13664,
      "grad_norm": 0.023988043889403343,
      "learning_rate": 1.9089280000000002e-05,
      "loss": 0.0012,
      "step": 4270
    },
    {
      "epoch": 0.13696,
      "grad_norm": 0.011538496240973473,
      "learning_rate": 1.9087146666666668e-05,
      "loss": 0.003,
      "step": 4280
    },
    {
      "epoch": 0.13728,
      "grad_norm": 0.028609566390514374,
      "learning_rate": 1.9085013333333336e-05,
      "loss": 0.0204,
      "step": 4290
    },
    {
      "epoch": 0.1376,
      "grad_norm": 0.010492000728845596,
      "learning_rate": 1.9082880000000002e-05,
      "loss": 0.0529,
      "step": 4300
    },
    {
      "epoch": 0.13792,
      "grad_norm": 0.013111530803143978,
      "learning_rate": 1.9080746666666667e-05,
      "loss": 0.0015,
      "step": 4310
    },
    {
      "epoch": 0.13824,
      "grad_norm": 0.01385561004281044,
      "learning_rate": 1.9078613333333336e-05,
      "loss": 0.0038,
      "step": 4320
    },
    {
      "epoch": 0.13856,
      "grad_norm": 0.013101456686854362,
      "learning_rate": 1.907648e-05,
      "loss": 0.0008,
      "step": 4330
    },
    {
      "epoch": 0.13888,
      "grad_norm": 0.17053508758544922,
      "learning_rate": 1.9074346666666667e-05,
      "loss": 0.001,
      "step": 4340
    },
    {
      "epoch": 0.1392,
      "grad_norm": 0.10530995577573776,
      "learning_rate": 1.9072213333333336e-05,
      "loss": 0.0111,
      "step": 4350
    },
    {
      "epoch": 0.13952,
      "grad_norm": 0.014895162545144558,
      "learning_rate": 1.907008e-05,
      "loss": 0.0008,
      "step": 4360
    },
    {
      "epoch": 0.13984,
      "grad_norm": 0.013369599357247353,
      "learning_rate": 1.9067946666666666e-05,
      "loss": 0.0007,
      "step": 4370
    },
    {
      "epoch": 0.14016,
      "grad_norm": 0.01005355454981327,
      "learning_rate": 1.9065813333333335e-05,
      "loss": 0.0211,
      "step": 4380
    },
    {
      "epoch": 0.14048,
      "grad_norm": 0.01119307428598404,
      "learning_rate": 1.9063680000000004e-05,
      "loss": 0.0007,
      "step": 4390
    },
    {
      "epoch": 0.1408,
      "grad_norm": 0.014994697645306587,
      "learning_rate": 1.906154666666667e-05,
      "loss": 0.0193,
      "step": 4400
    },
    {
      "epoch": 0.14112,
      "grad_norm": 0.008200296200811863,
      "learning_rate": 1.9059413333333335e-05,
      "loss": 0.128,
      "step": 4410
    },
    {
      "epoch": 0.14144,
      "grad_norm": 0.012093023397028446,
      "learning_rate": 1.9057280000000003e-05,
      "loss": 0.0008,
      "step": 4420
    },
    {
      "epoch": 0.14176,
      "grad_norm": 0.09112424403429031,
      "learning_rate": 1.905514666666667e-05,
      "loss": 0.001,
      "step": 4430
    },
    {
      "epoch": 0.14208,
      "grad_norm": 0.013001708313822746,
      "learning_rate": 1.9053013333333334e-05,
      "loss": 0.0161,
      "step": 4440
    },
    {
      "epoch": 0.1424,
      "grad_norm": 0.014246242120862007,
      "learning_rate": 1.905088e-05,
      "loss": 0.0027,
      "step": 4450
    },
    {
      "epoch": 0.14272,
      "grad_norm": 0.014889758080244064,
      "learning_rate": 1.9048746666666668e-05,
      "loss": 0.0723,
      "step": 4460
    },
    {
      "epoch": 0.14304,
      "grad_norm": 0.01332076359540224,
      "learning_rate": 1.9046613333333334e-05,
      "loss": 0.0016,
      "step": 4470
    },
    {
      "epoch": 0.14336,
      "grad_norm": 0.024048427119851112,
      "learning_rate": 1.9044480000000002e-05,
      "loss": 0.0015,
      "step": 4480
    },
    {
      "epoch": 0.14368,
      "grad_norm": 0.012438712641596794,
      "learning_rate": 1.9042346666666668e-05,
      "loss": 0.0288,
      "step": 4490
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.040944620966911316,
      "learning_rate": 1.9040213333333336e-05,
      "loss": 0.0009,
      "step": 4500
    },
    {
      "epoch": 0.14432,
      "grad_norm": 0.013902955688536167,
      "learning_rate": 1.9038080000000002e-05,
      "loss": 0.0435,
      "step": 4510
    },
    {
      "epoch": 0.14464,
      "grad_norm": 0.014224138110876083,
      "learning_rate": 1.903594666666667e-05,
      "loss": 0.0238,
      "step": 4520
    },
    {
      "epoch": 0.14496,
      "grad_norm": 0.017486024647951126,
      "learning_rate": 1.9033813333333336e-05,
      "loss": 0.001,
      "step": 4530
    },
    {
      "epoch": 0.14528,
      "grad_norm": 0.009709840640425682,
      "learning_rate": 1.903168e-05,
      "loss": 0.001,
      "step": 4540
    },
    {
      "epoch": 0.1456,
      "grad_norm": 0.04448901489377022,
      "learning_rate": 1.9029546666666667e-05,
      "loss": 0.0467,
      "step": 4550
    },
    {
      "epoch": 0.14592,
      "grad_norm": 0.04009890556335449,
      "learning_rate": 1.9027413333333336e-05,
      "loss": 0.0017,
      "step": 4560
    },
    {
      "epoch": 0.14624,
      "grad_norm": 0.009858323261141777,
      "learning_rate": 1.902528e-05,
      "loss": 0.0028,
      "step": 4570
    },
    {
      "epoch": 0.14656,
      "grad_norm": 0.030166568234562874,
      "learning_rate": 1.9023146666666666e-05,
      "loss": 0.0036,
      "step": 4580
    },
    {
      "epoch": 0.14688,
      "grad_norm": 0.012244784273207188,
      "learning_rate": 1.9021013333333335e-05,
      "loss": 0.0121,
      "step": 4590
    },
    {
      "epoch": 0.1472,
      "grad_norm": 0.01401909813284874,
      "learning_rate": 1.901888e-05,
      "loss": 0.0008,
      "step": 4600
    },
    {
      "epoch": 0.14752,
      "grad_norm": 0.24404166638851166,
      "learning_rate": 1.901674666666667e-05,
      "loss": 0.0011,
      "step": 4610
    },
    {
      "epoch": 0.14784,
      "grad_norm": 0.014216175302863121,
      "learning_rate": 1.9014613333333335e-05,
      "loss": 0.0007,
      "step": 4620
    },
    {
      "epoch": 0.14816,
      "grad_norm": 0.023671060800552368,
      "learning_rate": 1.9012480000000003e-05,
      "loss": 0.0446,
      "step": 4630
    },
    {
      "epoch": 0.14848,
      "grad_norm": 0.010805711150169373,
      "learning_rate": 1.901034666666667e-05,
      "loss": 0.0009,
      "step": 4640
    },
    {
      "epoch": 0.1488,
      "grad_norm": 0.011452623642981052,
      "learning_rate": 1.9008213333333334e-05,
      "loss": 0.043,
      "step": 4650
    },
    {
      "epoch": 0.14912,
      "grad_norm": 0.014041547663509846,
      "learning_rate": 1.9006080000000003e-05,
      "loss": 0.001,
      "step": 4660
    },
    {
      "epoch": 0.14944,
      "grad_norm": 0.017004694789648056,
      "learning_rate": 1.9003946666666668e-05,
      "loss": 0.004,
      "step": 4670
    },
    {
      "epoch": 0.14976,
      "grad_norm": 0.010026865638792515,
      "learning_rate": 1.9001813333333334e-05,
      "loss": 0.0426,
      "step": 4680
    },
    {
      "epoch": 0.15008,
      "grad_norm": 0.015140442177653313,
      "learning_rate": 1.8999680000000002e-05,
      "loss": 0.0019,
      "step": 4690
    },
    {
      "epoch": 0.1504,
      "grad_norm": 0.01383129507303238,
      "learning_rate": 1.8997546666666668e-05,
      "loss": 0.001,
      "step": 4700
    },
    {
      "epoch": 0.15072,
      "grad_norm": 0.012156283482909203,
      "learning_rate": 1.8995413333333333e-05,
      "loss": 0.0034,
      "step": 4710
    },
    {
      "epoch": 0.15104,
      "grad_norm": 0.013748071156442165,
      "learning_rate": 1.8993280000000002e-05,
      "loss": 0.0007,
      "step": 4720
    },
    {
      "epoch": 0.15136,
      "grad_norm": 0.009313388727605343,
      "learning_rate": 1.8991146666666667e-05,
      "loss": 0.0007,
      "step": 4730
    },
    {
      "epoch": 0.15168,
      "grad_norm": 0.010158812627196312,
      "learning_rate": 1.8989013333333336e-05,
      "loss": 0.014,
      "step": 4740
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.011728961952030659,
      "learning_rate": 1.898688e-05,
      "loss": 0.0006,
      "step": 4750
    },
    {
      "epoch": 0.15232,
      "grad_norm": 0.015517588704824448,
      "learning_rate": 1.898474666666667e-05,
      "loss": 0.0057,
      "step": 4760
    },
    {
      "epoch": 0.15264,
      "grad_norm": 0.014008892700076103,
      "learning_rate": 1.8982613333333336e-05,
      "loss": 0.052,
      "step": 4770
    },
    {
      "epoch": 0.15296,
      "grad_norm": 0.012266370467841625,
      "learning_rate": 1.898048e-05,
      "loss": 0.0008,
      "step": 4780
    },
    {
      "epoch": 0.15328,
      "grad_norm": 0.012522137723863125,
      "learning_rate": 1.8978346666666666e-05,
      "loss": 0.001,
      "step": 4790
    },
    {
      "epoch": 0.1536,
      "grad_norm": 0.013853286392986774,
      "learning_rate": 1.8976213333333335e-05,
      "loss": 0.056,
      "step": 4800
    },
    {
      "epoch": 0.15392,
      "grad_norm": 0.017286596819758415,
      "learning_rate": 1.897408e-05,
      "loss": 0.0189,
      "step": 4810
    },
    {
      "epoch": 0.15424,
      "grad_norm": 0.012709285132586956,
      "learning_rate": 1.8971946666666666e-05,
      "loss": 0.0007,
      "step": 4820
    },
    {
      "epoch": 0.15456,
      "grad_norm": 0.017370199784636497,
      "learning_rate": 1.8969813333333335e-05,
      "loss": 0.0051,
      "step": 4830
    },
    {
      "epoch": 0.15488,
      "grad_norm": 0.014568101614713669,
      "learning_rate": 1.896768e-05,
      "loss": 0.0802,
      "step": 4840
    },
    {
      "epoch": 0.1552,
      "grad_norm": 0.011279163882136345,
      "learning_rate": 1.896554666666667e-05,
      "loss": 0.0009,
      "step": 4850
    },
    {
      "epoch": 0.15552,
      "grad_norm": 0.01662246137857437,
      "learning_rate": 1.8963413333333338e-05,
      "loss": 0.0007,
      "step": 4860
    },
    {
      "epoch": 0.15584,
      "grad_norm": 0.011363079771399498,
      "learning_rate": 1.8961280000000003e-05,
      "loss": 0.0008,
      "step": 4870
    },
    {
      "epoch": 0.15616,
      "grad_norm": 0.020556127652525902,
      "learning_rate": 1.8959146666666668e-05,
      "loss": 0.0649,
      "step": 4880
    },
    {
      "epoch": 0.15648,
      "grad_norm": 0.01622570864856243,
      "learning_rate": 1.8957013333333334e-05,
      "loss": 0.0008,
      "step": 4890
    },
    {
      "epoch": 0.1568,
      "grad_norm": 0.017159679904580116,
      "learning_rate": 1.8954880000000002e-05,
      "loss": 0.0669,
      "step": 4900
    },
    {
      "epoch": 0.15712,
      "grad_norm": 0.023529257625341415,
      "learning_rate": 1.8952746666666668e-05,
      "loss": 0.0016,
      "step": 4910
    },
    {
      "epoch": 0.15744,
      "grad_norm": 0.016577223315835,
      "learning_rate": 1.8950613333333333e-05,
      "loss": 0.001,
      "step": 4920
    },
    {
      "epoch": 0.15776,
      "grad_norm": 0.014284626580774784,
      "learning_rate": 1.8948480000000002e-05,
      "loss": 0.0173,
      "step": 4930
    },
    {
      "epoch": 0.15808,
      "grad_norm": 0.008010131306946278,
      "learning_rate": 1.8946346666666667e-05,
      "loss": 0.0065,
      "step": 4940
    },
    {
      "epoch": 0.1584,
      "grad_norm": 0.01773514598608017,
      "learning_rate": 1.8944213333333336e-05,
      "loss": 0.0008,
      "step": 4950
    },
    {
      "epoch": 0.15872,
      "grad_norm": 0.012220294214785099,
      "learning_rate": 1.894208e-05,
      "loss": 0.0012,
      "step": 4960
    },
    {
      "epoch": 0.15904,
      "grad_norm": 0.015466342680156231,
      "learning_rate": 1.893994666666667e-05,
      "loss": 0.0008,
      "step": 4970
    },
    {
      "epoch": 0.15936,
      "grad_norm": 0.0279720276594162,
      "learning_rate": 1.8937813333333336e-05,
      "loss": 0.0011,
      "step": 4980
    },
    {
      "epoch": 0.15968,
      "grad_norm": 0.012684555724263191,
      "learning_rate": 1.893568e-05,
      "loss": 0.0445,
      "step": 4990
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.019743837416172028,
      "learning_rate": 1.893354666666667e-05,
      "loss": 0.0319,
      "step": 5000
    },
    {
      "epoch": 0.16032,
      "grad_norm": 0.014445101842284203,
      "learning_rate": 1.8931413333333335e-05,
      "loss": 0.0008,
      "step": 5010
    },
    {
      "epoch": 0.16064,
      "grad_norm": 0.02929217927157879,
      "learning_rate": 1.892928e-05,
      "loss": 0.0008,
      "step": 5020
    },
    {
      "epoch": 0.16096,
      "grad_norm": 0.010190240107476711,
      "learning_rate": 1.892714666666667e-05,
      "loss": 0.0008,
      "step": 5030
    },
    {
      "epoch": 0.16128,
      "grad_norm": 0.013015330769121647,
      "learning_rate": 1.8925013333333335e-05,
      "loss": 0.0009,
      "step": 5040
    },
    {
      "epoch": 0.1616,
      "grad_norm": 0.012124591507017612,
      "learning_rate": 1.892288e-05,
      "loss": 0.0008,
      "step": 5050
    },
    {
      "epoch": 0.16192,
      "grad_norm": 0.012755735777318478,
      "learning_rate": 1.892074666666667e-05,
      "loss": 0.0008,
      "step": 5060
    },
    {
      "epoch": 0.16224,
      "grad_norm": 0.016579948365688324,
      "learning_rate": 1.8918613333333334e-05,
      "loss": 0.0261,
      "step": 5070
    },
    {
      "epoch": 0.16256,
      "grad_norm": 0.008914419449865818,
      "learning_rate": 1.8916480000000003e-05,
      "loss": 0.0007,
      "step": 5080
    },
    {
      "epoch": 0.16288,
      "grad_norm": 0.41336825489997864,
      "learning_rate": 1.8914346666666668e-05,
      "loss": 0.0009,
      "step": 5090
    },
    {
      "epoch": 0.1632,
      "grad_norm": 0.010652138851583004,
      "learning_rate": 1.8912213333333337e-05,
      "loss": 0.0491,
      "step": 5100
    },
    {
      "epoch": 0.16352,
      "grad_norm": 0.012573949992656708,
      "learning_rate": 1.8910080000000002e-05,
      "loss": 0.0025,
      "step": 5110
    },
    {
      "epoch": 0.16384,
      "grad_norm": 0.012860496528446674,
      "learning_rate": 1.8907946666666668e-05,
      "loss": 0.0438,
      "step": 5120
    },
    {
      "epoch": 0.16416,
      "grad_norm": 0.011690928600728512,
      "learning_rate": 1.8905813333333333e-05,
      "loss": 0.0055,
      "step": 5130
    },
    {
      "epoch": 0.16448,
      "grad_norm": 2.9718592166900635,
      "learning_rate": 1.8903680000000002e-05,
      "loss": 0.0955,
      "step": 5140
    },
    {
      "epoch": 0.1648,
      "grad_norm": 0.0116634052246809,
      "learning_rate": 1.8901546666666667e-05,
      "loss": 0.0301,
      "step": 5150
    },
    {
      "epoch": 0.16512,
      "grad_norm": 0.015655191615223885,
      "learning_rate": 1.8899413333333333e-05,
      "loss": 0.0021,
      "step": 5160
    },
    {
      "epoch": 0.16544,
      "grad_norm": 4.034626007080078,
      "learning_rate": 1.889728e-05,
      "loss": 0.0086,
      "step": 5170
    },
    {
      "epoch": 0.16576,
      "grad_norm": 0.015045978128910065,
      "learning_rate": 1.8895146666666667e-05,
      "loss": 0.0008,
      "step": 5180
    },
    {
      "epoch": 0.16608,
      "grad_norm": 0.013718795962631702,
      "learning_rate": 1.8893013333333336e-05,
      "loss": 0.0835,
      "step": 5190
    },
    {
      "epoch": 0.1664,
      "grad_norm": 0.015414410270750523,
      "learning_rate": 1.889088e-05,
      "loss": 0.001,
      "step": 5200
    },
    {
      "epoch": 0.16672,
      "grad_norm": 0.019194073975086212,
      "learning_rate": 1.888874666666667e-05,
      "loss": 0.0011,
      "step": 5210
    },
    {
      "epoch": 0.16704,
      "grad_norm": 0.04273061454296112,
      "learning_rate": 1.8886613333333335e-05,
      "loss": 0.001,
      "step": 5220
    },
    {
      "epoch": 0.16736,
      "grad_norm": 0.016930684447288513,
      "learning_rate": 1.888448e-05,
      "loss": 0.0376,
      "step": 5230
    },
    {
      "epoch": 0.16768,
      "grad_norm": 3.4336893558502197,
      "learning_rate": 1.888234666666667e-05,
      "loss": 0.0544,
      "step": 5240
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.02131585404276848,
      "learning_rate": 1.8880213333333335e-05,
      "loss": 0.0012,
      "step": 5250
    },
    {
      "epoch": 0.16832,
      "grad_norm": 2.089156150817871,
      "learning_rate": 1.887808e-05,
      "loss": 0.0391,
      "step": 5260
    },
    {
      "epoch": 0.16864,
      "grad_norm": 0.013091759756207466,
      "learning_rate": 1.887594666666667e-05,
      "loss": 0.0017,
      "step": 5270
    },
    {
      "epoch": 0.16896,
      "grad_norm": 0.019329536706209183,
      "learning_rate": 1.8873813333333334e-05,
      "loss": 0.0138,
      "step": 5280
    },
    {
      "epoch": 0.16928,
      "grad_norm": 1.4214521646499634,
      "learning_rate": 1.887168e-05,
      "loss": 0.0421,
      "step": 5290
    },
    {
      "epoch": 0.1696,
      "grad_norm": 0.01613146811723709,
      "learning_rate": 1.8869546666666668e-05,
      "loss": 0.0012,
      "step": 5300
    },
    {
      "epoch": 0.16992,
      "grad_norm": 0.032315876334905624,
      "learning_rate": 1.8867413333333334e-05,
      "loss": 0.0011,
      "step": 5310
    },
    {
      "epoch": 0.17024,
      "grad_norm": 0.019463077187538147,
      "learning_rate": 1.8865280000000002e-05,
      "loss": 0.0016,
      "step": 5320
    },
    {
      "epoch": 0.17056,
      "grad_norm": 0.015419808216392994,
      "learning_rate": 1.8863146666666668e-05,
      "loss": 0.001,
      "step": 5330
    },
    {
      "epoch": 0.17088,
      "grad_norm": 0.012268057093024254,
      "learning_rate": 1.8861013333333337e-05,
      "loss": 0.0013,
      "step": 5340
    },
    {
      "epoch": 0.1712,
      "grad_norm": 0.020548120141029358,
      "learning_rate": 1.8858880000000002e-05,
      "loss": 0.001,
      "step": 5350
    },
    {
      "epoch": 0.17152,
      "grad_norm": 0.01703333482146263,
      "learning_rate": 1.8856746666666667e-05,
      "loss": 0.0009,
      "step": 5360
    },
    {
      "epoch": 0.17184,
      "grad_norm": 0.017605893313884735,
      "learning_rate": 1.8854613333333336e-05,
      "loss": 0.0011,
      "step": 5370
    },
    {
      "epoch": 0.17216,
      "grad_norm": 0.01186282467097044,
      "learning_rate": 1.885248e-05,
      "loss": 0.0169,
      "step": 5380
    },
    {
      "epoch": 0.17248,
      "grad_norm": 0.013081502169370651,
      "learning_rate": 1.8850346666666667e-05,
      "loss": 0.0247,
      "step": 5390
    },
    {
      "epoch": 0.1728,
      "grad_norm": 0.015822185203433037,
      "learning_rate": 1.8848213333333332e-05,
      "loss": 0.0011,
      "step": 5400
    },
    {
      "epoch": 0.17312,
      "grad_norm": 0.013102156110107899,
      "learning_rate": 1.884608e-05,
      "loss": 0.001,
      "step": 5410
    },
    {
      "epoch": 0.17344,
      "grad_norm": 0.0168608445674181,
      "learning_rate": 1.884394666666667e-05,
      "loss": 0.0012,
      "step": 5420
    },
    {
      "epoch": 0.17376,
      "grad_norm": 0.31779107451438904,
      "learning_rate": 1.8841813333333335e-05,
      "loss": 0.079,
      "step": 5430
    },
    {
      "epoch": 0.17408,
      "grad_norm": 0.011563828215003014,
      "learning_rate": 1.8839680000000004e-05,
      "loss": 0.0009,
      "step": 5440
    },
    {
      "epoch": 0.1744,
      "grad_norm": 0.022702539339661598,
      "learning_rate": 1.883754666666667e-05,
      "loss": 0.0011,
      "step": 5450
    },
    {
      "epoch": 0.17472,
      "grad_norm": 0.01712968945503235,
      "learning_rate": 1.8835413333333335e-05,
      "loss": 0.0009,
      "step": 5460
    },
    {
      "epoch": 0.17504,
      "grad_norm": 0.013675606809556484,
      "learning_rate": 1.883328e-05,
      "loss": 0.0013,
      "step": 5470
    },
    {
      "epoch": 0.17536,
      "grad_norm": 0.012006298638880253,
      "learning_rate": 1.883114666666667e-05,
      "loss": 0.0011,
      "step": 5480
    },
    {
      "epoch": 0.17568,
      "grad_norm": 0.020036080852150917,
      "learning_rate": 1.8829013333333334e-05,
      "loss": 0.0296,
      "step": 5490
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.009775791317224503,
      "learning_rate": 1.882688e-05,
      "loss": 0.0384,
      "step": 5500
    },
    {
      "epoch": 0.17632,
      "grad_norm": 0.0121321314945817,
      "learning_rate": 1.882474666666667e-05,
      "loss": 0.0022,
      "step": 5510
    },
    {
      "epoch": 0.17664,
      "grad_norm": 0.013275284320116043,
      "learning_rate": 1.8822613333333334e-05,
      "loss": 0.0032,
      "step": 5520
    },
    {
      "epoch": 0.17696,
      "grad_norm": 0.022237256169319153,
      "learning_rate": 1.8820480000000002e-05,
      "loss": 0.0009,
      "step": 5530
    },
    {
      "epoch": 0.17728,
      "grad_norm": 0.011242887005209923,
      "learning_rate": 1.8818346666666668e-05,
      "loss": 0.0421,
      "step": 5540
    },
    {
      "epoch": 0.1776,
      "grad_norm": 0.03762132674455643,
      "learning_rate": 1.8816213333333337e-05,
      "loss": 0.001,
      "step": 5550
    },
    {
      "epoch": 0.17792,
      "grad_norm": 0.014987519942224026,
      "learning_rate": 1.8814080000000002e-05,
      "loss": 0.0008,
      "step": 5560
    },
    {
      "epoch": 0.17824,
      "grad_norm": 0.032974306493997574,
      "learning_rate": 1.8811946666666667e-05,
      "loss": 0.001,
      "step": 5570
    },
    {
      "epoch": 0.17856,
      "grad_norm": 0.03549875691533089,
      "learning_rate": 1.8809813333333336e-05,
      "loss": 0.0331,
      "step": 5580
    },
    {
      "epoch": 0.17888,
      "grad_norm": 0.01492819469422102,
      "learning_rate": 1.880768e-05,
      "loss": 0.0032,
      "step": 5590
    },
    {
      "epoch": 0.1792,
      "grad_norm": 5.146620750427246,
      "learning_rate": 1.8805546666666667e-05,
      "loss": 0.004,
      "step": 5600
    },
    {
      "epoch": 0.17952,
      "grad_norm": 0.013011186383664608,
      "learning_rate": 1.8803413333333336e-05,
      "loss": 0.0473,
      "step": 5610
    },
    {
      "epoch": 0.17984,
      "grad_norm": 0.016501514241099358,
      "learning_rate": 1.880128e-05,
      "loss": 0.0008,
      "step": 5620
    },
    {
      "epoch": 0.18016,
      "grad_norm": 0.01953929103910923,
      "learning_rate": 1.8799146666666666e-05,
      "loss": 0.0456,
      "step": 5630
    },
    {
      "epoch": 0.18048,
      "grad_norm": 0.013664749450981617,
      "learning_rate": 1.8797013333333335e-05,
      "loss": 0.0094,
      "step": 5640
    },
    {
      "epoch": 0.1808,
      "grad_norm": 0.016140863299369812,
      "learning_rate": 1.879488e-05,
      "loss": 0.0013,
      "step": 5650
    },
    {
      "epoch": 0.18112,
      "grad_norm": 0.016713446006178856,
      "learning_rate": 1.879274666666667e-05,
      "loss": 0.0009,
      "step": 5660
    },
    {
      "epoch": 0.18144,
      "grad_norm": 0.016268495470285416,
      "learning_rate": 1.8790613333333335e-05,
      "loss": 0.0031,
      "step": 5670
    },
    {
      "epoch": 0.18176,
      "grad_norm": 0.017929868772625923,
      "learning_rate": 1.8788480000000003e-05,
      "loss": 0.043,
      "step": 5680
    },
    {
      "epoch": 0.18208,
      "grad_norm": 0.018819577991962433,
      "learning_rate": 1.878634666666667e-05,
      "loss": 0.0853,
      "step": 5690
    },
    {
      "epoch": 0.1824,
      "grad_norm": 0.015494370833039284,
      "learning_rate": 1.8784213333333334e-05,
      "loss": 0.0014,
      "step": 5700
    },
    {
      "epoch": 0.18272,
      "grad_norm": 0.01870099827647209,
      "learning_rate": 1.8782080000000003e-05,
      "loss": 0.0019,
      "step": 5710
    },
    {
      "epoch": 0.18304,
      "grad_norm": 0.015474306419491768,
      "learning_rate": 1.877994666666667e-05,
      "loss": 0.001,
      "step": 5720
    },
    {
      "epoch": 0.18336,
      "grad_norm": 0.02614145167171955,
      "learning_rate": 1.8777813333333334e-05,
      "loss": 0.001,
      "step": 5730
    },
    {
      "epoch": 0.18368,
      "grad_norm": 0.13463996350765228,
      "learning_rate": 1.877568e-05,
      "loss": 0.0011,
      "step": 5740
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.01327267661690712,
      "learning_rate": 1.8773546666666668e-05,
      "loss": 0.0012,
      "step": 5750
    },
    {
      "epoch": 0.18432,
      "grad_norm": 0.009857195429503918,
      "learning_rate": 1.8771413333333333e-05,
      "loss": 0.001,
      "step": 5760
    },
    {
      "epoch": 0.18464,
      "grad_norm": 0.012592168524861336,
      "learning_rate": 1.8769280000000002e-05,
      "loss": 0.036,
      "step": 5770
    },
    {
      "epoch": 0.18496,
      "grad_norm": 0.0405525378882885,
      "learning_rate": 1.8767146666666667e-05,
      "loss": 0.055,
      "step": 5780
    },
    {
      "epoch": 0.18528,
      "grad_norm": 0.014821508899331093,
      "learning_rate": 1.8765013333333336e-05,
      "loss": 0.0013,
      "step": 5790
    },
    {
      "epoch": 0.1856,
      "grad_norm": 0.028733810409903526,
      "learning_rate": 1.876288e-05,
      "loss": 0.001,
      "step": 5800
    },
    {
      "epoch": 0.18592,
      "grad_norm": 0.017356036230921745,
      "learning_rate": 1.8760746666666667e-05,
      "loss": 0.0532,
      "step": 5810
    },
    {
      "epoch": 0.18624,
      "grad_norm": 0.02428591065108776,
      "learning_rate": 1.8758613333333336e-05,
      "loss": 0.0166,
      "step": 5820
    },
    {
      "epoch": 0.18656,
      "grad_norm": 1.9126763343811035,
      "learning_rate": 1.875648e-05,
      "loss": 0.0551,
      "step": 5830
    },
    {
      "epoch": 0.18688,
      "grad_norm": 0.02294897846877575,
      "learning_rate": 1.8754346666666666e-05,
      "loss": 0.0362,
      "step": 5840
    },
    {
      "epoch": 0.1872,
      "grad_norm": 0.015659837052226067,
      "learning_rate": 1.8752213333333335e-05,
      "loss": 0.0013,
      "step": 5850
    },
    {
      "epoch": 0.18752,
      "grad_norm": 0.018301736563444138,
      "learning_rate": 1.875008e-05,
      "loss": 0.0013,
      "step": 5860
    },
    {
      "epoch": 0.18784,
      "grad_norm": 0.09197096526622772,
      "learning_rate": 1.8747946666666666e-05,
      "loss": 0.0019,
      "step": 5870
    },
    {
      "epoch": 0.18816,
      "grad_norm": 0.014968120492994785,
      "learning_rate": 1.8745813333333335e-05,
      "loss": 0.0427,
      "step": 5880
    },
    {
      "epoch": 0.18848,
      "grad_norm": 0.01564418151974678,
      "learning_rate": 1.8743680000000003e-05,
      "loss": 0.0016,
      "step": 5890
    },
    {
      "epoch": 0.1888,
      "grad_norm": 0.12335055321455002,
      "learning_rate": 1.874154666666667e-05,
      "loss": 0.0017,
      "step": 5900
    },
    {
      "epoch": 0.18912,
      "grad_norm": 0.014961476437747478,
      "learning_rate": 1.8739413333333334e-05,
      "loss": 0.05,
      "step": 5910
    },
    {
      "epoch": 0.18944,
      "grad_norm": 0.016898155212402344,
      "learning_rate": 1.8737280000000003e-05,
      "loss": 0.0404,
      "step": 5920
    },
    {
      "epoch": 0.18976,
      "grad_norm": 0.019011005759239197,
      "learning_rate": 1.873514666666667e-05,
      "loss": 0.0027,
      "step": 5930
    },
    {
      "epoch": 0.19008,
      "grad_norm": 5.371581554412842,
      "learning_rate": 1.8733013333333334e-05,
      "loss": 0.0113,
      "step": 5940
    },
    {
      "epoch": 0.1904,
      "grad_norm": 0.01939959079027176,
      "learning_rate": 1.8730880000000003e-05,
      "loss": 0.0011,
      "step": 5950
    },
    {
      "epoch": 0.19072,
      "grad_norm": 0.024274185299873352,
      "learning_rate": 1.8728746666666668e-05,
      "loss": 0.0012,
      "step": 5960
    },
    {
      "epoch": 0.19104,
      "grad_norm": 0.014375131577253342,
      "learning_rate": 1.8726613333333333e-05,
      "loss": 0.0011,
      "step": 5970
    },
    {
      "epoch": 0.19136,
      "grad_norm": 0.017972173169255257,
      "learning_rate": 1.8724480000000002e-05,
      "loss": 0.0011,
      "step": 5980
    },
    {
      "epoch": 0.19168,
      "grad_norm": 0.01702638529241085,
      "learning_rate": 1.8722346666666667e-05,
      "loss": 0.0015,
      "step": 5990
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.011488769203424454,
      "learning_rate": 1.8720213333333336e-05,
      "loss": 0.0009,
      "step": 6000
    },
    {
      "epoch": 0.19232,
      "grad_norm": 0.016104068607091904,
      "learning_rate": 1.871808e-05,
      "loss": 0.001,
      "step": 6010
    },
    {
      "epoch": 0.19264,
      "grad_norm": 0.01848243921995163,
      "learning_rate": 1.871594666666667e-05,
      "loss": 0.0008,
      "step": 6020
    },
    {
      "epoch": 0.19296,
      "grad_norm": 0.016385717317461967,
      "learning_rate": 1.8713813333333336e-05,
      "loss": 0.0703,
      "step": 6030
    },
    {
      "epoch": 0.19328,
      "grad_norm": 0.02126343920826912,
      "learning_rate": 1.871168e-05,
      "loss": 0.0011,
      "step": 6040
    },
    {
      "epoch": 0.1936,
      "grad_norm": 0.012689868919551373,
      "learning_rate": 1.870954666666667e-05,
      "loss": 0.0009,
      "step": 6050
    },
    {
      "epoch": 0.19392,
      "grad_norm": 2.672502040863037,
      "learning_rate": 1.8707413333333335e-05,
      "loss": 0.0319,
      "step": 6060
    },
    {
      "epoch": 0.19424,
      "grad_norm": 0.034612011164426804,
      "learning_rate": 1.870528e-05,
      "loss": 0.0014,
      "step": 6070
    },
    {
      "epoch": 0.19456,
      "grad_norm": 0.017206775024533272,
      "learning_rate": 1.8703146666666666e-05,
      "loss": 0.0011,
      "step": 6080
    },
    {
      "epoch": 0.19488,
      "grad_norm": 0.0920615866780281,
      "learning_rate": 1.8701013333333335e-05,
      "loss": 0.0011,
      "step": 6090
    },
    {
      "epoch": 0.1952,
      "grad_norm": 0.015893401578068733,
      "learning_rate": 1.869888e-05,
      "loss": 0.0414,
      "step": 6100
    },
    {
      "epoch": 0.19552,
      "grad_norm": 0.023245418444275856,
      "learning_rate": 1.869674666666667e-05,
      "loss": 0.0009,
      "step": 6110
    },
    {
      "epoch": 0.19584,
      "grad_norm": 0.025656649842858315,
      "learning_rate": 1.8694613333333334e-05,
      "loss": 0.0014,
      "step": 6120
    },
    {
      "epoch": 0.19616,
      "grad_norm": 0.11538698524236679,
      "learning_rate": 1.8692480000000003e-05,
      "loss": 0.0458,
      "step": 6130
    },
    {
      "epoch": 0.19648,
      "grad_norm": 0.053066436201334,
      "learning_rate": 1.869034666666667e-05,
      "loss": 0.0011,
      "step": 6140
    },
    {
      "epoch": 0.1968,
      "grad_norm": 0.012972396798431873,
      "learning_rate": 1.8688213333333334e-05,
      "loss": 0.001,
      "step": 6150
    },
    {
      "epoch": 0.19712,
      "grad_norm": 0.019023824483156204,
      "learning_rate": 1.8686080000000003e-05,
      "loss": 0.0694,
      "step": 6160
    },
    {
      "epoch": 0.19744,
      "grad_norm": 0.012247047387063503,
      "learning_rate": 1.8683946666666668e-05,
      "loss": 0.0009,
      "step": 6170
    },
    {
      "epoch": 0.19776,
      "grad_norm": 0.013529389165341854,
      "learning_rate": 1.8681813333333333e-05,
      "loss": 0.0011,
      "step": 6180
    },
    {
      "epoch": 0.19808,
      "grad_norm": 0.11785906553268433,
      "learning_rate": 1.8679680000000002e-05,
      "loss": 0.0372,
      "step": 6190
    },
    {
      "epoch": 0.1984,
      "grad_norm": 0.013980538584291935,
      "learning_rate": 1.8677546666666667e-05,
      "loss": 0.001,
      "step": 6200
    },
    {
      "epoch": 0.19872,
      "grad_norm": 0.015504005365073681,
      "learning_rate": 1.8675413333333333e-05,
      "loss": 0.0009,
      "step": 6210
    },
    {
      "epoch": 0.19904,
      "grad_norm": 0.014634723775088787,
      "learning_rate": 1.867328e-05,
      "loss": 0.0011,
      "step": 6220
    },
    {
      "epoch": 0.19936,
      "grad_norm": 0.01592906005680561,
      "learning_rate": 1.8671146666666667e-05,
      "loss": 0.0012,
      "step": 6230
    },
    {
      "epoch": 0.19968,
      "grad_norm": 0.014759295620024204,
      "learning_rate": 1.8669013333333336e-05,
      "loss": 0.0015,
      "step": 6240
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.013494090177118778,
      "learning_rate": 1.866688e-05,
      "loss": 0.0018,
      "step": 6250
    },
    {
      "epoch": 0.20032,
      "grad_norm": 0.01777702011168003,
      "learning_rate": 1.866474666666667e-05,
      "loss": 0.0259,
      "step": 6260
    },
    {
      "epoch": 0.20064,
      "grad_norm": 0.0181883592158556,
      "learning_rate": 1.8662613333333335e-05,
      "loss": 0.0008,
      "step": 6270
    },
    {
      "epoch": 0.20096,
      "grad_norm": 0.013691424392163754,
      "learning_rate": 1.866048e-05,
      "loss": 0.0018,
      "step": 6280
    },
    {
      "epoch": 0.20128,
      "grad_norm": 0.009037603624165058,
      "learning_rate": 1.865834666666667e-05,
      "loss": 0.0009,
      "step": 6290
    },
    {
      "epoch": 0.2016,
      "grad_norm": 0.011652316898107529,
      "learning_rate": 1.8656213333333335e-05,
      "loss": 0.0008,
      "step": 6300
    },
    {
      "epoch": 0.20192,
      "grad_norm": 0.030700527131557465,
      "learning_rate": 1.865408e-05,
      "loss": 0.0009,
      "step": 6310
    },
    {
      "epoch": 0.20224,
      "grad_norm": 0.010087214410305023,
      "learning_rate": 1.8651946666666666e-05,
      "loss": 0.001,
      "step": 6320
    },
    {
      "epoch": 0.20256,
      "grad_norm": 0.012015323154628277,
      "learning_rate": 1.8649813333333334e-05,
      "loss": 0.0007,
      "step": 6330
    },
    {
      "epoch": 0.20288,
      "grad_norm": 0.012083220295608044,
      "learning_rate": 1.864768e-05,
      "loss": 0.0009,
      "step": 6340
    },
    {
      "epoch": 0.2032,
      "grad_norm": 0.01329009234905243,
      "learning_rate": 1.864554666666667e-05,
      "loss": 0.0431,
      "step": 6350
    },
    {
      "epoch": 0.20352,
      "grad_norm": 0.015000591054558754,
      "learning_rate": 1.8643413333333337e-05,
      "loss": 0.004,
      "step": 6360
    },
    {
      "epoch": 0.20384,
      "grad_norm": 0.019017210230231285,
      "learning_rate": 1.8641280000000003e-05,
      "loss": 0.0008,
      "step": 6370
    },
    {
      "epoch": 0.20416,
      "grad_norm": 0.021234171465039253,
      "learning_rate": 1.8639146666666668e-05,
      "loss": 0.0393,
      "step": 6380
    },
    {
      "epoch": 0.20448,
      "grad_norm": 0.0223312396556139,
      "learning_rate": 1.8637013333333337e-05,
      "loss": 0.0047,
      "step": 6390
    },
    {
      "epoch": 0.2048,
      "grad_norm": 0.017704838886857033,
      "learning_rate": 1.8634880000000002e-05,
      "loss": 0.0008,
      "step": 6400
    },
    {
      "epoch": 0.20512,
      "grad_norm": 0.009270865470170975,
      "learning_rate": 1.8632746666666667e-05,
      "loss": 0.0489,
      "step": 6410
    },
    {
      "epoch": 0.20544,
      "grad_norm": 0.01346875261515379,
      "learning_rate": 1.8630613333333333e-05,
      "loss": 0.0007,
      "step": 6420
    },
    {
      "epoch": 0.20576,
      "grad_norm": 0.011383750475943089,
      "learning_rate": 1.862848e-05,
      "loss": 0.0015,
      "step": 6430
    },
    {
      "epoch": 0.20608,
      "grad_norm": 0.01774086430668831,
      "learning_rate": 1.8626346666666667e-05,
      "loss": 0.0008,
      "step": 6440
    },
    {
      "epoch": 0.2064,
      "grad_norm": 0.009388706646859646,
      "learning_rate": 1.8624213333333336e-05,
      "loss": 0.001,
      "step": 6450
    },
    {
      "epoch": 0.20672,
      "grad_norm": 0.024346306920051575,
      "learning_rate": 1.862208e-05,
      "loss": 0.0009,
      "step": 6460
    },
    {
      "epoch": 0.20704,
      "grad_norm": 0.014060691930353642,
      "learning_rate": 1.861994666666667e-05,
      "loss": 0.0035,
      "step": 6470
    },
    {
      "epoch": 0.20736,
      "grad_norm": 0.010324268601834774,
      "learning_rate": 1.8617813333333335e-05,
      "loss": 0.0403,
      "step": 6480
    },
    {
      "epoch": 0.20768,
      "grad_norm": 0.014220931567251682,
      "learning_rate": 1.861568e-05,
      "loss": 0.003,
      "step": 6490
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.013675177469849586,
      "learning_rate": 1.861354666666667e-05,
      "loss": 0.0318,
      "step": 6500
    },
    {
      "epoch": 0.20832,
      "grad_norm": 0.01147227268666029,
      "learning_rate": 1.8611413333333335e-05,
      "loss": 0.0007,
      "step": 6510
    },
    {
      "epoch": 0.20864,
      "grad_norm": 0.01064699050039053,
      "learning_rate": 1.860928e-05,
      "loss": 0.0451,
      "step": 6520
    },
    {
      "epoch": 0.20896,
      "grad_norm": 0.01511277537792921,
      "learning_rate": 1.860714666666667e-05,
      "loss": 0.0008,
      "step": 6530
    },
    {
      "epoch": 0.20928,
      "grad_norm": 0.012834655120968819,
      "learning_rate": 1.8605013333333334e-05,
      "loss": 0.0204,
      "step": 6540
    },
    {
      "epoch": 0.2096,
      "grad_norm": 0.013746336102485657,
      "learning_rate": 1.860288e-05,
      "loss": 0.0472,
      "step": 6550
    },
    {
      "epoch": 0.20992,
      "grad_norm": 0.02001991681754589,
      "learning_rate": 1.860074666666667e-05,
      "loss": 0.001,
      "step": 6560
    },
    {
      "epoch": 0.21024,
      "grad_norm": 0.014207073487341404,
      "learning_rate": 1.8598613333333334e-05,
      "loss": 0.0009,
      "step": 6570
    },
    {
      "epoch": 0.21056,
      "grad_norm": 0.08100861310958862,
      "learning_rate": 1.8596480000000003e-05,
      "loss": 0.0073,
      "step": 6580
    },
    {
      "epoch": 0.21088,
      "grad_norm": 0.08723237365484238,
      "learning_rate": 1.8594346666666668e-05,
      "loss": 0.0404,
      "step": 6590
    },
    {
      "epoch": 0.2112,
      "grad_norm": 0.01184940803796053,
      "learning_rate": 1.8592213333333337e-05,
      "loss": 0.0086,
      "step": 6600
    },
    {
      "epoch": 0.21152,
      "grad_norm": 0.013857252895832062,
      "learning_rate": 1.8590080000000002e-05,
      "loss": 0.0007,
      "step": 6610
    },
    {
      "epoch": 0.21184,
      "grad_norm": 0.01261989027261734,
      "learning_rate": 1.8587946666666667e-05,
      "loss": 0.0014,
      "step": 6620
    },
    {
      "epoch": 0.21216,
      "grad_norm": 0.029336893931031227,
      "learning_rate": 1.8585813333333336e-05,
      "loss": 0.0008,
      "step": 6630
    },
    {
      "epoch": 0.21248,
      "grad_norm": 0.011364058591425419,
      "learning_rate": 1.858368e-05,
      "loss": 0.0304,
      "step": 6640
    },
    {
      "epoch": 0.2128,
      "grad_norm": 0.012700757011771202,
      "learning_rate": 1.8581546666666667e-05,
      "loss": 0.0374,
      "step": 6650
    },
    {
      "epoch": 0.21312,
      "grad_norm": 0.01629664935171604,
      "learning_rate": 1.8579413333333332e-05,
      "loss": 0.001,
      "step": 6660
    },
    {
      "epoch": 0.21344,
      "grad_norm": 0.025881705805659294,
      "learning_rate": 1.857728e-05,
      "loss": 0.0009,
      "step": 6670
    },
    {
      "epoch": 0.21376,
      "grad_norm": 0.7157048583030701,
      "learning_rate": 1.8575146666666667e-05,
      "loss": 0.0015,
      "step": 6680
    },
    {
      "epoch": 0.21408,
      "grad_norm": 0.014259207993745804,
      "learning_rate": 1.8573013333333335e-05,
      "loss": 0.0152,
      "step": 6690
    },
    {
      "epoch": 0.2144,
      "grad_norm": 0.015881983563303947,
      "learning_rate": 1.857088e-05,
      "loss": 0.0009,
      "step": 6700
    },
    {
      "epoch": 0.21472,
      "grad_norm": 0.016986293718218803,
      "learning_rate": 1.856874666666667e-05,
      "loss": 0.0008,
      "step": 6710
    },
    {
      "epoch": 0.21504,
      "grad_norm": 0.014926637522876263,
      "learning_rate": 1.8566613333333335e-05,
      "loss": 0.0026,
      "step": 6720
    },
    {
      "epoch": 0.21536,
      "grad_norm": 0.01957686059176922,
      "learning_rate": 1.8564480000000004e-05,
      "loss": 0.0504,
      "step": 6730
    },
    {
      "epoch": 0.21568,
      "grad_norm": 0.015327328816056252,
      "learning_rate": 1.856234666666667e-05,
      "loss": 0.0427,
      "step": 6740
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.018411464989185333,
      "learning_rate": 1.8560213333333334e-05,
      "loss": 0.0008,
      "step": 6750
    },
    {
      "epoch": 0.21632,
      "grad_norm": 0.01795404776930809,
      "learning_rate": 1.855808e-05,
      "loss": 0.0009,
      "step": 6760
    },
    {
      "epoch": 0.21664,
      "grad_norm": 0.012368252500891685,
      "learning_rate": 1.855594666666667e-05,
      "loss": 0.0372,
      "step": 6770
    },
    {
      "epoch": 0.21696,
      "grad_norm": 0.01222479622811079,
      "learning_rate": 1.8553813333333334e-05,
      "loss": 0.0012,
      "step": 6780
    },
    {
      "epoch": 0.21728,
      "grad_norm": 0.015854710713028908,
      "learning_rate": 1.855168e-05,
      "loss": 0.0064,
      "step": 6790
    },
    {
      "epoch": 0.2176,
      "grad_norm": 0.012125053443014622,
      "learning_rate": 1.8549546666666668e-05,
      "loss": 0.0446,
      "step": 6800
    },
    {
      "epoch": 0.21792,
      "grad_norm": 1.5387568473815918,
      "learning_rate": 1.8547413333333333e-05,
      "loss": 0.0438,
      "step": 6810
    },
    {
      "epoch": 0.21824,
      "grad_norm": 0.01808055117726326,
      "learning_rate": 1.8545280000000002e-05,
      "loss": 0.001,
      "step": 6820
    },
    {
      "epoch": 0.21856,
      "grad_norm": 0.01623850129544735,
      "learning_rate": 1.854314666666667e-05,
      "loss": 0.001,
      "step": 6830
    },
    {
      "epoch": 0.21888,
      "grad_norm": 0.026055000722408295,
      "learning_rate": 1.8541013333333336e-05,
      "loss": 0.001,
      "step": 6840
    },
    {
      "epoch": 0.2192,
      "grad_norm": 0.022765841335058212,
      "learning_rate": 1.853888e-05,
      "loss": 0.0378,
      "step": 6850
    },
    {
      "epoch": 0.21952,
      "grad_norm": 0.03486842289566994,
      "learning_rate": 1.8536746666666667e-05,
      "loss": 0.0012,
      "step": 6860
    },
    {
      "epoch": 0.21984,
      "grad_norm": 0.012332581914961338,
      "learning_rate": 1.8534613333333336e-05,
      "loss": 0.0013,
      "step": 6870
    },
    {
      "epoch": 0.22016,
      "grad_norm": 0.016575094312429428,
      "learning_rate": 1.853248e-05,
      "loss": 0.034,
      "step": 6880
    },
    {
      "epoch": 0.22048,
      "grad_norm": 0.015045282430946827,
      "learning_rate": 1.8530346666666667e-05,
      "loss": 0.0013,
      "step": 6890
    },
    {
      "epoch": 0.2208,
      "grad_norm": 0.01541348360478878,
      "learning_rate": 1.8528213333333335e-05,
      "loss": 0.0008,
      "step": 6900
    },
    {
      "epoch": 0.22112,
      "grad_norm": 0.012714040465652943,
      "learning_rate": 1.852608e-05,
      "loss": 0.001,
      "step": 6910
    },
    {
      "epoch": 0.22144,
      "grad_norm": 0.016826488077640533,
      "learning_rate": 1.852394666666667e-05,
      "loss": 0.0012,
      "step": 6920
    },
    {
      "epoch": 0.22176,
      "grad_norm": 0.012820756994187832,
      "learning_rate": 1.8521813333333335e-05,
      "loss": 0.0011,
      "step": 6930
    },
    {
      "epoch": 0.22208,
      "grad_norm": 0.6787649989128113,
      "learning_rate": 1.8519680000000004e-05,
      "loss": 0.002,
      "step": 6940
    },
    {
      "epoch": 0.2224,
      "grad_norm": 0.013678504154086113,
      "learning_rate": 1.851754666666667e-05,
      "loss": 0.035,
      "step": 6950
    },
    {
      "epoch": 0.22272,
      "grad_norm": 0.05862214043736458,
      "learning_rate": 1.8515413333333334e-05,
      "loss": 0.0464,
      "step": 6960
    },
    {
      "epoch": 0.22304,
      "grad_norm": 1.9213449954986572,
      "learning_rate": 1.8513280000000003e-05,
      "loss": 0.1021,
      "step": 6970
    },
    {
      "epoch": 0.22336,
      "grad_norm": 0.025995301082730293,
      "learning_rate": 1.851114666666667e-05,
      "loss": 0.001,
      "step": 6980
    },
    {
      "epoch": 0.22368,
      "grad_norm": 0.016536695882678032,
      "learning_rate": 1.8509013333333334e-05,
      "loss": 0.001,
      "step": 6990
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.016655899584293365,
      "learning_rate": 1.8506880000000003e-05,
      "loss": 0.0667,
      "step": 7000
    },
    {
      "epoch": 0.22432,
      "grad_norm": 0.018597543239593506,
      "learning_rate": 1.8504746666666668e-05,
      "loss": 0.034,
      "step": 7010
    },
    {
      "epoch": 0.22464,
      "grad_norm": 0.06577430665493011,
      "learning_rate": 1.8502613333333333e-05,
      "loss": 0.0016,
      "step": 7020
    },
    {
      "epoch": 0.22496,
      "grad_norm": 0.018903469666838646,
      "learning_rate": 1.8500480000000002e-05,
      "loss": 0.034,
      "step": 7030
    },
    {
      "epoch": 0.22528,
      "grad_norm": 0.020318137481808662,
      "learning_rate": 1.8498346666666668e-05,
      "loss": 0.0011,
      "step": 7040
    },
    {
      "epoch": 0.2256,
      "grad_norm": 0.018525080755352974,
      "learning_rate": 1.8496213333333336e-05,
      "loss": 0.0018,
      "step": 7050
    },
    {
      "epoch": 0.22592,
      "grad_norm": 0.01731640286743641,
      "learning_rate": 1.849408e-05,
      "loss": 0.0012,
      "step": 7060
    },
    {
      "epoch": 0.22624,
      "grad_norm": 0.014930018223822117,
      "learning_rate": 1.849194666666667e-05,
      "loss": 0.039,
      "step": 7070
    },
    {
      "epoch": 0.22656,
      "grad_norm": 0.01782337948679924,
      "learning_rate": 1.8489813333333336e-05,
      "loss": 0.0011,
      "step": 7080
    },
    {
      "epoch": 0.22688,
      "grad_norm": 2.0377626419067383,
      "learning_rate": 1.848768e-05,
      "loss": 0.0046,
      "step": 7090
    },
    {
      "epoch": 0.2272,
      "grad_norm": 0.016846418380737305,
      "learning_rate": 1.8485546666666667e-05,
      "loss": 0.0058,
      "step": 7100
    },
    {
      "epoch": 0.22752,
      "grad_norm": 0.01622588001191616,
      "learning_rate": 1.8483413333333335e-05,
      "loss": 0.001,
      "step": 7110
    },
    {
      "epoch": 0.22784,
      "grad_norm": 0.013302594423294067,
      "learning_rate": 1.848128e-05,
      "loss": 0.0009,
      "step": 7120
    },
    {
      "epoch": 0.22816,
      "grad_norm": 0.014042803086340427,
      "learning_rate": 1.8479146666666666e-05,
      "loss": 0.0011,
      "step": 7130
    },
    {
      "epoch": 0.22848,
      "grad_norm": 0.016394643113017082,
      "learning_rate": 1.8477013333333335e-05,
      "loss": 0.0013,
      "step": 7140
    },
    {
      "epoch": 0.2288,
      "grad_norm": 0.016015155240893364,
      "learning_rate": 1.847488e-05,
      "loss": 0.0331,
      "step": 7150
    },
    {
      "epoch": 0.22912,
      "grad_norm": 0.016357216984033585,
      "learning_rate": 1.847274666666667e-05,
      "loss": 0.0009,
      "step": 7160
    },
    {
      "epoch": 0.22944,
      "grad_norm": 0.014463548548519611,
      "learning_rate": 1.8470613333333334e-05,
      "loss": 0.0189,
      "step": 7170
    },
    {
      "epoch": 0.22976,
      "grad_norm": 0.017036035656929016,
      "learning_rate": 1.8468480000000003e-05,
      "loss": 0.0009,
      "step": 7180
    },
    {
      "epoch": 0.23008,
      "grad_norm": 0.014512368477880955,
      "learning_rate": 1.846634666666667e-05,
      "loss": 0.0338,
      "step": 7190
    },
    {
      "epoch": 0.2304,
      "grad_norm": 0.021089205518364906,
      "learning_rate": 1.8464213333333334e-05,
      "loss": 0.001,
      "step": 7200
    },
    {
      "epoch": 0.23072,
      "grad_norm": 0.014500470831990242,
      "learning_rate": 1.8462080000000003e-05,
      "loss": 0.0009,
      "step": 7210
    },
    {
      "epoch": 0.23104,
      "grad_norm": 0.01576385833323002,
      "learning_rate": 1.8459946666666668e-05,
      "loss": 0.0412,
      "step": 7220
    },
    {
      "epoch": 0.23136,
      "grad_norm": 0.0782882496714592,
      "learning_rate": 1.8457813333333333e-05,
      "loss": 0.0011,
      "step": 7230
    },
    {
      "epoch": 0.23168,
      "grad_norm": 0.0181248988956213,
      "learning_rate": 1.8455680000000002e-05,
      "loss": 0.0019,
      "step": 7240
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.01772579364478588,
      "learning_rate": 1.8453546666666668e-05,
      "loss": 0.0422,
      "step": 7250
    },
    {
      "epoch": 0.23232,
      "grad_norm": 0.01688922569155693,
      "learning_rate": 1.8451413333333333e-05,
      "loss": 0.0013,
      "step": 7260
    },
    {
      "epoch": 0.23264,
      "grad_norm": 0.015533646568655968,
      "learning_rate": 1.844928e-05,
      "loss": 0.0007,
      "step": 7270
    },
    {
      "epoch": 0.23296,
      "grad_norm": 0.013400312513113022,
      "learning_rate": 1.844714666666667e-05,
      "loss": 0.001,
      "step": 7280
    },
    {
      "epoch": 0.23328,
      "grad_norm": 0.010228677652776241,
      "learning_rate": 1.8445013333333336e-05,
      "loss": 0.001,
      "step": 7290
    },
    {
      "epoch": 0.2336,
      "grad_norm": 0.009540154598653316,
      "learning_rate": 1.844288e-05,
      "loss": 0.0008,
      "step": 7300
    },
    {
      "epoch": 0.23392,
      "grad_norm": 0.013501010835170746,
      "learning_rate": 1.844074666666667e-05,
      "loss": 0.0007,
      "step": 7310
    },
    {
      "epoch": 0.23424,
      "grad_norm": 0.013313518837094307,
      "learning_rate": 1.8438613333333335e-05,
      "loss": 0.0025,
      "step": 7320
    },
    {
      "epoch": 0.23456,
      "grad_norm": 0.013576619327068329,
      "learning_rate": 1.843648e-05,
      "loss": 0.0008,
      "step": 7330
    },
    {
      "epoch": 0.23488,
      "grad_norm": 0.010073835961520672,
      "learning_rate": 1.843434666666667e-05,
      "loss": 0.0236,
      "step": 7340
    },
    {
      "epoch": 0.2352,
      "grad_norm": 8.850625991821289,
      "learning_rate": 1.8432213333333335e-05,
      "loss": 0.0182,
      "step": 7350
    },
    {
      "epoch": 0.23552,
      "grad_norm": 0.012541649863123894,
      "learning_rate": 1.843008e-05,
      "loss": 0.0009,
      "step": 7360
    },
    {
      "epoch": 0.23584,
      "grad_norm": 0.05540666729211807,
      "learning_rate": 1.842794666666667e-05,
      "loss": 0.0008,
      "step": 7370
    },
    {
      "epoch": 0.23616,
      "grad_norm": 0.014432534575462341,
      "learning_rate": 1.8425813333333334e-05,
      "loss": 0.0007,
      "step": 7380
    },
    {
      "epoch": 0.23648,
      "grad_norm": 0.06493335217237473,
      "learning_rate": 1.8423680000000003e-05,
      "loss": 0.047,
      "step": 7390
    },
    {
      "epoch": 0.2368,
      "grad_norm": 0.015484709292650223,
      "learning_rate": 1.842154666666667e-05,
      "loss": 0.0082,
      "step": 7400
    },
    {
      "epoch": 0.23712,
      "grad_norm": 0.010026250965893269,
      "learning_rate": 1.8419413333333337e-05,
      "loss": 0.0012,
      "step": 7410
    },
    {
      "epoch": 0.23744,
      "grad_norm": 0.014566494151949883,
      "learning_rate": 1.8417280000000003e-05,
      "loss": 0.0439,
      "step": 7420
    },
    {
      "epoch": 0.23776,
      "grad_norm": 0.22515371441841125,
      "learning_rate": 1.8415146666666668e-05,
      "loss": 0.1039,
      "step": 7430
    },
    {
      "epoch": 0.23808,
      "grad_norm": 0.016894623637199402,
      "learning_rate": 1.8413013333333333e-05,
      "loss": 0.0009,
      "step": 7440
    },
    {
      "epoch": 0.2384,
      "grad_norm": 0.06199127063155174,
      "learning_rate": 1.8410880000000002e-05,
      "loss": 0.0011,
      "step": 7450
    },
    {
      "epoch": 0.23872,
      "grad_norm": 0.013127243146300316,
      "learning_rate": 1.8408746666666668e-05,
      "loss": 0.001,
      "step": 7460
    },
    {
      "epoch": 0.23904,
      "grad_norm": 0.017334269359707832,
      "learning_rate": 1.8406613333333333e-05,
      "loss": 0.001,
      "step": 7470
    },
    {
      "epoch": 0.23936,
      "grad_norm": 0.016636019572615623,
      "learning_rate": 1.8404480000000002e-05,
      "loss": 0.0009,
      "step": 7480
    },
    {
      "epoch": 0.23968,
      "grad_norm": 0.017373595386743546,
      "learning_rate": 1.8402346666666667e-05,
      "loss": 0.0099,
      "step": 7490
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.011616725474596024,
      "learning_rate": 1.8400213333333336e-05,
      "loss": 0.0083,
      "step": 7500
    },
    {
      "epoch": 0.24032,
      "grad_norm": 0.009896433912217617,
      "learning_rate": 1.839808e-05,
      "loss": 0.0007,
      "step": 7510
    },
    {
      "epoch": 0.24064,
      "grad_norm": 0.011732887476682663,
      "learning_rate": 1.839594666666667e-05,
      "loss": 0.0023,
      "step": 7520
    },
    {
      "epoch": 0.24096,
      "grad_norm": 0.008180314674973488,
      "learning_rate": 1.8393813333333335e-05,
      "loss": 0.0007,
      "step": 7530
    },
    {
      "epoch": 0.24128,
      "grad_norm": 0.015001093968749046,
      "learning_rate": 1.839168e-05,
      "loss": 0.0093,
      "step": 7540
    },
    {
      "epoch": 0.2416,
      "grad_norm": 4.653637409210205,
      "learning_rate": 1.838954666666667e-05,
      "loss": 0.0641,
      "step": 7550
    },
    {
      "epoch": 0.24192,
      "grad_norm": 0.012928985059261322,
      "learning_rate": 1.8387413333333335e-05,
      "loss": 0.0006,
      "step": 7560
    },
    {
      "epoch": 0.24224,
      "grad_norm": 0.01288622710853815,
      "learning_rate": 1.838528e-05,
      "loss": 0.0008,
      "step": 7570
    },
    {
      "epoch": 0.24256,
      "grad_norm": 0.009365463629364967,
      "learning_rate": 1.838314666666667e-05,
      "loss": 0.0008,
      "step": 7580
    },
    {
      "epoch": 0.24288,
      "grad_norm": 0.01781223528087139,
      "learning_rate": 1.8381013333333334e-05,
      "loss": 0.0007,
      "step": 7590
    },
    {
      "epoch": 0.2432,
      "grad_norm": 0.010215471498668194,
      "learning_rate": 1.837888e-05,
      "loss": 0.0513,
      "step": 7600
    },
    {
      "epoch": 0.24352,
      "grad_norm": 0.012288845144212246,
      "learning_rate": 1.837674666666667e-05,
      "loss": 0.0276,
      "step": 7610
    },
    {
      "epoch": 0.24384,
      "grad_norm": 2.4743528366088867,
      "learning_rate": 1.8374613333333334e-05,
      "loss": 0.0376,
      "step": 7620
    },
    {
      "epoch": 0.24416,
      "grad_norm": 0.013902253471314907,
      "learning_rate": 1.8372480000000003e-05,
      "loss": 0.0009,
      "step": 7630
    },
    {
      "epoch": 0.24448,
      "grad_norm": 0.014695166610181332,
      "learning_rate": 1.8370346666666668e-05,
      "loss": 0.0473,
      "step": 7640
    },
    {
      "epoch": 0.2448,
      "grad_norm": 0.015051341615617275,
      "learning_rate": 1.8368213333333337e-05,
      "loss": 0.008,
      "step": 7650
    },
    {
      "epoch": 0.24512,
      "grad_norm": 0.1002437099814415,
      "learning_rate": 1.8366080000000002e-05,
      "loss": 0.0013,
      "step": 7660
    },
    {
      "epoch": 0.24544,
      "grad_norm": 0.010538077913224697,
      "learning_rate": 1.8363946666666668e-05,
      "loss": 0.0269,
      "step": 7670
    },
    {
      "epoch": 0.24576,
      "grad_norm": 0.019417930394411087,
      "learning_rate": 1.8361813333333336e-05,
      "loss": 0.0009,
      "step": 7680
    },
    {
      "epoch": 0.24608,
      "grad_norm": 0.014761609956622124,
      "learning_rate": 1.8359680000000002e-05,
      "loss": 0.0008,
      "step": 7690
    },
    {
      "epoch": 0.2464,
      "grad_norm": 0.019964298233389854,
      "learning_rate": 1.8357546666666667e-05,
      "loss": 0.0008,
      "step": 7700
    },
    {
      "epoch": 0.24672,
      "grad_norm": 0.021599365398287773,
      "learning_rate": 1.8355413333333332e-05,
      "loss": 0.0028,
      "step": 7710
    },
    {
      "epoch": 0.24704,
      "grad_norm": 0.01168910413980484,
      "learning_rate": 1.835328e-05,
      "loss": 0.0009,
      "step": 7720
    },
    {
      "epoch": 0.24736,
      "grad_norm": 0.01155680138617754,
      "learning_rate": 1.8351146666666667e-05,
      "loss": 0.0468,
      "step": 7730
    },
    {
      "epoch": 0.24768,
      "grad_norm": 0.02801225520670414,
      "learning_rate": 1.8349013333333335e-05,
      "loss": 0.0454,
      "step": 7740
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.015452500432729721,
      "learning_rate": 1.8346880000000004e-05,
      "loss": 0.0457,
      "step": 7750
    },
    {
      "epoch": 0.24832,
      "grad_norm": 0.03690032660961151,
      "learning_rate": 1.834474666666667e-05,
      "loss": 0.001,
      "step": 7760
    },
    {
      "epoch": 0.24864,
      "grad_norm": 0.01181389857083559,
      "learning_rate": 1.8342613333333335e-05,
      "loss": 0.0043,
      "step": 7770
    },
    {
      "epoch": 0.24896,
      "grad_norm": 0.016518210992217064,
      "learning_rate": 1.834048e-05,
      "loss": 0.001,
      "step": 7780
    },
    {
      "epoch": 0.24928,
      "grad_norm": 0.0180876012891531,
      "learning_rate": 1.833834666666667e-05,
      "loss": 0.0009,
      "step": 7790
    },
    {
      "epoch": 0.2496,
      "grad_norm": 0.07785242050886154,
      "learning_rate": 1.8336213333333334e-05,
      "loss": 0.0275,
      "step": 7800
    },
    {
      "epoch": 0.24992,
      "grad_norm": 2.2512013912200928,
      "learning_rate": 1.833408e-05,
      "loss": 0.0464,
      "step": 7810
    },
    {
      "epoch": 0.25024,
      "grad_norm": 0.01604864001274109,
      "learning_rate": 1.833194666666667e-05,
      "loss": 0.0016,
      "step": 7820
    },
    {
      "epoch": 0.25056,
      "grad_norm": 0.01401561126112938,
      "learning_rate": 1.8329813333333334e-05,
      "loss": 0.1122,
      "step": 7830
    },
    {
      "epoch": 0.25088,
      "grad_norm": 0.022033408284187317,
      "learning_rate": 1.8327680000000003e-05,
      "loss": 0.0581,
      "step": 7840
    },
    {
      "epoch": 0.2512,
      "grad_norm": 0.05883118137717247,
      "learning_rate": 1.8325546666666668e-05,
      "loss": 0.0012,
      "step": 7850
    },
    {
      "epoch": 0.25152,
      "grad_norm": 0.038594987243413925,
      "learning_rate": 1.8323413333333337e-05,
      "loss": 0.0012,
      "step": 7860
    },
    {
      "epoch": 0.25184,
      "grad_norm": 0.01711317151784897,
      "learning_rate": 1.8321280000000002e-05,
      "loss": 0.0011,
      "step": 7870
    },
    {
      "epoch": 0.25216,
      "grad_norm": 0.025843558833003044,
      "learning_rate": 1.8319146666666668e-05,
      "loss": 0.001,
      "step": 7880
    },
    {
      "epoch": 0.25248,
      "grad_norm": 0.03395116329193115,
      "learning_rate": 1.8317013333333336e-05,
      "loss": 0.0265,
      "step": 7890
    },
    {
      "epoch": 0.2528,
      "grad_norm": 0.018218815326690674,
      "learning_rate": 1.8314880000000002e-05,
      "loss": 0.0014,
      "step": 7900
    },
    {
      "epoch": 0.25312,
      "grad_norm": 0.019253401085734367,
      "learning_rate": 1.8312746666666667e-05,
      "loss": 0.0197,
      "step": 7910
    },
    {
      "epoch": 0.25344,
      "grad_norm": 0.03292231261730194,
      "learning_rate": 1.8310613333333336e-05,
      "loss": 0.0868,
      "step": 7920
    },
    {
      "epoch": 0.25376,
      "grad_norm": 0.031032999977469444,
      "learning_rate": 1.830848e-05,
      "loss": 0.0016,
      "step": 7930
    },
    {
      "epoch": 0.25408,
      "grad_norm": 0.01936955936253071,
      "learning_rate": 1.8306346666666667e-05,
      "loss": 0.0014,
      "step": 7940
    },
    {
      "epoch": 0.2544,
      "grad_norm": 0.25303134322166443,
      "learning_rate": 1.8304213333333335e-05,
      "loss": 0.0022,
      "step": 7950
    },
    {
      "epoch": 0.25472,
      "grad_norm": 0.019432099536061287,
      "learning_rate": 1.830208e-05,
      "loss": 0.0024,
      "step": 7960
    },
    {
      "epoch": 0.25504,
      "grad_norm": 0.016125857830047607,
      "learning_rate": 1.829994666666667e-05,
      "loss": 0.0029,
      "step": 7970
    },
    {
      "epoch": 0.25536,
      "grad_norm": 0.013155598193407059,
      "learning_rate": 1.8297813333333335e-05,
      "loss": 0.001,
      "step": 7980
    },
    {
      "epoch": 0.25568,
      "grad_norm": 0.2020081728696823,
      "learning_rate": 1.8295680000000004e-05,
      "loss": 0.0015,
      "step": 7990
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.016541847959160805,
      "learning_rate": 1.829354666666667e-05,
      "loss": 0.0012,
      "step": 8000
    },
    {
      "epoch": 0.25632,
      "grad_norm": 0.02456858567893505,
      "learning_rate": 1.8291413333333334e-05,
      "loss": 0.0011,
      "step": 8010
    },
    {
      "epoch": 0.25664,
      "grad_norm": 0.015290910378098488,
      "learning_rate": 1.8289280000000003e-05,
      "loss": 0.0614,
      "step": 8020
    },
    {
      "epoch": 0.25696,
      "grad_norm": 0.015507384203374386,
      "learning_rate": 1.828714666666667e-05,
      "loss": 0.0009,
      "step": 8030
    },
    {
      "epoch": 0.25728,
      "grad_norm": 0.014907082542777061,
      "learning_rate": 1.8285013333333334e-05,
      "loss": 0.0389,
      "step": 8040
    },
    {
      "epoch": 0.2576,
      "grad_norm": 0.020184168592095375,
      "learning_rate": 1.828288e-05,
      "loss": 0.007,
      "step": 8050
    },
    {
      "epoch": 0.25792,
      "grad_norm": 0.02085847407579422,
      "learning_rate": 1.8280746666666668e-05,
      "loss": 0.02,
      "step": 8060
    },
    {
      "epoch": 0.25824,
      "grad_norm": 0.013037963770329952,
      "learning_rate": 1.8278613333333333e-05,
      "loss": 0.0009,
      "step": 8070
    },
    {
      "epoch": 0.25856,
      "grad_norm": 0.017520740628242493,
      "learning_rate": 1.8276480000000002e-05,
      "loss": 0.0008,
      "step": 8080
    },
    {
      "epoch": 0.25888,
      "grad_norm": 0.021610897034406662,
      "learning_rate": 1.8274346666666668e-05,
      "loss": 0.0164,
      "step": 8090
    },
    {
      "epoch": 0.2592,
      "grad_norm": 0.015508253127336502,
      "learning_rate": 1.8272213333333336e-05,
      "loss": 0.0013,
      "step": 8100
    },
    {
      "epoch": 0.25952,
      "grad_norm": 0.06334029883146286,
      "learning_rate": 1.8270080000000002e-05,
      "loss": 0.0024,
      "step": 8110
    },
    {
      "epoch": 0.25984,
      "grad_norm": 0.018496479839086533,
      "learning_rate": 1.8267946666666667e-05,
      "loss": 0.0016,
      "step": 8120
    },
    {
      "epoch": 0.26016,
      "grad_norm": 0.01226548757404089,
      "learning_rate": 1.8265813333333336e-05,
      "loss": 0.0374,
      "step": 8130
    },
    {
      "epoch": 0.26048,
      "grad_norm": 0.017135273665189743,
      "learning_rate": 1.826368e-05,
      "loss": 0.001,
      "step": 8140
    },
    {
      "epoch": 0.2608,
      "grad_norm": 0.015599432401359081,
      "learning_rate": 1.8261546666666667e-05,
      "loss": 0.001,
      "step": 8150
    },
    {
      "epoch": 0.26112,
      "grad_norm": 0.01026055309921503,
      "learning_rate": 1.8259413333333335e-05,
      "loss": 0.0009,
      "step": 8160
    },
    {
      "epoch": 0.26144,
      "grad_norm": 0.022116558626294136,
      "learning_rate": 1.825728e-05,
      "loss": 0.0009,
      "step": 8170
    },
    {
      "epoch": 0.26176,
      "grad_norm": 0.011732812039554119,
      "learning_rate": 1.8255146666666666e-05,
      "loss": 0.0009,
      "step": 8180
    },
    {
      "epoch": 0.26208,
      "grad_norm": 0.011883600614964962,
      "learning_rate": 1.8253013333333335e-05,
      "loss": 0.0202,
      "step": 8190
    },
    {
      "epoch": 0.2624,
      "grad_norm": 0.0140531649813056,
      "learning_rate": 1.825088e-05,
      "loss": 0.0362,
      "step": 8200
    },
    {
      "epoch": 0.26272,
      "grad_norm": 0.016312330961227417,
      "learning_rate": 1.824874666666667e-05,
      "loss": 0.0008,
      "step": 8210
    },
    {
      "epoch": 0.26304,
      "grad_norm": 0.013644118793308735,
      "learning_rate": 1.8246613333333334e-05,
      "loss": 0.0011,
      "step": 8220
    },
    {
      "epoch": 0.26336,
      "grad_norm": 0.010496675036847591,
      "learning_rate": 1.8244480000000003e-05,
      "loss": 0.0461,
      "step": 8230
    },
    {
      "epoch": 0.26368,
      "grad_norm": 0.012479076161980629,
      "learning_rate": 1.824234666666667e-05,
      "loss": 0.0009,
      "step": 8240
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.022016361355781555,
      "learning_rate": 1.8240213333333334e-05,
      "loss": 0.0011,
      "step": 8250
    },
    {
      "epoch": 0.26432,
      "grad_norm": 0.017272626981139183,
      "learning_rate": 1.8238080000000003e-05,
      "loss": 0.0007,
      "step": 8260
    },
    {
      "epoch": 0.26464,
      "grad_norm": 0.012399519793689251,
      "learning_rate": 1.8235946666666668e-05,
      "loss": 0.0375,
      "step": 8270
    },
    {
      "epoch": 0.26496,
      "grad_norm": 0.3189760744571686,
      "learning_rate": 1.8233813333333334e-05,
      "loss": 0.0454,
      "step": 8280
    },
    {
      "epoch": 0.26528,
      "grad_norm": 0.01061607152223587,
      "learning_rate": 1.823168e-05,
      "loss": 0.0009,
      "step": 8290
    },
    {
      "epoch": 0.2656,
      "grad_norm": 0.01298239640891552,
      "learning_rate": 1.8229546666666668e-05,
      "loss": 0.0011,
      "step": 8300
    },
    {
      "epoch": 0.26592,
      "grad_norm": 0.01992214098572731,
      "learning_rate": 1.8227413333333336e-05,
      "loss": 0.0045,
      "step": 8310
    },
    {
      "epoch": 0.26624,
      "grad_norm": 0.014972729608416557,
      "learning_rate": 1.8225280000000002e-05,
      "loss": 0.001,
      "step": 8320
    },
    {
      "epoch": 0.26656,
      "grad_norm": 0.015244918875396252,
      "learning_rate": 1.822314666666667e-05,
      "loss": 0.0274,
      "step": 8330
    },
    {
      "epoch": 0.26688,
      "grad_norm": 0.012296877801418304,
      "learning_rate": 1.8221013333333336e-05,
      "loss": 0.0007,
      "step": 8340
    },
    {
      "epoch": 0.2672,
      "grad_norm": 0.01213189959526062,
      "learning_rate": 1.821888e-05,
      "loss": 0.0011,
      "step": 8350
    },
    {
      "epoch": 0.26752,
      "grad_norm": 0.013435259461402893,
      "learning_rate": 1.821674666666667e-05,
      "loss": 0.0008,
      "step": 8360
    },
    {
      "epoch": 0.26784,
      "grad_norm": 0.018481088802218437,
      "learning_rate": 1.8214613333333335e-05,
      "loss": 0.0008,
      "step": 8370
    },
    {
      "epoch": 0.26816,
      "grad_norm": 0.019470004364848137,
      "learning_rate": 1.821248e-05,
      "loss": 0.0344,
      "step": 8380
    },
    {
      "epoch": 0.26848,
      "grad_norm": 0.05148095265030861,
      "learning_rate": 1.8210346666666666e-05,
      "loss": 0.0009,
      "step": 8390
    },
    {
      "epoch": 0.2688,
      "grad_norm": 0.009242893196642399,
      "learning_rate": 1.8208213333333335e-05,
      "loss": 0.001,
      "step": 8400
    },
    {
      "epoch": 0.26912,
      "grad_norm": 0.018918626010417938,
      "learning_rate": 1.820608e-05,
      "loss": 0.0009,
      "step": 8410
    },
    {
      "epoch": 0.26944,
      "grad_norm": 0.011537933722138405,
      "learning_rate": 1.820394666666667e-05,
      "loss": 0.0008,
      "step": 8420
    },
    {
      "epoch": 0.26976,
      "grad_norm": 0.014798865653574467,
      "learning_rate": 1.8201813333333334e-05,
      "loss": 0.0009,
      "step": 8430
    },
    {
      "epoch": 0.27008,
      "grad_norm": 0.0262212585657835,
      "learning_rate": 1.8199680000000003e-05,
      "loss": 0.001,
      "step": 8440
    },
    {
      "epoch": 0.2704,
      "grad_norm": 0.010057034902274609,
      "learning_rate": 1.819754666666667e-05,
      "loss": 0.0381,
      "step": 8450
    },
    {
      "epoch": 0.27072,
      "grad_norm": 0.015742700546979904,
      "learning_rate": 1.8195413333333334e-05,
      "loss": 0.0007,
      "step": 8460
    },
    {
      "epoch": 0.27104,
      "grad_norm": 0.015678303316235542,
      "learning_rate": 1.8193280000000003e-05,
      "loss": 0.001,
      "step": 8470
    },
    {
      "epoch": 0.27136,
      "grad_norm": 0.012296962551772594,
      "learning_rate": 1.8191146666666668e-05,
      "loss": 0.0018,
      "step": 8480
    },
    {
      "epoch": 0.27168,
      "grad_norm": 0.015253410674631596,
      "learning_rate": 1.8189013333333334e-05,
      "loss": 0.0034,
      "step": 8490
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.011324802413582802,
      "learning_rate": 1.8186880000000002e-05,
      "loss": 0.0019,
      "step": 8500
    },
    {
      "epoch": 0.27232,
      "grad_norm": 0.02228526957333088,
      "learning_rate": 1.8184746666666668e-05,
      "loss": 0.0008,
      "step": 8510
    },
    {
      "epoch": 0.27264,
      "grad_norm": 0.010559534654021263,
      "learning_rate": 1.8182613333333333e-05,
      "loss": 0.0006,
      "step": 8520
    },
    {
      "epoch": 0.27296,
      "grad_norm": 0.01508819218724966,
      "learning_rate": 1.8180480000000002e-05,
      "loss": 0.0368,
      "step": 8530
    },
    {
      "epoch": 0.27328,
      "grad_norm": 0.5454279184341431,
      "learning_rate": 1.8178346666666667e-05,
      "loss": 0.0009,
      "step": 8540
    },
    {
      "epoch": 0.2736,
      "grad_norm": 0.008257110603153706,
      "learning_rate": 1.8176213333333336e-05,
      "loss": 0.0007,
      "step": 8550
    },
    {
      "epoch": 0.27392,
      "grad_norm": 0.012576010078191757,
      "learning_rate": 1.817408e-05,
      "loss": 0.0046,
      "step": 8560
    },
    {
      "epoch": 0.27424,
      "grad_norm": 0.01253475621342659,
      "learning_rate": 1.817194666666667e-05,
      "loss": 0.0006,
      "step": 8570
    },
    {
      "epoch": 0.27456,
      "grad_norm": 0.009083990938961506,
      "learning_rate": 1.8169813333333335e-05,
      "loss": 0.0006,
      "step": 8580
    },
    {
      "epoch": 0.27488,
      "grad_norm": 0.012244456447660923,
      "learning_rate": 1.816768e-05,
      "loss": 0.0441,
      "step": 8590
    },
    {
      "epoch": 0.2752,
      "grad_norm": 0.016239294782280922,
      "learning_rate": 1.816554666666667e-05,
      "loss": 0.0455,
      "step": 8600
    },
    {
      "epoch": 0.27552,
      "grad_norm": 0.01076887920498848,
      "learning_rate": 1.8163413333333335e-05,
      "loss": 0.0008,
      "step": 8610
    },
    {
      "epoch": 0.27584,
      "grad_norm": 0.009681246243417263,
      "learning_rate": 1.816128e-05,
      "loss": 0.0008,
      "step": 8620
    },
    {
      "epoch": 0.27616,
      "grad_norm": 0.014525544829666615,
      "learning_rate": 1.8159146666666666e-05,
      "loss": 0.0008,
      "step": 8630
    },
    {
      "epoch": 0.27648,
      "grad_norm": 0.008180443197488785,
      "learning_rate": 1.8157013333333335e-05,
      "loss": 0.0006,
      "step": 8640
    },
    {
      "epoch": 0.2768,
      "grad_norm": 0.01227589137852192,
      "learning_rate": 1.815488e-05,
      "loss": 0.001,
      "step": 8650
    },
    {
      "epoch": 0.27712,
      "grad_norm": 0.027664244174957275,
      "learning_rate": 1.815274666666667e-05,
      "loss": 0.0009,
      "step": 8660
    },
    {
      "epoch": 0.27744,
      "grad_norm": 0.00966903381049633,
      "learning_rate": 1.8150613333333334e-05,
      "loss": 0.0006,
      "step": 8670
    },
    {
      "epoch": 0.27776,
      "grad_norm": 0.01146615482866764,
      "learning_rate": 1.8148480000000003e-05,
      "loss": 0.0263,
      "step": 8680
    },
    {
      "epoch": 0.27808,
      "grad_norm": 0.012406609021127224,
      "learning_rate": 1.8146346666666668e-05,
      "loss": 0.001,
      "step": 8690
    },
    {
      "epoch": 0.2784,
      "grad_norm": 0.007298704236745834,
      "learning_rate": 1.8144213333333337e-05,
      "loss": 0.0008,
      "step": 8700
    },
    {
      "epoch": 0.27872,
      "grad_norm": 0.11569627374410629,
      "learning_rate": 1.8142080000000002e-05,
      "loss": 0.006,
      "step": 8710
    },
    {
      "epoch": 0.27904,
      "grad_norm": 0.010786066763103008,
      "learning_rate": 1.8139946666666668e-05,
      "loss": 0.0011,
      "step": 8720
    },
    {
      "epoch": 0.27936,
      "grad_norm": 0.010169816203415394,
      "learning_rate": 1.8137813333333333e-05,
      "loss": 0.0005,
      "step": 8730
    },
    {
      "epoch": 0.27968,
      "grad_norm": 0.022527482360601425,
      "learning_rate": 1.8135680000000002e-05,
      "loss": 0.0008,
      "step": 8740
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.011328103952109814,
      "learning_rate": 1.8133546666666667e-05,
      "loss": 0.0385,
      "step": 8750
    },
    {
      "epoch": 0.28032,
      "grad_norm": 0.010186822153627872,
      "learning_rate": 1.8131413333333333e-05,
      "loss": 0.0006,
      "step": 8760
    },
    {
      "epoch": 0.28064,
      "grad_norm": 0.00952532235532999,
      "learning_rate": 1.812928e-05,
      "loss": 0.0126,
      "step": 8770
    },
    {
      "epoch": 0.28096,
      "grad_norm": 0.01761050708591938,
      "learning_rate": 1.812714666666667e-05,
      "loss": 0.0008,
      "step": 8780
    },
    {
      "epoch": 0.28128,
      "grad_norm": 0.012900258414447308,
      "learning_rate": 1.8125013333333336e-05,
      "loss": 0.0207,
      "step": 8790
    },
    {
      "epoch": 0.2816,
      "grad_norm": 0.01302098948508501,
      "learning_rate": 1.812288e-05,
      "loss": 0.0044,
      "step": 8800
    },
    {
      "epoch": 0.28192,
      "grad_norm": 0.008363012224435806,
      "learning_rate": 1.812074666666667e-05,
      "loss": 0.0545,
      "step": 8810
    },
    {
      "epoch": 0.28224,
      "grad_norm": 0.00755480257794261,
      "learning_rate": 1.8118613333333335e-05,
      "loss": 0.0008,
      "step": 8820
    },
    {
      "epoch": 0.28256,
      "grad_norm": 0.011252795346081257,
      "learning_rate": 1.811648e-05,
      "loss": 0.0007,
      "step": 8830
    },
    {
      "epoch": 0.28288,
      "grad_norm": 0.01563456282019615,
      "learning_rate": 1.811434666666667e-05,
      "loss": 0.0019,
      "step": 8840
    },
    {
      "epoch": 0.2832,
      "grad_norm": 0.009202785789966583,
      "learning_rate": 1.8112213333333335e-05,
      "loss": 0.002,
      "step": 8850
    },
    {
      "epoch": 0.28352,
      "grad_norm": 0.013272244483232498,
      "learning_rate": 1.811008e-05,
      "loss": 0.0006,
      "step": 8860
    },
    {
      "epoch": 0.28384,
      "grad_norm": 0.010647696442902088,
      "learning_rate": 1.810794666666667e-05,
      "loss": 0.009,
      "step": 8870
    },
    {
      "epoch": 0.28416,
      "grad_norm": 0.010721257887780666,
      "learning_rate": 1.8105813333333334e-05,
      "loss": 0.0418,
      "step": 8880
    },
    {
      "epoch": 0.28448,
      "grad_norm": 1.5472720861434937,
      "learning_rate": 1.8103680000000003e-05,
      "loss": 0.0029,
      "step": 8890
    },
    {
      "epoch": 0.2848,
      "grad_norm": 0.008179563097655773,
      "learning_rate": 1.8101546666666668e-05,
      "loss": 0.0006,
      "step": 8900
    },
    {
      "epoch": 0.28512,
      "grad_norm": 0.008372670039534569,
      "learning_rate": 1.8099413333333337e-05,
      "loss": 0.0011,
      "step": 8910
    },
    {
      "epoch": 0.28544,
      "grad_norm": 0.006771743763238192,
      "learning_rate": 1.8097280000000002e-05,
      "loss": 0.0005,
      "step": 8920
    },
    {
      "epoch": 0.28576,
      "grad_norm": 0.009221990592777729,
      "learning_rate": 1.8095146666666668e-05,
      "loss": 0.0004,
      "step": 8930
    },
    {
      "epoch": 0.28608,
      "grad_norm": 0.006990415975451469,
      "learning_rate": 1.8093013333333336e-05,
      "loss": 0.0005,
      "step": 8940
    },
    {
      "epoch": 0.2864,
      "grad_norm": 0.05360626056790352,
      "learning_rate": 1.8090880000000002e-05,
      "loss": 0.0005,
      "step": 8950
    },
    {
      "epoch": 0.28672,
      "grad_norm": 0.005384601652622223,
      "learning_rate": 1.8088746666666667e-05,
      "loss": 0.0004,
      "step": 8960
    },
    {
      "epoch": 0.28704,
      "grad_norm": 0.023290513083338737,
      "learning_rate": 1.8086613333333333e-05,
      "loss": 0.0005,
      "step": 8970
    },
    {
      "epoch": 0.28736,
      "grad_norm": 0.0070243836380541325,
      "learning_rate": 1.808448e-05,
      "loss": 0.0005,
      "step": 8980
    },
    {
      "epoch": 0.28768,
      "grad_norm": 0.005761704873293638,
      "learning_rate": 1.8082346666666667e-05,
      "loss": 0.0533,
      "step": 8990
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.016574891284108162,
      "learning_rate": 1.8080213333333336e-05,
      "loss": 0.0004,
      "step": 9000
    },
    {
      "epoch": 0.28832,
      "grad_norm": 0.006181399337947369,
      "learning_rate": 1.807808e-05,
      "loss": 0.0007,
      "step": 9010
    },
    {
      "epoch": 0.28864,
      "grad_norm": 0.005782547406852245,
      "learning_rate": 1.807594666666667e-05,
      "loss": 0.0005,
      "step": 9020
    },
    {
      "epoch": 0.28896,
      "grad_norm": 0.005326234269887209,
      "learning_rate": 1.8073813333333335e-05,
      "loss": 0.0257,
      "step": 9030
    },
    {
      "epoch": 0.28928,
      "grad_norm": 0.01973559334874153,
      "learning_rate": 1.8071680000000004e-05,
      "loss": 0.0787,
      "step": 9040
    },
    {
      "epoch": 0.2896,
      "grad_norm": 0.006603119894862175,
      "learning_rate": 1.806954666666667e-05,
      "loss": 0.0019,
      "step": 9050
    },
    {
      "epoch": 0.28992,
      "grad_norm": 0.007660111878067255,
      "learning_rate": 1.8067413333333335e-05,
      "loss": 0.0005,
      "step": 9060
    },
    {
      "epoch": 0.29024,
      "grad_norm": 0.021467043086886406,
      "learning_rate": 1.806528e-05,
      "loss": 0.031,
      "step": 9070
    },
    {
      "epoch": 0.29056,
      "grad_norm": 0.007504719775170088,
      "learning_rate": 1.806314666666667e-05,
      "loss": 0.0389,
      "step": 9080
    },
    {
      "epoch": 0.29088,
      "grad_norm": 0.009476685896515846,
      "learning_rate": 1.8061013333333334e-05,
      "loss": 0.0007,
      "step": 9090
    },
    {
      "epoch": 0.2912,
      "grad_norm": 0.01812693104147911,
      "learning_rate": 1.805888e-05,
      "loss": 0.0006,
      "step": 9100
    },
    {
      "epoch": 0.29152,
      "grad_norm": 8.879613876342773,
      "learning_rate": 1.8056746666666668e-05,
      "loss": 0.0367,
      "step": 9110
    },
    {
      "epoch": 0.29184,
      "grad_norm": 0.00880496483296156,
      "learning_rate": 1.8054613333333334e-05,
      "loss": 0.0012,
      "step": 9120
    },
    {
      "epoch": 0.29216,
      "grad_norm": 0.010009925812482834,
      "learning_rate": 1.8052480000000002e-05,
      "loss": 0.052,
      "step": 9130
    },
    {
      "epoch": 0.29248,
      "grad_norm": 5.910918712615967,
      "learning_rate": 1.8050346666666668e-05,
      "loss": 0.055,
      "step": 9140
    },
    {
      "epoch": 0.2928,
      "grad_norm": 0.048922907561063766,
      "learning_rate": 1.8048213333333337e-05,
      "loss": 0.045,
      "step": 9150
    },
    {
      "epoch": 0.29312,
      "grad_norm": 0.015064203180372715,
      "learning_rate": 1.8046080000000002e-05,
      "loss": 0.0042,
      "step": 9160
    },
    {
      "epoch": 0.29344,
      "grad_norm": 0.010060291737318039,
      "learning_rate": 1.8043946666666667e-05,
      "loss": 0.0008,
      "step": 9170
    },
    {
      "epoch": 0.29376,
      "grad_norm": 0.011587255634367466,
      "learning_rate": 1.8041813333333336e-05,
      "loss": 0.0379,
      "step": 9180
    },
    {
      "epoch": 0.29408,
      "grad_norm": 4.250293731689453,
      "learning_rate": 1.803968e-05,
      "loss": 0.0249,
      "step": 9190
    },
    {
      "epoch": 0.2944,
      "grad_norm": 0.20601093769073486,
      "learning_rate": 1.8037546666666667e-05,
      "loss": 0.001,
      "step": 9200
    },
    {
      "epoch": 0.29472,
      "grad_norm": 0.01288458053022623,
      "learning_rate": 1.8035413333333336e-05,
      "loss": 0.005,
      "step": 9210
    },
    {
      "epoch": 0.29504,
      "grad_norm": 0.05976207181811333,
      "learning_rate": 1.803328e-05,
      "loss": 0.0413,
      "step": 9220
    },
    {
      "epoch": 0.29536,
      "grad_norm": 0.014874270185828209,
      "learning_rate": 1.8031146666666666e-05,
      "loss": 0.0007,
      "step": 9230
    },
    {
      "epoch": 0.29568,
      "grad_norm": 0.0500958189368248,
      "learning_rate": 1.8029013333333335e-05,
      "loss": 0.0009,
      "step": 9240
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.017396777868270874,
      "learning_rate": 1.8026880000000004e-05,
      "loss": 0.0054,
      "step": 9250
    },
    {
      "epoch": 0.29632,
      "grad_norm": 0.018863698467612267,
      "learning_rate": 1.802474666666667e-05,
      "loss": 0.0018,
      "step": 9260
    },
    {
      "epoch": 0.29664,
      "grad_norm": 0.023914914578199387,
      "learning_rate": 1.8022613333333335e-05,
      "loss": 0.0006,
      "step": 9270
    },
    {
      "epoch": 0.29696,
      "grad_norm": 0.0191776342689991,
      "learning_rate": 1.8020480000000003e-05,
      "loss": 0.0006,
      "step": 9280
    },
    {
      "epoch": 0.29728,
      "grad_norm": 0.01488747913390398,
      "learning_rate": 1.801834666666667e-05,
      "loss": 0.0009,
      "step": 9290
    },
    {
      "epoch": 0.2976,
      "grad_norm": 0.01456903014332056,
      "learning_rate": 1.8016213333333334e-05,
      "loss": 0.0007,
      "step": 9300
    },
    {
      "epoch": 0.29792,
      "grad_norm": 0.010529788210988045,
      "learning_rate": 1.801408e-05,
      "loss": 0.0009,
      "step": 9310
    },
    {
      "epoch": 0.29824,
      "grad_norm": 0.009910511784255505,
      "learning_rate": 1.8011946666666668e-05,
      "loss": 0.0005,
      "step": 9320
    },
    {
      "epoch": 0.29856,
      "grad_norm": 0.013269186019897461,
      "learning_rate": 1.8009813333333334e-05,
      "loss": 0.0777,
      "step": 9330
    },
    {
      "epoch": 0.29888,
      "grad_norm": 0.02306765876710415,
      "learning_rate": 1.8007680000000002e-05,
      "loss": 0.001,
      "step": 9340
    },
    {
      "epoch": 0.2992,
      "grad_norm": 0.006847233511507511,
      "learning_rate": 1.8005546666666668e-05,
      "loss": 0.0007,
      "step": 9350
    },
    {
      "epoch": 0.29952,
      "grad_norm": 0.017428332939743996,
      "learning_rate": 1.8003413333333337e-05,
      "loss": 0.0008,
      "step": 9360
    },
    {
      "epoch": 0.29984,
      "grad_norm": 0.011709990911185741,
      "learning_rate": 1.8001280000000002e-05,
      "loss": 0.0363,
      "step": 9370
    },
    {
      "epoch": 0.30016,
      "grad_norm": 0.008783354423940182,
      "learning_rate": 1.799914666666667e-05,
      "loss": 0.0021,
      "step": 9380
    },
    {
      "epoch": 0.30048,
      "grad_norm": 0.01023195218294859,
      "learning_rate": 1.7997013333333336e-05,
      "loss": 0.0008,
      "step": 9390
    },
    {
      "epoch": 0.3008,
      "grad_norm": 0.009786791168153286,
      "learning_rate": 1.799488e-05,
      "loss": 0.0006,
      "step": 9400
    },
    {
      "epoch": 0.30112,
      "grad_norm": 0.005632072687149048,
      "learning_rate": 1.7992746666666667e-05,
      "loss": 0.0147,
      "step": 9410
    },
    {
      "epoch": 0.30144,
      "grad_norm": 0.009031067602336407,
      "learning_rate": 1.7990613333333336e-05,
      "loss": 0.0005,
      "step": 9420
    },
    {
      "epoch": 0.30176,
      "grad_norm": 0.014463589526712894,
      "learning_rate": 1.798848e-05,
      "loss": 0.0597,
      "step": 9430
    },
    {
      "epoch": 0.30208,
      "grad_norm": 0.018680285662412643,
      "learning_rate": 1.7986346666666666e-05,
      "loss": 0.0006,
      "step": 9440
    },
    {
      "epoch": 0.3024,
      "grad_norm": 0.011661360040307045,
      "learning_rate": 1.7984213333333335e-05,
      "loss": 0.0007,
      "step": 9450
    },
    {
      "epoch": 0.30272,
      "grad_norm": 0.008800679817795753,
      "learning_rate": 1.798208e-05,
      "loss": 0.0008,
      "step": 9460
    },
    {
      "epoch": 0.30304,
      "grad_norm": 0.007793119177222252,
      "learning_rate": 1.797994666666667e-05,
      "loss": 0.0101,
      "step": 9470
    },
    {
      "epoch": 0.30336,
      "grad_norm": 0.013172116130590439,
      "learning_rate": 1.7977813333333335e-05,
      "loss": 0.0133,
      "step": 9480
    },
    {
      "epoch": 0.30368,
      "grad_norm": 0.03179018199443817,
      "learning_rate": 1.7975680000000003e-05,
      "loss": 0.0011,
      "step": 9490
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.015742182731628418,
      "learning_rate": 1.797354666666667e-05,
      "loss": 0.0006,
      "step": 9500
    },
    {
      "epoch": 0.30432,
      "grad_norm": 0.011642538011074066,
      "learning_rate": 1.7971413333333334e-05,
      "loss": 0.0367,
      "step": 9510
    },
    {
      "epoch": 0.30464,
      "grad_norm": 0.007691424805670977,
      "learning_rate": 1.7969280000000003e-05,
      "loss": 0.0015,
      "step": 9520
    },
    {
      "epoch": 0.30496,
      "grad_norm": 0.01479515340179205,
      "learning_rate": 1.7967146666666668e-05,
      "loss": 0.001,
      "step": 9530
    },
    {
      "epoch": 0.30528,
      "grad_norm": 0.0059833708219230175,
      "learning_rate": 1.7965013333333334e-05,
      "loss": 0.0104,
      "step": 9540
    },
    {
      "epoch": 0.3056,
      "grad_norm": 0.008918813429772854,
      "learning_rate": 1.7962880000000002e-05,
      "loss": 0.0007,
      "step": 9550
    },
    {
      "epoch": 0.30592,
      "grad_norm": 0.04489763453602791,
      "learning_rate": 1.7960746666666668e-05,
      "loss": 0.0007,
      "step": 9560
    },
    {
      "epoch": 0.30624,
      "grad_norm": 0.013471495360136032,
      "learning_rate": 1.7958613333333333e-05,
      "loss": 0.0006,
      "step": 9570
    },
    {
      "epoch": 0.30656,
      "grad_norm": 0.012504005804657936,
      "learning_rate": 1.7956480000000002e-05,
      "loss": 0.0006,
      "step": 9580
    },
    {
      "epoch": 0.30688,
      "grad_norm": 0.006920603569597006,
      "learning_rate": 1.7954346666666667e-05,
      "loss": 0.004,
      "step": 9590
    },
    {
      "epoch": 0.3072,
      "grad_norm": 0.024140257388353348,
      "learning_rate": 1.7952213333333336e-05,
      "loss": 0.0009,
      "step": 9600
    },
    {
      "epoch": 0.30752,
      "grad_norm": 0.006875442806631327,
      "learning_rate": 1.795008e-05,
      "loss": 0.0116,
      "step": 9610
    },
    {
      "epoch": 0.30784,
      "grad_norm": 2.586869478225708,
      "learning_rate": 1.794794666666667e-05,
      "loss": 0.0551,
      "step": 9620
    },
    {
      "epoch": 0.30816,
      "grad_norm": 0.010179772041738033,
      "learning_rate": 1.7945813333333336e-05,
      "loss": 0.0333,
      "step": 9630
    },
    {
      "epoch": 0.30848,
      "grad_norm": 0.14723548293113708,
      "learning_rate": 1.794368e-05,
      "loss": 0.0007,
      "step": 9640
    },
    {
      "epoch": 0.3088,
      "grad_norm": 0.011190100573003292,
      "learning_rate": 1.7941546666666666e-05,
      "loss": 0.0005,
      "step": 9650
    },
    {
      "epoch": 0.30912,
      "grad_norm": 0.011749454773962498,
      "learning_rate": 1.7939413333333335e-05,
      "loss": 0.0006,
      "step": 9660
    },
    {
      "epoch": 0.30944,
      "grad_norm": 0.0065137180499732494,
      "learning_rate": 1.793728e-05,
      "loss": 0.0078,
      "step": 9670
    },
    {
      "epoch": 0.30976,
      "grad_norm": 0.011584085412323475,
      "learning_rate": 1.7935146666666666e-05,
      "loss": 0.0007,
      "step": 9680
    },
    {
      "epoch": 0.31008,
      "grad_norm": 0.006478185299783945,
      "learning_rate": 1.7933013333333335e-05,
      "loss": 0.0008,
      "step": 9690
    },
    {
      "epoch": 0.3104,
      "grad_norm": 0.005813052412122488,
      "learning_rate": 1.793088e-05,
      "loss": 0.0451,
      "step": 9700
    },
    {
      "epoch": 0.31072,
      "grad_norm": 0.01395932026207447,
      "learning_rate": 1.792874666666667e-05,
      "loss": 0.0009,
      "step": 9710
    },
    {
      "epoch": 0.31104,
      "grad_norm": 0.010224108584225178,
      "learning_rate": 1.7926613333333338e-05,
      "loss": 0.0005,
      "step": 9720
    },
    {
      "epoch": 0.31136,
      "grad_norm": 0.009826562367379665,
      "learning_rate": 1.7924480000000003e-05,
      "loss": 0.0012,
      "step": 9730
    },
    {
      "epoch": 0.31168,
      "grad_norm": 0.02015615627169609,
      "learning_rate": 1.7922346666666668e-05,
      "loss": 0.0339,
      "step": 9740
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.029129551723599434,
      "learning_rate": 1.7920213333333334e-05,
      "loss": 0.0367,
      "step": 9750
    },
    {
      "epoch": 0.31232,
      "grad_norm": 0.04070575162768364,
      "learning_rate": 1.7918080000000002e-05,
      "loss": 0.0008,
      "step": 9760
    },
    {
      "epoch": 0.31264,
      "grad_norm": 0.0119944978505373,
      "learning_rate": 1.7915946666666668e-05,
      "loss": 0.0687,
      "step": 9770
    },
    {
      "epoch": 0.31296,
      "grad_norm": 0.013286378234624863,
      "learning_rate": 1.7913813333333333e-05,
      "loss": 0.0009,
      "step": 9780
    },
    {
      "epoch": 0.31328,
      "grad_norm": 0.011638452298939228,
      "learning_rate": 1.7911680000000002e-05,
      "loss": 0.0011,
      "step": 9790
    },
    {
      "epoch": 0.3136,
      "grad_norm": 0.028750529512763023,
      "learning_rate": 1.7909546666666667e-05,
      "loss": 0.0008,
      "step": 9800
    },
    {
      "epoch": 0.31392,
      "grad_norm": 0.01498456858098507,
      "learning_rate": 1.7907413333333336e-05,
      "loss": 0.0096,
      "step": 9810
    },
    {
      "epoch": 0.31424,
      "grad_norm": 0.007244874257594347,
      "learning_rate": 1.790528e-05,
      "loss": 0.0453,
      "step": 9820
    },
    {
      "epoch": 0.31456,
      "grad_norm": 1.6098273992538452,
      "learning_rate": 1.790314666666667e-05,
      "loss": 0.0137,
      "step": 9830
    },
    {
      "epoch": 0.31488,
      "grad_norm": 0.013499421067535877,
      "learning_rate": 1.7901013333333336e-05,
      "loss": 0.0008,
      "step": 9840
    },
    {
      "epoch": 0.3152,
      "grad_norm": 0.00921422615647316,
      "learning_rate": 1.789888e-05,
      "loss": 0.0116,
      "step": 9850
    },
    {
      "epoch": 0.31552,
      "grad_norm": 0.015651347115635872,
      "learning_rate": 1.789674666666667e-05,
      "loss": 0.0067,
      "step": 9860
    },
    {
      "epoch": 0.31584,
      "grad_norm": 2.196742296218872,
      "learning_rate": 1.7894613333333335e-05,
      "loss": 0.0431,
      "step": 9870
    },
    {
      "epoch": 0.31616,
      "grad_norm": 0.017191315069794655,
      "learning_rate": 1.789248e-05,
      "loss": 0.0008,
      "step": 9880
    },
    {
      "epoch": 0.31648,
      "grad_norm": 0.03477264195680618,
      "learning_rate": 1.789034666666667e-05,
      "loss": 0.0008,
      "step": 9890
    },
    {
      "epoch": 0.3168,
      "grad_norm": 0.00988746527582407,
      "learning_rate": 1.7888213333333335e-05,
      "loss": 0.002,
      "step": 9900
    },
    {
      "epoch": 0.31712,
      "grad_norm": 0.03911914303898811,
      "learning_rate": 1.788608e-05,
      "loss": 0.0014,
      "step": 9910
    },
    {
      "epoch": 0.31744,
      "grad_norm": 0.009347968734800816,
      "learning_rate": 1.788394666666667e-05,
      "loss": 0.0006,
      "step": 9920
    },
    {
      "epoch": 0.31776,
      "grad_norm": 3.311494827270508,
      "learning_rate": 1.7881813333333334e-05,
      "loss": 0.0493,
      "step": 9930
    },
    {
      "epoch": 0.31808,
      "grad_norm": 0.011528233997523785,
      "learning_rate": 1.7879680000000003e-05,
      "loss": 0.0005,
      "step": 9940
    },
    {
      "epoch": 0.3184,
      "grad_norm": 0.01074986532330513,
      "learning_rate": 1.787754666666667e-05,
      "loss": 0.0007,
      "step": 9950
    },
    {
      "epoch": 0.31872,
      "grad_norm": 0.010189306922256947,
      "learning_rate": 1.7875413333333337e-05,
      "loss": 0.0007,
      "step": 9960
    },
    {
      "epoch": 0.31904,
      "grad_norm": 0.01057327538728714,
      "learning_rate": 1.7873280000000002e-05,
      "loss": 0.0248,
      "step": 9970
    },
    {
      "epoch": 0.31936,
      "grad_norm": 0.010033686645328999,
      "learning_rate": 1.7871146666666668e-05,
      "loss": 0.0357,
      "step": 9980
    },
    {
      "epoch": 0.31968,
      "grad_norm": 0.011175466701388359,
      "learning_rate": 1.7869013333333333e-05,
      "loss": 0.0008,
      "step": 9990
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.019763849675655365,
      "learning_rate": 1.7866880000000002e-05,
      "loss": 0.0306,
      "step": 10000
    },
    {
      "epoch": 0.32032,
      "grad_norm": 0.009119502268731594,
      "learning_rate": 1.7864746666666667e-05,
      "loss": 0.0006,
      "step": 10010
    },
    {
      "epoch": 0.32064,
      "grad_norm": 0.07093638181686401,
      "learning_rate": 1.7862613333333333e-05,
      "loss": 0.0007,
      "step": 10020
    },
    {
      "epoch": 0.32096,
      "grad_norm": 0.014538097195327282,
      "learning_rate": 1.786048e-05,
      "loss": 0.001,
      "step": 10030
    },
    {
      "epoch": 0.32128,
      "grad_norm": 0.009405138902366161,
      "learning_rate": 1.7858346666666667e-05,
      "loss": 0.0005,
      "step": 10040
    },
    {
      "epoch": 0.3216,
      "grad_norm": 3.6171586513519287,
      "learning_rate": 1.7856213333333336e-05,
      "loss": 0.0104,
      "step": 10050
    },
    {
      "epoch": 0.32192,
      "grad_norm": 0.015168445184826851,
      "learning_rate": 1.785408e-05,
      "loss": 0.0017,
      "step": 10060
    },
    {
      "epoch": 0.32224,
      "grad_norm": 0.00813467800617218,
      "learning_rate": 1.785194666666667e-05,
      "loss": 0.0008,
      "step": 10070
    },
    {
      "epoch": 0.32256,
      "grad_norm": 0.009513678960502148,
      "learning_rate": 1.7849813333333335e-05,
      "loss": 0.0015,
      "step": 10080
    },
    {
      "epoch": 0.32288,
      "grad_norm": 0.008744065649807453,
      "learning_rate": 1.784768e-05,
      "loss": 0.0412,
      "step": 10090
    },
    {
      "epoch": 0.3232,
      "grad_norm": 0.02194775640964508,
      "learning_rate": 1.784554666666667e-05,
      "loss": 0.0234,
      "step": 10100
    },
    {
      "epoch": 0.32352,
      "grad_norm": 0.017422253265976906,
      "learning_rate": 1.7843413333333335e-05,
      "loss": 0.0005,
      "step": 10110
    },
    {
      "epoch": 0.32384,
      "grad_norm": 0.05214283615350723,
      "learning_rate": 1.784128e-05,
      "loss": 0.0014,
      "step": 10120
    },
    {
      "epoch": 0.32416,
      "grad_norm": 0.010259195230901241,
      "learning_rate": 1.783914666666667e-05,
      "loss": 0.0074,
      "step": 10130
    },
    {
      "epoch": 0.32448,
      "grad_norm": 0.008810552768409252,
      "learning_rate": 1.7837013333333334e-05,
      "loss": 0.0006,
      "step": 10140
    },
    {
      "epoch": 0.3248,
      "grad_norm": 0.01977057009935379,
      "learning_rate": 1.783488e-05,
      "loss": 0.001,
      "step": 10150
    },
    {
      "epoch": 0.32512,
      "grad_norm": 0.009232227690517902,
      "learning_rate": 1.783274666666667e-05,
      "loss": 0.0376,
      "step": 10160
    },
    {
      "epoch": 0.32544,
      "grad_norm": 0.01550916489213705,
      "learning_rate": 1.7830613333333334e-05,
      "loss": 0.0006,
      "step": 10170
    },
    {
      "epoch": 0.32576,
      "grad_norm": 0.015560993924736977,
      "learning_rate": 1.7828480000000002e-05,
      "loss": 0.0006,
      "step": 10180
    },
    {
      "epoch": 0.32608,
      "grad_norm": 0.02389448508620262,
      "learning_rate": 1.7826346666666668e-05,
      "loss": 0.0196,
      "step": 10190
    },
    {
      "epoch": 0.3264,
      "grad_norm": 0.009181271307170391,
      "learning_rate": 1.7824213333333337e-05,
      "loss": 0.0008,
      "step": 10200
    },
    {
      "epoch": 0.32672,
      "grad_norm": 1.5833287239074707,
      "learning_rate": 1.7822080000000002e-05,
      "loss": 0.048,
      "step": 10210
    },
    {
      "epoch": 0.32704,
      "grad_norm": 0.007141382433474064,
      "learning_rate": 1.7819946666666667e-05,
      "loss": 0.0061,
      "step": 10220
    },
    {
      "epoch": 0.32736,
      "grad_norm": 0.015512075275182724,
      "learning_rate": 1.7817813333333336e-05,
      "loss": 0.0007,
      "step": 10230
    },
    {
      "epoch": 0.32768,
      "grad_norm": 0.015314163640141487,
      "learning_rate": 1.781568e-05,
      "loss": 0.0005,
      "step": 10240
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.012465113773941994,
      "learning_rate": 1.7813546666666667e-05,
      "loss": 0.0007,
      "step": 10250
    },
    {
      "epoch": 0.32832,
      "grad_norm": 0.017504900693893433,
      "learning_rate": 1.7811413333333332e-05,
      "loss": 0.0041,
      "step": 10260
    },
    {
      "epoch": 0.32864,
      "grad_norm": 0.01389902550727129,
      "learning_rate": 1.780928e-05,
      "loss": 0.0005,
      "step": 10270
    },
    {
      "epoch": 0.32896,
      "grad_norm": 1.639737606048584,
      "learning_rate": 1.780714666666667e-05,
      "loss": 0.0647,
      "step": 10280
    },
    {
      "epoch": 0.32928,
      "grad_norm": 0.008342080749571323,
      "learning_rate": 1.7805013333333335e-05,
      "loss": 0.0189,
      "step": 10290
    },
    {
      "epoch": 0.3296,
      "grad_norm": 0.01014170702546835,
      "learning_rate": 1.7802880000000004e-05,
      "loss": 0.0008,
      "step": 10300
    },
    {
      "epoch": 0.32992,
      "grad_norm": 0.010290407575666904,
      "learning_rate": 1.780074666666667e-05,
      "loss": 0.0007,
      "step": 10310
    },
    {
      "epoch": 0.33024,
      "grad_norm": 0.009855672717094421,
      "learning_rate": 1.7798613333333335e-05,
      "loss": 0.0352,
      "step": 10320
    },
    {
      "epoch": 0.33056,
      "grad_norm": 0.006934575270861387,
      "learning_rate": 1.779648e-05,
      "loss": 0.0252,
      "step": 10330
    },
    {
      "epoch": 0.33088,
      "grad_norm": 0.011725564487278461,
      "learning_rate": 1.779434666666667e-05,
      "loss": 0.0131,
      "step": 10340
    },
    {
      "epoch": 0.3312,
      "grad_norm": 0.06306350231170654,
      "learning_rate": 1.7792213333333334e-05,
      "loss": 0.0009,
      "step": 10350
    },
    {
      "epoch": 0.33152,
      "grad_norm": 0.008170269429683685,
      "learning_rate": 1.779008e-05,
      "loss": 0.0007,
      "step": 10360
    },
    {
      "epoch": 0.33184,
      "grad_norm": 0.017380153760313988,
      "learning_rate": 1.778794666666667e-05,
      "loss": 0.0241,
      "step": 10370
    },
    {
      "epoch": 0.33216,
      "grad_norm": 2.2087762355804443,
      "learning_rate": 1.7785813333333334e-05,
      "loss": 0.0027,
      "step": 10380
    },
    {
      "epoch": 0.33248,
      "grad_norm": 2.6424639225006104,
      "learning_rate": 1.7783680000000003e-05,
      "loss": 0.0087,
      "step": 10390
    },
    {
      "epoch": 0.3328,
      "grad_norm": 0.093222476541996,
      "learning_rate": 1.7781546666666668e-05,
      "loss": 0.0015,
      "step": 10400
    },
    {
      "epoch": 0.33312,
      "grad_norm": 0.045642267912626266,
      "learning_rate": 1.7779413333333337e-05,
      "loss": 0.0008,
      "step": 10410
    },
    {
      "epoch": 0.33344,
      "grad_norm": 0.007722908165305853,
      "learning_rate": 1.7777280000000002e-05,
      "loss": 0.001,
      "step": 10420
    },
    {
      "epoch": 0.33376,
      "grad_norm": 0.014591931365430355,
      "learning_rate": 1.7775146666666667e-05,
      "loss": 0.0009,
      "step": 10430
    },
    {
      "epoch": 0.33408,
      "grad_norm": 0.008734344504773617,
      "learning_rate": 1.7773013333333336e-05,
      "loss": 0.0006,
      "step": 10440
    },
    {
      "epoch": 0.3344,
      "grad_norm": 0.0126578314229846,
      "learning_rate": 1.777088e-05,
      "loss": 0.0592,
      "step": 10450
    },
    {
      "epoch": 0.33472,
      "grad_norm": 0.006779494229704142,
      "learning_rate": 1.7768746666666667e-05,
      "loss": 0.0008,
      "step": 10460
    },
    {
      "epoch": 0.33504,
      "grad_norm": 0.009004006162285805,
      "learning_rate": 1.7766613333333336e-05,
      "loss": 0.0006,
      "step": 10470
    },
    {
      "epoch": 0.33536,
      "grad_norm": 0.020327633246779442,
      "learning_rate": 1.776448e-05,
      "loss": 0.0097,
      "step": 10480
    },
    {
      "epoch": 0.33568,
      "grad_norm": 0.013353477232158184,
      "learning_rate": 1.7762346666666666e-05,
      "loss": 0.0007,
      "step": 10490
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.00868749339133501,
      "learning_rate": 1.7760213333333335e-05,
      "loss": 0.0006,
      "step": 10500
    },
    {
      "epoch": 0.33632,
      "grad_norm": 2.5695481300354004,
      "learning_rate": 1.775808e-05,
      "loss": 0.0264,
      "step": 10510
    },
    {
      "epoch": 0.33664,
      "grad_norm": 0.05643496662378311,
      "learning_rate": 1.775594666666667e-05,
      "loss": 0.0008,
      "step": 10520
    },
    {
      "epoch": 0.33696,
      "grad_norm": 0.009333359077572823,
      "learning_rate": 1.7753813333333335e-05,
      "loss": 0.0005,
      "step": 10530
    },
    {
      "epoch": 0.33728,
      "grad_norm": 0.00950753502547741,
      "learning_rate": 1.7751680000000003e-05,
      "loss": 0.0005,
      "step": 10540
    },
    {
      "epoch": 0.3376,
      "grad_norm": 0.013230777345597744,
      "learning_rate": 1.774954666666667e-05,
      "loss": 0.0475,
      "step": 10550
    },
    {
      "epoch": 0.33792,
      "grad_norm": 0.008997565135359764,
      "learning_rate": 1.7747413333333334e-05,
      "loss": 0.0007,
      "step": 10560
    },
    {
      "epoch": 0.33824,
      "grad_norm": 0.012470993213355541,
      "learning_rate": 1.7745280000000003e-05,
      "loss": 0.0304,
      "step": 10570
    },
    {
      "epoch": 0.33856,
      "grad_norm": 4.310108184814453,
      "learning_rate": 1.774314666666667e-05,
      "loss": 0.0089,
      "step": 10580
    },
    {
      "epoch": 0.33888,
      "grad_norm": 0.005190744996070862,
      "learning_rate": 1.7741013333333334e-05,
      "loss": 0.0014,
      "step": 10590
    },
    {
      "epoch": 0.3392,
      "grad_norm": 0.02755558304488659,
      "learning_rate": 1.773888e-05,
      "loss": 0.0006,
      "step": 10600
    },
    {
      "epoch": 0.33952,
      "grad_norm": 0.774299681186676,
      "learning_rate": 1.7736746666666668e-05,
      "loss": 0.0036,
      "step": 10610
    },
    {
      "epoch": 0.33984,
      "grad_norm": 0.07568878680467606,
      "learning_rate": 1.7734613333333333e-05,
      "loss": 0.0006,
      "step": 10620
    },
    {
      "epoch": 0.34016,
      "grad_norm": 0.009037436917424202,
      "learning_rate": 1.7732480000000002e-05,
      "loss": 0.0019,
      "step": 10630
    },
    {
      "epoch": 0.34048,
      "grad_norm": 0.00790478102862835,
      "learning_rate": 1.7730346666666667e-05,
      "loss": 0.0475,
      "step": 10640
    },
    {
      "epoch": 0.3408,
      "grad_norm": 3.134976863861084,
      "learning_rate": 1.7728213333333336e-05,
      "loss": 0.0098,
      "step": 10650
    },
    {
      "epoch": 0.34112,
      "grad_norm": 0.012634359300136566,
      "learning_rate": 1.772608e-05,
      "loss": 0.0142,
      "step": 10660
    },
    {
      "epoch": 0.34144,
      "grad_norm": 0.9700695872306824,
      "learning_rate": 1.7723946666666667e-05,
      "loss": 0.053,
      "step": 10670
    },
    {
      "epoch": 0.34176,
      "grad_norm": 0.01317228190600872,
      "learning_rate": 1.7721813333333336e-05,
      "loss": 0.0035,
      "step": 10680
    },
    {
      "epoch": 0.34208,
      "grad_norm": 0.009687676094472408,
      "learning_rate": 1.771968e-05,
      "loss": 0.001,
      "step": 10690
    },
    {
      "epoch": 0.3424,
      "grad_norm": 0.017491944134235382,
      "learning_rate": 1.7717546666666666e-05,
      "loss": 0.0576,
      "step": 10700
    },
    {
      "epoch": 0.34272,
      "grad_norm": 0.015554684214293957,
      "learning_rate": 1.7715413333333335e-05,
      "loss": 0.0456,
      "step": 10710
    },
    {
      "epoch": 0.34304,
      "grad_norm": 0.010079876519739628,
      "learning_rate": 1.771328e-05,
      "loss": 0.0442,
      "step": 10720
    },
    {
      "epoch": 0.34336,
      "grad_norm": 0.009611496701836586,
      "learning_rate": 1.7711146666666666e-05,
      "loss": 0.0199,
      "step": 10730
    },
    {
      "epoch": 0.34368,
      "grad_norm": 0.012011874467134476,
      "learning_rate": 1.7709013333333335e-05,
      "loss": 0.0011,
      "step": 10740
    },
    {
      "epoch": 0.344,
      "grad_norm": 3.2937307357788086,
      "learning_rate": 1.7706880000000004e-05,
      "loss": 0.0123,
      "step": 10750
    },
    {
      "epoch": 0.34432,
      "grad_norm": 0.01069863885641098,
      "learning_rate": 1.770474666666667e-05,
      "loss": 0.0117,
      "step": 10760
    },
    {
      "epoch": 0.34464,
      "grad_norm": 0.01735256426036358,
      "learning_rate": 1.7702613333333334e-05,
      "loss": 0.0006,
      "step": 10770
    },
    {
      "epoch": 0.34496,
      "grad_norm": 0.01044926792383194,
      "learning_rate": 1.7700480000000003e-05,
      "loss": 0.0007,
      "step": 10780
    },
    {
      "epoch": 0.34528,
      "grad_norm": 0.016232561320066452,
      "learning_rate": 1.769834666666667e-05,
      "loss": 0.0011,
      "step": 10790
    },
    {
      "epoch": 0.3456,
      "grad_norm": 0.13840921223163605,
      "learning_rate": 1.7696213333333334e-05,
      "loss": 0.0225,
      "step": 10800
    },
    {
      "epoch": 0.34592,
      "grad_norm": 0.009413224644958973,
      "learning_rate": 1.7694080000000003e-05,
      "loss": 0.0327,
      "step": 10810
    },
    {
      "epoch": 0.34624,
      "grad_norm": 0.01238393597304821,
      "learning_rate": 1.7691946666666668e-05,
      "loss": 0.005,
      "step": 10820
    },
    {
      "epoch": 0.34656,
      "grad_norm": 3.3667218685150146,
      "learning_rate": 1.7689813333333333e-05,
      "loss": 0.0335,
      "step": 10830
    },
    {
      "epoch": 0.34688,
      "grad_norm": 0.01692638359963894,
      "learning_rate": 1.7687680000000002e-05,
      "loss": 0.0015,
      "step": 10840
    },
    {
      "epoch": 0.3472,
      "grad_norm": 0.013044202700257301,
      "learning_rate": 1.7685546666666667e-05,
      "loss": 0.0006,
      "step": 10850
    },
    {
      "epoch": 0.34752,
      "grad_norm": 0.010652105323970318,
      "learning_rate": 1.7683413333333336e-05,
      "loss": 0.0011,
      "step": 10860
    },
    {
      "epoch": 0.34784,
      "grad_norm": 0.4824065566062927,
      "learning_rate": 1.768128e-05,
      "loss": 0.0013,
      "step": 10870
    },
    {
      "epoch": 0.34816,
      "grad_norm": 0.018305746838450432,
      "learning_rate": 1.767914666666667e-05,
      "loss": 0.0147,
      "step": 10880
    },
    {
      "epoch": 0.34848,
      "grad_norm": 0.020441856235265732,
      "learning_rate": 1.7677013333333336e-05,
      "loss": 0.0007,
      "step": 10890
    },
    {
      "epoch": 0.3488,
      "grad_norm": 0.012222527526319027,
      "learning_rate": 1.767488e-05,
      "loss": 0.0018,
      "step": 10900
    },
    {
      "epoch": 0.34912,
      "grad_norm": 0.022530455142259598,
      "learning_rate": 1.767274666666667e-05,
      "loss": 0.0005,
      "step": 10910
    },
    {
      "epoch": 0.34944,
      "grad_norm": 0.025695741176605225,
      "learning_rate": 1.7670613333333335e-05,
      "loss": 0.0408,
      "step": 10920
    },
    {
      "epoch": 0.34976,
      "grad_norm": 0.008775588124990463,
      "learning_rate": 1.766848e-05,
      "loss": 0.0708,
      "step": 10930
    },
    {
      "epoch": 0.35008,
      "grad_norm": 0.016619492322206497,
      "learning_rate": 1.7666346666666666e-05,
      "loss": 0.0072,
      "step": 10940
    },
    {
      "epoch": 0.3504,
      "grad_norm": 0.0232002642005682,
      "learning_rate": 1.7664213333333335e-05,
      "loss": 0.0868,
      "step": 10950
    },
    {
      "epoch": 0.35072,
      "grad_norm": 0.014643318951129913,
      "learning_rate": 1.766208e-05,
      "loss": 0.0065,
      "step": 10960
    },
    {
      "epoch": 0.35104,
      "grad_norm": 0.07097438722848892,
      "learning_rate": 1.765994666666667e-05,
      "loss": 0.002,
      "step": 10970
    },
    {
      "epoch": 0.35136,
      "grad_norm": 0.010223585180938244,
      "learning_rate": 1.7657813333333334e-05,
      "loss": 0.0026,
      "step": 10980
    },
    {
      "epoch": 0.35168,
      "grad_norm": 0.19426696002483368,
      "learning_rate": 1.7655680000000003e-05,
      "loss": 0.0011,
      "step": 10990
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.04466282203793526,
      "learning_rate": 1.765354666666667e-05,
      "loss": 0.0423,
      "step": 11000
    },
    {
      "epoch": 0.35232,
      "grad_norm": 0.014287491329014301,
      "learning_rate": 1.7651413333333334e-05,
      "loss": 0.0015,
      "step": 11010
    },
    {
      "epoch": 0.35264,
      "grad_norm": 0.013077052310109138,
      "learning_rate": 1.7649280000000003e-05,
      "loss": 0.0008,
      "step": 11020
    },
    {
      "epoch": 0.35296,
      "grad_norm": 0.017945056781172752,
      "learning_rate": 1.7647146666666668e-05,
      "loss": 0.0008,
      "step": 11030
    },
    {
      "epoch": 0.35328,
      "grad_norm": 0.009553219191730022,
      "learning_rate": 1.7645013333333333e-05,
      "loss": 0.0451,
      "step": 11040
    },
    {
      "epoch": 0.3536,
      "grad_norm": 0.014004301279783249,
      "learning_rate": 1.7642880000000002e-05,
      "loss": 0.0315,
      "step": 11050
    },
    {
      "epoch": 0.35392,
      "grad_norm": 0.012502899393439293,
      "learning_rate": 1.7640746666666667e-05,
      "loss": 0.0013,
      "step": 11060
    },
    {
      "epoch": 0.35424,
      "grad_norm": 0.02038756012916565,
      "learning_rate": 1.7638613333333333e-05,
      "loss": 0.0009,
      "step": 11070
    },
    {
      "epoch": 0.35456,
      "grad_norm": 0.00908675231039524,
      "learning_rate": 1.763648e-05,
      "loss": 0.0514,
      "step": 11080
    },
    {
      "epoch": 0.35488,
      "grad_norm": 0.010684257373213768,
      "learning_rate": 1.7634346666666667e-05,
      "loss": 0.0011,
      "step": 11090
    },
    {
      "epoch": 0.3552,
      "grad_norm": 0.013046495616436005,
      "learning_rate": 1.7632213333333336e-05,
      "loss": 0.0053,
      "step": 11100
    },
    {
      "epoch": 0.35552,
      "grad_norm": 0.015234282240271568,
      "learning_rate": 1.763008e-05,
      "loss": 0.0022,
      "step": 11110
    },
    {
      "epoch": 0.35584,
      "grad_norm": 0.011145645752549171,
      "learning_rate": 1.762794666666667e-05,
      "loss": 0.0026,
      "step": 11120
    },
    {
      "epoch": 0.35616,
      "grad_norm": 0.00791477132588625,
      "learning_rate": 1.7625813333333335e-05,
      "loss": 0.0008,
      "step": 11130
    },
    {
      "epoch": 0.35648,
      "grad_norm": 0.014909174293279648,
      "learning_rate": 1.762368e-05,
      "loss": 0.0017,
      "step": 11140
    },
    {
      "epoch": 0.3568,
      "grad_norm": 0.032801851630210876,
      "learning_rate": 1.762154666666667e-05,
      "loss": 0.0008,
      "step": 11150
    },
    {
      "epoch": 0.35712,
      "grad_norm": 0.02016628161072731,
      "learning_rate": 1.7619413333333335e-05,
      "loss": 0.0395,
      "step": 11160
    },
    {
      "epoch": 0.35744,
      "grad_norm": 0.012865121476352215,
      "learning_rate": 1.761728e-05,
      "loss": 0.0487,
      "step": 11170
    },
    {
      "epoch": 0.35776,
      "grad_norm": 0.005310886539518833,
      "learning_rate": 1.7615146666666666e-05,
      "loss": 0.0009,
      "step": 11180
    },
    {
      "epoch": 0.35808,
      "grad_norm": 0.8722326755523682,
      "learning_rate": 1.7613013333333334e-05,
      "loss": 0.0019,
      "step": 11190
    },
    {
      "epoch": 0.3584,
      "grad_norm": 0.015612819232046604,
      "learning_rate": 1.761088e-05,
      "loss": 0.0011,
      "step": 11200
    },
    {
      "epoch": 0.35872,
      "grad_norm": 0.009023301303386688,
      "learning_rate": 1.760874666666667e-05,
      "loss": 0.0016,
      "step": 11210
    },
    {
      "epoch": 0.35904,
      "grad_norm": 0.019108839333057404,
      "learning_rate": 1.7606613333333337e-05,
      "loss": 0.0345,
      "step": 11220
    },
    {
      "epoch": 0.35936,
      "grad_norm": 0.027196545153856277,
      "learning_rate": 1.7604480000000003e-05,
      "loss": 0.0009,
      "step": 11230
    },
    {
      "epoch": 0.35968,
      "grad_norm": 0.015347884967923164,
      "learning_rate": 1.7602346666666668e-05,
      "loss": 0.0008,
      "step": 11240
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.006846523843705654,
      "learning_rate": 1.7600213333333337e-05,
      "loss": 0.0006,
      "step": 11250
    },
    {
      "epoch": 0.36032,
      "grad_norm": 0.011721514165401459,
      "learning_rate": 1.7598080000000002e-05,
      "loss": 0.0008,
      "step": 11260
    },
    {
      "epoch": 0.36064,
      "grad_norm": 0.017214976251125336,
      "learning_rate": 1.7595946666666667e-05,
      "loss": 0.0008,
      "step": 11270
    },
    {
      "epoch": 0.36096,
      "grad_norm": 0.01471620798110962,
      "learning_rate": 1.7593813333333333e-05,
      "loss": 0.0007,
      "step": 11280
    },
    {
      "epoch": 0.36128,
      "grad_norm": 0.028447549790143967,
      "learning_rate": 1.759168e-05,
      "loss": 0.0303,
      "step": 11290
    },
    {
      "epoch": 0.3616,
      "grad_norm": 0.01987057365477085,
      "learning_rate": 1.7589546666666667e-05,
      "loss": 0.001,
      "step": 11300
    },
    {
      "epoch": 0.36192,
      "grad_norm": 0.017892595380544662,
      "learning_rate": 1.7587413333333336e-05,
      "loss": 0.0009,
      "step": 11310
    },
    {
      "epoch": 0.36224,
      "grad_norm": 0.02868492156267166,
      "learning_rate": 1.758528e-05,
      "loss": 0.0008,
      "step": 11320
    },
    {
      "epoch": 0.36256,
      "grad_norm": 0.012513590045273304,
      "learning_rate": 1.758314666666667e-05,
      "loss": 0.0007,
      "step": 11330
    },
    {
      "epoch": 0.36288,
      "grad_norm": 0.013646194711327553,
      "learning_rate": 1.7581013333333335e-05,
      "loss": 0.0008,
      "step": 11340
    },
    {
      "epoch": 0.3632,
      "grad_norm": 0.013695377856492996,
      "learning_rate": 1.757888e-05,
      "loss": 0.0013,
      "step": 11350
    },
    {
      "epoch": 0.36352,
      "grad_norm": 0.009932029992341995,
      "learning_rate": 1.757674666666667e-05,
      "loss": 0.0112,
      "step": 11360
    },
    {
      "epoch": 0.36384,
      "grad_norm": 0.01689772494137287,
      "learning_rate": 1.7574613333333335e-05,
      "loss": 0.0491,
      "step": 11370
    },
    {
      "epoch": 0.36416,
      "grad_norm": 1.6426585912704468,
      "learning_rate": 1.757248e-05,
      "loss": 0.0694,
      "step": 11380
    },
    {
      "epoch": 0.36448,
      "grad_norm": 0.016701575368642807,
      "learning_rate": 1.757034666666667e-05,
      "loss": 0.0299,
      "step": 11390
    },
    {
      "epoch": 0.3648,
      "grad_norm": 0.015338825061917305,
      "learning_rate": 1.7568213333333334e-05,
      "loss": 0.0008,
      "step": 11400
    },
    {
      "epoch": 0.36512,
      "grad_norm": 0.024391070008277893,
      "learning_rate": 1.756608e-05,
      "loss": 0.0007,
      "step": 11410
    },
    {
      "epoch": 0.36544,
      "grad_norm": 0.0076783145777881145,
      "learning_rate": 1.756394666666667e-05,
      "loss": 0.0037,
      "step": 11420
    },
    {
      "epoch": 0.36576,
      "grad_norm": 0.02783491648733616,
      "learning_rate": 1.7561813333333334e-05,
      "loss": 0.0007,
      "step": 11430
    },
    {
      "epoch": 0.36608,
      "grad_norm": 0.013499618507921696,
      "learning_rate": 1.7559680000000003e-05,
      "loss": 0.0267,
      "step": 11440
    },
    {
      "epoch": 0.3664,
      "grad_norm": 0.02280469425022602,
      "learning_rate": 1.7557546666666668e-05,
      "loss": 0.0006,
      "step": 11450
    },
    {
      "epoch": 0.36672,
      "grad_norm": 0.007440593093633652,
      "learning_rate": 1.7555413333333337e-05,
      "loss": 0.0011,
      "step": 11460
    },
    {
      "epoch": 0.36704,
      "grad_norm": 0.018247142434120178,
      "learning_rate": 1.7553280000000002e-05,
      "loss": 0.0007,
      "step": 11470
    },
    {
      "epoch": 0.36736,
      "grad_norm": 0.013172319158911705,
      "learning_rate": 1.7551146666666668e-05,
      "loss": 0.0007,
      "step": 11480
    },
    {
      "epoch": 0.36768,
      "grad_norm": 0.009087967686355114,
      "learning_rate": 1.7549013333333336e-05,
      "loss": 0.0006,
      "step": 11490
    },
    {
      "epoch": 0.368,
      "grad_norm": 3.556331157684326,
      "learning_rate": 1.754688e-05,
      "loss": 0.0549,
      "step": 11500
    },
    {
      "epoch": 0.36832,
      "grad_norm": 0.0375165157020092,
      "learning_rate": 1.7544746666666667e-05,
      "loss": 0.0008,
      "step": 11510
    },
    {
      "epoch": 0.36864,
      "grad_norm": 0.04417283087968826,
      "learning_rate": 1.7542613333333332e-05,
      "loss": 0.0462,
      "step": 11520
    },
    {
      "epoch": 0.36896,
      "grad_norm": 0.013614664785563946,
      "learning_rate": 1.754048e-05,
      "loss": 0.0007,
      "step": 11530
    },
    {
      "epoch": 0.36928,
      "grad_norm": 0.019875196740031242,
      "learning_rate": 1.7538346666666667e-05,
      "loss": 0.0396,
      "step": 11540
    },
    {
      "epoch": 0.3696,
      "grad_norm": 0.02415260672569275,
      "learning_rate": 1.7536213333333335e-05,
      "loss": 0.0016,
      "step": 11550
    },
    {
      "epoch": 0.36992,
      "grad_norm": 0.052679501473903656,
      "learning_rate": 1.753408e-05,
      "loss": 0.0014,
      "step": 11560
    },
    {
      "epoch": 0.37024,
      "grad_norm": 0.03974354639649391,
      "learning_rate": 1.753194666666667e-05,
      "loss": 0.0023,
      "step": 11570
    },
    {
      "epoch": 0.37056,
      "grad_norm": 0.009712415747344494,
      "learning_rate": 1.7529813333333335e-05,
      "loss": 0.0029,
      "step": 11580
    },
    {
      "epoch": 0.37088,
      "grad_norm": 0.0170810054987669,
      "learning_rate": 1.7527680000000004e-05,
      "loss": 0.0007,
      "step": 11590
    },
    {
      "epoch": 0.3712,
      "grad_norm": 0.021527407690882683,
      "learning_rate": 1.752554666666667e-05,
      "loss": 0.0648,
      "step": 11600
    },
    {
      "epoch": 0.37152,
      "grad_norm": 0.008708837442100048,
      "learning_rate": 1.7523413333333334e-05,
      "loss": 0.0271,
      "step": 11610
    },
    {
      "epoch": 0.37184,
      "grad_norm": 0.03208906948566437,
      "learning_rate": 1.752128e-05,
      "loss": 0.0054,
      "step": 11620
    },
    {
      "epoch": 0.37216,
      "grad_norm": 0.014554869383573532,
      "learning_rate": 1.751914666666667e-05,
      "loss": 0.0377,
      "step": 11630
    },
    {
      "epoch": 0.37248,
      "grad_norm": 5.256735324859619,
      "learning_rate": 1.7517013333333334e-05,
      "loss": 0.0309,
      "step": 11640
    },
    {
      "epoch": 0.3728,
      "grad_norm": 0.41352760791778564,
      "learning_rate": 1.751488e-05,
      "loss": 0.0015,
      "step": 11650
    },
    {
      "epoch": 0.37312,
      "grad_norm": 1.8866970539093018,
      "learning_rate": 1.7512746666666668e-05,
      "loss": 0.0275,
      "step": 11660
    },
    {
      "epoch": 0.37344,
      "grad_norm": 0.027204405516386032,
      "learning_rate": 1.7510613333333333e-05,
      "loss": 0.005,
      "step": 11670
    },
    {
      "epoch": 0.37376,
      "grad_norm": 0.011724417097866535,
      "learning_rate": 1.7508480000000002e-05,
      "loss": 0.0008,
      "step": 11680
    },
    {
      "epoch": 0.37408,
      "grad_norm": 0.017847836017608643,
      "learning_rate": 1.7506346666666668e-05,
      "loss": 0.0009,
      "step": 11690
    },
    {
      "epoch": 0.3744,
      "grad_norm": 0.010670260526239872,
      "learning_rate": 1.7504213333333336e-05,
      "loss": 0.0212,
      "step": 11700
    },
    {
      "epoch": 0.37472,
      "grad_norm": 0.03557910770177841,
      "learning_rate": 1.750208e-05,
      "loss": 0.0008,
      "step": 11710
    },
    {
      "epoch": 0.37504,
      "grad_norm": 0.012569589540362358,
      "learning_rate": 1.7499946666666667e-05,
      "loss": 0.0007,
      "step": 11720
    },
    {
      "epoch": 0.37536,
      "grad_norm": 0.010234774090349674,
      "learning_rate": 1.7497813333333336e-05,
      "loss": 0.0006,
      "step": 11730
    },
    {
      "epoch": 0.37568,
      "grad_norm": 0.00708372425287962,
      "learning_rate": 1.749568e-05,
      "loss": 0.0005,
      "step": 11740
    },
    {
      "epoch": 0.376,
      "grad_norm": 0.009743710048496723,
      "learning_rate": 1.7493546666666667e-05,
      "loss": 0.0005,
      "step": 11750
    },
    {
      "epoch": 0.37632,
      "grad_norm": 0.011501161381602287,
      "learning_rate": 1.7491413333333335e-05,
      "loss": 0.0006,
      "step": 11760
    },
    {
      "epoch": 0.37664,
      "grad_norm": 0.01086992584168911,
      "learning_rate": 1.748928e-05,
      "loss": 0.0016,
      "step": 11770
    },
    {
      "epoch": 0.37696,
      "grad_norm": 0.008074103854596615,
      "learning_rate": 1.748714666666667e-05,
      "loss": 0.0008,
      "step": 11780
    },
    {
      "epoch": 0.37728,
      "grad_norm": 0.009480386041104794,
      "learning_rate": 1.7485013333333335e-05,
      "loss": 0.0008,
      "step": 11790
    },
    {
      "epoch": 0.3776,
      "grad_norm": 0.005953383632004261,
      "learning_rate": 1.7482880000000004e-05,
      "loss": 0.0215,
      "step": 11800
    },
    {
      "epoch": 0.37792,
      "grad_norm": 0.008625131100416183,
      "learning_rate": 1.748074666666667e-05,
      "loss": 0.0005,
      "step": 11810
    },
    {
      "epoch": 0.37824,
      "grad_norm": 0.010254351422190666,
      "learning_rate": 1.7478613333333334e-05,
      "loss": 0.0007,
      "step": 11820
    },
    {
      "epoch": 0.37856,
      "grad_norm": 0.03551212325692177,
      "learning_rate": 1.7476480000000003e-05,
      "loss": 0.0005,
      "step": 11830
    },
    {
      "epoch": 0.37888,
      "grad_norm": 0.1835552304983139,
      "learning_rate": 1.747434666666667e-05,
      "loss": 0.0013,
      "step": 11840
    },
    {
      "epoch": 0.3792,
      "grad_norm": 0.00625599967315793,
      "learning_rate": 1.7472213333333334e-05,
      "loss": 0.0329,
      "step": 11850
    },
    {
      "epoch": 0.37952,
      "grad_norm": 0.0071921623311936855,
      "learning_rate": 1.747008e-05,
      "loss": 0.0008,
      "step": 11860
    },
    {
      "epoch": 0.37984,
      "grad_norm": 0.006857291795313358,
      "learning_rate": 1.7467946666666668e-05,
      "loss": 0.0033,
      "step": 11870
    },
    {
      "epoch": 0.38016,
      "grad_norm": 0.008169515989720821,
      "learning_rate": 1.7465813333333333e-05,
      "loss": 0.0006,
      "step": 11880
    },
    {
      "epoch": 0.38048,
      "grad_norm": 0.007464664056897163,
      "learning_rate": 1.7463680000000002e-05,
      "loss": 0.0015,
      "step": 11890
    },
    {
      "epoch": 0.3808,
      "grad_norm": 0.024675114080309868,
      "learning_rate": 1.7461546666666668e-05,
      "loss": 0.0389,
      "step": 11900
    },
    {
      "epoch": 0.38112,
      "grad_norm": 0.004974062088876963,
      "learning_rate": 1.7459413333333336e-05,
      "loss": 0.0005,
      "step": 11910
    },
    {
      "epoch": 0.38144,
      "grad_norm": 0.014561295509338379,
      "learning_rate": 1.7457280000000002e-05,
      "loss": 0.0007,
      "step": 11920
    },
    {
      "epoch": 0.38176,
      "grad_norm": 0.0823957696557045,
      "learning_rate": 1.745514666666667e-05,
      "loss": 0.0007,
      "step": 11930
    },
    {
      "epoch": 0.38208,
      "grad_norm": 0.008495111018419266,
      "learning_rate": 1.7453013333333336e-05,
      "loss": 0.0006,
      "step": 11940
    },
    {
      "epoch": 0.3824,
      "grad_norm": 0.006199325900524855,
      "learning_rate": 1.745088e-05,
      "loss": 0.0006,
      "step": 11950
    },
    {
      "epoch": 0.38272,
      "grad_norm": 0.00857715867459774,
      "learning_rate": 1.7448746666666667e-05,
      "loss": 0.0006,
      "step": 11960
    },
    {
      "epoch": 0.38304,
      "grad_norm": 0.015650320798158646,
      "learning_rate": 1.7446613333333335e-05,
      "loss": 0.056,
      "step": 11970
    },
    {
      "epoch": 0.38336,
      "grad_norm": 0.11861825734376907,
      "learning_rate": 1.744448e-05,
      "loss": 0.0008,
      "step": 11980
    },
    {
      "epoch": 0.38368,
      "grad_norm": 0.03848975896835327,
      "learning_rate": 1.7442346666666666e-05,
      "loss": 0.0006,
      "step": 11990
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.00937273632735014,
      "learning_rate": 1.7440213333333335e-05,
      "loss": 0.0402,
      "step": 12000
    },
    {
      "epoch": 0.38432,
      "grad_norm": 0.0068262554705142975,
      "learning_rate": 1.743808e-05,
      "loss": 0.0005,
      "step": 12010
    },
    {
      "epoch": 0.38464,
      "grad_norm": 0.048057060688734055,
      "learning_rate": 1.743594666666667e-05,
      "loss": 0.001,
      "step": 12020
    },
    {
      "epoch": 0.38496,
      "grad_norm": 0.00751206511631608,
      "learning_rate": 1.7433813333333334e-05,
      "loss": 0.0004,
      "step": 12030
    },
    {
      "epoch": 0.38528,
      "grad_norm": 0.006061531137675047,
      "learning_rate": 1.7431680000000003e-05,
      "loss": 0.0004,
      "step": 12040
    },
    {
      "epoch": 0.3856,
      "grad_norm": 0.004560729023069143,
      "learning_rate": 1.742954666666667e-05,
      "loss": 0.0004,
      "step": 12050
    },
    {
      "epoch": 0.38592,
      "grad_norm": 0.010259401053190231,
      "learning_rate": 1.7427413333333334e-05,
      "loss": 0.0431,
      "step": 12060
    },
    {
      "epoch": 0.38624,
      "grad_norm": 0.011313781142234802,
      "learning_rate": 1.7425280000000003e-05,
      "loss": 0.0006,
      "step": 12070
    },
    {
      "epoch": 0.38656,
      "grad_norm": 0.008254694752395153,
      "learning_rate": 1.7423146666666668e-05,
      "loss": 0.0006,
      "step": 12080
    },
    {
      "epoch": 0.38688,
      "grad_norm": 0.0041076126508414745,
      "learning_rate": 1.7421013333333333e-05,
      "loss": 0.0004,
      "step": 12090
    },
    {
      "epoch": 0.3872,
      "grad_norm": 0.13191281259059906,
      "learning_rate": 1.7418880000000002e-05,
      "loss": 0.0063,
      "step": 12100
    },
    {
      "epoch": 0.38752,
      "grad_norm": 0.00514968391507864,
      "learning_rate": 1.7416746666666668e-05,
      "loss": 0.0324,
      "step": 12110
    },
    {
      "epoch": 0.38784,
      "grad_norm": 0.013993477448821068,
      "learning_rate": 1.7414613333333333e-05,
      "loss": 0.0006,
      "step": 12120
    },
    {
      "epoch": 0.38816,
      "grad_norm": 0.015838174149394035,
      "learning_rate": 1.7412480000000002e-05,
      "loss": 0.0005,
      "step": 12130
    },
    {
      "epoch": 0.38848,
      "grad_norm": 0.008196058683097363,
      "learning_rate": 1.7410346666666667e-05,
      "loss": 0.0006,
      "step": 12140
    },
    {
      "epoch": 0.3888,
      "grad_norm": 0.01128754299134016,
      "learning_rate": 1.7408213333333336e-05,
      "loss": 0.0005,
      "step": 12150
    },
    {
      "epoch": 0.38912,
      "grad_norm": 0.014594568870961666,
      "learning_rate": 1.740608e-05,
      "loss": 0.0288,
      "step": 12160
    },
    {
      "epoch": 0.38944,
      "grad_norm": 0.007591784931719303,
      "learning_rate": 1.740394666666667e-05,
      "loss": 0.0005,
      "step": 12170
    },
    {
      "epoch": 0.38976,
      "grad_norm": 0.005614378489553928,
      "learning_rate": 1.7401813333333335e-05,
      "loss": 0.0004,
      "step": 12180
    },
    {
      "epoch": 0.39008,
      "grad_norm": 0.008192607201635838,
      "learning_rate": 1.739968e-05,
      "loss": 0.0328,
      "step": 12190
    },
    {
      "epoch": 0.3904,
      "grad_norm": 0.008241203613579273,
      "learning_rate": 1.7397546666666666e-05,
      "loss": 0.0004,
      "step": 12200
    },
    {
      "epoch": 0.39072,
      "grad_norm": 0.007715418003499508,
      "learning_rate": 1.7395413333333335e-05,
      "loss": 0.0005,
      "step": 12210
    },
    {
      "epoch": 0.39104,
      "grad_norm": 0.006529762875288725,
      "learning_rate": 1.739328e-05,
      "loss": 0.035,
      "step": 12220
    },
    {
      "epoch": 0.39136,
      "grad_norm": 0.006758309435099363,
      "learning_rate": 1.7391146666666666e-05,
      "loss": 0.0005,
      "step": 12230
    },
    {
      "epoch": 0.39168,
      "grad_norm": 0.2709008753299713,
      "learning_rate": 1.7389013333333334e-05,
      "loss": 0.0046,
      "step": 12240
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.008228345774114132,
      "learning_rate": 1.7386880000000003e-05,
      "loss": 0.001,
      "step": 12250
    },
    {
      "epoch": 0.39232,
      "grad_norm": 0.004141829442232847,
      "learning_rate": 1.738474666666667e-05,
      "loss": 0.0008,
      "step": 12260
    },
    {
      "epoch": 0.39264,
      "grad_norm": 0.00596437556669116,
      "learning_rate": 1.7382613333333337e-05,
      "loss": 0.0018,
      "step": 12270
    },
    {
      "epoch": 0.39296,
      "grad_norm": 0.007076850160956383,
      "learning_rate": 1.7380480000000003e-05,
      "loss": 0.003,
      "step": 12280
    },
    {
      "epoch": 0.39328,
      "grad_norm": 0.009071297012269497,
      "learning_rate": 1.7378346666666668e-05,
      "loss": 0.0554,
      "step": 12290
    },
    {
      "epoch": 0.3936,
      "grad_norm": 0.00656267162412405,
      "learning_rate": 1.7376213333333333e-05,
      "loss": 0.0005,
      "step": 12300
    },
    {
      "epoch": 0.39392,
      "grad_norm": 0.005881811026483774,
      "learning_rate": 1.7374080000000002e-05,
      "loss": 0.0004,
      "step": 12310
    },
    {
      "epoch": 0.39424,
      "grad_norm": 0.008448881097137928,
      "learning_rate": 1.7371946666666668e-05,
      "loss": 0.0006,
      "step": 12320
    },
    {
      "epoch": 0.39456,
      "grad_norm": 1.4168862104415894,
      "learning_rate": 1.7369813333333333e-05,
      "loss": 0.0031,
      "step": 12330
    },
    {
      "epoch": 0.39488,
      "grad_norm": 0.010071733966469765,
      "learning_rate": 1.7367680000000002e-05,
      "loss": 0.0007,
      "step": 12340
    },
    {
      "epoch": 0.3952,
      "grad_norm": 0.12462688982486725,
      "learning_rate": 1.7365546666666667e-05,
      "loss": 0.0011,
      "step": 12350
    },
    {
      "epoch": 0.39552,
      "grad_norm": 0.011766903102397919,
      "learning_rate": 1.7363413333333336e-05,
      "loss": 0.0011,
      "step": 12360
    },
    {
      "epoch": 0.39584,
      "grad_norm": 0.011753398925065994,
      "learning_rate": 1.736128e-05,
      "loss": 0.0414,
      "step": 12370
    },
    {
      "epoch": 0.39616,
      "grad_norm": 0.0035607449244707823,
      "learning_rate": 1.735914666666667e-05,
      "loss": 0.0004,
      "step": 12380
    },
    {
      "epoch": 0.39648,
      "grad_norm": 0.014316799119114876,
      "learning_rate": 1.7357013333333335e-05,
      "loss": 0.0004,
      "step": 12390
    },
    {
      "epoch": 0.3968,
      "grad_norm": 0.006766144186258316,
      "learning_rate": 1.735488e-05,
      "loss": 0.0494,
      "step": 12400
    },
    {
      "epoch": 0.39712,
      "grad_norm": 0.0061914571560919285,
      "learning_rate": 1.735274666666667e-05,
      "loss": 0.0019,
      "step": 12410
    },
    {
      "epoch": 0.39744,
      "grad_norm": 0.006337607279419899,
      "learning_rate": 1.7350613333333335e-05,
      "loss": 0.0004,
      "step": 12420
    },
    {
      "epoch": 0.39776,
      "grad_norm": 0.006073700729757547,
      "learning_rate": 1.734848e-05,
      "loss": 0.0149,
      "step": 12430
    },
    {
      "epoch": 0.39808,
      "grad_norm": 0.018972909078001976,
      "learning_rate": 1.734634666666667e-05,
      "loss": 0.0004,
      "step": 12440
    },
    {
      "epoch": 0.3984,
      "grad_norm": 5.813806533813477,
      "learning_rate": 1.7344213333333334e-05,
      "loss": 0.0691,
      "step": 12450
    },
    {
      "epoch": 0.39872,
      "grad_norm": 0.012654098682105541,
      "learning_rate": 1.734208e-05,
      "loss": 0.0005,
      "step": 12460
    },
    {
      "epoch": 0.39904,
      "grad_norm": 0.010635405778884888,
      "learning_rate": 1.733994666666667e-05,
      "loss": 0.0538,
      "step": 12470
    },
    {
      "epoch": 0.39936,
      "grad_norm": 0.011842232197523117,
      "learning_rate": 1.7337813333333334e-05,
      "loss": 0.0072,
      "step": 12480
    },
    {
      "epoch": 0.39968,
      "grad_norm": 0.013700840063393116,
      "learning_rate": 1.7335680000000003e-05,
      "loss": 0.0042,
      "step": 12490
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.007350377272814512,
      "learning_rate": 1.7333546666666668e-05,
      "loss": 0.0533,
      "step": 12500
    },
    {
      "epoch": 0.40032,
      "grad_norm": 0.008180978707969189,
      "learning_rate": 1.7331413333333337e-05,
      "loss": 0.0004,
      "step": 12510
    },
    {
      "epoch": 0.40064,
      "grad_norm": 0.010626583360135555,
      "learning_rate": 1.7329280000000002e-05,
      "loss": 0.0004,
      "step": 12520
    },
    {
      "epoch": 0.40096,
      "grad_norm": 0.017023293301463127,
      "learning_rate": 1.7327146666666668e-05,
      "loss": 0.0005,
      "step": 12530
    },
    {
      "epoch": 0.40128,
      "grad_norm": 0.009923236444592476,
      "learning_rate": 1.7325013333333333e-05,
      "loss": 0.0013,
      "step": 12540
    },
    {
      "epoch": 0.4016,
      "grad_norm": 0.018213139846920967,
      "learning_rate": 1.7322880000000002e-05,
      "loss": 0.0005,
      "step": 12550
    },
    {
      "epoch": 0.40192,
      "grad_norm": 0.01149255782365799,
      "learning_rate": 1.7320746666666667e-05,
      "loss": 0.0006,
      "step": 12560
    },
    {
      "epoch": 0.40224,
      "grad_norm": 0.005521408747881651,
      "learning_rate": 1.7318613333333333e-05,
      "loss": 0.0375,
      "step": 12570
    },
    {
      "epoch": 0.40256,
      "grad_norm": 0.00966549851000309,
      "learning_rate": 1.731648e-05,
      "loss": 0.001,
      "step": 12580
    },
    {
      "epoch": 0.40288,
      "grad_norm": 0.008871260099112988,
      "learning_rate": 1.7314346666666667e-05,
      "loss": 0.0015,
      "step": 12590
    },
    {
      "epoch": 0.4032,
      "grad_norm": 0.06737606227397919,
      "learning_rate": 1.7312213333333335e-05,
      "loss": 0.0008,
      "step": 12600
    },
    {
      "epoch": 0.40352,
      "grad_norm": 0.004478059709072113,
      "learning_rate": 1.731008e-05,
      "loss": 0.0005,
      "step": 12610
    },
    {
      "epoch": 0.40384,
      "grad_norm": 0.009572776965796947,
      "learning_rate": 1.730794666666667e-05,
      "loss": 0.0006,
      "step": 12620
    },
    {
      "epoch": 0.40416,
      "grad_norm": 0.009767154231667519,
      "learning_rate": 1.7305813333333335e-05,
      "loss": 0.0005,
      "step": 12630
    },
    {
      "epoch": 0.40448,
      "grad_norm": 0.004553661681711674,
      "learning_rate": 1.730368e-05,
      "loss": 0.0098,
      "step": 12640
    },
    {
      "epoch": 0.4048,
      "grad_norm": 0.009359195828437805,
      "learning_rate": 1.730154666666667e-05,
      "loss": 0.0005,
      "step": 12650
    },
    {
      "epoch": 0.40512,
      "grad_norm": 0.007642036769539118,
      "learning_rate": 1.7299413333333334e-05,
      "loss": 0.0006,
      "step": 12660
    },
    {
      "epoch": 0.40544,
      "grad_norm": 0.012060403823852539,
      "learning_rate": 1.729728e-05,
      "loss": 0.0007,
      "step": 12670
    },
    {
      "epoch": 0.40576,
      "grad_norm": 0.016073888167738914,
      "learning_rate": 1.729514666666667e-05,
      "loss": 0.0005,
      "step": 12680
    },
    {
      "epoch": 0.40608,
      "grad_norm": 0.008721111342310905,
      "learning_rate": 1.7293013333333334e-05,
      "loss": 0.0004,
      "step": 12690
    },
    {
      "epoch": 0.4064,
      "grad_norm": 0.009232782758772373,
      "learning_rate": 1.729088e-05,
      "loss": 0.0006,
      "step": 12700
    },
    {
      "epoch": 0.40672,
      "grad_norm": 0.010651377029716969,
      "learning_rate": 1.7288746666666668e-05,
      "loss": 0.0475,
      "step": 12710
    },
    {
      "epoch": 0.40704,
      "grad_norm": 0.016758104786276817,
      "learning_rate": 1.7286613333333337e-05,
      "loss": 0.0412,
      "step": 12720
    },
    {
      "epoch": 0.40736,
      "grad_norm": 0.014250409789383411,
      "learning_rate": 1.7284480000000002e-05,
      "loss": 0.0005,
      "step": 12730
    },
    {
      "epoch": 0.40768,
      "grad_norm": 0.2832396924495697,
      "learning_rate": 1.7282346666666668e-05,
      "loss": 0.0011,
      "step": 12740
    },
    {
      "epoch": 0.408,
      "grad_norm": 2.585874080657959,
      "learning_rate": 1.7280213333333336e-05,
      "loss": 0.0275,
      "step": 12750
    },
    {
      "epoch": 0.40832,
      "grad_norm": 0.01254101563245058,
      "learning_rate": 1.7278080000000002e-05,
      "loss": 0.0005,
      "step": 12760
    },
    {
      "epoch": 0.40864,
      "grad_norm": 0.00872084591537714,
      "learning_rate": 1.7275946666666667e-05,
      "loss": 0.0004,
      "step": 12770
    },
    {
      "epoch": 0.40896,
      "grad_norm": 0.019103894010186195,
      "learning_rate": 1.7273813333333336e-05,
      "loss": 0.0037,
      "step": 12780
    },
    {
      "epoch": 0.40928,
      "grad_norm": 0.01202671229839325,
      "learning_rate": 1.727168e-05,
      "loss": 0.0121,
      "step": 12790
    },
    {
      "epoch": 0.4096,
      "grad_norm": 0.010255626402795315,
      "learning_rate": 1.7269546666666667e-05,
      "loss": 0.0398,
      "step": 12800
    },
    {
      "epoch": 0.40992,
      "grad_norm": 0.006993463728576899,
      "learning_rate": 1.7267413333333335e-05,
      "loss": 0.0008,
      "step": 12810
    },
    {
      "epoch": 0.41024,
      "grad_norm": 0.008626963943243027,
      "learning_rate": 1.726528e-05,
      "loss": 0.0005,
      "step": 12820
    },
    {
      "epoch": 0.41056,
      "grad_norm": 0.0052812471985816956,
      "learning_rate": 1.726314666666667e-05,
      "loss": 0.0004,
      "step": 12830
    },
    {
      "epoch": 0.41088,
      "grad_norm": 0.019118554890155792,
      "learning_rate": 1.7261013333333335e-05,
      "loss": 0.0013,
      "step": 12840
    },
    {
      "epoch": 0.4112,
      "grad_norm": 0.00520979193970561,
      "learning_rate": 1.7258880000000004e-05,
      "loss": 0.0011,
      "step": 12850
    },
    {
      "epoch": 0.41152,
      "grad_norm": 6.110079765319824,
      "learning_rate": 1.725674666666667e-05,
      "loss": 0.0591,
      "step": 12860
    },
    {
      "epoch": 0.41184,
      "grad_norm": 0.007083439733833075,
      "learning_rate": 1.7254613333333334e-05,
      "loss": 0.0003,
      "step": 12870
    },
    {
      "epoch": 0.41216,
      "grad_norm": 0.017947152256965637,
      "learning_rate": 1.725248e-05,
      "loss": 0.0639,
      "step": 12880
    },
    {
      "epoch": 0.41248,
      "grad_norm": 0.007665681187063456,
      "learning_rate": 1.725034666666667e-05,
      "loss": 0.0009,
      "step": 12890
    },
    {
      "epoch": 0.4128,
      "grad_norm": 0.013867934234440327,
      "learning_rate": 1.7248213333333334e-05,
      "loss": 0.0005,
      "step": 12900
    },
    {
      "epoch": 0.41312,
      "grad_norm": 0.04273097589612007,
      "learning_rate": 1.724608e-05,
      "loss": 0.0012,
      "step": 12910
    },
    {
      "epoch": 0.41344,
      "grad_norm": 0.02750726416707039,
      "learning_rate": 1.7243946666666668e-05,
      "loss": 0.0005,
      "step": 12920
    },
    {
      "epoch": 0.41376,
      "grad_norm": 0.007678601425141096,
      "learning_rate": 1.7241813333333334e-05,
      "loss": 0.0303,
      "step": 12930
    },
    {
      "epoch": 0.41408,
      "grad_norm": 0.00685703894123435,
      "learning_rate": 1.7239680000000002e-05,
      "loss": 0.0005,
      "step": 12940
    },
    {
      "epoch": 0.4144,
      "grad_norm": 0.013370264321565628,
      "learning_rate": 1.7237546666666668e-05,
      "loss": 0.0011,
      "step": 12950
    },
    {
      "epoch": 0.41472,
      "grad_norm": 0.010306967422366142,
      "learning_rate": 1.7235413333333336e-05,
      "loss": 0.0015,
      "step": 12960
    },
    {
      "epoch": 0.41504,
      "grad_norm": 0.00278691784478724,
      "learning_rate": 1.7233280000000002e-05,
      "loss": 0.0068,
      "step": 12970
    },
    {
      "epoch": 0.41536,
      "grad_norm": 0.10180266201496124,
      "learning_rate": 1.7231146666666667e-05,
      "loss": 0.0417,
      "step": 12980
    },
    {
      "epoch": 0.41568,
      "grad_norm": 0.00922079011797905,
      "learning_rate": 1.7229013333333336e-05,
      "loss": 0.0005,
      "step": 12990
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.005045522470027208,
      "learning_rate": 1.722688e-05,
      "loss": 0.001,
      "step": 13000
    },
    {
      "epoch": 0.41632,
      "grad_norm": 0.18171019852161407,
      "learning_rate": 1.7224746666666667e-05,
      "loss": 0.001,
      "step": 13010
    },
    {
      "epoch": 0.41664,
      "grad_norm": 0.006718629505485296,
      "learning_rate": 1.7222613333333335e-05,
      "loss": 0.0352,
      "step": 13020
    },
    {
      "epoch": 0.41696,
      "grad_norm": 0.005986672360450029,
      "learning_rate": 1.722048e-05,
      "loss": 0.0004,
      "step": 13030
    },
    {
      "epoch": 0.41728,
      "grad_norm": 0.03363415598869324,
      "learning_rate": 1.7218346666666666e-05,
      "loss": 0.0004,
      "step": 13040
    },
    {
      "epoch": 0.4176,
      "grad_norm": 0.0072080111131072044,
      "learning_rate": 1.7216213333333335e-05,
      "loss": 0.0515,
      "step": 13050
    },
    {
      "epoch": 0.41792,
      "grad_norm": 0.008387708105146885,
      "learning_rate": 1.721408e-05,
      "loss": 0.0203,
      "step": 13060
    },
    {
      "epoch": 0.41824,
      "grad_norm": 0.011594259180128574,
      "learning_rate": 1.721194666666667e-05,
      "loss": 0.0169,
      "step": 13070
    },
    {
      "epoch": 0.41856,
      "grad_norm": 0.010209847241640091,
      "learning_rate": 1.7209813333333335e-05,
      "loss": 0.0006,
      "step": 13080
    },
    {
      "epoch": 0.41888,
      "grad_norm": 0.009392749518156052,
      "learning_rate": 1.7207680000000003e-05,
      "loss": 0.0007,
      "step": 13090
    },
    {
      "epoch": 0.4192,
      "grad_norm": 0.007963147014379501,
      "learning_rate": 1.720554666666667e-05,
      "loss": 0.0473,
      "step": 13100
    },
    {
      "epoch": 0.41952,
      "grad_norm": 0.008937707170844078,
      "learning_rate": 1.7203413333333334e-05,
      "loss": 0.0004,
      "step": 13110
    },
    {
      "epoch": 0.41984,
      "grad_norm": 0.13711808621883392,
      "learning_rate": 1.7201280000000003e-05,
      "loss": 0.0335,
      "step": 13120
    },
    {
      "epoch": 0.42016,
      "grad_norm": 0.06676702201366425,
      "learning_rate": 1.7199146666666668e-05,
      "loss": 0.0023,
      "step": 13130
    },
    {
      "epoch": 0.42048,
      "grad_norm": 0.021293533965945244,
      "learning_rate": 1.7197013333333334e-05,
      "loss": 0.0011,
      "step": 13140
    },
    {
      "epoch": 0.4208,
      "grad_norm": 0.022218558937311172,
      "learning_rate": 1.719488e-05,
      "loss": 0.0099,
      "step": 13150
    },
    {
      "epoch": 0.42112,
      "grad_norm": 0.017757922410964966,
      "learning_rate": 1.7192746666666668e-05,
      "loss": 0.0006,
      "step": 13160
    },
    {
      "epoch": 0.42144,
      "grad_norm": 0.011883702129125595,
      "learning_rate": 1.7190613333333333e-05,
      "loss": 0.0008,
      "step": 13170
    },
    {
      "epoch": 0.42176,
      "grad_norm": 0.011768647469580173,
      "learning_rate": 1.7188480000000002e-05,
      "loss": 0.0025,
      "step": 13180
    },
    {
      "epoch": 0.42208,
      "grad_norm": 0.012160522863268852,
      "learning_rate": 1.718634666666667e-05,
      "loss": 0.0708,
      "step": 13190
    },
    {
      "epoch": 0.4224,
      "grad_norm": 0.01670631766319275,
      "learning_rate": 1.7184213333333336e-05,
      "loss": 0.0161,
      "step": 13200
    },
    {
      "epoch": 0.42272,
      "grad_norm": 0.023184454068541527,
      "learning_rate": 1.718208e-05,
      "loss": 0.0324,
      "step": 13210
    },
    {
      "epoch": 0.42304,
      "grad_norm": 0.0134544987231493,
      "learning_rate": 1.7179946666666667e-05,
      "loss": 0.0007,
      "step": 13220
    },
    {
      "epoch": 0.42336,
      "grad_norm": 0.018373413011431694,
      "learning_rate": 1.7177813333333335e-05,
      "loss": 0.0008,
      "step": 13230
    },
    {
      "epoch": 0.42368,
      "grad_norm": 0.019447747617959976,
      "learning_rate": 1.717568e-05,
      "loss": 0.0479,
      "step": 13240
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.011625695042312145,
      "learning_rate": 1.7173546666666666e-05,
      "loss": 0.0009,
      "step": 13250
    },
    {
      "epoch": 0.42432,
      "grad_norm": 0.011941472068428993,
      "learning_rate": 1.7171413333333335e-05,
      "loss": 0.0015,
      "step": 13260
    },
    {
      "epoch": 0.42464,
      "grad_norm": 0.02708425000309944,
      "learning_rate": 1.716928e-05,
      "loss": 0.0012,
      "step": 13270
    },
    {
      "epoch": 0.42496,
      "grad_norm": 0.010618358850479126,
      "learning_rate": 1.716714666666667e-05,
      "loss": 0.0006,
      "step": 13280
    },
    {
      "epoch": 0.42528,
      "grad_norm": 0.01052806619554758,
      "learning_rate": 1.7165013333333335e-05,
      "loss": 0.0005,
      "step": 13290
    },
    {
      "epoch": 0.4256,
      "grad_norm": 0.00861913338303566,
      "learning_rate": 1.7162880000000003e-05,
      "loss": 0.0004,
      "step": 13300
    },
    {
      "epoch": 0.42592,
      "grad_norm": 0.0059344954788684845,
      "learning_rate": 1.716074666666667e-05,
      "loss": 0.0005,
      "step": 13310
    },
    {
      "epoch": 0.42624,
      "grad_norm": 0.013078402727842331,
      "learning_rate": 1.7158613333333334e-05,
      "loss": 0.0009,
      "step": 13320
    },
    {
      "epoch": 0.42656,
      "grad_norm": 0.029359519481658936,
      "learning_rate": 1.7156480000000003e-05,
      "loss": 0.0224,
      "step": 13330
    },
    {
      "epoch": 0.42688,
      "grad_norm": 0.031884822994470596,
      "learning_rate": 1.7154346666666668e-05,
      "loss": 0.0005,
      "step": 13340
    },
    {
      "epoch": 0.4272,
      "grad_norm": 0.008484943769872189,
      "learning_rate": 1.7152213333333334e-05,
      "loss": 0.0005,
      "step": 13350
    },
    {
      "epoch": 0.42752,
      "grad_norm": 6.573117256164551,
      "learning_rate": 1.7150080000000002e-05,
      "loss": 0.0234,
      "step": 13360
    },
    {
      "epoch": 0.42784,
      "grad_norm": 0.013360208831727505,
      "learning_rate": 1.7147946666666668e-05,
      "loss": 0.0459,
      "step": 13370
    },
    {
      "epoch": 0.42816,
      "grad_norm": 0.0959644466638565,
      "learning_rate": 1.7145813333333333e-05,
      "loss": 0.0348,
      "step": 13380
    },
    {
      "epoch": 0.42848,
      "grad_norm": 0.014804783277213573,
      "learning_rate": 1.7143680000000002e-05,
      "loss": 0.0006,
      "step": 13390
    },
    {
      "epoch": 0.4288,
      "grad_norm": 0.010993297211825848,
      "learning_rate": 1.7141546666666667e-05,
      "loss": 0.0464,
      "step": 13400
    },
    {
      "epoch": 0.42912,
      "grad_norm": 0.026036854833364487,
      "learning_rate": 1.7139413333333336e-05,
      "loss": 0.0021,
      "step": 13410
    },
    {
      "epoch": 0.42944,
      "grad_norm": 0.009119867347180843,
      "learning_rate": 1.713728e-05,
      "loss": 0.0005,
      "step": 13420
    },
    {
      "epoch": 0.42976,
      "grad_norm": 0.3615550696849823,
      "learning_rate": 1.713514666666667e-05,
      "loss": 0.0018,
      "step": 13430
    },
    {
      "epoch": 0.43008,
      "grad_norm": 0.010735736228525639,
      "learning_rate": 1.7133013333333336e-05,
      "loss": 0.0007,
      "step": 13440
    },
    {
      "epoch": 0.4304,
      "grad_norm": 0.008325694128870964,
      "learning_rate": 1.713088e-05,
      "loss": 0.0005,
      "step": 13450
    },
    {
      "epoch": 0.43072,
      "grad_norm": 0.007398797664791346,
      "learning_rate": 1.712874666666667e-05,
      "loss": 0.0006,
      "step": 13460
    },
    {
      "epoch": 0.43104,
      "grad_norm": 0.011467262171208858,
      "learning_rate": 1.7126613333333335e-05,
      "loss": 0.0005,
      "step": 13470
    },
    {
      "epoch": 0.43136,
      "grad_norm": 0.014885909855365753,
      "learning_rate": 1.712448e-05,
      "loss": 0.0222,
      "step": 13480
    },
    {
      "epoch": 0.43168,
      "grad_norm": 0.015946967527270317,
      "learning_rate": 1.7122346666666666e-05,
      "loss": 0.0007,
      "step": 13490
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.011922948062419891,
      "learning_rate": 1.7120213333333335e-05,
      "loss": 0.0196,
      "step": 13500
    },
    {
      "epoch": 0.43232,
      "grad_norm": 0.013069205917418003,
      "learning_rate": 1.711808e-05,
      "loss": 0.0007,
      "step": 13510
    },
    {
      "epoch": 0.43264,
      "grad_norm": 0.008803286589682102,
      "learning_rate": 1.711594666666667e-05,
      "loss": 0.0026,
      "step": 13520
    },
    {
      "epoch": 0.43296,
      "grad_norm": 0.016223175451159477,
      "learning_rate": 1.7113813333333334e-05,
      "loss": 0.0006,
      "step": 13530
    },
    {
      "epoch": 0.43328,
      "grad_norm": 0.030202198773622513,
      "learning_rate": 1.7111680000000003e-05,
      "loss": 0.0025,
      "step": 13540
    },
    {
      "epoch": 0.4336,
      "grad_norm": 0.007557382341474295,
      "learning_rate": 1.7109546666666668e-05,
      "loss": 0.0005,
      "step": 13550
    },
    {
      "epoch": 0.43392,
      "grad_norm": 0.023318370804190636,
      "learning_rate": 1.7107413333333334e-05,
      "loss": 0.1074,
      "step": 13560
    },
    {
      "epoch": 0.43424,
      "grad_norm": 0.00759853795170784,
      "learning_rate": 1.7105280000000002e-05,
      "loss": 0.0007,
      "step": 13570
    },
    {
      "epoch": 0.43456,
      "grad_norm": 0.10031681507825851,
      "learning_rate": 1.7103146666666668e-05,
      "loss": 0.0007,
      "step": 13580
    },
    {
      "epoch": 0.43488,
      "grad_norm": 0.0631759911775589,
      "learning_rate": 1.7101013333333333e-05,
      "loss": 0.0009,
      "step": 13590
    },
    {
      "epoch": 0.4352,
      "grad_norm": 0.006336469203233719,
      "learning_rate": 1.7098880000000002e-05,
      "loss": 0.0091,
      "step": 13600
    },
    {
      "epoch": 0.43552,
      "grad_norm": 0.009955315850675106,
      "learning_rate": 1.7096746666666667e-05,
      "loss": 0.0005,
      "step": 13610
    },
    {
      "epoch": 0.43584,
      "grad_norm": 0.007749568205326796,
      "learning_rate": 1.7094613333333333e-05,
      "loss": 0.0187,
      "step": 13620
    },
    {
      "epoch": 0.43616,
      "grad_norm": 0.023904504254460335,
      "learning_rate": 1.709248e-05,
      "loss": 0.004,
      "step": 13630
    },
    {
      "epoch": 0.43648,
      "grad_norm": 0.016131237149238586,
      "learning_rate": 1.7090346666666667e-05,
      "loss": 0.0208,
      "step": 13640
    },
    {
      "epoch": 0.4368,
      "grad_norm": 0.01507010217756033,
      "learning_rate": 1.7088213333333336e-05,
      "loss": 0.0005,
      "step": 13650
    },
    {
      "epoch": 0.43712,
      "grad_norm": 0.03336549550294876,
      "learning_rate": 1.708608e-05,
      "loss": 0.0007,
      "step": 13660
    },
    {
      "epoch": 0.43744,
      "grad_norm": 3.0537564754486084,
      "learning_rate": 1.708394666666667e-05,
      "loss": 0.0319,
      "step": 13670
    },
    {
      "epoch": 0.43776,
      "grad_norm": 0.019104376435279846,
      "learning_rate": 1.7081813333333335e-05,
      "loss": 0.0255,
      "step": 13680
    },
    {
      "epoch": 0.43808,
      "grad_norm": 0.01117165107280016,
      "learning_rate": 1.707968e-05,
      "loss": 0.0008,
      "step": 13690
    },
    {
      "epoch": 0.4384,
      "grad_norm": 0.011012101545929909,
      "learning_rate": 1.707754666666667e-05,
      "loss": 0.0463,
      "step": 13700
    },
    {
      "epoch": 0.43872,
      "grad_norm": 0.011508856900036335,
      "learning_rate": 1.7075413333333335e-05,
      "loss": 0.0338,
      "step": 13710
    },
    {
      "epoch": 0.43904,
      "grad_norm": 0.013765359297394753,
      "learning_rate": 1.707328e-05,
      "loss": 0.0011,
      "step": 13720
    },
    {
      "epoch": 0.43936,
      "grad_norm": 0.00782830361276865,
      "learning_rate": 1.7071146666666665e-05,
      "loss": 0.0008,
      "step": 13730
    },
    {
      "epoch": 0.43968,
      "grad_norm": 0.010371344164013863,
      "learning_rate": 1.7069013333333334e-05,
      "loss": 0.0795,
      "step": 13740
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.042106226086616516,
      "learning_rate": 1.7066880000000003e-05,
      "loss": 0.0072,
      "step": 13750
    },
    {
      "epoch": 0.44032,
      "grad_norm": 4.29000997543335,
      "learning_rate": 1.7064746666666668e-05,
      "loss": 0.0224,
      "step": 13760
    },
    {
      "epoch": 0.44064,
      "grad_norm": 0.01144799031317234,
      "learning_rate": 1.7062613333333337e-05,
      "loss": 0.0007,
      "step": 13770
    },
    {
      "epoch": 0.44096,
      "grad_norm": 0.010286947712302208,
      "learning_rate": 1.7060480000000002e-05,
      "loss": 0.0559,
      "step": 13780
    },
    {
      "epoch": 0.44128,
      "grad_norm": 0.022360704839229584,
      "learning_rate": 1.7058346666666668e-05,
      "loss": 0.0037,
      "step": 13790
    },
    {
      "epoch": 0.4416,
      "grad_norm": 0.00873252097517252,
      "learning_rate": 1.7056213333333337e-05,
      "loss": 0.0006,
      "step": 13800
    },
    {
      "epoch": 0.44192,
      "grad_norm": 0.008449516259133816,
      "learning_rate": 1.7054080000000002e-05,
      "loss": 0.0013,
      "step": 13810
    },
    {
      "epoch": 0.44224,
      "grad_norm": 0.013778419233858585,
      "learning_rate": 1.7051946666666667e-05,
      "loss": 0.0006,
      "step": 13820
    },
    {
      "epoch": 0.44256,
      "grad_norm": 0.010539640672504902,
      "learning_rate": 1.7049813333333333e-05,
      "loss": 0.0143,
      "step": 13830
    },
    {
      "epoch": 0.44288,
      "grad_norm": 0.0074028377421200275,
      "learning_rate": 1.704768e-05,
      "loss": 0.018,
      "step": 13840
    },
    {
      "epoch": 0.4432,
      "grad_norm": 0.00877142883837223,
      "learning_rate": 1.7045546666666667e-05,
      "loss": 0.0005,
      "step": 13850
    },
    {
      "epoch": 0.44352,
      "grad_norm": 0.007773030083626509,
      "learning_rate": 1.7043413333333336e-05,
      "loss": 0.0088,
      "step": 13860
    },
    {
      "epoch": 0.44384,
      "grad_norm": 0.010547989048063755,
      "learning_rate": 1.704128e-05,
      "loss": 0.0059,
      "step": 13870
    },
    {
      "epoch": 0.44416,
      "grad_norm": 0.0645798072218895,
      "learning_rate": 1.703914666666667e-05,
      "loss": 0.0028,
      "step": 13880
    },
    {
      "epoch": 0.44448,
      "grad_norm": 0.009443581104278564,
      "learning_rate": 1.7037013333333335e-05,
      "loss": 0.0007,
      "step": 13890
    },
    {
      "epoch": 0.4448,
      "grad_norm": 0.08116009831428528,
      "learning_rate": 1.703488e-05,
      "loss": 0.0009,
      "step": 13900
    },
    {
      "epoch": 0.44512,
      "grad_norm": 0.005731511395424604,
      "learning_rate": 1.703274666666667e-05,
      "loss": 0.0011,
      "step": 13910
    },
    {
      "epoch": 0.44544,
      "grad_norm": 0.013022098690271378,
      "learning_rate": 1.7030613333333335e-05,
      "loss": 0.023,
      "step": 13920
    },
    {
      "epoch": 0.44576,
      "grad_norm": 0.011640859767794609,
      "learning_rate": 1.702848e-05,
      "loss": 0.0013,
      "step": 13930
    },
    {
      "epoch": 0.44608,
      "grad_norm": 0.00977246928960085,
      "learning_rate": 1.702634666666667e-05,
      "loss": 0.0005,
      "step": 13940
    },
    {
      "epoch": 0.4464,
      "grad_norm": 0.04734214395284653,
      "learning_rate": 1.7024213333333334e-05,
      "loss": 0.0035,
      "step": 13950
    },
    {
      "epoch": 0.44672,
      "grad_norm": 0.006231475155800581,
      "learning_rate": 1.702208e-05,
      "loss": 0.0004,
      "step": 13960
    },
    {
      "epoch": 0.44704,
      "grad_norm": 0.0425589457154274,
      "learning_rate": 1.7019946666666668e-05,
      "loss": 0.0005,
      "step": 13970
    },
    {
      "epoch": 0.44736,
      "grad_norm": 0.007320611272007227,
      "learning_rate": 1.7017813333333334e-05,
      "loss": 0.0224,
      "step": 13980
    },
    {
      "epoch": 0.44768,
      "grad_norm": 0.009577610529959202,
      "learning_rate": 1.7015680000000002e-05,
      "loss": 0.0006,
      "step": 13990
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.008090577088296413,
      "learning_rate": 1.7013546666666668e-05,
      "loss": 0.0009,
      "step": 14000
    },
    {
      "epoch": 0.44832,
      "grad_norm": 0.005303142126649618,
      "learning_rate": 1.7011413333333337e-05,
      "loss": 0.0009,
      "step": 14010
    },
    {
      "epoch": 0.44864,
      "grad_norm": 0.06404197216033936,
      "learning_rate": 1.7009280000000002e-05,
      "loss": 0.0037,
      "step": 14020
    },
    {
      "epoch": 0.44896,
      "grad_norm": 4.002235412597656,
      "learning_rate": 1.7007146666666667e-05,
      "loss": 0.0223,
      "step": 14030
    },
    {
      "epoch": 0.44928,
      "grad_norm": 1.6439979076385498,
      "learning_rate": 1.7005013333333336e-05,
      "loss": 0.0477,
      "step": 14040
    },
    {
      "epoch": 0.4496,
      "grad_norm": 0.010302078910171986,
      "learning_rate": 1.700288e-05,
      "loss": 0.0006,
      "step": 14050
    },
    {
      "epoch": 0.44992,
      "grad_norm": 0.010733149945735931,
      "learning_rate": 1.7000746666666667e-05,
      "loss": 0.0005,
      "step": 14060
    },
    {
      "epoch": 0.45024,
      "grad_norm": 0.00629138108342886,
      "learning_rate": 1.6998613333333332e-05,
      "loss": 0.05,
      "step": 14070
    },
    {
      "epoch": 0.45056,
      "grad_norm": 0.004443335812538862,
      "learning_rate": 1.699648e-05,
      "loss": 0.0462,
      "step": 14080
    },
    {
      "epoch": 0.45088,
      "grad_norm": 0.014525237493216991,
      "learning_rate": 1.6994346666666666e-05,
      "loss": 0.0008,
      "step": 14090
    },
    {
      "epoch": 0.4512,
      "grad_norm": 0.014713136479258537,
      "learning_rate": 1.6992213333333335e-05,
      "loss": 0.0005,
      "step": 14100
    },
    {
      "epoch": 0.45152,
      "grad_norm": 0.008635635487735271,
      "learning_rate": 1.699008e-05,
      "loss": 0.0008,
      "step": 14110
    },
    {
      "epoch": 0.45184,
      "grad_norm": 0.07763684540987015,
      "learning_rate": 1.698794666666667e-05,
      "loss": 0.0018,
      "step": 14120
    },
    {
      "epoch": 0.45216,
      "grad_norm": 0.006837877444922924,
      "learning_rate": 1.6985813333333335e-05,
      "loss": 0.0005,
      "step": 14130
    },
    {
      "epoch": 0.45248,
      "grad_norm": 0.00970817357301712,
      "learning_rate": 1.6983680000000003e-05,
      "loss": 0.0009,
      "step": 14140
    },
    {
      "epoch": 0.4528,
      "grad_norm": 0.8857409954071045,
      "learning_rate": 1.698154666666667e-05,
      "loss": 0.0019,
      "step": 14150
    },
    {
      "epoch": 0.45312,
      "grad_norm": 0.007872057147324085,
      "learning_rate": 1.6979413333333334e-05,
      "loss": 0.019,
      "step": 14160
    },
    {
      "epoch": 0.45344,
      "grad_norm": 0.009481414221227169,
      "learning_rate": 1.697728e-05,
      "loss": 0.0004,
      "step": 14170
    },
    {
      "epoch": 0.45376,
      "grad_norm": 0.011831511743366718,
      "learning_rate": 1.6975146666666668e-05,
      "loss": 0.0005,
      "step": 14180
    },
    {
      "epoch": 0.45408,
      "grad_norm": 0.013529636897146702,
      "learning_rate": 1.6973013333333334e-05,
      "loss": 0.0006,
      "step": 14190
    },
    {
      "epoch": 0.4544,
      "grad_norm": 0.00881804246455431,
      "learning_rate": 1.697088e-05,
      "loss": 0.05,
      "step": 14200
    },
    {
      "epoch": 0.45472,
      "grad_norm": 0.008989338763058186,
      "learning_rate": 1.6968746666666668e-05,
      "loss": 0.0006,
      "step": 14210
    },
    {
      "epoch": 0.45504,
      "grad_norm": 0.010258730500936508,
      "learning_rate": 1.6966613333333337e-05,
      "loss": 0.0007,
      "step": 14220
    },
    {
      "epoch": 0.45536,
      "grad_norm": 2.3138625621795654,
      "learning_rate": 1.6964480000000002e-05,
      "loss": 0.0351,
      "step": 14230
    },
    {
      "epoch": 0.45568,
      "grad_norm": 0.03986072540283203,
      "learning_rate": 1.6962346666666667e-05,
      "loss": 0.0288,
      "step": 14240
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.013075202703475952,
      "learning_rate": 1.6960213333333336e-05,
      "loss": 0.0056,
      "step": 14250
    },
    {
      "epoch": 0.45632,
      "grad_norm": 0.006960568483918905,
      "learning_rate": 1.695808e-05,
      "loss": 0.0005,
      "step": 14260
    },
    {
      "epoch": 0.45664,
      "grad_norm": 0.01851433515548706,
      "learning_rate": 1.6955946666666667e-05,
      "loss": 0.0033,
      "step": 14270
    },
    {
      "epoch": 0.45696,
      "grad_norm": 0.011884596198797226,
      "learning_rate": 1.6953813333333336e-05,
      "loss": 0.0018,
      "step": 14280
    },
    {
      "epoch": 0.45728,
      "grad_norm": 0.021474529057741165,
      "learning_rate": 1.695168e-05,
      "loss": 0.0046,
      "step": 14290
    },
    {
      "epoch": 0.4576,
      "grad_norm": 0.010416376404464245,
      "learning_rate": 1.6949546666666666e-05,
      "loss": 0.0679,
      "step": 14300
    },
    {
      "epoch": 0.45792,
      "grad_norm": 0.013778452761471272,
      "learning_rate": 1.6947413333333335e-05,
      "loss": 0.0006,
      "step": 14310
    },
    {
      "epoch": 0.45824,
      "grad_norm": 0.009030384011566639,
      "learning_rate": 1.694528e-05,
      "loss": 0.0203,
      "step": 14320
    },
    {
      "epoch": 0.45856,
      "grad_norm": 0.009698254987597466,
      "learning_rate": 1.694314666666667e-05,
      "loss": 0.0234,
      "step": 14330
    },
    {
      "epoch": 0.45888,
      "grad_norm": 0.015627430751919746,
      "learning_rate": 1.6941013333333335e-05,
      "loss": 0.0006,
      "step": 14340
    },
    {
      "epoch": 0.4592,
      "grad_norm": 0.013385046273469925,
      "learning_rate": 1.6938880000000003e-05,
      "loss": 0.0006,
      "step": 14350
    },
    {
      "epoch": 0.45952,
      "grad_norm": 0.008848795667290688,
      "learning_rate": 1.693674666666667e-05,
      "loss": 0.0009,
      "step": 14360
    },
    {
      "epoch": 0.45984,
      "grad_norm": 2.813544988632202,
      "learning_rate": 1.6934613333333334e-05,
      "loss": 0.0102,
      "step": 14370
    },
    {
      "epoch": 0.46016,
      "grad_norm": 0.018457572907209396,
      "learning_rate": 1.6932480000000003e-05,
      "loss": 0.0275,
      "step": 14380
    },
    {
      "epoch": 0.46048,
      "grad_norm": 0.012754974886775017,
      "learning_rate": 1.6930346666666668e-05,
      "loss": 0.0005,
      "step": 14390
    },
    {
      "epoch": 0.4608,
      "grad_norm": 0.05321265012025833,
      "learning_rate": 1.6928213333333334e-05,
      "loss": 0.0007,
      "step": 14400
    },
    {
      "epoch": 0.46112,
      "grad_norm": 0.009709497913718224,
      "learning_rate": 1.692608e-05,
      "loss": 0.0468,
      "step": 14410
    },
    {
      "epoch": 0.46144,
      "grad_norm": 0.0059446473605930805,
      "learning_rate": 1.6923946666666668e-05,
      "loss": 0.0006,
      "step": 14420
    },
    {
      "epoch": 0.46176,
      "grad_norm": 0.026576707139611244,
      "learning_rate": 1.6921813333333333e-05,
      "loss": 0.0006,
      "step": 14430
    },
    {
      "epoch": 0.46208,
      "grad_norm": 0.018319623544812202,
      "learning_rate": 1.6919680000000002e-05,
      "loss": 0.0011,
      "step": 14440
    },
    {
      "epoch": 0.4624,
      "grad_norm": 0.009928855113685131,
      "learning_rate": 1.6917546666666667e-05,
      "loss": 0.0511,
      "step": 14450
    },
    {
      "epoch": 0.46272,
      "grad_norm": 0.022359240800142288,
      "learning_rate": 1.6915413333333336e-05,
      "loss": 0.001,
      "step": 14460
    },
    {
      "epoch": 0.46304,
      "grad_norm": 0.010329388082027435,
      "learning_rate": 1.691328e-05,
      "loss": 0.0011,
      "step": 14470
    },
    {
      "epoch": 0.46336,
      "grad_norm": 0.010620098561048508,
      "learning_rate": 1.691114666666667e-05,
      "loss": 0.0338,
      "step": 14480
    },
    {
      "epoch": 0.46368,
      "grad_norm": 0.013814193196594715,
      "learning_rate": 1.6909013333333336e-05,
      "loss": 0.0007,
      "step": 14490
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.025365985929965973,
      "learning_rate": 1.690688e-05,
      "loss": 0.0008,
      "step": 14500
    },
    {
      "epoch": 0.46432,
      "grad_norm": 0.011362857185304165,
      "learning_rate": 1.6904746666666666e-05,
      "loss": 0.0008,
      "step": 14510
    },
    {
      "epoch": 0.46464,
      "grad_norm": 0.004900929518043995,
      "learning_rate": 1.6902613333333335e-05,
      "loss": 0.001,
      "step": 14520
    },
    {
      "epoch": 0.46496,
      "grad_norm": 0.010996158234775066,
      "learning_rate": 1.690048e-05,
      "loss": 0.0039,
      "step": 14530
    },
    {
      "epoch": 0.46528,
      "grad_norm": 0.011533014476299286,
      "learning_rate": 1.6898346666666666e-05,
      "loss": 0.0013,
      "step": 14540
    },
    {
      "epoch": 0.4656,
      "grad_norm": 0.010677730664610863,
      "learning_rate": 1.6896213333333335e-05,
      "loss": 0.0005,
      "step": 14550
    },
    {
      "epoch": 0.46592,
      "grad_norm": 0.009561535902321339,
      "learning_rate": 1.689408e-05,
      "loss": 0.0005,
      "step": 14560
    },
    {
      "epoch": 0.46624,
      "grad_norm": 0.0163420457392931,
      "learning_rate": 1.689194666666667e-05,
      "loss": 0.0514,
      "step": 14570
    },
    {
      "epoch": 0.46656,
      "grad_norm": 0.020564598962664604,
      "learning_rate": 1.6889813333333334e-05,
      "loss": 0.001,
      "step": 14580
    },
    {
      "epoch": 0.46688,
      "grad_norm": 0.005023443140089512,
      "learning_rate": 1.6887680000000003e-05,
      "loss": 0.0305,
      "step": 14590
    },
    {
      "epoch": 0.4672,
      "grad_norm": 0.009403156116604805,
      "learning_rate": 1.688554666666667e-05,
      "loss": 0.0007,
      "step": 14600
    },
    {
      "epoch": 0.46752,
      "grad_norm": 0.0341993123292923,
      "learning_rate": 1.6883413333333334e-05,
      "loss": 0.001,
      "step": 14610
    },
    {
      "epoch": 0.46784,
      "grad_norm": 0.0061044637113809586,
      "learning_rate": 1.6881280000000002e-05,
      "loss": 0.0006,
      "step": 14620
    },
    {
      "epoch": 0.46816,
      "grad_norm": 0.007403102237731218,
      "learning_rate": 1.6879146666666668e-05,
      "loss": 0.0011,
      "step": 14630
    },
    {
      "epoch": 0.46848,
      "grad_norm": 0.006709361914545298,
      "learning_rate": 1.6877013333333333e-05,
      "loss": 0.0005,
      "step": 14640
    },
    {
      "epoch": 0.4688,
      "grad_norm": 0.007873901166021824,
      "learning_rate": 1.6874880000000002e-05,
      "loss": 0.0006,
      "step": 14650
    },
    {
      "epoch": 0.46912,
      "grad_norm": 0.11933339387178421,
      "learning_rate": 1.6872746666666667e-05,
      "loss": 0.0141,
      "step": 14660
    },
    {
      "epoch": 0.46944,
      "grad_norm": 0.012887490913271904,
      "learning_rate": 1.6870613333333333e-05,
      "loss": 0.0314,
      "step": 14670
    },
    {
      "epoch": 0.46976,
      "grad_norm": 0.01252682600170374,
      "learning_rate": 1.686848e-05,
      "loss": 0.0006,
      "step": 14680
    },
    {
      "epoch": 0.47008,
      "grad_norm": 0.00880528800189495,
      "learning_rate": 1.686634666666667e-05,
      "loss": 0.0007,
      "step": 14690
    },
    {
      "epoch": 0.4704,
      "grad_norm": 0.03926606848835945,
      "learning_rate": 1.6864213333333336e-05,
      "loss": 0.0008,
      "step": 14700
    },
    {
      "epoch": 0.47072,
      "grad_norm": 0.009189624339342117,
      "learning_rate": 1.686208e-05,
      "loss": 0.001,
      "step": 14710
    },
    {
      "epoch": 0.47104,
      "grad_norm": 0.009210755117237568,
      "learning_rate": 1.685994666666667e-05,
      "loss": 0.0006,
      "step": 14720
    },
    {
      "epoch": 0.47136,
      "grad_norm": 0.012050008401274681,
      "learning_rate": 1.6857813333333335e-05,
      "loss": 0.0005,
      "step": 14730
    },
    {
      "epoch": 0.47168,
      "grad_norm": 0.00962317269295454,
      "learning_rate": 1.685568e-05,
      "loss": 0.0005,
      "step": 14740
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.018747884780168533,
      "learning_rate": 1.6853546666666666e-05,
      "loss": 0.0006,
      "step": 14750
    },
    {
      "epoch": 0.47232,
      "grad_norm": 0.008730529807507992,
      "learning_rate": 1.6851413333333335e-05,
      "loss": 0.0004,
      "step": 14760
    },
    {
      "epoch": 0.47264,
      "grad_norm": 0.01068638265132904,
      "learning_rate": 1.684928e-05,
      "loss": 0.0098,
      "step": 14770
    },
    {
      "epoch": 0.47296,
      "grad_norm": 0.12145819514989853,
      "learning_rate": 1.684714666666667e-05,
      "loss": 0.0008,
      "step": 14780
    },
    {
      "epoch": 0.47328,
      "grad_norm": 0.015807097777724266,
      "learning_rate": 1.6845013333333334e-05,
      "loss": 0.0244,
      "step": 14790
    },
    {
      "epoch": 0.4736,
      "grad_norm": 0.01852148212492466,
      "learning_rate": 1.6842880000000003e-05,
      "loss": 0.0007,
      "step": 14800
    },
    {
      "epoch": 0.47392,
      "grad_norm": 0.006820995360612869,
      "learning_rate": 1.684074666666667e-05,
      "loss": 0.0005,
      "step": 14810
    },
    {
      "epoch": 0.47424,
      "grad_norm": 0.007255211006850004,
      "learning_rate": 1.6838613333333337e-05,
      "loss": 0.0375,
      "step": 14820
    },
    {
      "epoch": 0.47456,
      "grad_norm": 0.018960611894726753,
      "learning_rate": 1.6836480000000002e-05,
      "loss": 0.0682,
      "step": 14830
    },
    {
      "epoch": 0.47488,
      "grad_norm": 0.01070430688560009,
      "learning_rate": 1.6834346666666668e-05,
      "loss": 0.0006,
      "step": 14840
    },
    {
      "epoch": 0.4752,
      "grad_norm": 0.006733170710504055,
      "learning_rate": 1.6832213333333333e-05,
      "loss": 0.0006,
      "step": 14850
    },
    {
      "epoch": 0.47552,
      "grad_norm": 0.006819766480475664,
      "learning_rate": 1.6830080000000002e-05,
      "loss": 0.0006,
      "step": 14860
    },
    {
      "epoch": 0.47584,
      "grad_norm": 0.006489396560937166,
      "learning_rate": 1.6827946666666667e-05,
      "loss": 0.0034,
      "step": 14870
    },
    {
      "epoch": 0.47616,
      "grad_norm": 0.17252598702907562,
      "learning_rate": 1.6825813333333333e-05,
      "loss": 0.001,
      "step": 14880
    },
    {
      "epoch": 0.47648,
      "grad_norm": 0.014808598905801773,
      "learning_rate": 1.682368e-05,
      "loss": 0.0005,
      "step": 14890
    },
    {
      "epoch": 0.4768,
      "grad_norm": 0.12523788213729858,
      "learning_rate": 1.6821546666666667e-05,
      "loss": 0.0286,
      "step": 14900
    },
    {
      "epoch": 0.47712,
      "grad_norm": 0.0093322042375803,
      "learning_rate": 1.6819413333333336e-05,
      "loss": 0.0004,
      "step": 14910
    },
    {
      "epoch": 0.47744,
      "grad_norm": 0.006327819544821978,
      "learning_rate": 1.681728e-05,
      "loss": 0.0004,
      "step": 14920
    },
    {
      "epoch": 0.47776,
      "grad_norm": 0.0061303093098104,
      "learning_rate": 1.681514666666667e-05,
      "loss": 0.001,
      "step": 14930
    },
    {
      "epoch": 0.47808,
      "grad_norm": 0.01181675773113966,
      "learning_rate": 1.6813013333333335e-05,
      "loss": 0.0003,
      "step": 14940
    },
    {
      "epoch": 0.4784,
      "grad_norm": 0.016534455120563507,
      "learning_rate": 1.681088e-05,
      "loss": 0.0007,
      "step": 14950
    },
    {
      "epoch": 0.47872,
      "grad_norm": 0.07288584113121033,
      "learning_rate": 1.680874666666667e-05,
      "loss": 0.0008,
      "step": 14960
    },
    {
      "epoch": 0.47904,
      "grad_norm": 0.007706455420702696,
      "learning_rate": 1.6806613333333335e-05,
      "loss": 0.0014,
      "step": 14970
    },
    {
      "epoch": 0.47936,
      "grad_norm": 0.008441716432571411,
      "learning_rate": 1.680448e-05,
      "loss": 0.022,
      "step": 14980
    },
    {
      "epoch": 0.47968,
      "grad_norm": 0.007204986643046141,
      "learning_rate": 1.680234666666667e-05,
      "loss": 0.0046,
      "step": 14990
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.009668241254985332,
      "learning_rate": 1.6800213333333334e-05,
      "loss": 0.0005,
      "step": 15000
    },
    {
      "epoch": 0.48032,
      "grad_norm": 0.010958350263535976,
      "learning_rate": 1.679808e-05,
      "loss": 0.0004,
      "step": 15010
    },
    {
      "epoch": 0.48064,
      "grad_norm": 0.008582535199820995,
      "learning_rate": 1.679594666666667e-05,
      "loss": 0.0091,
      "step": 15020
    },
    {
      "epoch": 0.48096,
      "grad_norm": 0.010254628956317902,
      "learning_rate": 1.6793813333333334e-05,
      "loss": 0.0003,
      "step": 15030
    },
    {
      "epoch": 0.48128,
      "grad_norm": 0.0059555210173130035,
      "learning_rate": 1.6791680000000003e-05,
      "loss": 0.0007,
      "step": 15040
    },
    {
      "epoch": 0.4816,
      "grad_norm": 0.004661965649574995,
      "learning_rate": 1.6789546666666668e-05,
      "loss": 0.0004,
      "step": 15050
    },
    {
      "epoch": 0.48192,
      "grad_norm": 0.028407985344529152,
      "learning_rate": 1.6787413333333337e-05,
      "loss": 0.0004,
      "step": 15060
    },
    {
      "epoch": 0.48224,
      "grad_norm": 0.017747992649674416,
      "learning_rate": 1.6785280000000002e-05,
      "loss": 0.0005,
      "step": 15070
    },
    {
      "epoch": 0.48256,
      "grad_norm": 0.011002443730831146,
      "learning_rate": 1.6783146666666667e-05,
      "loss": 0.0004,
      "step": 15080
    },
    {
      "epoch": 0.48288,
      "grad_norm": 0.007071537431329489,
      "learning_rate": 1.6781013333333333e-05,
      "loss": 0.0011,
      "step": 15090
    },
    {
      "epoch": 0.4832,
      "grad_norm": 0.009463144466280937,
      "learning_rate": 1.677888e-05,
      "loss": 0.0076,
      "step": 15100
    },
    {
      "epoch": 0.48352,
      "grad_norm": 0.005015865433961153,
      "learning_rate": 1.6776746666666667e-05,
      "loss": 0.0005,
      "step": 15110
    },
    {
      "epoch": 0.48384,
      "grad_norm": 0.010052614845335484,
      "learning_rate": 1.6774613333333332e-05,
      "loss": 0.0003,
      "step": 15120
    },
    {
      "epoch": 0.48416,
      "grad_norm": 0.005630084779113531,
      "learning_rate": 1.677248e-05,
      "loss": 0.0004,
      "step": 15130
    },
    {
      "epoch": 0.48448,
      "grad_norm": 0.005937451496720314,
      "learning_rate": 1.6770346666666666e-05,
      "loss": 0.0089,
      "step": 15140
    },
    {
      "epoch": 0.4848,
      "grad_norm": 3.479497194290161,
      "learning_rate": 1.6768213333333335e-05,
      "loss": 0.011,
      "step": 15150
    },
    {
      "epoch": 0.48512,
      "grad_norm": 1.6123161315917969,
      "learning_rate": 1.6766080000000004e-05,
      "loss": 0.0527,
      "step": 15160
    },
    {
      "epoch": 0.48544,
      "grad_norm": 0.006521038245409727,
      "learning_rate": 1.676394666666667e-05,
      "loss": 0.0003,
      "step": 15170
    },
    {
      "epoch": 0.48576,
      "grad_norm": 0.004858335014432669,
      "learning_rate": 1.6761813333333335e-05,
      "loss": 0.0004,
      "step": 15180
    },
    {
      "epoch": 0.48608,
      "grad_norm": 0.010810723528265953,
      "learning_rate": 1.675968e-05,
      "loss": 0.0003,
      "step": 15190
    },
    {
      "epoch": 0.4864,
      "grad_norm": 0.008574801497161388,
      "learning_rate": 1.675754666666667e-05,
      "loss": 0.0013,
      "step": 15200
    },
    {
      "epoch": 0.48672,
      "grad_norm": 0.007132408674806356,
      "learning_rate": 1.6755413333333334e-05,
      "loss": 0.0007,
      "step": 15210
    },
    {
      "epoch": 0.48704,
      "grad_norm": 0.00928807444870472,
      "learning_rate": 1.675328e-05,
      "loss": 0.0715,
      "step": 15220
    },
    {
      "epoch": 0.48736,
      "grad_norm": 0.007409196346998215,
      "learning_rate": 1.675114666666667e-05,
      "loss": 0.0011,
      "step": 15230
    },
    {
      "epoch": 0.48768,
      "grad_norm": 0.006588369142264128,
      "learning_rate": 1.6749013333333334e-05,
      "loss": 0.0005,
      "step": 15240
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.014666147530078888,
      "learning_rate": 1.6746880000000003e-05,
      "loss": 0.0006,
      "step": 15250
    },
    {
      "epoch": 0.48832,
      "grad_norm": 0.008545545861124992,
      "learning_rate": 1.6744746666666668e-05,
      "loss": 0.0004,
      "step": 15260
    },
    {
      "epoch": 0.48864,
      "grad_norm": 0.018001457676291466,
      "learning_rate": 1.6742613333333337e-05,
      "loss": 0.0461,
      "step": 15270
    },
    {
      "epoch": 0.48896,
      "grad_norm": 0.0035122232511639595,
      "learning_rate": 1.6740480000000002e-05,
      "loss": 0.0126,
      "step": 15280
    },
    {
      "epoch": 0.48928,
      "grad_norm": 0.009322572499513626,
      "learning_rate": 1.6738346666666667e-05,
      "loss": 0.0006,
      "step": 15290
    },
    {
      "epoch": 0.4896,
      "grad_norm": 0.003581420984119177,
      "learning_rate": 1.6736213333333336e-05,
      "loss": 0.0198,
      "step": 15300
    },
    {
      "epoch": 0.48992,
      "grad_norm": 0.018964465707540512,
      "learning_rate": 1.673408e-05,
      "loss": 0.0028,
      "step": 15310
    },
    {
      "epoch": 0.49024,
      "grad_norm": 0.006694371346384287,
      "learning_rate": 1.6731946666666667e-05,
      "loss": 0.0044,
      "step": 15320
    },
    {
      "epoch": 0.49056,
      "grad_norm": 0.011470415629446507,
      "learning_rate": 1.6729813333333336e-05,
      "loss": 0.0124,
      "step": 15330
    },
    {
      "epoch": 0.49088,
      "grad_norm": 0.007973075844347477,
      "learning_rate": 1.672768e-05,
      "loss": 0.0006,
      "step": 15340
    },
    {
      "epoch": 0.4912,
      "grad_norm": 0.007313998881727457,
      "learning_rate": 1.6725546666666666e-05,
      "loss": 0.0004,
      "step": 15350
    },
    {
      "epoch": 0.49152,
      "grad_norm": 0.022447960451245308,
      "learning_rate": 1.6723413333333335e-05,
      "loss": 0.0005,
      "step": 15360
    },
    {
      "epoch": 0.49184,
      "grad_norm": 0.00832937192171812,
      "learning_rate": 1.672128e-05,
      "loss": 0.0547,
      "step": 15370
    },
    {
      "epoch": 0.49216,
      "grad_norm": 0.004530587699264288,
      "learning_rate": 1.671914666666667e-05,
      "loss": 0.0005,
      "step": 15380
    },
    {
      "epoch": 0.49248,
      "grad_norm": 0.009006605483591557,
      "learning_rate": 1.6717013333333335e-05,
      "loss": 0.0006,
      "step": 15390
    },
    {
      "epoch": 0.4928,
      "grad_norm": 0.00567994499579072,
      "learning_rate": 1.6714880000000004e-05,
      "loss": 0.0004,
      "step": 15400
    },
    {
      "epoch": 0.49312,
      "grad_norm": 0.010037272237241268,
      "learning_rate": 1.671274666666667e-05,
      "loss": 0.0006,
      "step": 15410
    },
    {
      "epoch": 0.49344,
      "grad_norm": 0.01298694871366024,
      "learning_rate": 1.6710613333333334e-05,
      "loss": 0.0011,
      "step": 15420
    },
    {
      "epoch": 0.49376,
      "grad_norm": 0.0076503693126142025,
      "learning_rate": 1.6708480000000003e-05,
      "loss": 0.0017,
      "step": 15430
    },
    {
      "epoch": 0.49408,
      "grad_norm": 0.009372192434966564,
      "learning_rate": 1.670634666666667e-05,
      "loss": 0.0461,
      "step": 15440
    },
    {
      "epoch": 0.4944,
      "grad_norm": 0.009101237170398235,
      "learning_rate": 1.6704213333333334e-05,
      "loss": 0.0004,
      "step": 15450
    },
    {
      "epoch": 0.49472,
      "grad_norm": 0.025440478697419167,
      "learning_rate": 1.670208e-05,
      "loss": 0.0005,
      "step": 15460
    },
    {
      "epoch": 0.49504,
      "grad_norm": 0.012817516922950745,
      "learning_rate": 1.6699946666666668e-05,
      "loss": 0.001,
      "step": 15470
    },
    {
      "epoch": 0.49536,
      "grad_norm": 0.009114973247051239,
      "learning_rate": 1.6697813333333333e-05,
      "loss": 0.0005,
      "step": 15480
    },
    {
      "epoch": 0.49568,
      "grad_norm": 0.006581297609955072,
      "learning_rate": 1.6695680000000002e-05,
      "loss": 0.017,
      "step": 15490
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.04003908112645149,
      "learning_rate": 1.6693546666666667e-05,
      "loss": 0.0004,
      "step": 15500
    },
    {
      "epoch": 0.49632,
      "grad_norm": 0.007248455658555031,
      "learning_rate": 1.6691413333333336e-05,
      "loss": 0.0504,
      "step": 15510
    },
    {
      "epoch": 0.49664,
      "grad_norm": 0.009357291273772717,
      "learning_rate": 1.668928e-05,
      "loss": 0.0395,
      "step": 15520
    },
    {
      "epoch": 0.49696,
      "grad_norm": 0.025481654331088066,
      "learning_rate": 1.6687146666666667e-05,
      "loss": 0.0097,
      "step": 15530
    },
    {
      "epoch": 0.49728,
      "grad_norm": 0.007140530738979578,
      "learning_rate": 1.6685013333333336e-05,
      "loss": 0.0004,
      "step": 15540
    },
    {
      "epoch": 0.4976,
      "grad_norm": 2.9134838581085205,
      "learning_rate": 1.668288e-05,
      "loss": 0.0295,
      "step": 15550
    },
    {
      "epoch": 0.49792,
      "grad_norm": 0.004155518487095833,
      "learning_rate": 1.6680746666666666e-05,
      "loss": 0.0006,
      "step": 15560
    },
    {
      "epoch": 0.49824,
      "grad_norm": 0.018664482980966568,
      "learning_rate": 1.6678613333333335e-05,
      "loss": 0.0004,
      "step": 15570
    },
    {
      "epoch": 0.49856,
      "grad_norm": 0.008965153247117996,
      "learning_rate": 1.667648e-05,
      "loss": 0.0005,
      "step": 15580
    },
    {
      "epoch": 0.49888,
      "grad_norm": 0.008553759194910526,
      "learning_rate": 1.6674346666666666e-05,
      "loss": 0.0449,
      "step": 15590
    },
    {
      "epoch": 0.4992,
      "grad_norm": 0.0076292650774121284,
      "learning_rate": 1.6672213333333335e-05,
      "loss": 0.0004,
      "step": 15600
    },
    {
      "epoch": 0.49952,
      "grad_norm": 0.021941306069493294,
      "learning_rate": 1.667008e-05,
      "loss": 0.0006,
      "step": 15610
    },
    {
      "epoch": 0.49984,
      "grad_norm": 0.016787368804216385,
      "learning_rate": 1.666794666666667e-05,
      "loss": 0.0006,
      "step": 15620
    },
    {
      "epoch": 0.50016,
      "grad_norm": 0.012165706604719162,
      "learning_rate": 1.6665813333333334e-05,
      "loss": 0.0286,
      "step": 15630
    },
    {
      "epoch": 0.50048,
      "grad_norm": 0.009444166906177998,
      "learning_rate": 1.6663680000000003e-05,
      "loss": 0.0006,
      "step": 15640
    },
    {
      "epoch": 0.5008,
      "grad_norm": 0.012014218606054783,
      "learning_rate": 1.666154666666667e-05,
      "loss": 0.0007,
      "step": 15650
    },
    {
      "epoch": 0.50112,
      "grad_norm": 0.004837926011532545,
      "learning_rate": 1.6659413333333334e-05,
      "loss": 0.0143,
      "step": 15660
    },
    {
      "epoch": 0.50144,
      "grad_norm": 0.007448794785887003,
      "learning_rate": 1.6657280000000003e-05,
      "loss": 0.0009,
      "step": 15670
    },
    {
      "epoch": 0.50176,
      "grad_norm": 0.015588238835334778,
      "learning_rate": 1.6655146666666668e-05,
      "loss": 0.0005,
      "step": 15680
    },
    {
      "epoch": 0.50208,
      "grad_norm": 0.008955066092312336,
      "learning_rate": 1.6653013333333333e-05,
      "loss": 0.0062,
      "step": 15690
    },
    {
      "epoch": 0.5024,
      "grad_norm": 0.008835074491798878,
      "learning_rate": 1.665088e-05,
      "loss": 0.0565,
      "step": 15700
    },
    {
      "epoch": 0.50272,
      "grad_norm": 0.008672750554978848,
      "learning_rate": 1.6648746666666667e-05,
      "loss": 0.0006,
      "step": 15710
    },
    {
      "epoch": 0.50304,
      "grad_norm": 0.005411512218415737,
      "learning_rate": 1.6646613333333336e-05,
      "loss": 0.001,
      "step": 15720
    },
    {
      "epoch": 0.50336,
      "grad_norm": 0.012405527755618095,
      "learning_rate": 1.664448e-05,
      "loss": 0.0233,
      "step": 15730
    },
    {
      "epoch": 0.50368,
      "grad_norm": 0.006954175420105457,
      "learning_rate": 1.664234666666667e-05,
      "loss": 0.0354,
      "step": 15740
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.021947689354419708,
      "learning_rate": 1.6640213333333336e-05,
      "loss": 0.0006,
      "step": 15750
    },
    {
      "epoch": 0.50432,
      "grad_norm": 0.008964603766798973,
      "learning_rate": 1.663808e-05,
      "loss": 0.0149,
      "step": 15760
    },
    {
      "epoch": 0.50464,
      "grad_norm": 0.008128819055855274,
      "learning_rate": 1.663594666666667e-05,
      "loss": 0.0006,
      "step": 15770
    },
    {
      "epoch": 0.50496,
      "grad_norm": 0.6806969046592712,
      "learning_rate": 1.6633813333333335e-05,
      "loss": 0.0239,
      "step": 15780
    },
    {
      "epoch": 0.50528,
      "grad_norm": 0.008370463736355305,
      "learning_rate": 1.663168e-05,
      "loss": 0.0009,
      "step": 15790
    },
    {
      "epoch": 0.5056,
      "grad_norm": 0.008708340115845203,
      "learning_rate": 1.6629546666666666e-05,
      "loss": 0.0042,
      "step": 15800
    },
    {
      "epoch": 0.50592,
      "grad_norm": 0.023999515920877457,
      "learning_rate": 1.6627413333333335e-05,
      "loss": 0.0004,
      "step": 15810
    },
    {
      "epoch": 0.50624,
      "grad_norm": 0.02924046479165554,
      "learning_rate": 1.662528e-05,
      "loss": 0.0265,
      "step": 15820
    },
    {
      "epoch": 0.50656,
      "grad_norm": 0.010226327925920486,
      "learning_rate": 1.662314666666667e-05,
      "loss": 0.0006,
      "step": 15830
    },
    {
      "epoch": 0.50688,
      "grad_norm": 0.012180779129266739,
      "learning_rate": 1.6621013333333334e-05,
      "loss": 0.0006,
      "step": 15840
    },
    {
      "epoch": 0.5072,
      "grad_norm": 0.016560040414333344,
      "learning_rate": 1.6618880000000003e-05,
      "loss": 0.0006,
      "step": 15850
    },
    {
      "epoch": 0.50752,
      "grad_norm": 0.020702406764030457,
      "learning_rate": 1.661674666666667e-05,
      "loss": 0.0006,
      "step": 15860
    },
    {
      "epoch": 0.50784,
      "grad_norm": 0.006248245947062969,
      "learning_rate": 1.6614613333333334e-05,
      "loss": 0.0006,
      "step": 15870
    },
    {
      "epoch": 0.50816,
      "grad_norm": 0.007577529642730951,
      "learning_rate": 1.6612480000000003e-05,
      "loss": 0.0005,
      "step": 15880
    },
    {
      "epoch": 0.50848,
      "grad_norm": 0.00874683540314436,
      "learning_rate": 1.6610346666666668e-05,
      "loss": 0.0493,
      "step": 15890
    },
    {
      "epoch": 0.5088,
      "grad_norm": 0.02148962952196598,
      "learning_rate": 1.6608213333333333e-05,
      "loss": 0.0471,
      "step": 15900
    },
    {
      "epoch": 0.50912,
      "grad_norm": 0.03802371770143509,
      "learning_rate": 1.6606080000000002e-05,
      "loss": 0.0007,
      "step": 15910
    },
    {
      "epoch": 0.50944,
      "grad_norm": 0.03131064400076866,
      "learning_rate": 1.6603946666666667e-05,
      "loss": 0.001,
      "step": 15920
    },
    {
      "epoch": 0.50976,
      "grad_norm": 0.014754248782992363,
      "learning_rate": 1.6601813333333333e-05,
      "loss": 0.0065,
      "step": 15930
    },
    {
      "epoch": 0.51008,
      "grad_norm": 0.01264454610645771,
      "learning_rate": 1.659968e-05,
      "loss": 0.0005,
      "step": 15940
    },
    {
      "epoch": 0.5104,
      "grad_norm": 0.02803925983607769,
      "learning_rate": 1.6597546666666667e-05,
      "loss": 0.0144,
      "step": 15950
    },
    {
      "epoch": 0.51072,
      "grad_norm": 0.014864684082567692,
      "learning_rate": 1.6595413333333336e-05,
      "loss": 0.0511,
      "step": 15960
    },
    {
      "epoch": 0.51104,
      "grad_norm": 0.01787485182285309,
      "learning_rate": 1.659328e-05,
      "loss": 0.0007,
      "step": 15970
    },
    {
      "epoch": 0.51136,
      "grad_norm": 0.0063425954431295395,
      "learning_rate": 1.659114666666667e-05,
      "loss": 0.0008,
      "step": 15980
    },
    {
      "epoch": 0.51168,
      "grad_norm": 0.01797250285744667,
      "learning_rate": 1.6589013333333335e-05,
      "loss": 0.0007,
      "step": 15990
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.006293045356869698,
      "learning_rate": 1.658688e-05,
      "loss": 0.0004,
      "step": 16000
    },
    {
      "epoch": 0.51232,
      "grad_norm": 0.00760841928422451,
      "learning_rate": 1.658474666666667e-05,
      "loss": 0.0431,
      "step": 16010
    },
    {
      "epoch": 0.51264,
      "grad_norm": 0.03618704155087471,
      "learning_rate": 1.6582613333333335e-05,
      "loss": 0.0008,
      "step": 16020
    },
    {
      "epoch": 0.51296,
      "grad_norm": 0.006916073616594076,
      "learning_rate": 1.658048e-05,
      "loss": 0.0008,
      "step": 16030
    },
    {
      "epoch": 0.51328,
      "grad_norm": 0.007720166817307472,
      "learning_rate": 1.6578346666666666e-05,
      "loss": 0.0006,
      "step": 16040
    },
    {
      "epoch": 0.5136,
      "grad_norm": 0.050419460982084274,
      "learning_rate": 1.6576213333333334e-05,
      "loss": 0.0006,
      "step": 16050
    },
    {
      "epoch": 0.51392,
      "grad_norm": 0.008027644827961922,
      "learning_rate": 1.657408e-05,
      "loss": 0.0186,
      "step": 16060
    },
    {
      "epoch": 0.51424,
      "grad_norm": 0.0076301670633256435,
      "learning_rate": 1.657194666666667e-05,
      "loss": 0.0005,
      "step": 16070
    },
    {
      "epoch": 0.51456,
      "grad_norm": 0.009769988246262074,
      "learning_rate": 1.6569813333333334e-05,
      "loss": 0.0191,
      "step": 16080
    },
    {
      "epoch": 0.51488,
      "grad_norm": 0.013529240153729916,
      "learning_rate": 1.6567680000000003e-05,
      "loss": 0.0005,
      "step": 16090
    },
    {
      "epoch": 0.5152,
      "grad_norm": 0.011153902858495712,
      "learning_rate": 1.6565546666666668e-05,
      "loss": 0.0092,
      "step": 16100
    },
    {
      "epoch": 0.51552,
      "grad_norm": 0.014069945551455021,
      "learning_rate": 1.6563413333333337e-05,
      "loss": 0.0009,
      "step": 16110
    },
    {
      "epoch": 0.51584,
      "grad_norm": 0.009013408794999123,
      "learning_rate": 1.6561280000000002e-05,
      "loss": 0.0007,
      "step": 16120
    },
    {
      "epoch": 0.51616,
      "grad_norm": 0.006428043358027935,
      "learning_rate": 1.6559146666666668e-05,
      "loss": 0.0006,
      "step": 16130
    },
    {
      "epoch": 0.51648,
      "grad_norm": 0.08254373073577881,
      "learning_rate": 1.6557013333333333e-05,
      "loss": 0.0713,
      "step": 16140
    },
    {
      "epoch": 0.5168,
      "grad_norm": 0.013099506497383118,
      "learning_rate": 1.655488e-05,
      "loss": 0.0094,
      "step": 16150
    },
    {
      "epoch": 0.51712,
      "grad_norm": 0.009414001367986202,
      "learning_rate": 1.6552746666666667e-05,
      "loss": 0.0004,
      "step": 16160
    },
    {
      "epoch": 0.51744,
      "grad_norm": 0.004849375691264868,
      "learning_rate": 1.6550613333333332e-05,
      "loss": 0.0006,
      "step": 16170
    },
    {
      "epoch": 0.51776,
      "grad_norm": 0.007160808425396681,
      "learning_rate": 1.654848e-05,
      "loss": 0.0008,
      "step": 16180
    },
    {
      "epoch": 0.51808,
      "grad_norm": 0.02427312172949314,
      "learning_rate": 1.654634666666667e-05,
      "loss": 0.0611,
      "step": 16190
    },
    {
      "epoch": 0.5184,
      "grad_norm": 0.025341179221868515,
      "learning_rate": 1.6544213333333335e-05,
      "loss": 0.0004,
      "step": 16200
    },
    {
      "epoch": 0.51872,
      "grad_norm": 0.020960360765457153,
      "learning_rate": 1.654208e-05,
      "loss": 0.0042,
      "step": 16210
    },
    {
      "epoch": 0.51904,
      "grad_norm": 1.7069436311721802,
      "learning_rate": 1.653994666666667e-05,
      "loss": 0.0027,
      "step": 16220
    },
    {
      "epoch": 0.51936,
      "grad_norm": 0.008468563668429852,
      "learning_rate": 1.6537813333333335e-05,
      "loss": 0.0219,
      "step": 16230
    },
    {
      "epoch": 0.51968,
      "grad_norm": 0.005741333123296499,
      "learning_rate": 1.653568e-05,
      "loss": 0.0374,
      "step": 16240
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.05520280450582504,
      "learning_rate": 1.653354666666667e-05,
      "loss": 0.0005,
      "step": 16250
    },
    {
      "epoch": 0.52032,
      "grad_norm": 0.006684124935418367,
      "learning_rate": 1.6531413333333334e-05,
      "loss": 0.0005,
      "step": 16260
    },
    {
      "epoch": 0.52064,
      "grad_norm": 0.06199348345398903,
      "learning_rate": 1.652928e-05,
      "loss": 0.0029,
      "step": 16270
    },
    {
      "epoch": 0.52096,
      "grad_norm": 0.0197795107960701,
      "learning_rate": 1.652714666666667e-05,
      "loss": 0.0007,
      "step": 16280
    },
    {
      "epoch": 0.52128,
      "grad_norm": 0.006254140753298998,
      "learning_rate": 1.6525013333333334e-05,
      "loss": 0.0007,
      "step": 16290
    },
    {
      "epoch": 0.5216,
      "grad_norm": 0.007585591170936823,
      "learning_rate": 1.6522880000000003e-05,
      "loss": 0.0004,
      "step": 16300
    },
    {
      "epoch": 0.52192,
      "grad_norm": 0.14864322543144226,
      "learning_rate": 1.6520746666666668e-05,
      "loss": 0.0096,
      "step": 16310
    },
    {
      "epoch": 0.52224,
      "grad_norm": 0.11790836602449417,
      "learning_rate": 1.6518613333333337e-05,
      "loss": 0.0008,
      "step": 16320
    },
    {
      "epoch": 0.52256,
      "grad_norm": 0.005242343060672283,
      "learning_rate": 1.6516480000000002e-05,
      "loss": 0.0004,
      "step": 16330
    },
    {
      "epoch": 0.52288,
      "grad_norm": 0.007900950498878956,
      "learning_rate": 1.6514346666666668e-05,
      "loss": 0.0034,
      "step": 16340
    },
    {
      "epoch": 0.5232,
      "grad_norm": 0.008792420849204063,
      "learning_rate": 1.6512213333333336e-05,
      "loss": 0.0012,
      "step": 16350
    },
    {
      "epoch": 0.52352,
      "grad_norm": 0.0823657214641571,
      "learning_rate": 1.651008e-05,
      "loss": 0.0007,
      "step": 16360
    },
    {
      "epoch": 0.52384,
      "grad_norm": 0.003863989608362317,
      "learning_rate": 1.6507946666666667e-05,
      "loss": 0.0003,
      "step": 16370
    },
    {
      "epoch": 0.52416,
      "grad_norm": 0.0098470663651824,
      "learning_rate": 1.6505813333333332e-05,
      "loss": 0.0558,
      "step": 16380
    },
    {
      "epoch": 0.52448,
      "grad_norm": 0.17699892818927765,
      "learning_rate": 1.650368e-05,
      "loss": 0.0009,
      "step": 16390
    },
    {
      "epoch": 0.5248,
      "grad_norm": 0.0056085665710270405,
      "learning_rate": 1.6501546666666667e-05,
      "loss": 0.0003,
      "step": 16400
    },
    {
      "epoch": 0.52512,
      "grad_norm": 0.00898407306522131,
      "learning_rate": 1.6499413333333335e-05,
      "loss": 0.0337,
      "step": 16410
    },
    {
      "epoch": 0.52544,
      "grad_norm": 0.012412551790475845,
      "learning_rate": 1.649728e-05,
      "loss": 0.0018,
      "step": 16420
    },
    {
      "epoch": 0.52576,
      "grad_norm": 0.06839016079902649,
      "learning_rate": 1.649514666666667e-05,
      "loss": 0.008,
      "step": 16430
    },
    {
      "epoch": 0.52608,
      "grad_norm": 0.006187459919601679,
      "learning_rate": 1.6493013333333335e-05,
      "loss": 0.0481,
      "step": 16440
    },
    {
      "epoch": 0.5264,
      "grad_norm": 0.00996171310544014,
      "learning_rate": 1.6490880000000004e-05,
      "loss": 0.0007,
      "step": 16450
    },
    {
      "epoch": 0.52672,
      "grad_norm": 0.004227558150887489,
      "learning_rate": 1.648874666666667e-05,
      "loss": 0.0008,
      "step": 16460
    },
    {
      "epoch": 0.52704,
      "grad_norm": 0.028133511543273926,
      "learning_rate": 1.6486613333333334e-05,
      "loss": 0.0007,
      "step": 16470
    },
    {
      "epoch": 0.52736,
      "grad_norm": 0.017372077330946922,
      "learning_rate": 1.648448e-05,
      "loss": 0.0008,
      "step": 16480
    },
    {
      "epoch": 0.52768,
      "grad_norm": 0.013264352455735207,
      "learning_rate": 1.648234666666667e-05,
      "loss": 0.0012,
      "step": 16490
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.011651508510112762,
      "learning_rate": 1.6480213333333334e-05,
      "loss": 0.0065,
      "step": 16500
    },
    {
      "epoch": 0.52832,
      "grad_norm": 0.006269482430070639,
      "learning_rate": 1.647808e-05,
      "loss": 0.003,
      "step": 16510
    },
    {
      "epoch": 0.52864,
      "grad_norm": 0.010473573580384254,
      "learning_rate": 1.6475946666666668e-05,
      "loss": 0.047,
      "step": 16520
    },
    {
      "epoch": 0.52896,
      "grad_norm": 0.012331679463386536,
      "learning_rate": 1.6473813333333333e-05,
      "loss": 0.0005,
      "step": 16530
    },
    {
      "epoch": 0.52928,
      "grad_norm": 0.008601754903793335,
      "learning_rate": 1.6471680000000002e-05,
      "loss": 0.0006,
      "step": 16540
    },
    {
      "epoch": 0.5296,
      "grad_norm": 0.00580970523878932,
      "learning_rate": 1.6469546666666668e-05,
      "loss": 0.0004,
      "step": 16550
    },
    {
      "epoch": 0.52992,
      "grad_norm": 0.004670686554163694,
      "learning_rate": 1.6467413333333336e-05,
      "loss": 0.0646,
      "step": 16560
    },
    {
      "epoch": 0.53024,
      "grad_norm": 0.0063790143467485905,
      "learning_rate": 1.6465280000000002e-05,
      "loss": 0.0008,
      "step": 16570
    },
    {
      "epoch": 0.53056,
      "grad_norm": 0.005650926847010851,
      "learning_rate": 1.6463146666666667e-05,
      "loss": 0.0006,
      "step": 16580
    },
    {
      "epoch": 0.53088,
      "grad_norm": 0.004978883545845747,
      "learning_rate": 1.6461013333333336e-05,
      "loss": 0.0103,
      "step": 16590
    },
    {
      "epoch": 0.5312,
      "grad_norm": 0.017972702160477638,
      "learning_rate": 1.645888e-05,
      "loss": 0.0007,
      "step": 16600
    },
    {
      "epoch": 0.53152,
      "grad_norm": 0.005401307251304388,
      "learning_rate": 1.6456746666666667e-05,
      "loss": 0.0005,
      "step": 16610
    },
    {
      "epoch": 0.53184,
      "grad_norm": 0.00806860625743866,
      "learning_rate": 1.6454613333333335e-05,
      "loss": 0.0004,
      "step": 16620
    },
    {
      "epoch": 0.53216,
      "grad_norm": 0.01709476299583912,
      "learning_rate": 1.645248e-05,
      "loss": 0.0012,
      "step": 16630
    },
    {
      "epoch": 0.53248,
      "grad_norm": 0.008746933192014694,
      "learning_rate": 1.6450346666666666e-05,
      "loss": 0.0039,
      "step": 16640
    },
    {
      "epoch": 0.5328,
      "grad_norm": 0.010770902037620544,
      "learning_rate": 1.6448213333333335e-05,
      "loss": 0.0004,
      "step": 16650
    },
    {
      "epoch": 0.53312,
      "grad_norm": 0.011954624205827713,
      "learning_rate": 1.6446080000000004e-05,
      "loss": 0.0004,
      "step": 16660
    },
    {
      "epoch": 0.53344,
      "grad_norm": 0.008293809369206429,
      "learning_rate": 1.644394666666667e-05,
      "loss": 0.0006,
      "step": 16670
    },
    {
      "epoch": 0.53376,
      "grad_norm": 0.0057153161615133286,
      "learning_rate": 1.6441813333333334e-05,
      "loss": 0.0003,
      "step": 16680
    },
    {
      "epoch": 0.53408,
      "grad_norm": 1.9493955373764038,
      "learning_rate": 1.6439680000000003e-05,
      "loss": 0.0288,
      "step": 16690
    },
    {
      "epoch": 0.5344,
      "grad_norm": 0.010040847584605217,
      "learning_rate": 1.643754666666667e-05,
      "loss": 0.001,
      "step": 16700
    },
    {
      "epoch": 0.53472,
      "grad_norm": 0.007364096585661173,
      "learning_rate": 1.6435413333333334e-05,
      "loss": 0.0004,
      "step": 16710
    },
    {
      "epoch": 0.53504,
      "grad_norm": 1.0101820230484009,
      "learning_rate": 1.643328e-05,
      "loss": 0.049,
      "step": 16720
    },
    {
      "epoch": 0.53536,
      "grad_norm": 0.08620171248912811,
      "learning_rate": 1.6431146666666668e-05,
      "loss": 0.0466,
      "step": 16730
    },
    {
      "epoch": 0.53568,
      "grad_norm": 0.01428964827209711,
      "learning_rate": 1.6429013333333333e-05,
      "loss": 0.0005,
      "step": 16740
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.02808183990418911,
      "learning_rate": 1.6426880000000002e-05,
      "loss": 0.0007,
      "step": 16750
    },
    {
      "epoch": 0.53632,
      "grad_norm": 0.01794525608420372,
      "learning_rate": 1.6424746666666668e-05,
      "loss": 0.0009,
      "step": 16760
    },
    {
      "epoch": 0.53664,
      "grad_norm": 0.01461729034781456,
      "learning_rate": 1.6422613333333336e-05,
      "loss": 0.0495,
      "step": 16770
    },
    {
      "epoch": 0.53696,
      "grad_norm": 0.006425789091736078,
      "learning_rate": 1.6420480000000002e-05,
      "loss": 0.001,
      "step": 16780
    },
    {
      "epoch": 0.53728,
      "grad_norm": 0.004753948654979467,
      "learning_rate": 1.641834666666667e-05,
      "loss": 0.0005,
      "step": 16790
    },
    {
      "epoch": 0.5376,
      "grad_norm": 0.0166563019156456,
      "learning_rate": 1.6416213333333336e-05,
      "loss": 0.0007,
      "step": 16800
    },
    {
      "epoch": 0.53792,
      "grad_norm": 0.005572624038904905,
      "learning_rate": 1.641408e-05,
      "loss": 0.0006,
      "step": 16810
    },
    {
      "epoch": 0.53824,
      "grad_norm": 0.013714288361370564,
      "learning_rate": 1.6411946666666667e-05,
      "loss": 0.0491,
      "step": 16820
    },
    {
      "epoch": 0.53856,
      "grad_norm": 0.01428413949906826,
      "learning_rate": 1.6409813333333335e-05,
      "loss": 0.0093,
      "step": 16830
    },
    {
      "epoch": 0.53888,
      "grad_norm": 0.030580712482333183,
      "learning_rate": 1.640768e-05,
      "loss": 0.0009,
      "step": 16840
    },
    {
      "epoch": 0.5392,
      "grad_norm": 0.00859631597995758,
      "learning_rate": 1.6405546666666666e-05,
      "loss": 0.001,
      "step": 16850
    },
    {
      "epoch": 0.53952,
      "grad_norm": 0.015007009729743004,
      "learning_rate": 1.6403413333333335e-05,
      "loss": 0.0006,
      "step": 16860
    },
    {
      "epoch": 0.53984,
      "grad_norm": 0.014844509772956371,
      "learning_rate": 1.640128e-05,
      "loss": 0.0181,
      "step": 16870
    },
    {
      "epoch": 0.54016,
      "grad_norm": 0.031823620200157166,
      "learning_rate": 1.639914666666667e-05,
      "loss": 0.0007,
      "step": 16880
    },
    {
      "epoch": 0.54048,
      "grad_norm": 0.007065914571285248,
      "learning_rate": 1.6397013333333334e-05,
      "loss": 0.006,
      "step": 16890
    },
    {
      "epoch": 0.5408,
      "grad_norm": 0.023421481251716614,
      "learning_rate": 1.6394880000000003e-05,
      "loss": 0.0062,
      "step": 16900
    },
    {
      "epoch": 0.54112,
      "grad_norm": 0.03895605728030205,
      "learning_rate": 1.639274666666667e-05,
      "loss": 0.0012,
      "step": 16910
    },
    {
      "epoch": 0.54144,
      "grad_norm": 0.01346171461045742,
      "learning_rate": 1.6390613333333334e-05,
      "loss": 0.0019,
      "step": 16920
    },
    {
      "epoch": 0.54176,
      "grad_norm": 0.013321447186172009,
      "learning_rate": 1.6388480000000003e-05,
      "loss": 0.0006,
      "step": 16930
    },
    {
      "epoch": 0.54208,
      "grad_norm": 0.0035541332326829433,
      "learning_rate": 1.6386346666666668e-05,
      "loss": 0.0005,
      "step": 16940
    },
    {
      "epoch": 0.5424,
      "grad_norm": 0.009942485950887203,
      "learning_rate": 1.6384213333333333e-05,
      "loss": 0.0163,
      "step": 16950
    },
    {
      "epoch": 0.54272,
      "grad_norm": 0.009142715483903885,
      "learning_rate": 1.6382080000000002e-05,
      "loss": 0.0006,
      "step": 16960
    },
    {
      "epoch": 0.54304,
      "grad_norm": 0.010740731842815876,
      "learning_rate": 1.6379946666666668e-05,
      "loss": 0.0005,
      "step": 16970
    },
    {
      "epoch": 0.54336,
      "grad_norm": 0.005160598084330559,
      "learning_rate": 1.6377813333333333e-05,
      "loss": 0.0004,
      "step": 16980
    },
    {
      "epoch": 0.54368,
      "grad_norm": 0.010314601473510265,
      "learning_rate": 1.6375680000000002e-05,
      "loss": 0.0124,
      "step": 16990
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.007102685514837503,
      "learning_rate": 1.6373546666666667e-05,
      "loss": 0.0004,
      "step": 17000
    },
    {
      "epoch": 0.54432,
      "grad_norm": 0.006388181354850531,
      "learning_rate": 1.6371413333333336e-05,
      "loss": 0.015,
      "step": 17010
    },
    {
      "epoch": 0.54464,
      "grad_norm": 0.005647857673466206,
      "learning_rate": 1.636928e-05,
      "loss": 0.0004,
      "step": 17020
    },
    {
      "epoch": 0.54496,
      "grad_norm": 0.007888346910476685,
      "learning_rate": 1.636714666666667e-05,
      "loss": 0.0003,
      "step": 17030
    },
    {
      "epoch": 0.54528,
      "grad_norm": 0.015814799815416336,
      "learning_rate": 1.6365013333333335e-05,
      "loss": 0.0005,
      "step": 17040
    },
    {
      "epoch": 0.5456,
      "grad_norm": 0.008077528327703476,
      "learning_rate": 1.636288e-05,
      "loss": 0.0003,
      "step": 17050
    },
    {
      "epoch": 0.54592,
      "grad_norm": 0.006486616563051939,
      "learning_rate": 1.6360746666666666e-05,
      "loss": 0.0377,
      "step": 17060
    },
    {
      "epoch": 0.54624,
      "grad_norm": 0.5301576256752014,
      "learning_rate": 1.6358613333333335e-05,
      "loss": 0.0019,
      "step": 17070
    },
    {
      "epoch": 0.54656,
      "grad_norm": 0.005705027375370264,
      "learning_rate": 1.635648e-05,
      "loss": 0.0007,
      "step": 17080
    },
    {
      "epoch": 0.54688,
      "grad_norm": 0.008722960017621517,
      "learning_rate": 1.6354346666666666e-05,
      "loss": 0.0532,
      "step": 17090
    },
    {
      "epoch": 0.5472,
      "grad_norm": 0.022483717650175095,
      "learning_rate": 1.6352213333333334e-05,
      "loss": 0.0005,
      "step": 17100
    },
    {
      "epoch": 0.54752,
      "grad_norm": 0.011900920420885086,
      "learning_rate": 1.635008e-05,
      "loss": 0.0237,
      "step": 17110
    },
    {
      "epoch": 0.54784,
      "grad_norm": 0.025427130982279778,
      "learning_rate": 1.634794666666667e-05,
      "loss": 0.0003,
      "step": 17120
    },
    {
      "epoch": 0.54816,
      "grad_norm": 0.004987354390323162,
      "learning_rate": 1.6345813333333337e-05,
      "loss": 0.0379,
      "step": 17130
    },
    {
      "epoch": 0.54848,
      "grad_norm": 0.01972009614109993,
      "learning_rate": 1.6343680000000003e-05,
      "loss": 0.0136,
      "step": 17140
    },
    {
      "epoch": 0.5488,
      "grad_norm": 0.004994882270693779,
      "learning_rate": 1.6341546666666668e-05,
      "loss": 0.0005,
      "step": 17150
    },
    {
      "epoch": 0.54912,
      "grad_norm": 0.0058973003178834915,
      "learning_rate": 1.6339413333333333e-05,
      "loss": 0.0218,
      "step": 17160
    },
    {
      "epoch": 0.54944,
      "grad_norm": 0.010474300011992455,
      "learning_rate": 1.6337280000000002e-05,
      "loss": 0.0006,
      "step": 17170
    },
    {
      "epoch": 0.54976,
      "grad_norm": 0.01255826186388731,
      "learning_rate": 1.6335146666666668e-05,
      "loss": 0.0004,
      "step": 17180
    },
    {
      "epoch": 0.55008,
      "grad_norm": 0.02796795964241028,
      "learning_rate": 1.6333013333333333e-05,
      "loss": 0.0005,
      "step": 17190
    },
    {
      "epoch": 0.5504,
      "grad_norm": 0.00768160680308938,
      "learning_rate": 1.6330880000000002e-05,
      "loss": 0.0006,
      "step": 17200
    },
    {
      "epoch": 0.55072,
      "grad_norm": 0.004203083924949169,
      "learning_rate": 1.6328746666666667e-05,
      "loss": 0.0003,
      "step": 17210
    },
    {
      "epoch": 0.55104,
      "grad_norm": 0.028849322348833084,
      "learning_rate": 1.6326613333333336e-05,
      "loss": 0.0126,
      "step": 17220
    },
    {
      "epoch": 0.55136,
      "grad_norm": 2.379599094390869,
      "learning_rate": 1.632448e-05,
      "loss": 0.0445,
      "step": 17230
    },
    {
      "epoch": 0.55168,
      "grad_norm": 0.006259124260395765,
      "learning_rate": 1.632234666666667e-05,
      "loss": 0.0004,
      "step": 17240
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.0056764427572488785,
      "learning_rate": 1.6320213333333335e-05,
      "loss": 0.0005,
      "step": 17250
    },
    {
      "epoch": 0.55232,
      "grad_norm": 0.007224116008728743,
      "learning_rate": 1.631808e-05,
      "loss": 0.0028,
      "step": 17260
    },
    {
      "epoch": 0.55264,
      "grad_norm": 0.015809983015060425,
      "learning_rate": 1.631594666666667e-05,
      "loss": 0.0005,
      "step": 17270
    },
    {
      "epoch": 0.55296,
      "grad_norm": 0.005285319872200489,
      "learning_rate": 1.6313813333333335e-05,
      "loss": 0.0004,
      "step": 17280
    },
    {
      "epoch": 0.55328,
      "grad_norm": 0.01479177363216877,
      "learning_rate": 1.631168e-05,
      "loss": 0.0004,
      "step": 17290
    },
    {
      "epoch": 0.5536,
      "grad_norm": 0.004237360320985317,
      "learning_rate": 1.630954666666667e-05,
      "loss": 0.0024,
      "step": 17300
    },
    {
      "epoch": 0.55392,
      "grad_norm": 0.012408585287630558,
      "learning_rate": 1.6307413333333334e-05,
      "loss": 0.0501,
      "step": 17310
    },
    {
      "epoch": 0.55424,
      "grad_norm": 0.005244848784059286,
      "learning_rate": 1.630528e-05,
      "loss": 0.0004,
      "step": 17320
    },
    {
      "epoch": 0.55456,
      "grad_norm": 0.005836265627294779,
      "learning_rate": 1.630314666666667e-05,
      "loss": 0.0012,
      "step": 17330
    },
    {
      "epoch": 0.55488,
      "grad_norm": 0.006033594720065594,
      "learning_rate": 1.6301013333333334e-05,
      "loss": 0.0008,
      "step": 17340
    },
    {
      "epoch": 0.5552,
      "grad_norm": 0.011604146100580692,
      "learning_rate": 1.6298880000000003e-05,
      "loss": 0.0083,
      "step": 17350
    },
    {
      "epoch": 0.55552,
      "grad_norm": 0.006415731739252806,
      "learning_rate": 1.6296746666666668e-05,
      "loss": 0.0006,
      "step": 17360
    },
    {
      "epoch": 0.55584,
      "grad_norm": 0.011144128628075123,
      "learning_rate": 1.6294613333333337e-05,
      "loss": 0.0004,
      "step": 17370
    },
    {
      "epoch": 0.55616,
      "grad_norm": 0.006591759156435728,
      "learning_rate": 1.6292480000000002e-05,
      "loss": 0.0314,
      "step": 17380
    },
    {
      "epoch": 0.55648,
      "grad_norm": 0.006845675874501467,
      "learning_rate": 1.6290346666666668e-05,
      "loss": 0.0003,
      "step": 17390
    },
    {
      "epoch": 0.5568,
      "grad_norm": 0.009548668749630451,
      "learning_rate": 1.6288213333333333e-05,
      "loss": 0.0181,
      "step": 17400
    },
    {
      "epoch": 0.55712,
      "grad_norm": 0.0052825030870735645,
      "learning_rate": 1.6286080000000002e-05,
      "loss": 0.0005,
      "step": 17410
    },
    {
      "epoch": 0.55744,
      "grad_norm": 5.266290664672852,
      "learning_rate": 1.6283946666666667e-05,
      "loss": 0.0215,
      "step": 17420
    },
    {
      "epoch": 0.55776,
      "grad_norm": 0.006205935496836901,
      "learning_rate": 1.6281813333333333e-05,
      "loss": 0.0056,
      "step": 17430
    },
    {
      "epoch": 0.55808,
      "grad_norm": 0.006010144483298063,
      "learning_rate": 1.627968e-05,
      "loss": 0.0005,
      "step": 17440
    },
    {
      "epoch": 0.5584,
      "grad_norm": 0.039228081703186035,
      "learning_rate": 1.6277546666666667e-05,
      "loss": 0.0391,
      "step": 17450
    },
    {
      "epoch": 0.55872,
      "grad_norm": 0.008574292063713074,
      "learning_rate": 1.6275413333333335e-05,
      "loss": 0.0006,
      "step": 17460
    },
    {
      "epoch": 0.55904,
      "grad_norm": 0.00689248600974679,
      "learning_rate": 1.627328e-05,
      "loss": 0.0005,
      "step": 17470
    },
    {
      "epoch": 0.55936,
      "grad_norm": 0.005737015511840582,
      "learning_rate": 1.627114666666667e-05,
      "loss": 0.0562,
      "step": 17480
    },
    {
      "epoch": 0.55968,
      "grad_norm": 0.00597362732514739,
      "learning_rate": 1.6269013333333335e-05,
      "loss": 0.0367,
      "step": 17490
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.005883547477424145,
      "learning_rate": 1.626688e-05,
      "loss": 0.0005,
      "step": 17500
    },
    {
      "epoch": 0.56032,
      "grad_norm": 0.0072342222556471825,
      "learning_rate": 1.626474666666667e-05,
      "loss": 0.0007,
      "step": 17510
    },
    {
      "epoch": 0.56064,
      "grad_norm": 0.006151384208351374,
      "learning_rate": 1.6262613333333334e-05,
      "loss": 0.0004,
      "step": 17520
    },
    {
      "epoch": 0.56096,
      "grad_norm": 3.8675174713134766,
      "learning_rate": 1.626048e-05,
      "loss": 0.0116,
      "step": 17530
    },
    {
      "epoch": 0.56128,
      "grad_norm": 0.00608885008841753,
      "learning_rate": 1.625834666666667e-05,
      "loss": 0.0191,
      "step": 17540
    },
    {
      "epoch": 0.5616,
      "grad_norm": 0.008850731886923313,
      "learning_rate": 1.6256213333333334e-05,
      "loss": 0.0004,
      "step": 17550
    },
    {
      "epoch": 0.56192,
      "grad_norm": 0.007957668974995613,
      "learning_rate": 1.625408e-05,
      "loss": 0.0008,
      "step": 17560
    },
    {
      "epoch": 0.56224,
      "grad_norm": 0.014701077714562416,
      "learning_rate": 1.6251946666666668e-05,
      "loss": 0.0005,
      "step": 17570
    },
    {
      "epoch": 0.56256,
      "grad_norm": 0.03772115707397461,
      "learning_rate": 1.6249813333333334e-05,
      "loss": 0.0196,
      "step": 17580
    },
    {
      "epoch": 0.56288,
      "grad_norm": 0.009811838157474995,
      "learning_rate": 1.6247680000000002e-05,
      "loss": 0.0004,
      "step": 17590
    },
    {
      "epoch": 0.5632,
      "grad_norm": 0.03140385076403618,
      "learning_rate": 1.6245546666666668e-05,
      "loss": 0.0006,
      "step": 17600
    },
    {
      "epoch": 0.56352,
      "grad_norm": 0.023722777143120766,
      "learning_rate": 1.6243413333333336e-05,
      "loss": 0.0557,
      "step": 17610
    },
    {
      "epoch": 0.56384,
      "grad_norm": 0.020146694034337997,
      "learning_rate": 1.6241280000000002e-05,
      "loss": 0.0541,
      "step": 17620
    },
    {
      "epoch": 0.56416,
      "grad_norm": 0.054431673139333725,
      "learning_rate": 1.6239146666666667e-05,
      "loss": 0.0088,
      "step": 17630
    },
    {
      "epoch": 0.56448,
      "grad_norm": 0.008496927097439766,
      "learning_rate": 1.6237013333333336e-05,
      "loss": 0.0518,
      "step": 17640
    },
    {
      "epoch": 0.5648,
      "grad_norm": 0.037471357733011246,
      "learning_rate": 1.623488e-05,
      "loss": 0.0005,
      "step": 17650
    },
    {
      "epoch": 0.56512,
      "grad_norm": 0.009221923537552357,
      "learning_rate": 1.6232746666666667e-05,
      "loss": 0.0007,
      "step": 17660
    },
    {
      "epoch": 0.56544,
      "grad_norm": 0.009234665893018246,
      "learning_rate": 1.6230613333333332e-05,
      "loss": 0.0419,
      "step": 17670
    },
    {
      "epoch": 0.56576,
      "grad_norm": 0.00978864822536707,
      "learning_rate": 1.622848e-05,
      "loss": 0.0013,
      "step": 17680
    },
    {
      "epoch": 0.56608,
      "grad_norm": 0.012449204921722412,
      "learning_rate": 1.622634666666667e-05,
      "loss": 0.0005,
      "step": 17690
    },
    {
      "epoch": 0.5664,
      "grad_norm": 0.009232760407030582,
      "learning_rate": 1.6224213333333335e-05,
      "loss": 0.0006,
      "step": 17700
    },
    {
      "epoch": 0.56672,
      "grad_norm": 0.00645520118996501,
      "learning_rate": 1.6222080000000004e-05,
      "loss": 0.0005,
      "step": 17710
    },
    {
      "epoch": 0.56704,
      "grad_norm": 0.01742754690349102,
      "learning_rate": 1.621994666666667e-05,
      "loss": 0.0014,
      "step": 17720
    },
    {
      "epoch": 0.56736,
      "grad_norm": 0.004862730856984854,
      "learning_rate": 1.6217813333333335e-05,
      "loss": 0.0005,
      "step": 17730
    },
    {
      "epoch": 0.56768,
      "grad_norm": 0.005444931332021952,
      "learning_rate": 1.621568e-05,
      "loss": 0.0012,
      "step": 17740
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.01130647026002407,
      "learning_rate": 1.621354666666667e-05,
      "loss": 0.0006,
      "step": 17750
    },
    {
      "epoch": 0.56832,
      "grad_norm": 0.004404942970722914,
      "learning_rate": 1.6211413333333334e-05,
      "loss": 0.0007,
      "step": 17760
    },
    {
      "epoch": 0.56864,
      "grad_norm": 0.008590629324316978,
      "learning_rate": 1.620928e-05,
      "loss": 0.0419,
      "step": 17770
    },
    {
      "epoch": 0.56896,
      "grad_norm": 0.009971345774829388,
      "learning_rate": 1.6207146666666668e-05,
      "loss": 0.002,
      "step": 17780
    },
    {
      "epoch": 0.56928,
      "grad_norm": 0.01890561915934086,
      "learning_rate": 1.6205013333333334e-05,
      "loss": 0.0005,
      "step": 17790
    },
    {
      "epoch": 0.5696,
      "grad_norm": 0.005286029074341059,
      "learning_rate": 1.6202880000000002e-05,
      "loss": 0.0005,
      "step": 17800
    },
    {
      "epoch": 0.56992,
      "grad_norm": 0.010238283313810825,
      "learning_rate": 1.6200746666666668e-05,
      "loss": 0.0004,
      "step": 17810
    },
    {
      "epoch": 0.57024,
      "grad_norm": 0.0075180912390351295,
      "learning_rate": 1.6198613333333336e-05,
      "loss": 0.0056,
      "step": 17820
    },
    {
      "epoch": 0.57056,
      "grad_norm": 0.009645598009228706,
      "learning_rate": 1.6196480000000002e-05,
      "loss": 0.0082,
      "step": 17830
    },
    {
      "epoch": 0.57088,
      "grad_norm": 0.014012332074344158,
      "learning_rate": 1.6194346666666667e-05,
      "loss": 0.0005,
      "step": 17840
    },
    {
      "epoch": 0.5712,
      "grad_norm": 0.007015069015324116,
      "learning_rate": 1.6192213333333336e-05,
      "loss": 0.0006,
      "step": 17850
    },
    {
      "epoch": 0.57152,
      "grad_norm": 0.006870867218822241,
      "learning_rate": 1.619008e-05,
      "loss": 0.0006,
      "step": 17860
    },
    {
      "epoch": 0.57184,
      "grad_norm": 0.008737211115658283,
      "learning_rate": 1.6187946666666667e-05,
      "loss": 0.0566,
      "step": 17870
    },
    {
      "epoch": 0.57216,
      "grad_norm": 0.005723545327782631,
      "learning_rate": 1.6185813333333336e-05,
      "loss": 0.0008,
      "step": 17880
    },
    {
      "epoch": 0.57248,
      "grad_norm": 0.00872796680778265,
      "learning_rate": 1.618368e-05,
      "loss": 0.0301,
      "step": 17890
    },
    {
      "epoch": 0.5728,
      "grad_norm": 0.01784851774573326,
      "learning_rate": 1.6181546666666666e-05,
      "loss": 0.0005,
      "step": 17900
    },
    {
      "epoch": 0.57312,
      "grad_norm": 0.0029273969121277332,
      "learning_rate": 1.6179413333333335e-05,
      "loss": 0.0007,
      "step": 17910
    },
    {
      "epoch": 0.57344,
      "grad_norm": 0.0129149304702878,
      "learning_rate": 1.617728e-05,
      "loss": 0.0032,
      "step": 17920
    },
    {
      "epoch": 0.57376,
      "grad_norm": 0.007931580767035484,
      "learning_rate": 1.617514666666667e-05,
      "loss": 0.0006,
      "step": 17930
    },
    {
      "epoch": 0.57408,
      "grad_norm": 0.007445762865245342,
      "learning_rate": 1.6173013333333335e-05,
      "loss": 0.0309,
      "step": 17940
    },
    {
      "epoch": 0.5744,
      "grad_norm": 0.01032265741378069,
      "learning_rate": 1.6170880000000003e-05,
      "loss": 0.0004,
      "step": 17950
    },
    {
      "epoch": 0.57472,
      "grad_norm": 0.007033883593976498,
      "learning_rate": 1.616874666666667e-05,
      "loss": 0.0004,
      "step": 17960
    },
    {
      "epoch": 0.57504,
      "grad_norm": 0.005912238731980324,
      "learning_rate": 1.6166613333333334e-05,
      "loss": 0.0012,
      "step": 17970
    },
    {
      "epoch": 0.57536,
      "grad_norm": 0.027225282043218613,
      "learning_rate": 1.6164480000000003e-05,
      "loss": 0.0008,
      "step": 17980
    },
    {
      "epoch": 0.57568,
      "grad_norm": 0.008889248594641685,
      "learning_rate": 1.6162346666666668e-05,
      "loss": 0.0197,
      "step": 17990
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.02388838678598404,
      "learning_rate": 1.6160213333333334e-05,
      "loss": 0.0004,
      "step": 18000
    },
    {
      "epoch": 0.57632,
      "grad_norm": 0.04145796597003937,
      "learning_rate": 1.615808e-05,
      "loss": 0.0005,
      "step": 18010
    },
    {
      "epoch": 0.57664,
      "grad_norm": 0.006866331212222576,
      "learning_rate": 1.6155946666666668e-05,
      "loss": 0.0003,
      "step": 18020
    },
    {
      "epoch": 0.57696,
      "grad_norm": 0.04962507635354996,
      "learning_rate": 1.6153813333333333e-05,
      "loss": 0.0208,
      "step": 18030
    },
    {
      "epoch": 0.57728,
      "grad_norm": 0.005740475840866566,
      "learning_rate": 1.6151680000000002e-05,
      "loss": 0.0004,
      "step": 18040
    },
    {
      "epoch": 0.5776,
      "grad_norm": 0.007069256156682968,
      "learning_rate": 1.6149546666666667e-05,
      "loss": 0.0004,
      "step": 18050
    },
    {
      "epoch": 0.57792,
      "grad_norm": 0.00790198054164648,
      "learning_rate": 1.6147413333333336e-05,
      "loss": 0.0006,
      "step": 18060
    },
    {
      "epoch": 0.57824,
      "grad_norm": 0.005528813693672419,
      "learning_rate": 1.614528e-05,
      "loss": 0.0003,
      "step": 18070
    },
    {
      "epoch": 0.57856,
      "grad_norm": 0.006962733343243599,
      "learning_rate": 1.6143146666666667e-05,
      "loss": 0.0004,
      "step": 18080
    },
    {
      "epoch": 0.57888,
      "grad_norm": 0.00890094693750143,
      "learning_rate": 1.6141013333333336e-05,
      "loss": 0.0006,
      "step": 18090
    },
    {
      "epoch": 0.5792,
      "grad_norm": 0.006172149442136288,
      "learning_rate": 1.613888e-05,
      "loss": 0.0003,
      "step": 18100
    },
    {
      "epoch": 0.57952,
      "grad_norm": 0.004863081034272909,
      "learning_rate": 1.6136746666666666e-05,
      "loss": 0.0003,
      "step": 18110
    },
    {
      "epoch": 0.57984,
      "grad_norm": 0.10115894675254822,
      "learning_rate": 1.6134613333333335e-05,
      "loss": 0.0529,
      "step": 18120
    },
    {
      "epoch": 0.58016,
      "grad_norm": 0.010898931883275509,
      "learning_rate": 1.613248e-05,
      "loss": 0.0006,
      "step": 18130
    },
    {
      "epoch": 0.58048,
      "grad_norm": 0.008997765369713306,
      "learning_rate": 1.6130346666666666e-05,
      "loss": 0.0004,
      "step": 18140
    },
    {
      "epoch": 0.5808,
      "grad_norm": 0.010005610063672066,
      "learning_rate": 1.6128213333333335e-05,
      "loss": 0.0006,
      "step": 18150
    },
    {
      "epoch": 0.58112,
      "grad_norm": 0.005536671727895737,
      "learning_rate": 1.6126080000000003e-05,
      "loss": 0.0004,
      "step": 18160
    },
    {
      "epoch": 0.58144,
      "grad_norm": 0.6570156216621399,
      "learning_rate": 1.612394666666667e-05,
      "loss": 0.0016,
      "step": 18170
    },
    {
      "epoch": 0.58176,
      "grad_norm": 0.009800763800740242,
      "learning_rate": 1.6121813333333334e-05,
      "loss": 0.0003,
      "step": 18180
    },
    {
      "epoch": 0.58208,
      "grad_norm": 0.010150873102247715,
      "learning_rate": 1.6119680000000003e-05,
      "loss": 0.0035,
      "step": 18190
    },
    {
      "epoch": 0.5824,
      "grad_norm": 0.005635949317365885,
      "learning_rate": 1.6117546666666668e-05,
      "loss": 0.0003,
      "step": 18200
    },
    {
      "epoch": 0.58272,
      "grad_norm": 0.009979951195418835,
      "learning_rate": 1.6115413333333334e-05,
      "loss": 0.0507,
      "step": 18210
    },
    {
      "epoch": 0.58304,
      "grad_norm": 0.008815892040729523,
      "learning_rate": 1.6113280000000002e-05,
      "loss": 0.0335,
      "step": 18220
    },
    {
      "epoch": 0.58336,
      "grad_norm": 0.012523481622338295,
      "learning_rate": 1.6111146666666668e-05,
      "loss": 0.0005,
      "step": 18230
    },
    {
      "epoch": 0.58368,
      "grad_norm": 0.006829879246652126,
      "learning_rate": 1.6109013333333333e-05,
      "loss": 0.0003,
      "step": 18240
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.007962164469063282,
      "learning_rate": 1.6106880000000002e-05,
      "loss": 0.004,
      "step": 18250
    },
    {
      "epoch": 0.58432,
      "grad_norm": 0.029414596036076546,
      "learning_rate": 1.6104746666666667e-05,
      "loss": 0.0005,
      "step": 18260
    },
    {
      "epoch": 0.58464,
      "grad_norm": 0.009702688083052635,
      "learning_rate": 1.6102613333333336e-05,
      "loss": 0.0006,
      "step": 18270
    },
    {
      "epoch": 0.58496,
      "grad_norm": 1.7056615352630615,
      "learning_rate": 1.610048e-05,
      "loss": 0.0546,
      "step": 18280
    },
    {
      "epoch": 0.58528,
      "grad_norm": 0.00911217462271452,
      "learning_rate": 1.609834666666667e-05,
      "loss": 0.0379,
      "step": 18290
    },
    {
      "epoch": 0.5856,
      "grad_norm": 0.03677118197083473,
      "learning_rate": 1.6096213333333336e-05,
      "loss": 0.0008,
      "step": 18300
    },
    {
      "epoch": 0.58592,
      "grad_norm": 0.005281697027385235,
      "learning_rate": 1.609408e-05,
      "loss": 0.0008,
      "step": 18310
    },
    {
      "epoch": 0.58624,
      "grad_norm": 0.01769012212753296,
      "learning_rate": 1.609194666666667e-05,
      "loss": 0.0005,
      "step": 18320
    },
    {
      "epoch": 0.58656,
      "grad_norm": 1.7061008214950562,
      "learning_rate": 1.6089813333333335e-05,
      "loss": 0.0211,
      "step": 18330
    },
    {
      "epoch": 0.58688,
      "grad_norm": 0.00692414678633213,
      "learning_rate": 1.608768e-05,
      "loss": 0.0005,
      "step": 18340
    },
    {
      "epoch": 0.5872,
      "grad_norm": 0.0866098627448082,
      "learning_rate": 1.6085546666666666e-05,
      "loss": 0.0006,
      "step": 18350
    },
    {
      "epoch": 0.58752,
      "grad_norm": 0.005139687564224005,
      "learning_rate": 1.6083413333333335e-05,
      "loss": 0.0004,
      "step": 18360
    },
    {
      "epoch": 0.58784,
      "grad_norm": 0.005848530679941177,
      "learning_rate": 1.608128e-05,
      "loss": 0.0248,
      "step": 18370
    },
    {
      "epoch": 0.58816,
      "grad_norm": 0.030651504173874855,
      "learning_rate": 1.607914666666667e-05,
      "loss": 0.0005,
      "step": 18380
    },
    {
      "epoch": 0.58848,
      "grad_norm": 0.01591617986559868,
      "learning_rate": 1.6077013333333334e-05,
      "loss": 0.0005,
      "step": 18390
    },
    {
      "epoch": 0.5888,
      "grad_norm": 0.008082276210188866,
      "learning_rate": 1.6074880000000003e-05,
      "loss": 0.001,
      "step": 18400
    },
    {
      "epoch": 0.58912,
      "grad_norm": 0.007589387241750956,
      "learning_rate": 1.6072746666666668e-05,
      "loss": 0.0005,
      "step": 18410
    },
    {
      "epoch": 0.58944,
      "grad_norm": 0.0065714409574866295,
      "learning_rate": 1.6070613333333334e-05,
      "loss": 0.0059,
      "step": 18420
    },
    {
      "epoch": 0.58976,
      "grad_norm": 0.009183471091091633,
      "learning_rate": 1.6068480000000002e-05,
      "loss": 0.0021,
      "step": 18430
    },
    {
      "epoch": 0.59008,
      "grad_norm": 0.0185050368309021,
      "learning_rate": 1.6066346666666668e-05,
      "loss": 0.0005,
      "step": 18440
    },
    {
      "epoch": 0.5904,
      "grad_norm": 0.011019529774785042,
      "learning_rate": 1.6064213333333333e-05,
      "loss": 0.0008,
      "step": 18450
    },
    {
      "epoch": 0.59072,
      "grad_norm": 0.005762944463640451,
      "learning_rate": 1.6062080000000002e-05,
      "loss": 0.0004,
      "step": 18460
    },
    {
      "epoch": 0.59104,
      "grad_norm": 0.006066249217838049,
      "learning_rate": 1.6059946666666667e-05,
      "loss": 0.064,
      "step": 18470
    },
    {
      "epoch": 0.59136,
      "grad_norm": 0.007433176040649414,
      "learning_rate": 1.6057813333333333e-05,
      "loss": 0.0006,
      "step": 18480
    },
    {
      "epoch": 0.59168,
      "grad_norm": 0.0064173173159360886,
      "learning_rate": 1.605568e-05,
      "loss": 0.0068,
      "step": 18490
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.04674149304628372,
      "learning_rate": 1.6053546666666667e-05,
      "loss": 0.0098,
      "step": 18500
    },
    {
      "epoch": 0.59232,
      "grad_norm": 0.004816717002540827,
      "learning_rate": 1.6051413333333336e-05,
      "loss": 0.0009,
      "step": 18510
    },
    {
      "epoch": 0.59264,
      "grad_norm": 0.0041008261032402515,
      "learning_rate": 1.604928e-05,
      "loss": 0.0003,
      "step": 18520
    },
    {
      "epoch": 0.59296,
      "grad_norm": 0.0032351939007639885,
      "learning_rate": 1.604714666666667e-05,
      "loss": 0.0031,
      "step": 18530
    },
    {
      "epoch": 0.59328,
      "grad_norm": 0.008281230926513672,
      "learning_rate": 1.6045013333333335e-05,
      "loss": 0.0066,
      "step": 18540
    },
    {
      "epoch": 0.5936,
      "grad_norm": 0.024779457598924637,
      "learning_rate": 1.604288e-05,
      "loss": 0.0252,
      "step": 18550
    },
    {
      "epoch": 0.59392,
      "grad_norm": 0.004267206881195307,
      "learning_rate": 1.604074666666667e-05,
      "loss": 0.0024,
      "step": 18560
    },
    {
      "epoch": 0.59424,
      "grad_norm": 0.006742196623235941,
      "learning_rate": 1.6038613333333335e-05,
      "loss": 0.0004,
      "step": 18570
    },
    {
      "epoch": 0.59456,
      "grad_norm": 0.007538653910160065,
      "learning_rate": 1.603648e-05,
      "loss": 0.0338,
      "step": 18580
    },
    {
      "epoch": 0.59488,
      "grad_norm": 0.0060672578401863575,
      "learning_rate": 1.6034346666666665e-05,
      "loss": 0.0406,
      "step": 18590
    },
    {
      "epoch": 0.5952,
      "grad_norm": 0.010197840631008148,
      "learning_rate": 1.6032213333333334e-05,
      "loss": 0.0009,
      "step": 18600
    },
    {
      "epoch": 0.59552,
      "grad_norm": 0.019144820049405098,
      "learning_rate": 1.603008e-05,
      "loss": 0.0009,
      "step": 18610
    },
    {
      "epoch": 0.59584,
      "grad_norm": 0.009175346232950687,
      "learning_rate": 1.6027946666666668e-05,
      "loss": 0.0005,
      "step": 18620
    },
    {
      "epoch": 0.59616,
      "grad_norm": 0.013149399310350418,
      "learning_rate": 1.6025813333333337e-05,
      "loss": 0.001,
      "step": 18630
    },
    {
      "epoch": 0.59648,
      "grad_norm": 0.06719144433736801,
      "learning_rate": 1.6023680000000002e-05,
      "loss": 0.0008,
      "step": 18640
    },
    {
      "epoch": 0.5968,
      "grad_norm": 0.015859995037317276,
      "learning_rate": 1.6021546666666668e-05,
      "loss": 0.0009,
      "step": 18650
    },
    {
      "epoch": 0.59712,
      "grad_norm": 0.007520809303969145,
      "learning_rate": 1.6019413333333337e-05,
      "loss": 0.0003,
      "step": 18660
    },
    {
      "epoch": 0.59744,
      "grad_norm": 0.06773251295089722,
      "learning_rate": 1.6017280000000002e-05,
      "loss": 0.0011,
      "step": 18670
    },
    {
      "epoch": 0.59776,
      "grad_norm": 0.009148182347416878,
      "learning_rate": 1.6015146666666667e-05,
      "loss": 0.0015,
      "step": 18680
    },
    {
      "epoch": 0.59808,
      "grad_norm": 0.01253350730985403,
      "learning_rate": 1.6013013333333333e-05,
      "loss": 0.0544,
      "step": 18690
    },
    {
      "epoch": 0.5984,
      "grad_norm": 0.008781357668340206,
      "learning_rate": 1.601088e-05,
      "loss": 0.0004,
      "step": 18700
    },
    {
      "epoch": 0.59872,
      "grad_norm": 0.015915175899863243,
      "learning_rate": 1.6008746666666667e-05,
      "loss": 0.064,
      "step": 18710
    },
    {
      "epoch": 0.59904,
      "grad_norm": 0.008044206537306309,
      "learning_rate": 1.6006613333333336e-05,
      "loss": 0.0004,
      "step": 18720
    },
    {
      "epoch": 0.59936,
      "grad_norm": 0.03624079376459122,
      "learning_rate": 1.600448e-05,
      "loss": 0.0012,
      "step": 18730
    },
    {
      "epoch": 0.59968,
      "grad_norm": 0.008894356898963451,
      "learning_rate": 1.600234666666667e-05,
      "loss": 0.0534,
      "step": 18740
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.02296494133770466,
      "learning_rate": 1.6000213333333335e-05,
      "loss": 0.0007,
      "step": 18750
    },
    {
      "epoch": 0.60032,
      "grad_norm": 0.04124687239527702,
      "learning_rate": 1.599808e-05,
      "loss": 0.0005,
      "step": 18760
    },
    {
      "epoch": 0.60064,
      "grad_norm": 0.015925439074635506,
      "learning_rate": 1.599594666666667e-05,
      "loss": 0.0004,
      "step": 18770
    },
    {
      "epoch": 0.60096,
      "grad_norm": 0.014562596566975117,
      "learning_rate": 1.5993813333333335e-05,
      "loss": 0.0205,
      "step": 18780
    },
    {
      "epoch": 0.60128,
      "grad_norm": 0.016241008415818214,
      "learning_rate": 1.599168e-05,
      "loss": 0.0004,
      "step": 18790
    },
    {
      "epoch": 0.6016,
      "grad_norm": 4.755019664764404,
      "learning_rate": 1.598954666666667e-05,
      "loss": 0.0169,
      "step": 18800
    },
    {
      "epoch": 0.60192,
      "grad_norm": 0.05117999017238617,
      "learning_rate": 1.5987413333333334e-05,
      "loss": 0.0004,
      "step": 18810
    },
    {
      "epoch": 0.60224,
      "grad_norm": 0.05985076352953911,
      "learning_rate": 1.598528e-05,
      "loss": 0.0005,
      "step": 18820
    },
    {
      "epoch": 0.60256,
      "grad_norm": 5.8601813316345215,
      "learning_rate": 1.5983146666666668e-05,
      "loss": 0.016,
      "step": 18830
    },
    {
      "epoch": 0.60288,
      "grad_norm": 0.008502987213432789,
      "learning_rate": 1.5981013333333334e-05,
      "loss": 0.0004,
      "step": 18840
    },
    {
      "epoch": 0.6032,
      "grad_norm": 0.007010730914771557,
      "learning_rate": 1.5978880000000002e-05,
      "loss": 0.0238,
      "step": 18850
    },
    {
      "epoch": 0.60352,
      "grad_norm": 0.008032907731831074,
      "learning_rate": 1.5976746666666668e-05,
      "loss": 0.0003,
      "step": 18860
    },
    {
      "epoch": 0.60384,
      "grad_norm": 2.1164960861206055,
      "learning_rate": 1.5974613333333337e-05,
      "loss": 0.0056,
      "step": 18870
    },
    {
      "epoch": 0.60416,
      "grad_norm": 0.006241224706172943,
      "learning_rate": 1.5972480000000002e-05,
      "loss": 0.0004,
      "step": 18880
    },
    {
      "epoch": 0.60448,
      "grad_norm": 0.0038178334943950176,
      "learning_rate": 1.5970346666666667e-05,
      "loss": 0.0004,
      "step": 18890
    },
    {
      "epoch": 0.6048,
      "grad_norm": 3.5617809295654297,
      "learning_rate": 1.5968213333333336e-05,
      "loss": 0.0292,
      "step": 18900
    },
    {
      "epoch": 0.60512,
      "grad_norm": 0.01138173695653677,
      "learning_rate": 1.596608e-05,
      "loss": 0.0592,
      "step": 18910
    },
    {
      "epoch": 0.60544,
      "grad_norm": 0.004556574858725071,
      "learning_rate": 1.5963946666666667e-05,
      "loss": 0.0009,
      "step": 18920
    },
    {
      "epoch": 0.60576,
      "grad_norm": 0.05339987203478813,
      "learning_rate": 1.5961813333333332e-05,
      "loss": 0.0004,
      "step": 18930
    },
    {
      "epoch": 0.60608,
      "grad_norm": 0.01852697692811489,
      "learning_rate": 1.595968e-05,
      "loss": 0.0042,
      "step": 18940
    },
    {
      "epoch": 0.6064,
      "grad_norm": 0.006583413574844599,
      "learning_rate": 1.5957546666666666e-05,
      "loss": 0.057,
      "step": 18950
    },
    {
      "epoch": 0.60672,
      "grad_norm": 0.004904472269117832,
      "learning_rate": 1.5955413333333335e-05,
      "loss": 0.0004,
      "step": 18960
    },
    {
      "epoch": 0.60704,
      "grad_norm": 0.03507038205862045,
      "learning_rate": 1.595328e-05,
      "loss": 0.0226,
      "step": 18970
    },
    {
      "epoch": 0.60736,
      "grad_norm": 0.006267218850553036,
      "learning_rate": 1.595114666666667e-05,
      "loss": 0.0004,
      "step": 18980
    },
    {
      "epoch": 0.60768,
      "grad_norm": 0.0065050870180130005,
      "learning_rate": 1.5949013333333335e-05,
      "loss": 0.0012,
      "step": 18990
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.005078020039945841,
      "learning_rate": 1.5946880000000003e-05,
      "loss": 0.0004,
      "step": 19000
    },
    {
      "epoch": 0.60832,
      "grad_norm": 0.04511337727308273,
      "learning_rate": 1.594474666666667e-05,
      "loss": 0.0006,
      "step": 19010
    },
    {
      "epoch": 0.60864,
      "grad_norm": 0.007576251868158579,
      "learning_rate": 1.5942613333333334e-05,
      "loss": 0.0003,
      "step": 19020
    },
    {
      "epoch": 0.60896,
      "grad_norm": 2.0283756256103516,
      "learning_rate": 1.594048e-05,
      "loss": 0.0025,
      "step": 19030
    },
    {
      "epoch": 0.60928,
      "grad_norm": 0.01865973509848118,
      "learning_rate": 1.593834666666667e-05,
      "loss": 0.0004,
      "step": 19040
    },
    {
      "epoch": 0.6096,
      "grad_norm": 0.01624344475567341,
      "learning_rate": 1.5936213333333334e-05,
      "loss": 0.0003,
      "step": 19050
    },
    {
      "epoch": 0.60992,
      "grad_norm": 0.02659733034670353,
      "learning_rate": 1.593408e-05,
      "loss": 0.0008,
      "step": 19060
    },
    {
      "epoch": 0.61024,
      "grad_norm": 0.0044623808935284615,
      "learning_rate": 1.5931946666666668e-05,
      "loss": 0.0004,
      "step": 19070
    },
    {
      "epoch": 0.61056,
      "grad_norm": 0.004182884003967047,
      "learning_rate": 1.5929813333333337e-05,
      "loss": 0.0008,
      "step": 19080
    },
    {
      "epoch": 0.61088,
      "grad_norm": 0.013055682182312012,
      "learning_rate": 1.5927680000000002e-05,
      "loss": 0.0003,
      "step": 19090
    },
    {
      "epoch": 0.6112,
      "grad_norm": 0.007648404687643051,
      "learning_rate": 1.5925546666666667e-05,
      "loss": 0.0367,
      "step": 19100
    },
    {
      "epoch": 0.61152,
      "grad_norm": 0.0038278226274996996,
      "learning_rate": 1.5923413333333336e-05,
      "loss": 0.0005,
      "step": 19110
    },
    {
      "epoch": 0.61184,
      "grad_norm": 0.00462587084621191,
      "learning_rate": 1.592128e-05,
      "loss": 0.0534,
      "step": 19120
    },
    {
      "epoch": 0.61216,
      "grad_norm": 0.004139276687055826,
      "learning_rate": 1.5919146666666667e-05,
      "loss": 0.0121,
      "step": 19130
    },
    {
      "epoch": 0.61248,
      "grad_norm": 0.009951833635568619,
      "learning_rate": 1.5917013333333336e-05,
      "loss": 0.0319,
      "step": 19140
    },
    {
      "epoch": 0.6128,
      "grad_norm": 0.005257409065961838,
      "learning_rate": 1.591488e-05,
      "loss": 0.0003,
      "step": 19150
    },
    {
      "epoch": 0.61312,
      "grad_norm": 0.011839745566248894,
      "learning_rate": 1.5912746666666666e-05,
      "loss": 0.0003,
      "step": 19160
    },
    {
      "epoch": 0.61344,
      "grad_norm": 0.21200869977474213,
      "learning_rate": 1.5910613333333335e-05,
      "loss": 0.0009,
      "step": 19170
    },
    {
      "epoch": 0.61376,
      "grad_norm": 0.010425180196762085,
      "learning_rate": 1.590848e-05,
      "loss": 0.0701,
      "step": 19180
    },
    {
      "epoch": 0.61408,
      "grad_norm": 0.008880143985152245,
      "learning_rate": 1.590634666666667e-05,
      "loss": 0.0007,
      "step": 19190
    },
    {
      "epoch": 0.6144,
      "grad_norm": 0.006093055475503206,
      "learning_rate": 1.5904213333333335e-05,
      "loss": 0.0212,
      "step": 19200
    },
    {
      "epoch": 0.61472,
      "grad_norm": 0.00740625848993659,
      "learning_rate": 1.5902080000000003e-05,
      "loss": 0.001,
      "step": 19210
    },
    {
      "epoch": 0.61504,
      "grad_norm": 0.01615491509437561,
      "learning_rate": 1.589994666666667e-05,
      "loss": 0.0004,
      "step": 19220
    },
    {
      "epoch": 0.61536,
      "grad_norm": 0.00905455183237791,
      "learning_rate": 1.5897813333333334e-05,
      "loss": 0.0109,
      "step": 19230
    },
    {
      "epoch": 0.61568,
      "grad_norm": 0.01681612804532051,
      "learning_rate": 1.5895680000000003e-05,
      "loss": 0.0023,
      "step": 19240
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.009654941968619823,
      "learning_rate": 1.589354666666667e-05,
      "loss": 0.0129,
      "step": 19250
    },
    {
      "epoch": 0.61632,
      "grad_norm": 0.010534659959375858,
      "learning_rate": 1.5891413333333334e-05,
      "loss": 0.0003,
      "step": 19260
    },
    {
      "epoch": 0.61664,
      "grad_norm": 0.007346743252128363,
      "learning_rate": 1.588928e-05,
      "loss": 0.0003,
      "step": 19270
    },
    {
      "epoch": 0.61696,
      "grad_norm": 0.005553992465138435,
      "learning_rate": 1.5887146666666668e-05,
      "loss": 0.0004,
      "step": 19280
    },
    {
      "epoch": 0.61728,
      "grad_norm": 0.13406074047088623,
      "learning_rate": 1.5885013333333333e-05,
      "loss": 0.0006,
      "step": 19290
    },
    {
      "epoch": 0.6176,
      "grad_norm": 0.0081886425614357,
      "learning_rate": 1.5882880000000002e-05,
      "loss": 0.0005,
      "step": 19300
    },
    {
      "epoch": 0.61792,
      "grad_norm": 0.004646464716643095,
      "learning_rate": 1.5880746666666667e-05,
      "loss": 0.0019,
      "step": 19310
    },
    {
      "epoch": 0.61824,
      "grad_norm": 0.004390597343444824,
      "learning_rate": 1.5878613333333336e-05,
      "loss": 0.0005,
      "step": 19320
    },
    {
      "epoch": 0.61856,
      "grad_norm": 0.005479812156409025,
      "learning_rate": 1.587648e-05,
      "loss": 0.0414,
      "step": 19330
    },
    {
      "epoch": 0.61888,
      "grad_norm": 0.015538979321718216,
      "learning_rate": 1.587434666666667e-05,
      "loss": 0.0006,
      "step": 19340
    },
    {
      "epoch": 0.6192,
      "grad_norm": 0.005007006227970123,
      "learning_rate": 1.5872213333333336e-05,
      "loss": 0.0004,
      "step": 19350
    },
    {
      "epoch": 0.61952,
      "grad_norm": 0.00524883484467864,
      "learning_rate": 1.587008e-05,
      "loss": 0.0161,
      "step": 19360
    },
    {
      "epoch": 0.61984,
      "grad_norm": 0.37106627225875854,
      "learning_rate": 1.5867946666666666e-05,
      "loss": 0.0023,
      "step": 19370
    },
    {
      "epoch": 0.62016,
      "grad_norm": 0.013633234426379204,
      "learning_rate": 1.5865813333333335e-05,
      "loss": 0.0354,
      "step": 19380
    },
    {
      "epoch": 0.62048,
      "grad_norm": 0.004976000636816025,
      "learning_rate": 1.586368e-05,
      "loss": 0.0005,
      "step": 19390
    },
    {
      "epoch": 0.6208,
      "grad_norm": 0.012562704272568226,
      "learning_rate": 1.5861546666666666e-05,
      "loss": 0.0006,
      "step": 19400
    },
    {
      "epoch": 0.62112,
      "grad_norm": 0.008487639017403126,
      "learning_rate": 1.5859413333333335e-05,
      "loss": 0.0005,
      "step": 19410
    },
    {
      "epoch": 0.62144,
      "grad_norm": 0.019269756972789764,
      "learning_rate": 1.585728e-05,
      "loss": 0.0006,
      "step": 19420
    },
    {
      "epoch": 0.62176,
      "grad_norm": 0.010155814699828625,
      "learning_rate": 1.585514666666667e-05,
      "loss": 0.0005,
      "step": 19430
    },
    {
      "epoch": 0.62208,
      "grad_norm": 0.010310519486665726,
      "learning_rate": 1.5853013333333334e-05,
      "loss": 0.0006,
      "step": 19440
    },
    {
      "epoch": 0.6224,
      "grad_norm": 0.014579486101865768,
      "learning_rate": 1.5850880000000003e-05,
      "loss": 0.0004,
      "step": 19450
    },
    {
      "epoch": 0.62272,
      "grad_norm": 0.0062414477579295635,
      "learning_rate": 1.584874666666667e-05,
      "loss": 0.0004,
      "step": 19460
    },
    {
      "epoch": 0.62304,
      "grad_norm": 0.0060941847041249275,
      "learning_rate": 1.5846613333333334e-05,
      "loss": 0.0201,
      "step": 19470
    },
    {
      "epoch": 0.62336,
      "grad_norm": 0.007862451486289501,
      "learning_rate": 1.5844480000000002e-05,
      "loss": 0.0752,
      "step": 19480
    },
    {
      "epoch": 0.62368,
      "grad_norm": 0.006270629819482565,
      "learning_rate": 1.5842346666666668e-05,
      "loss": 0.0389,
      "step": 19490
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.003938135225325823,
      "learning_rate": 1.5840213333333333e-05,
      "loss": 0.0209,
      "step": 19500
    },
    {
      "epoch": 0.62432,
      "grad_norm": 0.007729065604507923,
      "learning_rate": 1.5838080000000002e-05,
      "loss": 0.0008,
      "step": 19510
    },
    {
      "epoch": 0.62464,
      "grad_norm": 0.25307705998420715,
      "learning_rate": 1.5835946666666667e-05,
      "loss": 0.0008,
      "step": 19520
    },
    {
      "epoch": 0.62496,
      "grad_norm": 0.011925549246370792,
      "learning_rate": 1.5833813333333333e-05,
      "loss": 0.0004,
      "step": 19530
    },
    {
      "epoch": 0.62528,
      "grad_norm": 0.10505592823028564,
      "learning_rate": 1.583168e-05,
      "loss": 0.0037,
      "step": 19540
    },
    {
      "epoch": 0.6256,
      "grad_norm": 0.0049987006932497025,
      "learning_rate": 1.582954666666667e-05,
      "loss": 0.0004,
      "step": 19550
    },
    {
      "epoch": 0.62592,
      "grad_norm": 0.009198617190122604,
      "learning_rate": 1.5827413333333336e-05,
      "loss": 0.0359,
      "step": 19560
    },
    {
      "epoch": 0.62624,
      "grad_norm": 0.01116827130317688,
      "learning_rate": 1.582528e-05,
      "loss": 0.0594,
      "step": 19570
    },
    {
      "epoch": 0.62656,
      "grad_norm": 0.009103797376155853,
      "learning_rate": 1.582314666666667e-05,
      "loss": 0.051,
      "step": 19580
    },
    {
      "epoch": 0.62688,
      "grad_norm": 1.852043628692627,
      "learning_rate": 1.5821013333333335e-05,
      "loss": 0.0032,
      "step": 19590
    },
    {
      "epoch": 0.6272,
      "grad_norm": 0.4995514154434204,
      "learning_rate": 1.581888e-05,
      "loss": 0.0036,
      "step": 19600
    },
    {
      "epoch": 0.62752,
      "grad_norm": 0.008361341431736946,
      "learning_rate": 1.5816746666666666e-05,
      "loss": 0.0008,
      "step": 19610
    },
    {
      "epoch": 0.62784,
      "grad_norm": 0.007644224911928177,
      "learning_rate": 1.5814613333333335e-05,
      "loss": 0.0006,
      "step": 19620
    },
    {
      "epoch": 0.62816,
      "grad_norm": 0.014050119556486607,
      "learning_rate": 1.581248e-05,
      "loss": 0.0007,
      "step": 19630
    },
    {
      "epoch": 0.62848,
      "grad_norm": 0.008553278632462025,
      "learning_rate": 1.581034666666667e-05,
      "loss": 0.0166,
      "step": 19640
    },
    {
      "epoch": 0.6288,
      "grad_norm": 0.03307892382144928,
      "learning_rate": 1.5808213333333334e-05,
      "loss": 0.0005,
      "step": 19650
    },
    {
      "epoch": 0.62912,
      "grad_norm": 0.01733812317252159,
      "learning_rate": 1.5806080000000003e-05,
      "loss": 0.0011,
      "step": 19660
    },
    {
      "epoch": 0.62944,
      "grad_norm": 0.009120369330048561,
      "learning_rate": 1.580394666666667e-05,
      "loss": 0.0003,
      "step": 19670
    },
    {
      "epoch": 0.62976,
      "grad_norm": 0.007438657805323601,
      "learning_rate": 1.5801813333333337e-05,
      "loss": 0.0007,
      "step": 19680
    },
    {
      "epoch": 0.63008,
      "grad_norm": 0.07433135062456131,
      "learning_rate": 1.5799680000000003e-05,
      "loss": 0.0006,
      "step": 19690
    },
    {
      "epoch": 0.6304,
      "grad_norm": 0.014307145029306412,
      "learning_rate": 1.5797546666666668e-05,
      "loss": 0.0041,
      "step": 19700
    },
    {
      "epoch": 0.63072,
      "grad_norm": 0.005450793541967869,
      "learning_rate": 1.5795413333333333e-05,
      "loss": 0.0004,
      "step": 19710
    },
    {
      "epoch": 0.63104,
      "grad_norm": 0.05302194133400917,
      "learning_rate": 1.5793280000000002e-05,
      "loss": 0.0065,
      "step": 19720
    },
    {
      "epoch": 0.63136,
      "grad_norm": 0.011728024110198021,
      "learning_rate": 1.5791146666666667e-05,
      "loss": 0.0004,
      "step": 19730
    },
    {
      "epoch": 0.63168,
      "grad_norm": 0.003929913975298405,
      "learning_rate": 1.5789013333333333e-05,
      "loss": 0.0003,
      "step": 19740
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.0077598015777766705,
      "learning_rate": 1.578688e-05,
      "loss": 0.0437,
      "step": 19750
    },
    {
      "epoch": 0.63232,
      "grad_norm": 2.761335849761963,
      "learning_rate": 1.5784746666666667e-05,
      "loss": 0.0598,
      "step": 19760
    },
    {
      "epoch": 0.63264,
      "grad_norm": 0.009572653099894524,
      "learning_rate": 1.5782613333333336e-05,
      "loss": 0.0363,
      "step": 19770
    },
    {
      "epoch": 0.63296,
      "grad_norm": 0.33602622151374817,
      "learning_rate": 1.578048e-05,
      "loss": 0.0011,
      "step": 19780
    },
    {
      "epoch": 0.63328,
      "grad_norm": 3.8836822509765625,
      "learning_rate": 1.577834666666667e-05,
      "loss": 0.0228,
      "step": 19790
    },
    {
      "epoch": 0.6336,
      "grad_norm": 0.009802867658436298,
      "learning_rate": 1.5776213333333335e-05,
      "loss": 0.001,
      "step": 19800
    },
    {
      "epoch": 0.63392,
      "grad_norm": 0.014940383844077587,
      "learning_rate": 1.577408e-05,
      "loss": 0.0347,
      "step": 19810
    },
    {
      "epoch": 0.63424,
      "grad_norm": 0.015333499759435654,
      "learning_rate": 1.577194666666667e-05,
      "loss": 0.0321,
      "step": 19820
    },
    {
      "epoch": 0.63456,
      "grad_norm": 0.009325142949819565,
      "learning_rate": 1.5769813333333335e-05,
      "loss": 0.0598,
      "step": 19830
    },
    {
      "epoch": 0.63488,
      "grad_norm": 0.0063213868997991085,
      "learning_rate": 1.576768e-05,
      "loss": 0.0007,
      "step": 19840
    },
    {
      "epoch": 0.6352,
      "grad_norm": 0.019086947664618492,
      "learning_rate": 1.576554666666667e-05,
      "loss": 0.0505,
      "step": 19850
    },
    {
      "epoch": 0.63552,
      "grad_norm": 0.011027953587472439,
      "learning_rate": 1.5763413333333334e-05,
      "loss": 0.0015,
      "step": 19860
    },
    {
      "epoch": 0.63584,
      "grad_norm": 0.006147363223135471,
      "learning_rate": 1.576128e-05,
      "loss": 0.0006,
      "step": 19870
    },
    {
      "epoch": 0.63616,
      "grad_norm": 0.015838857740163803,
      "learning_rate": 1.575914666666667e-05,
      "loss": 0.0007,
      "step": 19880
    },
    {
      "epoch": 0.63648,
      "grad_norm": 0.010699336417019367,
      "learning_rate": 1.5757013333333334e-05,
      "loss": 0.0007,
      "step": 19890
    },
    {
      "epoch": 0.6368,
      "grad_norm": 0.0711754783987999,
      "learning_rate": 1.5754880000000003e-05,
      "loss": 0.0238,
      "step": 19900
    },
    {
      "epoch": 0.63712,
      "grad_norm": 0.02141333557665348,
      "learning_rate": 1.5752746666666668e-05,
      "loss": 0.0018,
      "step": 19910
    },
    {
      "epoch": 0.63744,
      "grad_norm": 0.02005387470126152,
      "learning_rate": 1.5750613333333337e-05,
      "loss": 0.0005,
      "step": 19920
    },
    {
      "epoch": 0.63776,
      "grad_norm": 0.015684014186263084,
      "learning_rate": 1.5748480000000002e-05,
      "loss": 0.0007,
      "step": 19930
    },
    {
      "epoch": 0.63808,
      "grad_norm": 0.013132380321621895,
      "learning_rate": 1.5746346666666667e-05,
      "loss": 0.0018,
      "step": 19940
    },
    {
      "epoch": 0.6384,
      "grad_norm": 0.030742764472961426,
      "learning_rate": 1.5744213333333333e-05,
      "loss": 0.0005,
      "step": 19950
    },
    {
      "epoch": 0.63872,
      "grad_norm": 0.0082556689158082,
      "learning_rate": 1.574208e-05,
      "loss": 0.002,
      "step": 19960
    },
    {
      "epoch": 0.63904,
      "grad_norm": 0.00921507179737091,
      "learning_rate": 1.5739946666666667e-05,
      "loss": 0.0008,
      "step": 19970
    },
    {
      "epoch": 0.63936,
      "grad_norm": 0.006067337468266487,
      "learning_rate": 1.5737813333333332e-05,
      "loss": 0.0005,
      "step": 19980
    },
    {
      "epoch": 0.63968,
      "grad_norm": 0.007960360497236252,
      "learning_rate": 1.573568e-05,
      "loss": 0.0011,
      "step": 19990
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.010110598057508469,
      "learning_rate": 1.5733546666666666e-05,
      "loss": 0.0004,
      "step": 20000
    },
    {
      "epoch": 0.64032,
      "grad_norm": 0.06811469793319702,
      "learning_rate": 1.5731413333333335e-05,
      "loss": 0.044,
      "step": 20010
    },
    {
      "epoch": 0.64064,
      "grad_norm": 4.270623207092285,
      "learning_rate": 1.5729280000000004e-05,
      "loss": 0.0489,
      "step": 20020
    },
    {
      "epoch": 0.64096,
      "grad_norm": 0.04232225939631462,
      "learning_rate": 1.572714666666667e-05,
      "loss": 0.0048,
      "step": 20030
    },
    {
      "epoch": 0.64128,
      "grad_norm": 0.012299972586333752,
      "learning_rate": 1.5725013333333335e-05,
      "loss": 0.001,
      "step": 20040
    },
    {
      "epoch": 0.6416,
      "grad_norm": 0.011480435729026794,
      "learning_rate": 1.572288e-05,
      "loss": 0.0006,
      "step": 20050
    },
    {
      "epoch": 0.64192,
      "grad_norm": 0.041912950575351715,
      "learning_rate": 1.572074666666667e-05,
      "loss": 0.0004,
      "step": 20060
    },
    {
      "epoch": 0.64224,
      "grad_norm": 0.012646188959479332,
      "learning_rate": 1.5718613333333334e-05,
      "loss": 0.0004,
      "step": 20070
    },
    {
      "epoch": 0.64256,
      "grad_norm": 0.004684716463088989,
      "learning_rate": 1.571648e-05,
      "loss": 0.0004,
      "step": 20080
    },
    {
      "epoch": 0.64288,
      "grad_norm": 0.013922472484409809,
      "learning_rate": 1.571434666666667e-05,
      "loss": 0.0008,
      "step": 20090
    },
    {
      "epoch": 0.6432,
      "grad_norm": 0.005573829635977745,
      "learning_rate": 1.5712213333333334e-05,
      "loss": 0.0004,
      "step": 20100
    },
    {
      "epoch": 0.64352,
      "grad_norm": 0.016661319881677628,
      "learning_rate": 1.5710080000000003e-05,
      "loss": 0.0008,
      "step": 20110
    },
    {
      "epoch": 0.64384,
      "grad_norm": 0.012339821085333824,
      "learning_rate": 1.5707946666666668e-05,
      "loss": 0.051,
      "step": 20120
    },
    {
      "epoch": 0.64416,
      "grad_norm": 0.006996355950832367,
      "learning_rate": 1.5705813333333337e-05,
      "loss": 0.0312,
      "step": 20130
    },
    {
      "epoch": 0.64448,
      "grad_norm": 0.005869621876627207,
      "learning_rate": 1.5703680000000002e-05,
      "loss": 0.0004,
      "step": 20140
    },
    {
      "epoch": 0.6448,
      "grad_norm": 0.11236998438835144,
      "learning_rate": 1.5701546666666667e-05,
      "loss": 0.0111,
      "step": 20150
    },
    {
      "epoch": 0.64512,
      "grad_norm": 0.018409475684165955,
      "learning_rate": 1.5699413333333336e-05,
      "loss": 0.0133,
      "step": 20160
    },
    {
      "epoch": 0.64544,
      "grad_norm": 0.006976770702749491,
      "learning_rate": 1.569728e-05,
      "loss": 0.0265,
      "step": 20170
    },
    {
      "epoch": 0.64576,
      "grad_norm": 0.008388001471757889,
      "learning_rate": 1.5695146666666667e-05,
      "loss": 0.0004,
      "step": 20180
    },
    {
      "epoch": 0.64608,
      "grad_norm": 0.00841684639453888,
      "learning_rate": 1.5693013333333336e-05,
      "loss": 0.0008,
      "step": 20190
    },
    {
      "epoch": 0.6464,
      "grad_norm": 0.008569392375648022,
      "learning_rate": 1.569088e-05,
      "loss": 0.0209,
      "step": 20200
    },
    {
      "epoch": 0.64672,
      "grad_norm": 0.007989926263689995,
      "learning_rate": 1.5688746666666667e-05,
      "loss": 0.0005,
      "step": 20210
    },
    {
      "epoch": 0.64704,
      "grad_norm": 0.017318541184067726,
      "learning_rate": 1.5686613333333335e-05,
      "loss": 0.043,
      "step": 20220
    },
    {
      "epoch": 0.64736,
      "grad_norm": 0.01279289461672306,
      "learning_rate": 1.568448e-05,
      "loss": 0.0101,
      "step": 20230
    },
    {
      "epoch": 0.64768,
      "grad_norm": 0.0074513377621769905,
      "learning_rate": 1.568234666666667e-05,
      "loss": 0.0005,
      "step": 20240
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.010840976610779762,
      "learning_rate": 1.5680213333333335e-05,
      "loss": 0.0006,
      "step": 20250
    },
    {
      "epoch": 0.64832,
      "grad_norm": 0.007881375961005688,
      "learning_rate": 1.5678080000000004e-05,
      "loss": 0.0216,
      "step": 20260
    },
    {
      "epoch": 0.64864,
      "grad_norm": 0.024973025545477867,
      "learning_rate": 1.567594666666667e-05,
      "loss": 0.0024,
      "step": 20270
    },
    {
      "epoch": 0.64896,
      "grad_norm": 0.017369717359542847,
      "learning_rate": 1.5673813333333334e-05,
      "loss": 0.0008,
      "step": 20280
    },
    {
      "epoch": 0.64928,
      "grad_norm": 0.006580080837011337,
      "learning_rate": 1.567168e-05,
      "loss": 0.0005,
      "step": 20290
    },
    {
      "epoch": 0.6496,
      "grad_norm": 0.008799764327704906,
      "learning_rate": 1.566954666666667e-05,
      "loss": 0.0004,
      "step": 20300
    },
    {
      "epoch": 0.64992,
      "grad_norm": 0.011193593963980675,
      "learning_rate": 1.5667413333333334e-05,
      "loss": 0.0616,
      "step": 20310
    },
    {
      "epoch": 0.65024,
      "grad_norm": 0.007295617833733559,
      "learning_rate": 1.566528e-05,
      "loss": 0.0005,
      "step": 20320
    },
    {
      "epoch": 0.65056,
      "grad_norm": 0.08301297575235367,
      "learning_rate": 1.5663146666666668e-05,
      "loss": 0.0005,
      "step": 20330
    },
    {
      "epoch": 0.65088,
      "grad_norm": 0.008680988103151321,
      "learning_rate": 1.5661013333333333e-05,
      "loss": 0.0307,
      "step": 20340
    },
    {
      "epoch": 0.6512,
      "grad_norm": 0.019287409260869026,
      "learning_rate": 1.5658880000000002e-05,
      "loss": 0.0005,
      "step": 20350
    },
    {
      "epoch": 0.65152,
      "grad_norm": 0.008633282035589218,
      "learning_rate": 1.5656746666666667e-05,
      "loss": 0.0005,
      "step": 20360
    },
    {
      "epoch": 0.65184,
      "grad_norm": 0.01595495641231537,
      "learning_rate": 1.5654613333333336e-05,
      "loss": 0.0005,
      "step": 20370
    },
    {
      "epoch": 0.65216,
      "grad_norm": 2.3450233936309814,
      "learning_rate": 1.565248e-05,
      "loss": 0.0042,
      "step": 20380
    },
    {
      "epoch": 0.65248,
      "grad_norm": 0.007129249628633261,
      "learning_rate": 1.5650346666666667e-05,
      "loss": 0.0029,
      "step": 20390
    },
    {
      "epoch": 0.6528,
      "grad_norm": 0.005892185959964991,
      "learning_rate": 1.5648213333333336e-05,
      "loss": 0.0116,
      "step": 20400
    },
    {
      "epoch": 0.65312,
      "grad_norm": 0.004277904983609915,
      "learning_rate": 1.564608e-05,
      "loss": 0.0004,
      "step": 20410
    },
    {
      "epoch": 0.65344,
      "grad_norm": 0.013838757760822773,
      "learning_rate": 1.5643946666666667e-05,
      "loss": 0.0088,
      "step": 20420
    },
    {
      "epoch": 0.65376,
      "grad_norm": 0.014322788454592228,
      "learning_rate": 1.5641813333333335e-05,
      "loss": 0.0243,
      "step": 20430
    },
    {
      "epoch": 0.65408,
      "grad_norm": 0.006057289894670248,
      "learning_rate": 1.563968e-05,
      "loss": 0.0004,
      "step": 20440
    },
    {
      "epoch": 0.6544,
      "grad_norm": 0.051521606743335724,
      "learning_rate": 1.5637546666666666e-05,
      "loss": 0.0004,
      "step": 20450
    },
    {
      "epoch": 0.65472,
      "grad_norm": 0.005283738486468792,
      "learning_rate": 1.5635413333333335e-05,
      "loss": 0.0011,
      "step": 20460
    },
    {
      "epoch": 0.65504,
      "grad_norm": 0.005187489092350006,
      "learning_rate": 1.563328e-05,
      "loss": 0.0011,
      "step": 20470
    },
    {
      "epoch": 0.65536,
      "grad_norm": 0.005429734010249376,
      "learning_rate": 1.563114666666667e-05,
      "loss": 0.0004,
      "step": 20480
    },
    {
      "epoch": 0.65568,
      "grad_norm": 0.0077198646031320095,
      "learning_rate": 1.5629013333333334e-05,
      "loss": 0.0004,
      "step": 20490
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.012644177302718163,
      "learning_rate": 1.5626880000000003e-05,
      "loss": 0.028,
      "step": 20500
    },
    {
      "epoch": 0.65632,
      "grad_norm": 0.008689756505191326,
      "learning_rate": 1.562474666666667e-05,
      "loss": 0.0006,
      "step": 20510
    },
    {
      "epoch": 0.65664,
      "grad_norm": 0.007687509525567293,
      "learning_rate": 1.5622613333333334e-05,
      "loss": 0.0004,
      "step": 20520
    },
    {
      "epoch": 0.65696,
      "grad_norm": 0.003131293458864093,
      "learning_rate": 1.5620480000000003e-05,
      "loss": 0.0002,
      "step": 20530
    },
    {
      "epoch": 0.65728,
      "grad_norm": 3.4591946601867676,
      "learning_rate": 1.5618346666666668e-05,
      "loss": 0.0079,
      "step": 20540
    },
    {
      "epoch": 0.6576,
      "grad_norm": 0.003213671036064625,
      "learning_rate": 1.5616213333333333e-05,
      "loss": 0.0086,
      "step": 20550
    },
    {
      "epoch": 0.65792,
      "grad_norm": 0.021975336596369743,
      "learning_rate": 1.561408e-05,
      "loss": 0.0004,
      "step": 20560
    },
    {
      "epoch": 0.65824,
      "grad_norm": 0.0125304339453578,
      "learning_rate": 1.5611946666666668e-05,
      "loss": 0.0018,
      "step": 20570
    },
    {
      "epoch": 0.65856,
      "grad_norm": 0.06037638336420059,
      "learning_rate": 1.5609813333333336e-05,
      "loss": 0.0004,
      "step": 20580
    },
    {
      "epoch": 0.65888,
      "grad_norm": 0.002913521137088537,
      "learning_rate": 1.560768e-05,
      "loss": 0.0382,
      "step": 20590
    },
    {
      "epoch": 0.6592,
      "grad_norm": 0.004125342704355717,
      "learning_rate": 1.560554666666667e-05,
      "loss": 0.0003,
      "step": 20600
    },
    {
      "epoch": 0.65952,
      "grad_norm": 0.006463692057877779,
      "learning_rate": 1.5603413333333336e-05,
      "loss": 0.0003,
      "step": 20610
    },
    {
      "epoch": 0.65984,
      "grad_norm": 0.0055312118493020535,
      "learning_rate": 1.560128e-05,
      "loss": 0.0003,
      "step": 20620
    },
    {
      "epoch": 0.66016,
      "grad_norm": 0.006551711354404688,
      "learning_rate": 1.5599146666666667e-05,
      "loss": 0.0006,
      "step": 20630
    },
    {
      "epoch": 0.66048,
      "grad_norm": 0.0030491380020976067,
      "learning_rate": 1.5597013333333335e-05,
      "loss": 0.0005,
      "step": 20640
    },
    {
      "epoch": 0.6608,
      "grad_norm": 0.004051359836012125,
      "learning_rate": 1.559488e-05,
      "loss": 0.0003,
      "step": 20650
    },
    {
      "epoch": 0.66112,
      "grad_norm": 0.0044152927584946156,
      "learning_rate": 1.5592746666666666e-05,
      "loss": 0.0004,
      "step": 20660
    },
    {
      "epoch": 0.66144,
      "grad_norm": 0.0050193509086966515,
      "learning_rate": 1.5590613333333335e-05,
      "loss": 0.0002,
      "step": 20670
    },
    {
      "epoch": 0.66176,
      "grad_norm": 0.05972805991768837,
      "learning_rate": 1.558848e-05,
      "loss": 0.0003,
      "step": 20680
    },
    {
      "epoch": 0.66208,
      "grad_norm": 0.012664572335779667,
      "learning_rate": 1.558634666666667e-05,
      "loss": 0.0003,
      "step": 20690
    },
    {
      "epoch": 0.6624,
      "grad_norm": 0.0032565188594162464,
      "learning_rate": 1.5584213333333334e-05,
      "loss": 0.0003,
      "step": 20700
    },
    {
      "epoch": 0.66272,
      "grad_norm": 0.00545291043817997,
      "learning_rate": 1.5582080000000003e-05,
      "loss": 0.0441,
      "step": 20710
    },
    {
      "epoch": 0.66304,
      "grad_norm": 5.6937432289123535,
      "learning_rate": 1.557994666666667e-05,
      "loss": 0.0131,
      "step": 20720
    },
    {
      "epoch": 0.66336,
      "grad_norm": 0.006865277886390686,
      "learning_rate": 1.5577813333333334e-05,
      "loss": 0.0349,
      "step": 20730
    },
    {
      "epoch": 0.66368,
      "grad_norm": 0.007679390721023083,
      "learning_rate": 1.5575680000000003e-05,
      "loss": 0.0097,
      "step": 20740
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.0057571143843233585,
      "learning_rate": 1.5573546666666668e-05,
      "loss": 0.0004,
      "step": 20750
    },
    {
      "epoch": 0.66432,
      "grad_norm": 0.005705915857106447,
      "learning_rate": 1.5571413333333333e-05,
      "loss": 0.0002,
      "step": 20760
    },
    {
      "epoch": 0.66464,
      "grad_norm": 0.002830925164744258,
      "learning_rate": 1.5569280000000002e-05,
      "loss": 0.0003,
      "step": 20770
    },
    {
      "epoch": 0.66496,
      "grad_norm": 0.004297350067645311,
      "learning_rate": 1.5567146666666668e-05,
      "loss": 0.0508,
      "step": 20780
    },
    {
      "epoch": 0.66528,
      "grad_norm": 0.005163885187357664,
      "learning_rate": 1.5565013333333333e-05,
      "loss": 0.0004,
      "step": 20790
    },
    {
      "epoch": 0.6656,
      "grad_norm": 0.02080851048231125,
      "learning_rate": 1.556288e-05,
      "loss": 0.0595,
      "step": 20800
    },
    {
      "epoch": 0.66592,
      "grad_norm": 0.015245436690747738,
      "learning_rate": 1.5560746666666667e-05,
      "loss": 0.036,
      "step": 20810
    },
    {
      "epoch": 0.66624,
      "grad_norm": 2.168010950088501,
      "learning_rate": 1.5558613333333336e-05,
      "loss": 0.0441,
      "step": 20820
    },
    {
      "epoch": 0.66656,
      "grad_norm": 0.0040189106948673725,
      "learning_rate": 1.555648e-05,
      "loss": 0.0003,
      "step": 20830
    },
    {
      "epoch": 0.66688,
      "grad_norm": 0.013687538914382458,
      "learning_rate": 1.555434666666667e-05,
      "loss": 0.0008,
      "step": 20840
    },
    {
      "epoch": 0.6672,
      "grad_norm": 0.006644971668720245,
      "learning_rate": 1.5552213333333335e-05,
      "loss": 0.0006,
      "step": 20850
    },
    {
      "epoch": 0.66752,
      "grad_norm": 0.007424729876220226,
      "learning_rate": 1.555008e-05,
      "loss": 0.0003,
      "step": 20860
    },
    {
      "epoch": 0.66784,
      "grad_norm": 0.00887062307447195,
      "learning_rate": 1.554794666666667e-05,
      "loss": 0.0004,
      "step": 20870
    },
    {
      "epoch": 0.66816,
      "grad_norm": 0.011150720529258251,
      "learning_rate": 1.5545813333333335e-05,
      "loss": 0.0282,
      "step": 20880
    },
    {
      "epoch": 0.66848,
      "grad_norm": 0.008178566582500935,
      "learning_rate": 1.554368e-05,
      "loss": 0.0202,
      "step": 20890
    },
    {
      "epoch": 0.6688,
      "grad_norm": 0.004835185129195452,
      "learning_rate": 1.5541546666666666e-05,
      "loss": 0.0003,
      "step": 20900
    },
    {
      "epoch": 0.66912,
      "grad_norm": 0.0043670074082911015,
      "learning_rate": 1.5539413333333334e-05,
      "loss": 0.05,
      "step": 20910
    },
    {
      "epoch": 0.66944,
      "grad_norm": 0.1375492960214615,
      "learning_rate": 1.553728e-05,
      "loss": 0.0008,
      "step": 20920
    },
    {
      "epoch": 0.66976,
      "grad_norm": 0.3062613606452942,
      "learning_rate": 1.553514666666667e-05,
      "loss": 0.0007,
      "step": 20930
    },
    {
      "epoch": 0.67008,
      "grad_norm": 3.5840554237365723,
      "learning_rate": 1.5533013333333334e-05,
      "loss": 0.0224,
      "step": 20940
    },
    {
      "epoch": 0.6704,
      "grad_norm": 0.009800998494029045,
      "learning_rate": 1.5530880000000003e-05,
      "loss": 0.0015,
      "step": 20950
    },
    {
      "epoch": 0.67072,
      "grad_norm": 0.004924944136291742,
      "learning_rate": 1.5528746666666668e-05,
      "loss": 0.0018,
      "step": 20960
    },
    {
      "epoch": 0.67104,
      "grad_norm": 0.006139600183814764,
      "learning_rate": 1.5526613333333333e-05,
      "loss": 0.0887,
      "step": 20970
    },
    {
      "epoch": 0.67136,
      "grad_norm": 0.012386550195515156,
      "learning_rate": 1.5524480000000002e-05,
      "loss": 0.0003,
      "step": 20980
    },
    {
      "epoch": 0.67168,
      "grad_norm": 3.578536033630371,
      "learning_rate": 1.5522346666666668e-05,
      "loss": 0.0513,
      "step": 20990
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.009800258092582226,
      "learning_rate": 1.5520213333333333e-05,
      "loss": 0.0005,
      "step": 21000
    },
    {
      "epoch": 0.67232,
      "grad_norm": 0.0054434859193861485,
      "learning_rate": 1.5518080000000002e-05,
      "loss": 0.0006,
      "step": 21010
    },
    {
      "epoch": 0.67264,
      "grad_norm": 0.0101222088560462,
      "learning_rate": 1.5515946666666667e-05,
      "loss": 0.053,
      "step": 21020
    },
    {
      "epoch": 0.67296,
      "grad_norm": 0.015529985539615154,
      "learning_rate": 1.5513813333333332e-05,
      "loss": 0.0005,
      "step": 21030
    },
    {
      "epoch": 0.67328,
      "grad_norm": 0.021708572283387184,
      "learning_rate": 1.551168e-05,
      "loss": 0.0072,
      "step": 21040
    },
    {
      "epoch": 0.6736,
      "grad_norm": 0.331199049949646,
      "learning_rate": 1.550954666666667e-05,
      "loss": 0.0008,
      "step": 21050
    },
    {
      "epoch": 0.67392,
      "grad_norm": 0.042445577681064606,
      "learning_rate": 1.5507413333333335e-05,
      "loss": 0.0005,
      "step": 21060
    },
    {
      "epoch": 0.67424,
      "grad_norm": 0.02456316538155079,
      "learning_rate": 1.550528e-05,
      "loss": 0.0005,
      "step": 21070
    },
    {
      "epoch": 0.67456,
      "grad_norm": 2.7213919162750244,
      "learning_rate": 1.550314666666667e-05,
      "loss": 0.0082,
      "step": 21080
    },
    {
      "epoch": 0.67488,
      "grad_norm": 0.008098562248051167,
      "learning_rate": 1.5501013333333335e-05,
      "loss": 0.0007,
      "step": 21090
    },
    {
      "epoch": 0.6752,
      "grad_norm": 0.0036718319170176983,
      "learning_rate": 1.549888e-05,
      "loss": 0.0009,
      "step": 21100
    },
    {
      "epoch": 0.67552,
      "grad_norm": 0.013729169964790344,
      "learning_rate": 1.549674666666667e-05,
      "loss": 0.0004,
      "step": 21110
    },
    {
      "epoch": 0.67584,
      "grad_norm": 0.009409824386239052,
      "learning_rate": 1.5494613333333334e-05,
      "loss": 0.0475,
      "step": 21120
    },
    {
      "epoch": 0.67616,
      "grad_norm": 0.008000656962394714,
      "learning_rate": 1.549248e-05,
      "loss": 0.0194,
      "step": 21130
    },
    {
      "epoch": 0.67648,
      "grad_norm": 0.009829680435359478,
      "learning_rate": 1.549034666666667e-05,
      "loss": 0.0007,
      "step": 21140
    },
    {
      "epoch": 0.6768,
      "grad_norm": 0.01873682625591755,
      "learning_rate": 1.5488213333333334e-05,
      "loss": 0.0008,
      "step": 21150
    },
    {
      "epoch": 0.67712,
      "grad_norm": 0.49409160017967224,
      "learning_rate": 1.5486080000000003e-05,
      "loss": 0.0023,
      "step": 21160
    },
    {
      "epoch": 0.67744,
      "grad_norm": 0.00905068963766098,
      "learning_rate": 1.5483946666666668e-05,
      "loss": 0.0003,
      "step": 21170
    },
    {
      "epoch": 0.67776,
      "grad_norm": 0.011067508719861507,
      "learning_rate": 1.5481813333333337e-05,
      "loss": 0.0526,
      "step": 21180
    },
    {
      "epoch": 0.67808,
      "grad_norm": 0.021182380616664886,
      "learning_rate": 1.5479680000000002e-05,
      "loss": 0.0006,
      "step": 21190
    },
    {
      "epoch": 0.6784,
      "grad_norm": 0.007522019557654858,
      "learning_rate": 1.5477546666666668e-05,
      "loss": 0.0004,
      "step": 21200
    },
    {
      "epoch": 0.67872,
      "grad_norm": 0.010972610674798489,
      "learning_rate": 1.5475413333333336e-05,
      "loss": 0.001,
      "step": 21210
    },
    {
      "epoch": 0.67904,
      "grad_norm": 0.008845651522278786,
      "learning_rate": 1.5473280000000002e-05,
      "loss": 0.0166,
      "step": 21220
    },
    {
      "epoch": 0.67936,
      "grad_norm": 0.00926103163510561,
      "learning_rate": 1.5471146666666667e-05,
      "loss": 0.0006,
      "step": 21230
    },
    {
      "epoch": 0.67968,
      "grad_norm": 0.007870730012655258,
      "learning_rate": 1.5469013333333332e-05,
      "loss": 0.0122,
      "step": 21240
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.09711959213018417,
      "learning_rate": 1.546688e-05,
      "loss": 0.0008,
      "step": 21250
    },
    {
      "epoch": 0.68032,
      "grad_norm": 0.0041306233033537865,
      "learning_rate": 1.5464746666666667e-05,
      "loss": 0.0006,
      "step": 21260
    },
    {
      "epoch": 0.68064,
      "grad_norm": 0.010438266210258007,
      "learning_rate": 1.5462613333333335e-05,
      "loss": 0.0006,
      "step": 21270
    },
    {
      "epoch": 0.68096,
      "grad_norm": 0.028859848156571388,
      "learning_rate": 1.546048e-05,
      "loss": 0.0021,
      "step": 21280
    },
    {
      "epoch": 0.68128,
      "grad_norm": 0.006347006652504206,
      "learning_rate": 1.545834666666667e-05,
      "loss": 0.0126,
      "step": 21290
    },
    {
      "epoch": 0.6816,
      "grad_norm": 0.010051319375634193,
      "learning_rate": 1.5456213333333335e-05,
      "loss": 0.0006,
      "step": 21300
    },
    {
      "epoch": 0.68192,
      "grad_norm": 0.006506905425339937,
      "learning_rate": 1.545408e-05,
      "loss": 0.0004,
      "step": 21310
    },
    {
      "epoch": 0.68224,
      "grad_norm": 0.026237932965159416,
      "learning_rate": 1.545194666666667e-05,
      "loss": 0.0006,
      "step": 21320
    },
    {
      "epoch": 0.68256,
      "grad_norm": 0.0070555866695940495,
      "learning_rate": 1.5449813333333334e-05,
      "loss": 0.0006,
      "step": 21330
    },
    {
      "epoch": 0.68288,
      "grad_norm": 0.006081649102270603,
      "learning_rate": 1.544768e-05,
      "loss": 0.0155,
      "step": 21340
    },
    {
      "epoch": 0.6832,
      "grad_norm": 0.01973593793809414,
      "learning_rate": 1.544554666666667e-05,
      "loss": 0.0288,
      "step": 21350
    },
    {
      "epoch": 0.68352,
      "grad_norm": 0.008912389166653156,
      "learning_rate": 1.5443413333333334e-05,
      "loss": 0.0005,
      "step": 21360
    },
    {
      "epoch": 0.68384,
      "grad_norm": 0.00987975113093853,
      "learning_rate": 1.544128e-05,
      "loss": 0.0434,
      "step": 21370
    },
    {
      "epoch": 0.68416,
      "grad_norm": 0.009771648794412613,
      "learning_rate": 1.5439146666666668e-05,
      "loss": 0.0123,
      "step": 21380
    },
    {
      "epoch": 0.68448,
      "grad_norm": 0.012530233711004257,
      "learning_rate": 1.5437013333333333e-05,
      "loss": 0.0005,
      "step": 21390
    },
    {
      "epoch": 0.6848,
      "grad_norm": 0.006118759047240019,
      "learning_rate": 1.5434880000000002e-05,
      "loss": 0.0006,
      "step": 21400
    },
    {
      "epoch": 0.68512,
      "grad_norm": 0.005458774045109749,
      "learning_rate": 1.5432746666666668e-05,
      "loss": 0.0005,
      "step": 21410
    },
    {
      "epoch": 0.68544,
      "grad_norm": 0.04517574608325958,
      "learning_rate": 1.5430613333333336e-05,
      "loss": 0.0006,
      "step": 21420
    },
    {
      "epoch": 0.68576,
      "grad_norm": 0.01566150411963463,
      "learning_rate": 1.5428480000000002e-05,
      "loss": 0.0014,
      "step": 21430
    },
    {
      "epoch": 0.68608,
      "grad_norm": 0.0098186070099473,
      "learning_rate": 1.5426346666666667e-05,
      "loss": 0.0008,
      "step": 21440
    },
    {
      "epoch": 0.6864,
      "grad_norm": 0.018254779279232025,
      "learning_rate": 1.5424213333333336e-05,
      "loss": 0.0005,
      "step": 21450
    },
    {
      "epoch": 0.68672,
      "grad_norm": 0.007894601672887802,
      "learning_rate": 1.542208e-05,
      "loss": 0.0275,
      "step": 21460
    },
    {
      "epoch": 0.68704,
      "grad_norm": 0.012173017486929893,
      "learning_rate": 1.5419946666666667e-05,
      "loss": 0.0004,
      "step": 21470
    },
    {
      "epoch": 0.68736,
      "grad_norm": 0.007009484339505434,
      "learning_rate": 1.5417813333333332e-05,
      "loss": 0.0004,
      "step": 21480
    },
    {
      "epoch": 0.68768,
      "grad_norm": 0.006333181168884039,
      "learning_rate": 1.541568e-05,
      "loss": 0.0005,
      "step": 21490
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.004429429303854704,
      "learning_rate": 1.5413546666666666e-05,
      "loss": 0.0024,
      "step": 21500
    },
    {
      "epoch": 0.68832,
      "grad_norm": 0.00857448112219572,
      "learning_rate": 1.5411413333333335e-05,
      "loss": 0.0004,
      "step": 21510
    },
    {
      "epoch": 0.68864,
      "grad_norm": 0.008151826448738575,
      "learning_rate": 1.5409280000000004e-05,
      "loss": 0.0156,
      "step": 21520
    },
    {
      "epoch": 0.68896,
      "grad_norm": 0.01624424383044243,
      "learning_rate": 1.540714666666667e-05,
      "loss": 0.0003,
      "step": 21530
    },
    {
      "epoch": 0.68928,
      "grad_norm": 0.19490522146224976,
      "learning_rate": 1.5405013333333334e-05,
      "loss": 0.0012,
      "step": 21540
    },
    {
      "epoch": 0.6896,
      "grad_norm": 0.006738563999533653,
      "learning_rate": 1.5402880000000003e-05,
      "loss": 0.0003,
      "step": 21550
    },
    {
      "epoch": 0.68992,
      "grad_norm": 0.005426195450127125,
      "learning_rate": 1.540074666666667e-05,
      "loss": 0.0004,
      "step": 21560
    },
    {
      "epoch": 0.69024,
      "grad_norm": 0.007209343835711479,
      "learning_rate": 1.5398613333333334e-05,
      "loss": 0.0003,
      "step": 21570
    },
    {
      "epoch": 0.69056,
      "grad_norm": 0.0034456041175872087,
      "learning_rate": 1.539648e-05,
      "loss": 0.0004,
      "step": 21580
    },
    {
      "epoch": 0.69088,
      "grad_norm": 0.003666930366307497,
      "learning_rate": 1.5394346666666668e-05,
      "loss": 0.0004,
      "step": 21590
    },
    {
      "epoch": 0.6912,
      "grad_norm": 0.003013131208717823,
      "learning_rate": 1.5392213333333333e-05,
      "loss": 0.0005,
      "step": 21600
    },
    {
      "epoch": 0.69152,
      "grad_norm": 0.002831794787198305,
      "learning_rate": 1.5390080000000002e-05,
      "loss": 0.0052,
      "step": 21610
    },
    {
      "epoch": 0.69184,
      "grad_norm": 0.10814683884382248,
      "learning_rate": 1.5387946666666668e-05,
      "loss": 0.0014,
      "step": 21620
    },
    {
      "epoch": 0.69216,
      "grad_norm": 0.00659974617883563,
      "learning_rate": 1.5385813333333336e-05,
      "loss": 0.0003,
      "step": 21630
    },
    {
      "epoch": 0.69248,
      "grad_norm": 0.010778446681797504,
      "learning_rate": 1.5383680000000002e-05,
      "loss": 0.0002,
      "step": 21640
    },
    {
      "epoch": 0.6928,
      "grad_norm": 0.007673012558370829,
      "learning_rate": 1.5381546666666667e-05,
      "loss": 0.0003,
      "step": 21650
    },
    {
      "epoch": 0.69312,
      "grad_norm": 0.0044539812952280045,
      "learning_rate": 1.5379413333333336e-05,
      "loss": 0.0003,
      "step": 21660
    },
    {
      "epoch": 0.69344,
      "grad_norm": 0.016773993149399757,
      "learning_rate": 1.537728e-05,
      "loss": 0.0003,
      "step": 21670
    },
    {
      "epoch": 0.69376,
      "grad_norm": 0.030144331976771355,
      "learning_rate": 1.5375146666666667e-05,
      "loss": 0.0516,
      "step": 21680
    },
    {
      "epoch": 0.69408,
      "grad_norm": 0.004023753572255373,
      "learning_rate": 1.5373013333333335e-05,
      "loss": 0.0004,
      "step": 21690
    },
    {
      "epoch": 0.6944,
      "grad_norm": 0.010781231336295605,
      "learning_rate": 1.537088e-05,
      "loss": 0.0006,
      "step": 21700
    },
    {
      "epoch": 0.69472,
      "grad_norm": 0.004580394364893436,
      "learning_rate": 1.5368746666666666e-05,
      "loss": 0.0094,
      "step": 21710
    },
    {
      "epoch": 0.69504,
      "grad_norm": 0.008622200228273869,
      "learning_rate": 1.5366613333333335e-05,
      "loss": 0.0003,
      "step": 21720
    },
    {
      "epoch": 0.69536,
      "grad_norm": 0.017331238836050034,
      "learning_rate": 1.536448e-05,
      "loss": 0.0003,
      "step": 21730
    },
    {
      "epoch": 0.69568,
      "grad_norm": 0.007636541500687599,
      "learning_rate": 1.536234666666667e-05,
      "loss": 0.0492,
      "step": 21740
    },
    {
      "epoch": 0.696,
      "grad_norm": 1.4693793058395386,
      "learning_rate": 1.5360213333333334e-05,
      "loss": 0.0575,
      "step": 21750
    },
    {
      "epoch": 0.69632,
      "grad_norm": 0.006587831769138575,
      "learning_rate": 1.5358080000000003e-05,
      "loss": 0.0005,
      "step": 21760
    },
    {
      "epoch": 0.69664,
      "grad_norm": 0.0048348973505198956,
      "learning_rate": 1.535594666666667e-05,
      "loss": 0.0013,
      "step": 21770
    },
    {
      "epoch": 0.69696,
      "grad_norm": 0.006998030003160238,
      "learning_rate": 1.5353813333333334e-05,
      "loss": 0.0004,
      "step": 21780
    },
    {
      "epoch": 0.69728,
      "grad_norm": 0.007231167983263731,
      "learning_rate": 1.5351680000000003e-05,
      "loss": 0.0005,
      "step": 21790
    },
    {
      "epoch": 0.6976,
      "grad_norm": 0.010910465382039547,
      "learning_rate": 1.5349546666666668e-05,
      "loss": 0.0007,
      "step": 21800
    },
    {
      "epoch": 0.69792,
      "grad_norm": 0.003529696259647608,
      "learning_rate": 1.5347413333333333e-05,
      "loss": 0.0005,
      "step": 21810
    },
    {
      "epoch": 0.69824,
      "grad_norm": 0.006036913488060236,
      "learning_rate": 1.534528e-05,
      "loss": 0.0004,
      "step": 21820
    },
    {
      "epoch": 0.69856,
      "grad_norm": 0.006524249445647001,
      "learning_rate": 1.5343146666666668e-05,
      "loss": 0.0345,
      "step": 21830
    },
    {
      "epoch": 0.69888,
      "grad_norm": 0.011572657153010368,
      "learning_rate": 1.5341013333333333e-05,
      "loss": 0.0243,
      "step": 21840
    },
    {
      "epoch": 0.6992,
      "grad_norm": 0.022552287206053734,
      "learning_rate": 1.5338880000000002e-05,
      "loss": 0.0007,
      "step": 21850
    },
    {
      "epoch": 0.69952,
      "grad_norm": 0.004433976020663977,
      "learning_rate": 1.5336746666666667e-05,
      "loss": 0.0004,
      "step": 21860
    },
    {
      "epoch": 0.69984,
      "grad_norm": 0.006528322119265795,
      "learning_rate": 1.5334613333333336e-05,
      "loss": 0.0006,
      "step": 21870
    },
    {
      "epoch": 0.70016,
      "grad_norm": 0.019775787368416786,
      "learning_rate": 1.533248e-05,
      "loss": 0.0136,
      "step": 21880
    },
    {
      "epoch": 0.70048,
      "grad_norm": 0.0070884013548493385,
      "learning_rate": 1.533034666666667e-05,
      "loss": 0.0296,
      "step": 21890
    },
    {
      "epoch": 0.7008,
      "grad_norm": 0.013824074529111385,
      "learning_rate": 1.5328213333333335e-05,
      "loss": 0.0006,
      "step": 21900
    },
    {
      "epoch": 0.70112,
      "grad_norm": 0.011644667945802212,
      "learning_rate": 1.532608e-05,
      "loss": 0.0004,
      "step": 21910
    },
    {
      "epoch": 0.70144,
      "grad_norm": 0.024439554661512375,
      "learning_rate": 1.5323946666666666e-05,
      "loss": 0.0005,
      "step": 21920
    },
    {
      "epoch": 0.70176,
      "grad_norm": 0.01042922493070364,
      "learning_rate": 1.5321813333333335e-05,
      "loss": 0.0048,
      "step": 21930
    },
    {
      "epoch": 0.70208,
      "grad_norm": 0.05077186971902847,
      "learning_rate": 1.531968e-05,
      "loss": 0.0005,
      "step": 21940
    },
    {
      "epoch": 0.7024,
      "grad_norm": 0.013688960112631321,
      "learning_rate": 1.5317546666666666e-05,
      "loss": 0.0004,
      "step": 21950
    },
    {
      "epoch": 0.70272,
      "grad_norm": 0.012048640288412571,
      "learning_rate": 1.5315413333333334e-05,
      "loss": 0.0004,
      "step": 21960
    },
    {
      "epoch": 0.70304,
      "grad_norm": 0.03335944190621376,
      "learning_rate": 1.531328e-05,
      "loss": 0.0013,
      "step": 21970
    },
    {
      "epoch": 0.70336,
      "grad_norm": 0.005964995361864567,
      "learning_rate": 1.531114666666667e-05,
      "loss": 0.0563,
      "step": 21980
    },
    {
      "epoch": 0.70368,
      "grad_norm": 0.004129074513912201,
      "learning_rate": 1.5309013333333334e-05,
      "loss": 0.0006,
      "step": 21990
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.00436205742880702,
      "learning_rate": 1.5306880000000003e-05,
      "loss": 0.0003,
      "step": 22000
    },
    {
      "epoch": 0.70432,
      "grad_norm": 0.005986555013805628,
      "learning_rate": 1.5304746666666668e-05,
      "loss": 0.0008,
      "step": 22010
    },
    {
      "epoch": 0.70464,
      "grad_norm": 0.011821758933365345,
      "learning_rate": 1.5302613333333334e-05,
      "loss": 0.0003,
      "step": 22020
    },
    {
      "epoch": 0.70496,
      "grad_norm": 0.009343201294541359,
      "learning_rate": 1.5300480000000002e-05,
      "loss": 0.0004,
      "step": 22030
    },
    {
      "epoch": 0.70528,
      "grad_norm": 0.0069579011760652065,
      "learning_rate": 1.5298346666666668e-05,
      "loss": 0.0003,
      "step": 22040
    },
    {
      "epoch": 0.7056,
      "grad_norm": 5.5267863273620605,
      "learning_rate": 1.5296213333333333e-05,
      "loss": 0.0306,
      "step": 22050
    },
    {
      "epoch": 0.70592,
      "grad_norm": 2.1060831546783447,
      "learning_rate": 1.5294080000000002e-05,
      "loss": 0.096,
      "step": 22060
    },
    {
      "epoch": 0.70624,
      "grad_norm": 0.010816970840096474,
      "learning_rate": 1.5291946666666667e-05,
      "loss": 0.0008,
      "step": 22070
    },
    {
      "epoch": 0.70656,
      "grad_norm": 0.012094548903405666,
      "learning_rate": 1.5289813333333336e-05,
      "loss": 0.0004,
      "step": 22080
    },
    {
      "epoch": 0.70688,
      "grad_norm": 0.024237824603915215,
      "learning_rate": 1.528768e-05,
      "loss": 0.0512,
      "step": 22090
    },
    {
      "epoch": 0.7072,
      "grad_norm": 0.008354656398296356,
      "learning_rate": 1.528554666666667e-05,
      "loss": 0.0005,
      "step": 22100
    },
    {
      "epoch": 0.70752,
      "grad_norm": 0.006554591003805399,
      "learning_rate": 1.5283413333333335e-05,
      "loss": 0.0006,
      "step": 22110
    },
    {
      "epoch": 0.70784,
      "grad_norm": 0.04193057492375374,
      "learning_rate": 1.528128e-05,
      "loss": 0.0011,
      "step": 22120
    },
    {
      "epoch": 0.70816,
      "grad_norm": 0.24556571245193481,
      "learning_rate": 1.527914666666667e-05,
      "loss": 0.0016,
      "step": 22130
    },
    {
      "epoch": 0.70848,
      "grad_norm": 0.009079400449991226,
      "learning_rate": 1.5277013333333335e-05,
      "loss": 0.0035,
      "step": 22140
    },
    {
      "epoch": 0.7088,
      "grad_norm": 0.007460626773536205,
      "learning_rate": 1.527488e-05,
      "loss": 0.0011,
      "step": 22150
    },
    {
      "epoch": 0.70912,
      "grad_norm": 0.782328188419342,
      "learning_rate": 1.5272746666666666e-05,
      "loss": 0.0456,
      "step": 22160
    },
    {
      "epoch": 0.70944,
      "grad_norm": 0.048050131648778915,
      "learning_rate": 1.5270613333333335e-05,
      "loss": 0.0006,
      "step": 22170
    },
    {
      "epoch": 0.70976,
      "grad_norm": 0.056624967604875565,
      "learning_rate": 1.526848e-05,
      "loss": 0.0391,
      "step": 22180
    },
    {
      "epoch": 0.71008,
      "grad_norm": 0.0059740906581282616,
      "learning_rate": 1.526634666666667e-05,
      "loss": 0.0006,
      "step": 22190
    },
    {
      "epoch": 0.7104,
      "grad_norm": 0.007412228267639875,
      "learning_rate": 1.5264213333333334e-05,
      "loss": 0.0007,
      "step": 22200
    },
    {
      "epoch": 0.71072,
      "grad_norm": 0.014186860993504524,
      "learning_rate": 1.5262080000000003e-05,
      "loss": 0.0004,
      "step": 22210
    },
    {
      "epoch": 0.71104,
      "grad_norm": 0.02589516155421734,
      "learning_rate": 1.5259946666666668e-05,
      "loss": 0.0191,
      "step": 22220
    },
    {
      "epoch": 0.71136,
      "grad_norm": 0.008214869536459446,
      "learning_rate": 1.5257813333333335e-05,
      "loss": 0.0122,
      "step": 22230
    },
    {
      "epoch": 0.71168,
      "grad_norm": 2.3997268676757812,
      "learning_rate": 1.5255680000000002e-05,
      "loss": 0.0155,
      "step": 22240
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.009842869825661182,
      "learning_rate": 1.5253546666666668e-05,
      "loss": 0.0269,
      "step": 22250
    },
    {
      "epoch": 0.71232,
      "grad_norm": 0.006342894863337278,
      "learning_rate": 1.5251413333333333e-05,
      "loss": 0.0005,
      "step": 22260
    },
    {
      "epoch": 0.71264,
      "grad_norm": 0.03613680228590965,
      "learning_rate": 1.5249280000000002e-05,
      "loss": 0.0152,
      "step": 22270
    },
    {
      "epoch": 0.71296,
      "grad_norm": 0.017246421426534653,
      "learning_rate": 1.5247146666666667e-05,
      "loss": 0.0005,
      "step": 22280
    },
    {
      "epoch": 0.71328,
      "grad_norm": 0.011845963075757027,
      "learning_rate": 1.5245013333333334e-05,
      "loss": 0.0023,
      "step": 22290
    },
    {
      "epoch": 0.7136,
      "grad_norm": 0.023907151073217392,
      "learning_rate": 1.5242880000000001e-05,
      "loss": 0.0647,
      "step": 22300
    },
    {
      "epoch": 0.71392,
      "grad_norm": 0.010410359129309654,
      "learning_rate": 1.5240746666666668e-05,
      "loss": 0.0006,
      "step": 22310
    },
    {
      "epoch": 0.71424,
      "grad_norm": 0.010403149761259556,
      "learning_rate": 1.5238613333333334e-05,
      "loss": 0.001,
      "step": 22320
    },
    {
      "epoch": 0.71456,
      "grad_norm": 0.049724821001291275,
      "learning_rate": 1.5236480000000001e-05,
      "loss": 0.0599,
      "step": 22330
    },
    {
      "epoch": 0.71488,
      "grad_norm": 0.019842078909277916,
      "learning_rate": 1.5234346666666668e-05,
      "loss": 0.0014,
      "step": 22340
    },
    {
      "epoch": 0.7152,
      "grad_norm": 0.013577164150774479,
      "learning_rate": 1.5232213333333335e-05,
      "loss": 0.0009,
      "step": 22350
    },
    {
      "epoch": 0.71552,
      "grad_norm": 0.01683777943253517,
      "learning_rate": 1.523008e-05,
      "loss": 0.0005,
      "step": 22360
    },
    {
      "epoch": 0.71584,
      "grad_norm": 0.033906422555446625,
      "learning_rate": 1.5227946666666669e-05,
      "loss": 0.0033,
      "step": 22370
    },
    {
      "epoch": 0.71616,
      "grad_norm": 0.01634283736348152,
      "learning_rate": 1.5225813333333335e-05,
      "loss": 0.0015,
      "step": 22380
    },
    {
      "epoch": 0.71648,
      "grad_norm": 0.014520674012601376,
      "learning_rate": 1.522368e-05,
      "loss": 0.0005,
      "step": 22390
    },
    {
      "epoch": 0.7168,
      "grad_norm": 0.02429884858429432,
      "learning_rate": 1.5221546666666669e-05,
      "loss": 0.0405,
      "step": 22400
    },
    {
      "epoch": 0.71712,
      "grad_norm": 0.02816755138337612,
      "learning_rate": 1.5219413333333336e-05,
      "loss": 0.0009,
      "step": 22410
    },
    {
      "epoch": 0.71744,
      "grad_norm": 0.015832507982850075,
      "learning_rate": 1.5217280000000001e-05,
      "loss": 0.0009,
      "step": 22420
    },
    {
      "epoch": 0.71776,
      "grad_norm": 0.013985172845423222,
      "learning_rate": 1.5215146666666666e-05,
      "loss": 0.0006,
      "step": 22430
    },
    {
      "epoch": 0.71808,
      "grad_norm": 0.01867293007671833,
      "learning_rate": 1.5213013333333335e-05,
      "loss": 0.0464,
      "step": 22440
    },
    {
      "epoch": 0.7184,
      "grad_norm": 0.10479901731014252,
      "learning_rate": 1.521088e-05,
      "loss": 0.0011,
      "step": 22450
    },
    {
      "epoch": 0.71872,
      "grad_norm": 0.013441408984363079,
      "learning_rate": 1.5208746666666668e-05,
      "loss": 0.0015,
      "step": 22460
    },
    {
      "epoch": 0.71904,
      "grad_norm": 0.010478242300450802,
      "learning_rate": 1.5206613333333335e-05,
      "loss": 0.0005,
      "step": 22470
    },
    {
      "epoch": 0.71936,
      "grad_norm": 0.0085397157818079,
      "learning_rate": 1.5204480000000002e-05,
      "loss": 0.0372,
      "step": 22480
    },
    {
      "epoch": 0.71968,
      "grad_norm": 0.013129991479218006,
      "learning_rate": 1.5202346666666667e-05,
      "loss": 0.0168,
      "step": 22490
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.004436487797647715,
      "learning_rate": 1.5200213333333334e-05,
      "loss": 0.0006,
      "step": 22500
    },
    {
      "epoch": 0.72032,
      "grad_norm": 0.00939975492656231,
      "learning_rate": 1.5198080000000001e-05,
      "loss": 0.0005,
      "step": 22510
    },
    {
      "epoch": 0.72064,
      "grad_norm": 0.028457915410399437,
      "learning_rate": 1.5195946666666668e-05,
      "loss": 0.0008,
      "step": 22520
    },
    {
      "epoch": 0.72096,
      "grad_norm": 0.009404951706528664,
      "learning_rate": 1.5193813333333334e-05,
      "loss": 0.0005,
      "step": 22530
    },
    {
      "epoch": 0.72128,
      "grad_norm": 0.019881414249539375,
      "learning_rate": 1.5191680000000003e-05,
      "loss": 0.0017,
      "step": 22540
    },
    {
      "epoch": 0.7216,
      "grad_norm": 0.018687311559915543,
      "learning_rate": 1.5189546666666668e-05,
      "loss": 0.0019,
      "step": 22550
    },
    {
      "epoch": 0.72192,
      "grad_norm": 0.007578164339065552,
      "learning_rate": 1.5187413333333333e-05,
      "loss": 0.0005,
      "step": 22560
    },
    {
      "epoch": 0.72224,
      "grad_norm": 0.6194393038749695,
      "learning_rate": 1.5185280000000002e-05,
      "loss": 0.0015,
      "step": 22570
    },
    {
      "epoch": 0.72256,
      "grad_norm": 0.007080398965626955,
      "learning_rate": 1.5183146666666667e-05,
      "loss": 0.0005,
      "step": 22580
    },
    {
      "epoch": 0.72288,
      "grad_norm": 0.02569607086479664,
      "learning_rate": 1.5181013333333335e-05,
      "loss": 0.0007,
      "step": 22590
    },
    {
      "epoch": 0.7232,
      "grad_norm": 0.007290617097169161,
      "learning_rate": 1.517888e-05,
      "loss": 0.0004,
      "step": 22600
    },
    {
      "epoch": 0.72352,
      "grad_norm": 0.004427412059158087,
      "learning_rate": 1.5176746666666669e-05,
      "loss": 0.0006,
      "step": 22610
    },
    {
      "epoch": 0.72384,
      "grad_norm": 0.009686636738479137,
      "learning_rate": 1.5174613333333334e-05,
      "loss": 0.0004,
      "step": 22620
    },
    {
      "epoch": 0.72416,
      "grad_norm": 0.012271246872842312,
      "learning_rate": 1.5172480000000001e-05,
      "loss": 0.0007,
      "step": 22630
    },
    {
      "epoch": 0.72448,
      "grad_norm": 0.023130645975470543,
      "learning_rate": 1.5170346666666668e-05,
      "loss": 0.0007,
      "step": 22640
    },
    {
      "epoch": 0.7248,
      "grad_norm": 0.009114867076277733,
      "learning_rate": 1.5168213333333335e-05,
      "loss": 0.0004,
      "step": 22650
    },
    {
      "epoch": 0.72512,
      "grad_norm": 0.010632535442709923,
      "learning_rate": 1.516608e-05,
      "loss": 0.0008,
      "step": 22660
    },
    {
      "epoch": 0.72544,
      "grad_norm": 0.01877271756529808,
      "learning_rate": 1.5163946666666666e-05,
      "loss": 0.0403,
      "step": 22670
    },
    {
      "epoch": 0.72576,
      "grad_norm": 0.005475280340760946,
      "learning_rate": 1.5161813333333335e-05,
      "loss": 0.0004,
      "step": 22680
    },
    {
      "epoch": 0.72608,
      "grad_norm": 0.00950050912797451,
      "learning_rate": 1.5159680000000002e-05,
      "loss": 0.0018,
      "step": 22690
    },
    {
      "epoch": 0.7264,
      "grad_norm": 0.0292983241379261,
      "learning_rate": 1.5157546666666667e-05,
      "loss": 0.0006,
      "step": 22700
    },
    {
      "epoch": 0.72672,
      "grad_norm": 0.012648846954107285,
      "learning_rate": 1.5155413333333336e-05,
      "loss": 0.0423,
      "step": 22710
    },
    {
      "epoch": 0.72704,
      "grad_norm": 0.01437341794371605,
      "learning_rate": 1.5153280000000001e-05,
      "loss": 0.0006,
      "step": 22720
    },
    {
      "epoch": 0.72736,
      "grad_norm": 0.01653245836496353,
      "learning_rate": 1.5151146666666667e-05,
      "loss": 0.0004,
      "step": 22730
    },
    {
      "epoch": 0.72768,
      "grad_norm": 0.003243278479203582,
      "learning_rate": 1.5149013333333336e-05,
      "loss": 0.0031,
      "step": 22740
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.0072404127568006516,
      "learning_rate": 1.5146880000000001e-05,
      "loss": 0.0003,
      "step": 22750
    },
    {
      "epoch": 0.72832,
      "grad_norm": 0.0073670148849487305,
      "learning_rate": 1.5144746666666668e-05,
      "loss": 0.0351,
      "step": 22760
    },
    {
      "epoch": 0.72864,
      "grad_norm": 0.013204121962189674,
      "learning_rate": 1.5142613333333333e-05,
      "loss": 0.0033,
      "step": 22770
    },
    {
      "epoch": 0.72896,
      "grad_norm": 0.009584427811205387,
      "learning_rate": 1.5140480000000002e-05,
      "loss": 0.0004,
      "step": 22780
    },
    {
      "epoch": 0.72928,
      "grad_norm": 0.30192145705223083,
      "learning_rate": 1.5138346666666668e-05,
      "loss": 0.0013,
      "step": 22790
    },
    {
      "epoch": 0.7296,
      "grad_norm": 0.0069018020294606686,
      "learning_rate": 1.5136213333333335e-05,
      "loss": 0.0004,
      "step": 22800
    },
    {
      "epoch": 0.72992,
      "grad_norm": 0.006255629938095808,
      "learning_rate": 1.5134080000000002e-05,
      "loss": 0.0006,
      "step": 22810
    },
    {
      "epoch": 0.73024,
      "grad_norm": 0.04568549990653992,
      "learning_rate": 1.5131946666666669e-05,
      "loss": 0.0003,
      "step": 22820
    },
    {
      "epoch": 0.73056,
      "grad_norm": 0.005593704525381327,
      "learning_rate": 1.5129813333333334e-05,
      "loss": 0.0003,
      "step": 22830
    },
    {
      "epoch": 0.73088,
      "grad_norm": 0.028371671214699745,
      "learning_rate": 1.512768e-05,
      "loss": 0.0005,
      "step": 22840
    },
    {
      "epoch": 0.7312,
      "grad_norm": 0.005173375364392996,
      "learning_rate": 1.5125546666666668e-05,
      "loss": 0.0186,
      "step": 22850
    },
    {
      "epoch": 0.73152,
      "grad_norm": 0.005813329480588436,
      "learning_rate": 1.5123413333333334e-05,
      "loss": 0.0003,
      "step": 22860
    },
    {
      "epoch": 0.73184,
      "grad_norm": 0.0076172794215381145,
      "learning_rate": 1.512128e-05,
      "loss": 0.0452,
      "step": 22870
    },
    {
      "epoch": 0.73216,
      "grad_norm": 0.0047310213558375835,
      "learning_rate": 1.511914666666667e-05,
      "loss": 0.0491,
      "step": 22880
    },
    {
      "epoch": 0.73248,
      "grad_norm": 0.005610882304608822,
      "learning_rate": 1.5117013333333335e-05,
      "loss": 0.009,
      "step": 22890
    },
    {
      "epoch": 0.7328,
      "grad_norm": 0.015378935262560844,
      "learning_rate": 1.511488e-05,
      "loss": 0.0004,
      "step": 22900
    },
    {
      "epoch": 0.73312,
      "grad_norm": 0.007735346909612417,
      "learning_rate": 1.5112746666666669e-05,
      "loss": 0.0003,
      "step": 22910
    },
    {
      "epoch": 0.73344,
      "grad_norm": 0.009845701046288013,
      "learning_rate": 1.5110613333333334e-05,
      "loss": 0.0004,
      "step": 22920
    },
    {
      "epoch": 0.73376,
      "grad_norm": 0.0038437179755419493,
      "learning_rate": 1.5108480000000001e-05,
      "loss": 0.007,
      "step": 22930
    },
    {
      "epoch": 0.73408,
      "grad_norm": 0.006373433396220207,
      "learning_rate": 1.5106346666666667e-05,
      "loss": 0.0003,
      "step": 22940
    },
    {
      "epoch": 0.7344,
      "grad_norm": 0.004883418790996075,
      "learning_rate": 1.5104213333333336e-05,
      "loss": 0.0495,
      "step": 22950
    },
    {
      "epoch": 0.73472,
      "grad_norm": 0.007243501488119364,
      "learning_rate": 1.5102080000000001e-05,
      "loss": 0.0004,
      "step": 22960
    },
    {
      "epoch": 0.73504,
      "grad_norm": 0.005760573782026768,
      "learning_rate": 1.5099946666666668e-05,
      "loss": 0.0016,
      "step": 22970
    },
    {
      "epoch": 0.73536,
      "grad_norm": 3.9926090240478516,
      "learning_rate": 1.5097813333333335e-05,
      "loss": 0.0171,
      "step": 22980
    },
    {
      "epoch": 0.73568,
      "grad_norm": 0.09783735871315002,
      "learning_rate": 1.5095680000000002e-05,
      "loss": 0.0005,
      "step": 22990
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.01324577908962965,
      "learning_rate": 1.5093546666666668e-05,
      "loss": 0.0005,
      "step": 23000
    },
    {
      "epoch": 0.73632,
      "grad_norm": 0.007267736364156008,
      "learning_rate": 1.5091413333333333e-05,
      "loss": 0.0003,
      "step": 23010
    },
    {
      "epoch": 0.73664,
      "grad_norm": 0.0682920515537262,
      "learning_rate": 1.5089280000000002e-05,
      "loss": 0.0004,
      "step": 23020
    },
    {
      "epoch": 0.73696,
      "grad_norm": 0.09346083551645279,
      "learning_rate": 1.5087146666666667e-05,
      "loss": 0.0048,
      "step": 23030
    },
    {
      "epoch": 0.73728,
      "grad_norm": 0.007002854719758034,
      "learning_rate": 1.5085013333333334e-05,
      "loss": 0.0151,
      "step": 23040
    },
    {
      "epoch": 0.7376,
      "grad_norm": 0.007703091949224472,
      "learning_rate": 1.5082880000000001e-05,
      "loss": 0.001,
      "step": 23050
    },
    {
      "epoch": 0.73792,
      "grad_norm": 0.006637695711106062,
      "learning_rate": 1.5080746666666668e-05,
      "loss": 0.0005,
      "step": 23060
    },
    {
      "epoch": 0.73824,
      "grad_norm": 0.6789957880973816,
      "learning_rate": 1.5078613333333334e-05,
      "loss": 0.0018,
      "step": 23070
    },
    {
      "epoch": 0.73856,
      "grad_norm": 0.009173383004963398,
      "learning_rate": 1.5076480000000002e-05,
      "loss": 0.0029,
      "step": 23080
    },
    {
      "epoch": 0.73888,
      "grad_norm": 0.00703813461586833,
      "learning_rate": 1.5074346666666668e-05,
      "loss": 0.0002,
      "step": 23090
    },
    {
      "epoch": 0.7392,
      "grad_norm": 0.0034327146131545305,
      "learning_rate": 1.5072213333333335e-05,
      "loss": 0.0002,
      "step": 23100
    },
    {
      "epoch": 0.73952,
      "grad_norm": 0.00586831197142601,
      "learning_rate": 1.507008e-05,
      "loss": 0.0004,
      "step": 23110
    },
    {
      "epoch": 0.73984,
      "grad_norm": 0.00484106270596385,
      "learning_rate": 1.5067946666666669e-05,
      "loss": 0.0003,
      "step": 23120
    },
    {
      "epoch": 0.74016,
      "grad_norm": 0.004982771817594767,
      "learning_rate": 1.5065813333333334e-05,
      "loss": 0.0003,
      "step": 23130
    },
    {
      "epoch": 0.74048,
      "grad_norm": 0.012533724308013916,
      "learning_rate": 1.506368e-05,
      "loss": 0.0169,
      "step": 23140
    },
    {
      "epoch": 0.7408,
      "grad_norm": 0.006441531237214804,
      "learning_rate": 1.5061546666666669e-05,
      "loss": 0.0018,
      "step": 23150
    },
    {
      "epoch": 0.74112,
      "grad_norm": 0.0036224822979420424,
      "learning_rate": 1.5059413333333336e-05,
      "loss": 0.0005,
      "step": 23160
    },
    {
      "epoch": 0.74144,
      "grad_norm": 0.0026752923149615526,
      "learning_rate": 1.5057280000000001e-05,
      "loss": 0.0385,
      "step": 23170
    },
    {
      "epoch": 0.74176,
      "grad_norm": 0.0052496688440442085,
      "learning_rate": 1.5055146666666666e-05,
      "loss": 0.0003,
      "step": 23180
    },
    {
      "epoch": 0.74208,
      "grad_norm": 0.009184247814118862,
      "learning_rate": 1.5053013333333335e-05,
      "loss": 0.0003,
      "step": 23190
    },
    {
      "epoch": 0.7424,
      "grad_norm": 0.10342131555080414,
      "learning_rate": 1.505088e-05,
      "loss": 0.0005,
      "step": 23200
    },
    {
      "epoch": 0.74272,
      "grad_norm": 0.003967660013586283,
      "learning_rate": 1.5048746666666668e-05,
      "loss": 0.0628,
      "step": 23210
    },
    {
      "epoch": 0.74304,
      "grad_norm": 0.006904344540089369,
      "learning_rate": 1.5046613333333335e-05,
      "loss": 0.0003,
      "step": 23220
    },
    {
      "epoch": 0.74336,
      "grad_norm": 0.005350644234567881,
      "learning_rate": 1.5044480000000002e-05,
      "loss": 0.0003,
      "step": 23230
    },
    {
      "epoch": 0.74368,
      "grad_norm": 0.004379752092063427,
      "learning_rate": 1.5042346666666667e-05,
      "loss": 0.0003,
      "step": 23240
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.008250623010098934,
      "learning_rate": 1.5040213333333336e-05,
      "loss": 0.0006,
      "step": 23250
    },
    {
      "epoch": 0.74432,
      "grad_norm": 0.00631836848333478,
      "learning_rate": 1.5038080000000001e-05,
      "loss": 0.0002,
      "step": 23260
    },
    {
      "epoch": 0.74464,
      "grad_norm": 0.003880083095282316,
      "learning_rate": 1.5035946666666668e-05,
      "loss": 0.0017,
      "step": 23270
    },
    {
      "epoch": 0.74496,
      "grad_norm": 0.00667070085182786,
      "learning_rate": 1.5033813333333334e-05,
      "loss": 0.0004,
      "step": 23280
    },
    {
      "epoch": 0.74528,
      "grad_norm": 1.0741041898727417,
      "learning_rate": 1.5031680000000002e-05,
      "loss": 0.0047,
      "step": 23290
    },
    {
      "epoch": 0.7456,
      "grad_norm": 4.4368696212768555,
      "learning_rate": 1.5029546666666668e-05,
      "loss": 0.0359,
      "step": 23300
    },
    {
      "epoch": 0.74592,
      "grad_norm": 0.002415020950138569,
      "learning_rate": 1.5027413333333333e-05,
      "loss": 0.0004,
      "step": 23310
    },
    {
      "epoch": 0.74624,
      "grad_norm": 0.00637067761272192,
      "learning_rate": 1.5025280000000002e-05,
      "loss": 0.0426,
      "step": 23320
    },
    {
      "epoch": 0.74656,
      "grad_norm": 0.006889516953378916,
      "learning_rate": 1.5023146666666667e-05,
      "loss": 0.0018,
      "step": 23330
    },
    {
      "epoch": 0.74688,
      "grad_norm": 0.014166587963700294,
      "learning_rate": 1.5021013333333334e-05,
      "loss": 0.0648,
      "step": 23340
    },
    {
      "epoch": 0.7472,
      "grad_norm": 0.00639719795435667,
      "learning_rate": 1.501888e-05,
      "loss": 0.0005,
      "step": 23350
    },
    {
      "epoch": 0.74752,
      "grad_norm": 0.005699200555682182,
      "learning_rate": 1.5016746666666669e-05,
      "loss": 0.0006,
      "step": 23360
    },
    {
      "epoch": 0.74784,
      "grad_norm": 0.007197046186774969,
      "learning_rate": 1.5014613333333334e-05,
      "loss": 0.0038,
      "step": 23370
    },
    {
      "epoch": 0.74816,
      "grad_norm": 3.014951705932617,
      "learning_rate": 1.5012480000000001e-05,
      "loss": 0.0858,
      "step": 23380
    },
    {
      "epoch": 0.74848,
      "grad_norm": 0.007746328599750996,
      "learning_rate": 1.5010346666666668e-05,
      "loss": 0.0003,
      "step": 23390
    },
    {
      "epoch": 0.7488,
      "grad_norm": 0.037790533155202866,
      "learning_rate": 1.5008213333333335e-05,
      "loss": 0.028,
      "step": 23400
    },
    {
      "epoch": 0.74912,
      "grad_norm": 0.010192999616265297,
      "learning_rate": 1.500608e-05,
      "loss": 0.0003,
      "step": 23410
    },
    {
      "epoch": 0.74944,
      "grad_norm": 0.011020230129361153,
      "learning_rate": 1.500394666666667e-05,
      "loss": 0.0004,
      "step": 23420
    },
    {
      "epoch": 0.74976,
      "grad_norm": 0.03290150687098503,
      "learning_rate": 1.5001813333333335e-05,
      "loss": 0.0438,
      "step": 23430
    },
    {
      "epoch": 0.75008,
      "grad_norm": 0.004965605214238167,
      "learning_rate": 1.4999680000000002e-05,
      "loss": 0.0005,
      "step": 23440
    },
    {
      "epoch": 0.7504,
      "grad_norm": 0.009152967482805252,
      "learning_rate": 1.4997546666666667e-05,
      "loss": 0.0003,
      "step": 23450
    },
    {
      "epoch": 0.75072,
      "grad_norm": 0.004643394146114588,
      "learning_rate": 1.4995413333333336e-05,
      "loss": 0.0005,
      "step": 23460
    },
    {
      "epoch": 0.75104,
      "grad_norm": 0.02696854993700981,
      "learning_rate": 1.4993280000000001e-05,
      "loss": 0.0601,
      "step": 23470
    },
    {
      "epoch": 0.75136,
      "grad_norm": 0.009444605559110641,
      "learning_rate": 1.4991146666666667e-05,
      "loss": 0.0003,
      "step": 23480
    },
    {
      "epoch": 0.75168,
      "grad_norm": 0.023920467123389244,
      "learning_rate": 1.4989013333333335e-05,
      "loss": 0.0005,
      "step": 23490
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.07411074638366699,
      "learning_rate": 1.498688e-05,
      "loss": 0.0031,
      "step": 23500
    },
    {
      "epoch": 0.75232,
      "grad_norm": 0.004177604336291552,
      "learning_rate": 1.4984746666666668e-05,
      "loss": 0.041,
      "step": 23510
    },
    {
      "epoch": 0.75264,
      "grad_norm": 0.2526058256626129,
      "learning_rate": 1.4982613333333333e-05,
      "loss": 0.005,
      "step": 23520
    },
    {
      "epoch": 0.75296,
      "grad_norm": 0.010484659112989902,
      "learning_rate": 1.4980480000000002e-05,
      "loss": 0.0005,
      "step": 23530
    },
    {
      "epoch": 0.75328,
      "grad_norm": 0.015260225161910057,
      "learning_rate": 1.4978346666666667e-05,
      "loss": 0.0004,
      "step": 23540
    },
    {
      "epoch": 0.7536,
      "grad_norm": 4.55979061126709,
      "learning_rate": 1.4976213333333334e-05,
      "loss": 0.032,
      "step": 23550
    },
    {
      "epoch": 0.75392,
      "grad_norm": 0.0062665631994605064,
      "learning_rate": 1.4974080000000001e-05,
      "loss": 0.0035,
      "step": 23560
    },
    {
      "epoch": 0.75424,
      "grad_norm": 0.005202160216867924,
      "learning_rate": 1.4971946666666669e-05,
      "loss": 0.0004,
      "step": 23570
    },
    {
      "epoch": 0.75456,
      "grad_norm": 0.004860322922468185,
      "learning_rate": 1.4969813333333334e-05,
      "loss": 0.0003,
      "step": 23580
    },
    {
      "epoch": 0.75488,
      "grad_norm": 0.012165160849690437,
      "learning_rate": 1.4967680000000003e-05,
      "loss": 0.0156,
      "step": 23590
    },
    {
      "epoch": 0.7552,
      "grad_norm": 0.023915760219097137,
      "learning_rate": 1.4965546666666668e-05,
      "loss": 0.0004,
      "step": 23600
    },
    {
      "epoch": 0.75552,
      "grad_norm": 0.009325740858912468,
      "learning_rate": 1.4963413333333333e-05,
      "loss": 0.0005,
      "step": 23610
    },
    {
      "epoch": 0.75584,
      "grad_norm": 0.00831026304513216,
      "learning_rate": 1.496128e-05,
      "loss": 0.0003,
      "step": 23620
    },
    {
      "epoch": 0.75616,
      "grad_norm": 0.004881519358605146,
      "learning_rate": 1.495914666666667e-05,
      "loss": 0.0006,
      "step": 23630
    },
    {
      "epoch": 0.75648,
      "grad_norm": 0.04037395492196083,
      "learning_rate": 1.4957013333333335e-05,
      "loss": 0.0009,
      "step": 23640
    },
    {
      "epoch": 0.7568,
      "grad_norm": 0.007643245626240969,
      "learning_rate": 1.495488e-05,
      "loss": 0.0115,
      "step": 23650
    },
    {
      "epoch": 0.75712,
      "grad_norm": 0.003289185930043459,
      "learning_rate": 1.4952746666666669e-05,
      "loss": 0.0425,
      "step": 23660
    },
    {
      "epoch": 0.75744,
      "grad_norm": 0.0038341409526765347,
      "learning_rate": 1.4950613333333334e-05,
      "loss": 0.0016,
      "step": 23670
    },
    {
      "epoch": 0.75776,
      "grad_norm": 0.006979398429393768,
      "learning_rate": 1.4948480000000001e-05,
      "loss": 0.0343,
      "step": 23680
    },
    {
      "epoch": 0.75808,
      "grad_norm": 0.010167248547077179,
      "learning_rate": 1.4946346666666667e-05,
      "loss": 0.0047,
      "step": 23690
    },
    {
      "epoch": 0.7584,
      "grad_norm": 0.004174449946731329,
      "learning_rate": 1.4944213333333335e-05,
      "loss": 0.0004,
      "step": 23700
    },
    {
      "epoch": 0.75872,
      "grad_norm": 0.008985108695924282,
      "learning_rate": 1.494208e-05,
      "loss": 0.0003,
      "step": 23710
    },
    {
      "epoch": 0.75904,
      "grad_norm": 0.00942122284322977,
      "learning_rate": 1.4939946666666668e-05,
      "loss": 0.02,
      "step": 23720
    },
    {
      "epoch": 0.75936,
      "grad_norm": 0.00518441665917635,
      "learning_rate": 1.4937813333333335e-05,
      "loss": 0.0004,
      "step": 23730
    },
    {
      "epoch": 0.75968,
      "grad_norm": 0.006699107587337494,
      "learning_rate": 1.4935680000000002e-05,
      "loss": 0.0387,
      "step": 23740
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.004199457820504904,
      "learning_rate": 1.4933546666666667e-05,
      "loss": 0.0009,
      "step": 23750
    },
    {
      "epoch": 0.76032,
      "grad_norm": 0.004646286368370056,
      "learning_rate": 1.4931413333333336e-05,
      "loss": 0.0005,
      "step": 23760
    },
    {
      "epoch": 0.76064,
      "grad_norm": 0.007301639299839735,
      "learning_rate": 1.4929280000000002e-05,
      "loss": 0.0064,
      "step": 23770
    },
    {
      "epoch": 0.76096,
      "grad_norm": 0.005741803906857967,
      "learning_rate": 1.4927146666666667e-05,
      "loss": 0.0226,
      "step": 23780
    },
    {
      "epoch": 0.76128,
      "grad_norm": 0.008940059691667557,
      "learning_rate": 1.4925013333333334e-05,
      "loss": 0.0007,
      "step": 23790
    },
    {
      "epoch": 0.7616,
      "grad_norm": 0.003274280810728669,
      "learning_rate": 1.4922880000000001e-05,
      "loss": 0.0005,
      "step": 23800
    },
    {
      "epoch": 0.76192,
      "grad_norm": 0.009159989655017853,
      "learning_rate": 1.4920746666666668e-05,
      "loss": 0.0494,
      "step": 23810
    },
    {
      "epoch": 0.76224,
      "grad_norm": 0.008701899088919163,
      "learning_rate": 1.4918613333333333e-05,
      "loss": 0.0004,
      "step": 23820
    },
    {
      "epoch": 0.76256,
      "grad_norm": 0.0047410642728209496,
      "learning_rate": 1.4916480000000002e-05,
      "loss": 0.0014,
      "step": 23830
    },
    {
      "epoch": 0.76288,
      "grad_norm": 0.09505487978458405,
      "learning_rate": 1.4914346666666668e-05,
      "loss": 0.0005,
      "step": 23840
    },
    {
      "epoch": 0.7632,
      "grad_norm": 0.008582892827689648,
      "learning_rate": 1.4912213333333335e-05,
      "loss": 0.0137,
      "step": 23850
    },
    {
      "epoch": 0.76352,
      "grad_norm": 0.6020164489746094,
      "learning_rate": 1.491008e-05,
      "loss": 0.0018,
      "step": 23860
    },
    {
      "epoch": 0.76384,
      "grad_norm": 0.012750295922160149,
      "learning_rate": 1.4907946666666669e-05,
      "loss": 0.0006,
      "step": 23870
    },
    {
      "epoch": 0.76416,
      "grad_norm": 0.02704533003270626,
      "learning_rate": 1.4905813333333334e-05,
      "loss": 0.0063,
      "step": 23880
    },
    {
      "epoch": 0.76448,
      "grad_norm": 0.013968131504952908,
      "learning_rate": 1.490368e-05,
      "loss": 0.0004,
      "step": 23890
    },
    {
      "epoch": 0.7648,
      "grad_norm": 0.0053936452604830265,
      "learning_rate": 1.4901546666666668e-05,
      "loss": 0.0005,
      "step": 23900
    },
    {
      "epoch": 0.76512,
      "grad_norm": 0.04476012662053108,
      "learning_rate": 1.4899413333333335e-05,
      "loss": 0.0323,
      "step": 23910
    },
    {
      "epoch": 0.76544,
      "grad_norm": 0.004835784435272217,
      "learning_rate": 1.489728e-05,
      "loss": 0.0147,
      "step": 23920
    },
    {
      "epoch": 0.76576,
      "grad_norm": 3.9597980976104736,
      "learning_rate": 1.489514666666667e-05,
      "loss": 0.0126,
      "step": 23930
    },
    {
      "epoch": 0.76608,
      "grad_norm": 0.013097506947815418,
      "learning_rate": 1.4893013333333335e-05,
      "loss": 0.0008,
      "step": 23940
    },
    {
      "epoch": 0.7664,
      "grad_norm": 0.008219663053750992,
      "learning_rate": 1.489088e-05,
      "loss": 0.0005,
      "step": 23950
    },
    {
      "epoch": 0.76672,
      "grad_norm": 0.00522593455389142,
      "learning_rate": 1.4888746666666667e-05,
      "loss": 0.0081,
      "step": 23960
    },
    {
      "epoch": 0.76704,
      "grad_norm": 0.006004386581480503,
      "learning_rate": 1.4886613333333334e-05,
      "loss": 0.0003,
      "step": 23970
    },
    {
      "epoch": 0.76736,
      "grad_norm": 0.018987400457262993,
      "learning_rate": 1.4884480000000002e-05,
      "loss": 0.0003,
      "step": 23980
    },
    {
      "epoch": 0.76768,
      "grad_norm": 0.005949296988546848,
      "learning_rate": 1.4882346666666667e-05,
      "loss": 0.0004,
      "step": 23990
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.0062486412934958935,
      "learning_rate": 1.4880213333333336e-05,
      "loss": 0.0005,
      "step": 24000
    },
    {
      "epoch": 0.76832,
      "grad_norm": 0.01909574866294861,
      "learning_rate": 1.4878080000000001e-05,
      "loss": 0.0006,
      "step": 24010
    },
    {
      "epoch": 0.76864,
      "grad_norm": 0.5331904888153076,
      "learning_rate": 1.4875946666666668e-05,
      "loss": 0.0196,
      "step": 24020
    },
    {
      "epoch": 0.76896,
      "grad_norm": 0.014809620566666126,
      "learning_rate": 1.4873813333333335e-05,
      "loss": 0.001,
      "step": 24030
    },
    {
      "epoch": 0.76928,
      "grad_norm": 5.939159393310547,
      "learning_rate": 1.4871680000000002e-05,
      "loss": 0.0565,
      "step": 24040
    },
    {
      "epoch": 0.7696,
      "grad_norm": 0.0059358468279242516,
      "learning_rate": 1.4869546666666668e-05,
      "loss": 0.0003,
      "step": 24050
    },
    {
      "epoch": 0.76992,
      "grad_norm": 0.634605348110199,
      "learning_rate": 1.4867413333333333e-05,
      "loss": 0.0022,
      "step": 24060
    },
    {
      "epoch": 0.77024,
      "grad_norm": 2.964205265045166,
      "learning_rate": 1.4865280000000002e-05,
      "loss": 0.0166,
      "step": 24070
    },
    {
      "epoch": 0.77056,
      "grad_norm": 0.02122538350522518,
      "learning_rate": 1.4863146666666667e-05,
      "loss": 0.0004,
      "step": 24080
    },
    {
      "epoch": 0.77088,
      "grad_norm": 0.007771217729896307,
      "learning_rate": 1.4861013333333334e-05,
      "loss": 0.0003,
      "step": 24090
    },
    {
      "epoch": 0.7712,
      "grad_norm": 0.023899871855974197,
      "learning_rate": 1.4858880000000003e-05,
      "loss": 0.0193,
      "step": 24100
    },
    {
      "epoch": 0.77152,
      "grad_norm": 0.004560369998216629,
      "learning_rate": 1.4856746666666668e-05,
      "loss": 0.0008,
      "step": 24110
    },
    {
      "epoch": 0.77184,
      "grad_norm": 0.0031840279698371887,
      "learning_rate": 1.4854613333333334e-05,
      "loss": 0.0004,
      "step": 24120
    },
    {
      "epoch": 0.77216,
      "grad_norm": 0.006171771325170994,
      "learning_rate": 1.485248e-05,
      "loss": 0.0007,
      "step": 24130
    },
    {
      "epoch": 0.77248,
      "grad_norm": 0.006345116999000311,
      "learning_rate": 1.4850346666666668e-05,
      "loss": 0.0356,
      "step": 24140
    },
    {
      "epoch": 0.7728,
      "grad_norm": 0.007408568169921637,
      "learning_rate": 1.4848213333333335e-05,
      "loss": 0.0507,
      "step": 24150
    },
    {
      "epoch": 0.77312,
      "grad_norm": 0.005199773702770472,
      "learning_rate": 1.484608e-05,
      "loss": 0.0036,
      "step": 24160
    },
    {
      "epoch": 0.77344,
      "grad_norm": 0.004709620960056782,
      "learning_rate": 1.4843946666666669e-05,
      "loss": 0.0065,
      "step": 24170
    },
    {
      "epoch": 0.77376,
      "grad_norm": 0.007863802835345268,
      "learning_rate": 1.4841813333333334e-05,
      "loss": 0.0065,
      "step": 24180
    },
    {
      "epoch": 0.77408,
      "grad_norm": 0.18673405051231384,
      "learning_rate": 1.4839680000000002e-05,
      "loss": 0.001,
      "step": 24190
    },
    {
      "epoch": 0.7744,
      "grad_norm": 0.019352762028574944,
      "learning_rate": 1.4837546666666669e-05,
      "loss": 0.0005,
      "step": 24200
    },
    {
      "epoch": 0.77472,
      "grad_norm": 0.013744713738560677,
      "learning_rate": 1.4835413333333336e-05,
      "loss": 0.0037,
      "step": 24210
    },
    {
      "epoch": 0.77504,
      "grad_norm": 0.00599877443164587,
      "learning_rate": 1.4833280000000001e-05,
      "loss": 0.0004,
      "step": 24220
    },
    {
      "epoch": 0.77536,
      "grad_norm": 4.386270523071289,
      "learning_rate": 1.4831146666666666e-05,
      "loss": 0.0647,
      "step": 24230
    },
    {
      "epoch": 0.77568,
      "grad_norm": 0.012936056591570377,
      "learning_rate": 1.4829013333333335e-05,
      "loss": 0.0006,
      "step": 24240
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.010195277631282806,
      "learning_rate": 1.482688e-05,
      "loss": 0.0005,
      "step": 24250
    },
    {
      "epoch": 0.77632,
      "grad_norm": 0.004740435630083084,
      "learning_rate": 1.4824746666666668e-05,
      "loss": 0.0014,
      "step": 24260
    },
    {
      "epoch": 0.77664,
      "grad_norm": 0.005099376663565636,
      "learning_rate": 1.4822613333333335e-05,
      "loss": 0.0003,
      "step": 24270
    },
    {
      "epoch": 0.77696,
      "grad_norm": 0.008966382592916489,
      "learning_rate": 1.4820480000000002e-05,
      "loss": 0.0004,
      "step": 24280
    },
    {
      "epoch": 0.77728,
      "grad_norm": 0.009380615316331387,
      "learning_rate": 1.4818346666666667e-05,
      "loss": 0.0005,
      "step": 24290
    },
    {
      "epoch": 0.7776,
      "grad_norm": 0.008663943968713284,
      "learning_rate": 1.4816213333333334e-05,
      "loss": 0.001,
      "step": 24300
    },
    {
      "epoch": 0.77792,
      "grad_norm": 0.010607586242258549,
      "learning_rate": 1.4814080000000001e-05,
      "loss": 0.0071,
      "step": 24310
    },
    {
      "epoch": 0.77824,
      "grad_norm": 0.008727896958589554,
      "learning_rate": 1.4811946666666668e-05,
      "loss": 0.0004,
      "step": 24320
    },
    {
      "epoch": 0.77856,
      "grad_norm": 0.010067751631140709,
      "learning_rate": 1.4809813333333334e-05,
      "loss": 0.002,
      "step": 24330
    },
    {
      "epoch": 0.77888,
      "grad_norm": 0.0028758568223565817,
      "learning_rate": 1.4807680000000003e-05,
      "loss": 0.053,
      "step": 24340
    },
    {
      "epoch": 0.7792,
      "grad_norm": 0.00879490002989769,
      "learning_rate": 1.4805546666666668e-05,
      "loss": 0.0006,
      "step": 24350
    },
    {
      "epoch": 0.77952,
      "grad_norm": 0.01737263984978199,
      "learning_rate": 1.4803413333333333e-05,
      "loss": 0.0009,
      "step": 24360
    },
    {
      "epoch": 0.77984,
      "grad_norm": 0.0048322370275855064,
      "learning_rate": 1.4801280000000002e-05,
      "loss": 0.0007,
      "step": 24370
    },
    {
      "epoch": 0.78016,
      "grad_norm": 0.0076964301988482475,
      "learning_rate": 1.4799146666666669e-05,
      "loss": 0.0004,
      "step": 24380
    },
    {
      "epoch": 0.78048,
      "grad_norm": 0.006167770829051733,
      "learning_rate": 1.4797013333333335e-05,
      "loss": 0.0003,
      "step": 24390
    },
    {
      "epoch": 0.7808,
      "grad_norm": 0.005661969073116779,
      "learning_rate": 1.479488e-05,
      "loss": 0.0003,
      "step": 24400
    },
    {
      "epoch": 0.78112,
      "grad_norm": 0.009448175318539143,
      "learning_rate": 1.4792746666666669e-05,
      "loss": 0.0003,
      "step": 24410
    },
    {
      "epoch": 0.78144,
      "grad_norm": 0.00419126870110631,
      "learning_rate": 1.4790613333333334e-05,
      "loss": 0.0554,
      "step": 24420
    },
    {
      "epoch": 0.78176,
      "grad_norm": 0.004876499529927969,
      "learning_rate": 1.4788480000000001e-05,
      "loss": 0.0289,
      "step": 24430
    },
    {
      "epoch": 0.78208,
      "grad_norm": 0.006429504137486219,
      "learning_rate": 1.4786346666666668e-05,
      "loss": 0.0005,
      "step": 24440
    },
    {
      "epoch": 0.7824,
      "grad_norm": 3.0106165409088135,
      "learning_rate": 1.4784213333333335e-05,
      "loss": 0.0068,
      "step": 24450
    },
    {
      "epoch": 0.78272,
      "grad_norm": 0.006538152229040861,
      "learning_rate": 1.478208e-05,
      "loss": 0.0003,
      "step": 24460
    },
    {
      "epoch": 0.78304,
      "grad_norm": 0.07742297649383545,
      "learning_rate": 1.4779946666666668e-05,
      "loss": 0.0821,
      "step": 24470
    },
    {
      "epoch": 0.78336,
      "grad_norm": 0.0058842315338552,
      "learning_rate": 1.4777813333333335e-05,
      "loss": 0.0493,
      "step": 24480
    },
    {
      "epoch": 0.78368,
      "grad_norm": 0.009605452418327332,
      "learning_rate": 1.4775680000000002e-05,
      "loss": 0.0008,
      "step": 24490
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.007693585939705372,
      "learning_rate": 1.4773546666666667e-05,
      "loss": 0.001,
      "step": 24500
    },
    {
      "epoch": 0.78432,
      "grad_norm": 0.007693121675401926,
      "learning_rate": 1.4771413333333336e-05,
      "loss": 0.0222,
      "step": 24510
    },
    {
      "epoch": 0.78464,
      "grad_norm": 0.008282054215669632,
      "learning_rate": 1.4769280000000001e-05,
      "loss": 0.0188,
      "step": 24520
    },
    {
      "epoch": 0.78496,
      "grad_norm": 0.012059282511472702,
      "learning_rate": 1.4767146666666667e-05,
      "loss": 0.0023,
      "step": 24530
    },
    {
      "epoch": 0.78528,
      "grad_norm": 0.0035200200509279966,
      "learning_rate": 1.4765013333333335e-05,
      "loss": 0.0015,
      "step": 24540
    },
    {
      "epoch": 0.7856,
      "grad_norm": 0.006989176385104656,
      "learning_rate": 1.4762880000000001e-05,
      "loss": 0.0005,
      "step": 24550
    },
    {
      "epoch": 0.78592,
      "grad_norm": 0.0037787286564707756,
      "learning_rate": 1.4760746666666668e-05,
      "loss": 0.0004,
      "step": 24560
    },
    {
      "epoch": 0.78624,
      "grad_norm": 0.005097902379930019,
      "learning_rate": 1.4758613333333333e-05,
      "loss": 0.0003,
      "step": 24570
    },
    {
      "epoch": 0.78656,
      "grad_norm": 0.00934410747140646,
      "learning_rate": 1.4756480000000002e-05,
      "loss": 0.0586,
      "step": 24580
    },
    {
      "epoch": 0.78688,
      "grad_norm": 0.008486852049827576,
      "learning_rate": 1.4754346666666667e-05,
      "loss": 0.0005,
      "step": 24590
    },
    {
      "epoch": 0.7872,
      "grad_norm": 0.004353917669504881,
      "learning_rate": 1.4752213333333335e-05,
      "loss": 0.0003,
      "step": 24600
    },
    {
      "epoch": 0.78752,
      "grad_norm": 2.1338844299316406,
      "learning_rate": 1.4750080000000002e-05,
      "loss": 0.0273,
      "step": 24610
    },
    {
      "epoch": 0.78784,
      "grad_norm": 0.005299747921526432,
      "learning_rate": 1.4747946666666669e-05,
      "loss": 0.0004,
      "step": 24620
    },
    {
      "epoch": 0.78816,
      "grad_norm": 0.04905460774898529,
      "learning_rate": 1.4745813333333334e-05,
      "loss": 0.0005,
      "step": 24630
    },
    {
      "epoch": 0.78848,
      "grad_norm": 0.010879075154662132,
      "learning_rate": 1.474368e-05,
      "loss": 0.0018,
      "step": 24640
    },
    {
      "epoch": 0.7888,
      "grad_norm": 0.501166582107544,
      "learning_rate": 1.4741546666666668e-05,
      "loss": 0.0078,
      "step": 24650
    },
    {
      "epoch": 0.78912,
      "grad_norm": 0.010215125046670437,
      "learning_rate": 1.4739413333333335e-05,
      "loss": 0.0003,
      "step": 24660
    },
    {
      "epoch": 0.78944,
      "grad_norm": 1.5102276802062988,
      "learning_rate": 1.473728e-05,
      "loss": 0.0023,
      "step": 24670
    },
    {
      "epoch": 0.78976,
      "grad_norm": 0.009823017753660679,
      "learning_rate": 1.473514666666667e-05,
      "loss": 0.0003,
      "step": 24680
    },
    {
      "epoch": 0.79008,
      "grad_norm": 0.011121310293674469,
      "learning_rate": 1.4733013333333335e-05,
      "loss": 0.0017,
      "step": 24690
    },
    {
      "epoch": 0.7904,
      "grad_norm": 0.003653100924566388,
      "learning_rate": 1.473088e-05,
      "loss": 0.0004,
      "step": 24700
    },
    {
      "epoch": 0.79072,
      "grad_norm": 0.004647460300475359,
      "learning_rate": 1.4728746666666669e-05,
      "loss": 0.0006,
      "step": 24710
    },
    {
      "epoch": 0.79104,
      "grad_norm": 0.11042995750904083,
      "learning_rate": 1.4726613333333334e-05,
      "loss": 0.0012,
      "step": 24720
    },
    {
      "epoch": 0.79136,
      "grad_norm": 0.006288428790867329,
      "learning_rate": 1.4724480000000001e-05,
      "loss": 0.0006,
      "step": 24730
    },
    {
      "epoch": 0.79168,
      "grad_norm": 0.0032671578228473663,
      "learning_rate": 1.4722346666666667e-05,
      "loss": 0.043,
      "step": 24740
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.005729529075324535,
      "learning_rate": 1.4720213333333336e-05,
      "loss": 0.0011,
      "step": 24750
    },
    {
      "epoch": 0.79232,
      "grad_norm": 0.05666675046086311,
      "learning_rate": 1.4718080000000001e-05,
      "loss": 0.0003,
      "step": 24760
    },
    {
      "epoch": 0.79264,
      "grad_norm": 0.00917765498161316,
      "learning_rate": 1.4715946666666668e-05,
      "loss": 0.0003,
      "step": 24770
    },
    {
      "epoch": 0.79296,
      "grad_norm": 0.004954391159117222,
      "learning_rate": 1.4713813333333335e-05,
      "loss": 0.0008,
      "step": 24780
    },
    {
      "epoch": 0.79328,
      "grad_norm": 0.004422618076205254,
      "learning_rate": 1.4711680000000002e-05,
      "loss": 0.0003,
      "step": 24790
    },
    {
      "epoch": 0.7936,
      "grad_norm": 0.0036478405818343163,
      "learning_rate": 1.4709546666666667e-05,
      "loss": 0.0173,
      "step": 24800
    },
    {
      "epoch": 0.79392,
      "grad_norm": 0.00298679294064641,
      "learning_rate": 1.4707413333333333e-05,
      "loss": 0.048,
      "step": 24810
    },
    {
      "epoch": 0.79424,
      "grad_norm": 0.0050445375964045525,
      "learning_rate": 1.4705280000000002e-05,
      "loss": 0.0006,
      "step": 24820
    },
    {
      "epoch": 0.79456,
      "grad_norm": 0.005561176221817732,
      "learning_rate": 1.4703146666666667e-05,
      "loss": 0.0006,
      "step": 24830
    },
    {
      "epoch": 0.79488,
      "grad_norm": 0.009679258801043034,
      "learning_rate": 1.4701013333333334e-05,
      "loss": 0.0003,
      "step": 24840
    },
    {
      "epoch": 0.7952,
      "grad_norm": 0.009515278041362762,
      "learning_rate": 1.4698880000000003e-05,
      "loss": 0.0003,
      "step": 24850
    },
    {
      "epoch": 0.79552,
      "grad_norm": 3.478323459625244,
      "learning_rate": 1.4696746666666668e-05,
      "loss": 0.0997,
      "step": 24860
    },
    {
      "epoch": 0.79584,
      "grad_norm": 0.006779974326491356,
      "learning_rate": 1.4694613333333334e-05,
      "loss": 0.0003,
      "step": 24870
    },
    {
      "epoch": 0.79616,
      "grad_norm": 0.016493402421474457,
      "learning_rate": 1.4692480000000002e-05,
      "loss": 0.0006,
      "step": 24880
    },
    {
      "epoch": 0.79648,
      "grad_norm": 0.12005753815174103,
      "learning_rate": 1.4690346666666668e-05,
      "loss": 0.0007,
      "step": 24890
    },
    {
      "epoch": 0.7968,
      "grad_norm": 0.1291808933019638,
      "learning_rate": 1.4688213333333335e-05,
      "loss": 0.0253,
      "step": 24900
    },
    {
      "epoch": 0.79712,
      "grad_norm": 0.054951827973127365,
      "learning_rate": 1.468608e-05,
      "loss": 0.0005,
      "step": 24910
    },
    {
      "epoch": 0.79744,
      "grad_norm": 0.006220545154064894,
      "learning_rate": 1.4683946666666669e-05,
      "loss": 0.0081,
      "step": 24920
    },
    {
      "epoch": 0.79776,
      "grad_norm": 0.004927660804241896,
      "learning_rate": 1.4681813333333334e-05,
      "loss": 0.0004,
      "step": 24930
    },
    {
      "epoch": 0.79808,
      "grad_norm": 0.007145551033318043,
      "learning_rate": 1.4679680000000001e-05,
      "loss": 0.0004,
      "step": 24940
    },
    {
      "epoch": 0.7984,
      "grad_norm": 0.029866283759474754,
      "learning_rate": 1.4677546666666668e-05,
      "loss": 0.0723,
      "step": 24950
    },
    {
      "epoch": 0.79872,
      "grad_norm": 0.024887340143322945,
      "learning_rate": 1.4675413333333336e-05,
      "loss": 0.0074,
      "step": 24960
    },
    {
      "epoch": 0.79904,
      "grad_norm": 0.0065990472212433815,
      "learning_rate": 1.4673280000000001e-05,
      "loss": 0.001,
      "step": 24970
    },
    {
      "epoch": 0.79936,
      "grad_norm": 0.0420149490237236,
      "learning_rate": 1.4671146666666666e-05,
      "loss": 0.0004,
      "step": 24980
    },
    {
      "epoch": 0.79968,
      "grad_norm": 0.007408187724649906,
      "learning_rate": 1.4669013333333335e-05,
      "loss": 0.0114,
      "step": 24990
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.03605630248785019,
      "learning_rate": 1.466688e-05,
      "loss": 0.0502,
      "step": 25000
    },
    {
      "epoch": 0.80032,
      "grad_norm": 0.06421563774347305,
      "learning_rate": 1.4664746666666667e-05,
      "loss": 0.0005,
      "step": 25010
    },
    {
      "epoch": 0.80064,
      "grad_norm": 0.015334759838879108,
      "learning_rate": 1.4662613333333335e-05,
      "loss": 0.0008,
      "step": 25020
    },
    {
      "epoch": 0.80096,
      "grad_norm": 0.017632808536291122,
      "learning_rate": 1.4660480000000002e-05,
      "loss": 0.0005,
      "step": 25030
    },
    {
      "epoch": 0.80128,
      "grad_norm": 0.00897501315921545,
      "learning_rate": 1.4658346666666667e-05,
      "loss": 0.0023,
      "step": 25040
    },
    {
      "epoch": 0.8016,
      "grad_norm": 0.005619424395263195,
      "learning_rate": 1.4656213333333336e-05,
      "loss": 0.0016,
      "step": 25050
    },
    {
      "epoch": 0.80192,
      "grad_norm": 0.006411267910152674,
      "learning_rate": 1.4654080000000001e-05,
      "loss": 0.0003,
      "step": 25060
    },
    {
      "epoch": 0.80224,
      "grad_norm": 0.015295987948775291,
      "learning_rate": 1.4651946666666668e-05,
      "loss": 0.0389,
      "step": 25070
    },
    {
      "epoch": 0.80256,
      "grad_norm": 0.005986078176647425,
      "learning_rate": 1.4649813333333334e-05,
      "loss": 0.0007,
      "step": 25080
    },
    {
      "epoch": 0.80288,
      "grad_norm": 0.0055546835064888,
      "learning_rate": 1.4647680000000002e-05,
      "loss": 0.0013,
      "step": 25090
    },
    {
      "epoch": 0.8032,
      "grad_norm": 0.01869920641183853,
      "learning_rate": 1.4645546666666668e-05,
      "loss": 0.0005,
      "step": 25100
    },
    {
      "epoch": 0.80352,
      "grad_norm": 0.008129525929689407,
      "learning_rate": 1.4643413333333333e-05,
      "loss": 0.0006,
      "step": 25110
    },
    {
      "epoch": 0.80384,
      "grad_norm": 0.027183745056390762,
      "learning_rate": 1.4641280000000002e-05,
      "loss": 0.0009,
      "step": 25120
    },
    {
      "epoch": 0.80416,
      "grad_norm": 0.025239046663045883,
      "learning_rate": 1.4639146666666669e-05,
      "loss": 0.0007,
      "step": 25130
    },
    {
      "epoch": 0.80448,
      "grad_norm": 0.0075747850351035595,
      "learning_rate": 1.4637013333333334e-05,
      "loss": 0.0023,
      "step": 25140
    },
    {
      "epoch": 0.8048,
      "grad_norm": 0.049729399383068085,
      "learning_rate": 1.463488e-05,
      "loss": 0.001,
      "step": 25150
    },
    {
      "epoch": 0.80512,
      "grad_norm": 0.006097342818975449,
      "learning_rate": 1.4632746666666668e-05,
      "loss": 0.0003,
      "step": 25160
    },
    {
      "epoch": 0.80544,
      "grad_norm": 0.006330110132694244,
      "learning_rate": 1.4630613333333334e-05,
      "loss": 0.0003,
      "step": 25170
    },
    {
      "epoch": 0.80576,
      "grad_norm": 0.009173114784061909,
      "learning_rate": 1.4628480000000001e-05,
      "loss": 0.0007,
      "step": 25180
    },
    {
      "epoch": 0.80608,
      "grad_norm": 0.4734523296356201,
      "learning_rate": 1.4626346666666668e-05,
      "loss": 0.004,
      "step": 25190
    },
    {
      "epoch": 0.8064,
      "grad_norm": 0.0037188956048339605,
      "learning_rate": 1.4624213333333335e-05,
      "loss": 0.0014,
      "step": 25200
    },
    {
      "epoch": 0.80672,
      "grad_norm": 0.009408453479409218,
      "learning_rate": 1.462208e-05,
      "loss": 0.0005,
      "step": 25210
    },
    {
      "epoch": 0.80704,
      "grad_norm": 0.004418613389134407,
      "learning_rate": 1.461994666666667e-05,
      "loss": 0.0007,
      "step": 25220
    },
    {
      "epoch": 0.80736,
      "grad_norm": 0.011512026190757751,
      "learning_rate": 1.4617813333333335e-05,
      "loss": 0.0003,
      "step": 25230
    },
    {
      "epoch": 0.80768,
      "grad_norm": 0.004265964031219482,
      "learning_rate": 1.4615680000000002e-05,
      "loss": 0.0006,
      "step": 25240
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.006810079328715801,
      "learning_rate": 1.4613546666666667e-05,
      "loss": 0.0434,
      "step": 25250
    },
    {
      "epoch": 0.80832,
      "grad_norm": 0.03148351609706879,
      "learning_rate": 1.4611413333333336e-05,
      "loss": 0.0004,
      "step": 25260
    },
    {
      "epoch": 0.80864,
      "grad_norm": 0.02752183936536312,
      "learning_rate": 1.4609280000000001e-05,
      "loss": 0.0004,
      "step": 25270
    },
    {
      "epoch": 0.80896,
      "grad_norm": 0.013992833904922009,
      "learning_rate": 1.4607146666666667e-05,
      "loss": 0.0006,
      "step": 25280
    },
    {
      "epoch": 0.80928,
      "grad_norm": 0.013630026020109653,
      "learning_rate": 1.4605013333333335e-05,
      "loss": 0.0502,
      "step": 25290
    },
    {
      "epoch": 0.8096,
      "grad_norm": 0.0026245638728141785,
      "learning_rate": 1.460288e-05,
      "loss": 0.0008,
      "step": 25300
    },
    {
      "epoch": 0.80992,
      "grad_norm": 0.005087028257548809,
      "learning_rate": 1.4600746666666668e-05,
      "loss": 0.0011,
      "step": 25310
    },
    {
      "epoch": 0.81024,
      "grad_norm": 0.02399999462068081,
      "learning_rate": 1.4598613333333333e-05,
      "loss": 0.0071,
      "step": 25320
    },
    {
      "epoch": 0.81056,
      "grad_norm": 0.013541300781071186,
      "learning_rate": 1.4596480000000002e-05,
      "loss": 0.0144,
      "step": 25330
    },
    {
      "epoch": 0.81088,
      "grad_norm": 0.008786199614405632,
      "learning_rate": 1.4594346666666667e-05,
      "loss": 0.0006,
      "step": 25340
    },
    {
      "epoch": 0.8112,
      "grad_norm": 0.010051984339952469,
      "learning_rate": 1.4592213333333334e-05,
      "loss": 0.0003,
      "step": 25350
    },
    {
      "epoch": 0.81152,
      "grad_norm": 0.022933954373002052,
      "learning_rate": 1.4590080000000001e-05,
      "loss": 0.0003,
      "step": 25360
    },
    {
      "epoch": 0.81184,
      "grad_norm": 0.006869570817798376,
      "learning_rate": 1.4587946666666669e-05,
      "loss": 0.0003,
      "step": 25370
    },
    {
      "epoch": 0.81216,
      "grad_norm": 0.0057258689776062965,
      "learning_rate": 1.4585813333333334e-05,
      "loss": 0.0004,
      "step": 25380
    },
    {
      "epoch": 0.81248,
      "grad_norm": 0.0039141299203038216,
      "learning_rate": 1.4583680000000003e-05,
      "loss": 0.0003,
      "step": 25390
    },
    {
      "epoch": 0.8128,
      "grad_norm": 0.009493183344602585,
      "learning_rate": 1.4581546666666668e-05,
      "loss": 0.0003,
      "step": 25400
    },
    {
      "epoch": 0.81312,
      "grad_norm": 0.0045957863330841064,
      "learning_rate": 1.4579413333333335e-05,
      "loss": 0.0044,
      "step": 25410
    },
    {
      "epoch": 0.81344,
      "grad_norm": 0.004920536652207375,
      "learning_rate": 1.457728e-05,
      "loss": 0.0008,
      "step": 25420
    },
    {
      "epoch": 0.81376,
      "grad_norm": 0.0038151934277266264,
      "learning_rate": 1.457514666666667e-05,
      "loss": 0.0014,
      "step": 25430
    },
    {
      "epoch": 0.81408,
      "grad_norm": 0.02722458355128765,
      "learning_rate": 1.4573013333333335e-05,
      "loss": 0.0164,
      "step": 25440
    },
    {
      "epoch": 0.8144,
      "grad_norm": 0.010852011851966381,
      "learning_rate": 1.457088e-05,
      "loss": 0.0555,
      "step": 25450
    },
    {
      "epoch": 0.81472,
      "grad_norm": 0.031733740121126175,
      "learning_rate": 1.4568746666666669e-05,
      "loss": 0.0004,
      "step": 25460
    },
    {
      "epoch": 0.81504,
      "grad_norm": 0.011012518778443336,
      "learning_rate": 1.4566613333333334e-05,
      "loss": 0.0003,
      "step": 25470
    },
    {
      "epoch": 0.81536,
      "grad_norm": 0.003921290393918753,
      "learning_rate": 1.4564480000000001e-05,
      "loss": 0.0236,
      "step": 25480
    },
    {
      "epoch": 0.81568,
      "grad_norm": 0.005780232138931751,
      "learning_rate": 1.4562346666666667e-05,
      "loss": 0.0047,
      "step": 25490
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.005725076887756586,
      "learning_rate": 1.4560213333333335e-05,
      "loss": 0.0009,
      "step": 25500
    },
    {
      "epoch": 0.81632,
      "grad_norm": 0.004742488265037537,
      "learning_rate": 1.455808e-05,
      "loss": 0.0003,
      "step": 25510
    },
    {
      "epoch": 0.81664,
      "grad_norm": 0.006547836586833,
      "learning_rate": 1.4555946666666668e-05,
      "loss": 0.0008,
      "step": 25520
    },
    {
      "epoch": 0.81696,
      "grad_norm": 0.005747745744884014,
      "learning_rate": 1.4553813333333335e-05,
      "loss": 0.0049,
      "step": 25530
    },
    {
      "epoch": 0.81728,
      "grad_norm": 0.005773276090621948,
      "learning_rate": 1.4551680000000002e-05,
      "loss": 0.0019,
      "step": 25540
    },
    {
      "epoch": 0.8176,
      "grad_norm": 0.006339799612760544,
      "learning_rate": 1.4549546666666667e-05,
      "loss": 0.0002,
      "step": 25550
    },
    {
      "epoch": 0.81792,
      "grad_norm": 0.07890033721923828,
      "learning_rate": 1.4547413333333336e-05,
      "loss": 0.0004,
      "step": 25560
    },
    {
      "epoch": 0.81824,
      "grad_norm": 0.006798157002776861,
      "learning_rate": 1.4545280000000001e-05,
      "loss": 0.0006,
      "step": 25570
    },
    {
      "epoch": 0.81856,
      "grad_norm": 0.004928379785269499,
      "learning_rate": 1.4543146666666667e-05,
      "loss": 0.0111,
      "step": 25580
    },
    {
      "epoch": 0.81888,
      "grad_norm": 0.005765174515545368,
      "learning_rate": 1.4541013333333334e-05,
      "loss": 0.0002,
      "step": 25590
    },
    {
      "epoch": 0.8192,
      "grad_norm": 0.0035405613016337156,
      "learning_rate": 1.4538880000000003e-05,
      "loss": 0.0014,
      "step": 25600
    },
    {
      "epoch": 0.81952,
      "grad_norm": 0.004792670253664255,
      "learning_rate": 1.4536746666666668e-05,
      "loss": 0.0006,
      "step": 25610
    },
    {
      "epoch": 0.81984,
      "grad_norm": 0.007313303183764219,
      "learning_rate": 1.4534613333333333e-05,
      "loss": 0.0022,
      "step": 25620
    },
    {
      "epoch": 0.82016,
      "grad_norm": 0.018071044236421585,
      "learning_rate": 1.4532480000000002e-05,
      "loss": 0.0005,
      "step": 25630
    },
    {
      "epoch": 0.82048,
      "grad_norm": 0.008362500928342342,
      "learning_rate": 1.4530346666666668e-05,
      "loss": 0.0121,
      "step": 25640
    },
    {
      "epoch": 0.8208,
      "grad_norm": 0.008248494938015938,
      "learning_rate": 1.4528213333333335e-05,
      "loss": 0.0005,
      "step": 25650
    },
    {
      "epoch": 0.82112,
      "grad_norm": 0.005400148686021566,
      "learning_rate": 1.452608e-05,
      "loss": 0.0004,
      "step": 25660
    },
    {
      "epoch": 0.82144,
      "grad_norm": 0.010120953433215618,
      "learning_rate": 1.4523946666666669e-05,
      "loss": 0.0003,
      "step": 25670
    },
    {
      "epoch": 0.82176,
      "grad_norm": 0.004067123401910067,
      "learning_rate": 1.4521813333333334e-05,
      "loss": 0.0023,
      "step": 25680
    },
    {
      "epoch": 0.82208,
      "grad_norm": 0.004118124954402447,
      "learning_rate": 1.4519680000000001e-05,
      "loss": 0.0004,
      "step": 25690
    },
    {
      "epoch": 0.8224,
      "grad_norm": 0.005998941138386726,
      "learning_rate": 1.4517546666666668e-05,
      "loss": 0.0002,
      "step": 25700
    },
    {
      "epoch": 0.82272,
      "grad_norm": 0.006172399502247572,
      "learning_rate": 1.4515413333333335e-05,
      "loss": 0.0003,
      "step": 25710
    },
    {
      "epoch": 0.82304,
      "grad_norm": 0.005907461047172546,
      "learning_rate": 1.451328e-05,
      "loss": 0.0004,
      "step": 25720
    },
    {
      "epoch": 0.82336,
      "grad_norm": 0.005744142457842827,
      "learning_rate": 1.451114666666667e-05,
      "loss": 0.0003,
      "step": 25730
    },
    {
      "epoch": 0.82368,
      "grad_norm": 0.02141692489385605,
      "learning_rate": 1.4509013333333335e-05,
      "loss": 0.0017,
      "step": 25740
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.008129341527819633,
      "learning_rate": 1.450688e-05,
      "loss": 0.0008,
      "step": 25750
    },
    {
      "epoch": 0.82432,
      "grad_norm": 0.005716528277844191,
      "learning_rate": 1.4504746666666667e-05,
      "loss": 0.0196,
      "step": 25760
    },
    {
      "epoch": 0.82464,
      "grad_norm": 0.0024610720574855804,
      "learning_rate": 1.4502613333333334e-05,
      "loss": 0.0002,
      "step": 25770
    },
    {
      "epoch": 0.82496,
      "grad_norm": 0.0032547907903790474,
      "learning_rate": 1.4500480000000001e-05,
      "loss": 0.0004,
      "step": 25780
    },
    {
      "epoch": 0.82528,
      "grad_norm": 0.007219549734145403,
      "learning_rate": 1.4498346666666667e-05,
      "loss": 0.0096,
      "step": 25790
    },
    {
      "epoch": 0.8256,
      "grad_norm": 0.008594166487455368,
      "learning_rate": 1.4496213333333336e-05,
      "loss": 0.0002,
      "step": 25800
    },
    {
      "epoch": 0.82592,
      "grad_norm": 0.00869186781346798,
      "learning_rate": 1.4494080000000001e-05,
      "loss": 0.0003,
      "step": 25810
    },
    {
      "epoch": 0.82624,
      "grad_norm": 0.0020702597685158253,
      "learning_rate": 1.4491946666666668e-05,
      "loss": 0.0003,
      "step": 25820
    },
    {
      "epoch": 0.82656,
      "grad_norm": 0.0041802190244197845,
      "learning_rate": 1.4489813333333333e-05,
      "loss": 0.0007,
      "step": 25830
    },
    {
      "epoch": 0.82688,
      "grad_norm": 0.006381683051586151,
      "learning_rate": 1.4487680000000002e-05,
      "loss": 0.0485,
      "step": 25840
    },
    {
      "epoch": 0.8272,
      "grad_norm": 0.015137429349124432,
      "learning_rate": 1.4485546666666668e-05,
      "loss": 0.0002,
      "step": 25850
    },
    {
      "epoch": 0.82752,
      "grad_norm": 0.0062796431593596935,
      "learning_rate": 1.4483413333333333e-05,
      "loss": 0.0414,
      "step": 25860
    },
    {
      "epoch": 0.82784,
      "grad_norm": 0.003586430102586746,
      "learning_rate": 1.4481280000000002e-05,
      "loss": 0.0004,
      "step": 25870
    },
    {
      "epoch": 0.82816,
      "grad_norm": 0.005315160378813744,
      "learning_rate": 1.4479146666666669e-05,
      "loss": 0.0004,
      "step": 25880
    },
    {
      "epoch": 0.82848,
      "grad_norm": 0.005471743177622557,
      "learning_rate": 1.4477013333333334e-05,
      "loss": 0.0003,
      "step": 25890
    },
    {
      "epoch": 0.8288,
      "grad_norm": 0.006437036674469709,
      "learning_rate": 1.4474880000000003e-05,
      "loss": 0.0004,
      "step": 25900
    },
    {
      "epoch": 0.82912,
      "grad_norm": 0.002280821092426777,
      "learning_rate": 1.4472746666666668e-05,
      "loss": 0.0002,
      "step": 25910
    },
    {
      "epoch": 0.82944,
      "grad_norm": 0.011353148147463799,
      "learning_rate": 1.4470613333333334e-05,
      "loss": 0.0002,
      "step": 25920
    },
    {
      "epoch": 0.82976,
      "grad_norm": 0.003975437488406897,
      "learning_rate": 1.446848e-05,
      "loss": 0.0019,
      "step": 25930
    },
    {
      "epoch": 0.83008,
      "grad_norm": 0.003018802497535944,
      "learning_rate": 1.4466346666666668e-05,
      "loss": 0.0003,
      "step": 25940
    },
    {
      "epoch": 0.8304,
      "grad_norm": 4.779410362243652,
      "learning_rate": 1.4464213333333335e-05,
      "loss": 0.0394,
      "step": 25950
    },
    {
      "epoch": 0.83072,
      "grad_norm": 0.00826229527592659,
      "learning_rate": 1.446208e-05,
      "loss": 0.0036,
      "step": 25960
    },
    {
      "epoch": 0.83104,
      "grad_norm": 0.46702221035957336,
      "learning_rate": 1.4459946666666669e-05,
      "loss": 0.0006,
      "step": 25970
    },
    {
      "epoch": 0.83136,
      "grad_norm": 0.007564760744571686,
      "learning_rate": 1.4457813333333334e-05,
      "loss": 0.0585,
      "step": 25980
    },
    {
      "epoch": 0.83168,
      "grad_norm": 0.035931166261434555,
      "learning_rate": 1.4455680000000001e-05,
      "loss": 0.048,
      "step": 25990
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.016650715842843056,
      "learning_rate": 1.4453546666666667e-05,
      "loss": 0.0004,
      "step": 26000
    },
    {
      "epoch": 0.83232,
      "grad_norm": 0.0073569645173847675,
      "learning_rate": 1.4451413333333336e-05,
      "loss": 0.0002,
      "step": 26010
    },
    {
      "epoch": 0.83264,
      "grad_norm": 0.0037973274011164904,
      "learning_rate": 1.4449280000000001e-05,
      "loss": 0.0002,
      "step": 26020
    },
    {
      "epoch": 0.83296,
      "grad_norm": 0.006790217477828264,
      "learning_rate": 1.4447146666666666e-05,
      "loss": 0.0002,
      "step": 26030
    },
    {
      "epoch": 0.83328,
      "grad_norm": 0.02136463299393654,
      "learning_rate": 1.4445013333333335e-05,
      "loss": 0.0003,
      "step": 26040
    },
    {
      "epoch": 0.8336,
      "grad_norm": 0.008638191968202591,
      "learning_rate": 1.444288e-05,
      "loss": 0.0123,
      "step": 26050
    },
    {
      "epoch": 0.83392,
      "grad_norm": 0.0062284632585942745,
      "learning_rate": 1.4440746666666668e-05,
      "loss": 0.0003,
      "step": 26060
    },
    {
      "epoch": 0.83424,
      "grad_norm": 0.005453909747302532,
      "learning_rate": 1.4438613333333336e-05,
      "loss": 0.0492,
      "step": 26070
    },
    {
      "epoch": 0.83456,
      "grad_norm": 0.016310464590787888,
      "learning_rate": 1.4436480000000002e-05,
      "loss": 0.0452,
      "step": 26080
    },
    {
      "epoch": 0.83488,
      "grad_norm": 0.0051767281256616116,
      "learning_rate": 1.4434346666666667e-05,
      "loss": 0.0005,
      "step": 26090
    },
    {
      "epoch": 0.8352,
      "grad_norm": 0.009967445395886898,
      "learning_rate": 1.4432213333333334e-05,
      "loss": 0.0007,
      "step": 26100
    },
    {
      "epoch": 0.83552,
      "grad_norm": 0.004316668026149273,
      "learning_rate": 1.4430080000000001e-05,
      "loss": 0.0003,
      "step": 26110
    },
    {
      "epoch": 0.83584,
      "grad_norm": 0.008090076968073845,
      "learning_rate": 1.4427946666666668e-05,
      "loss": 0.0004,
      "step": 26120
    },
    {
      "epoch": 0.83616,
      "grad_norm": 0.002577562350779772,
      "learning_rate": 1.4425813333333334e-05,
      "loss": 0.0004,
      "step": 26130
    },
    {
      "epoch": 0.83648,
      "grad_norm": 0.00861936155706644,
      "learning_rate": 1.4423680000000002e-05,
      "loss": 0.0005,
      "step": 26140
    },
    {
      "epoch": 0.8368,
      "grad_norm": 0.007303949445486069,
      "learning_rate": 1.4421546666666668e-05,
      "loss": 0.0005,
      "step": 26150
    },
    {
      "epoch": 0.83712,
      "grad_norm": 0.011355356313288212,
      "learning_rate": 1.4419413333333335e-05,
      "loss": 0.0059,
      "step": 26160
    },
    {
      "epoch": 0.83744,
      "grad_norm": 0.026623228564858437,
      "learning_rate": 1.441728e-05,
      "loss": 0.0007,
      "step": 26170
    },
    {
      "epoch": 0.83776,
      "grad_norm": 0.008532010018825531,
      "learning_rate": 1.4415146666666669e-05,
      "loss": 0.0003,
      "step": 26180
    },
    {
      "epoch": 0.83808,
      "grad_norm": 0.06609824299812317,
      "learning_rate": 1.4413013333333334e-05,
      "loss": 0.0006,
      "step": 26190
    },
    {
      "epoch": 0.8384,
      "grad_norm": 0.00279603386297822,
      "learning_rate": 1.441088e-05,
      "loss": 0.0083,
      "step": 26200
    },
    {
      "epoch": 0.83872,
      "grad_norm": 0.012002186849713326,
      "learning_rate": 1.4408746666666669e-05,
      "loss": 0.0226,
      "step": 26210
    },
    {
      "epoch": 0.83904,
      "grad_norm": 0.00921151228249073,
      "learning_rate": 1.4406613333333334e-05,
      "loss": 0.0004,
      "step": 26220
    },
    {
      "epoch": 0.83936,
      "grad_norm": 0.004548782017081976,
      "learning_rate": 1.4404480000000001e-05,
      "loss": 0.0003,
      "step": 26230
    },
    {
      "epoch": 0.83968,
      "grad_norm": 0.006442139856517315,
      "learning_rate": 1.4402346666666668e-05,
      "loss": 0.0003,
      "step": 26240
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.010003851726651192,
      "learning_rate": 1.4400213333333335e-05,
      "loss": 0.1072,
      "step": 26250
    },
    {
      "epoch": 0.84032,
      "grad_norm": 0.004311335738748312,
      "learning_rate": 1.439808e-05,
      "loss": 0.0009,
      "step": 26260
    },
    {
      "epoch": 0.84064,
      "grad_norm": 0.032050032168626785,
      "learning_rate": 1.4395946666666668e-05,
      "loss": 0.0004,
      "step": 26270
    },
    {
      "epoch": 0.84096,
      "grad_norm": 1.1145424842834473,
      "learning_rate": 1.4393813333333335e-05,
      "loss": 0.0784,
      "step": 26280
    },
    {
      "epoch": 0.84128,
      "grad_norm": 0.00440179230645299,
      "learning_rate": 1.4391680000000002e-05,
      "loss": 0.0004,
      "step": 26290
    },
    {
      "epoch": 0.8416,
      "grad_norm": 0.004892744589596987,
      "learning_rate": 1.4389546666666667e-05,
      "loss": 0.0006,
      "step": 26300
    },
    {
      "epoch": 0.84192,
      "grad_norm": 0.005836165975779295,
      "learning_rate": 1.4387413333333336e-05,
      "loss": 0.015,
      "step": 26310
    },
    {
      "epoch": 0.84224,
      "grad_norm": 0.009588669054210186,
      "learning_rate": 1.4385280000000001e-05,
      "loss": 0.0005,
      "step": 26320
    },
    {
      "epoch": 0.84256,
      "grad_norm": 0.004641362931579351,
      "learning_rate": 1.4383146666666667e-05,
      "loss": 0.0378,
      "step": 26330
    },
    {
      "epoch": 0.84288,
      "grad_norm": 0.007304590195417404,
      "learning_rate": 1.4381013333333334e-05,
      "loss": 0.033,
      "step": 26340
    },
    {
      "epoch": 0.8432,
      "grad_norm": 0.07802720367908478,
      "learning_rate": 1.4378880000000003e-05,
      "loss": 0.0059,
      "step": 26350
    },
    {
      "epoch": 0.84352,
      "grad_norm": 0.03668588399887085,
      "learning_rate": 1.4376746666666668e-05,
      "loss": 0.0006,
      "step": 26360
    },
    {
      "epoch": 0.84384,
      "grad_norm": 0.004987508989870548,
      "learning_rate": 1.4374613333333333e-05,
      "loss": 0.0025,
      "step": 26370
    },
    {
      "epoch": 0.84416,
      "grad_norm": 0.009002145379781723,
      "learning_rate": 1.4372480000000002e-05,
      "loss": 0.0005,
      "step": 26380
    },
    {
      "epoch": 0.84448,
      "grad_norm": 0.0048685744404792786,
      "learning_rate": 1.4370346666666667e-05,
      "loss": 0.0032,
      "step": 26390
    },
    {
      "epoch": 0.8448,
      "grad_norm": 1.2278324365615845,
      "learning_rate": 1.4368213333333334e-05,
      "loss": 0.0549,
      "step": 26400
    },
    {
      "epoch": 0.84512,
      "grad_norm": 0.008479374460875988,
      "learning_rate": 1.4366080000000002e-05,
      "loss": 0.0007,
      "step": 26410
    },
    {
      "epoch": 0.84544,
      "grad_norm": 0.011417877860367298,
      "learning_rate": 1.4363946666666669e-05,
      "loss": 0.0005,
      "step": 26420
    },
    {
      "epoch": 0.84576,
      "grad_norm": 0.02471216209232807,
      "learning_rate": 1.4361813333333334e-05,
      "loss": 0.0464,
      "step": 26430
    },
    {
      "epoch": 0.84608,
      "grad_norm": 0.01005722489207983,
      "learning_rate": 1.4359680000000001e-05,
      "loss": 0.0005,
      "step": 26440
    },
    {
      "epoch": 0.8464,
      "grad_norm": 0.0063303387723863125,
      "learning_rate": 1.4357546666666668e-05,
      "loss": 0.0022,
      "step": 26450
    },
    {
      "epoch": 0.84672,
      "grad_norm": 0.01500319130718708,
      "learning_rate": 1.4355413333333335e-05,
      "loss": 0.0169,
      "step": 26460
    },
    {
      "epoch": 0.84704,
      "grad_norm": 0.00992299523204565,
      "learning_rate": 1.435328e-05,
      "loss": 0.0005,
      "step": 26470
    },
    {
      "epoch": 0.84736,
      "grad_norm": 0.009267129935324192,
      "learning_rate": 1.435114666666667e-05,
      "loss": 0.0386,
      "step": 26480
    },
    {
      "epoch": 0.84768,
      "grad_norm": 0.012478050775825977,
      "learning_rate": 1.4349013333333335e-05,
      "loss": 0.0013,
      "step": 26490
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.012255570851266384,
      "learning_rate": 1.434688e-05,
      "loss": 0.048,
      "step": 26500
    },
    {
      "epoch": 0.84832,
      "grad_norm": 0.012308941222727299,
      "learning_rate": 1.4344746666666667e-05,
      "loss": 0.0019,
      "step": 26510
    },
    {
      "epoch": 0.84864,
      "grad_norm": 0.015338672325015068,
      "learning_rate": 1.4342613333333334e-05,
      "loss": 0.0007,
      "step": 26520
    },
    {
      "epoch": 0.84896,
      "grad_norm": 0.005837411619722843,
      "learning_rate": 1.4340480000000001e-05,
      "loss": 0.0006,
      "step": 26530
    },
    {
      "epoch": 0.84928,
      "grad_norm": 0.01008571870625019,
      "learning_rate": 1.4338346666666667e-05,
      "loss": 0.0015,
      "step": 26540
    },
    {
      "epoch": 0.8496,
      "grad_norm": 0.0065283928997814655,
      "learning_rate": 1.4336213333333335e-05,
      "loss": 0.0004,
      "step": 26550
    },
    {
      "epoch": 0.84992,
      "grad_norm": 0.00471399025991559,
      "learning_rate": 1.433408e-05,
      "loss": 0.001,
      "step": 26560
    },
    {
      "epoch": 0.85024,
      "grad_norm": 0.011596865952014923,
      "learning_rate": 1.4331946666666668e-05,
      "loss": 0.0004,
      "step": 26570
    },
    {
      "epoch": 0.85056,
      "grad_norm": 0.0039472742937505245,
      "learning_rate": 1.4329813333333335e-05,
      "loss": 0.0004,
      "step": 26580
    },
    {
      "epoch": 0.85088,
      "grad_norm": 0.005235331133008003,
      "learning_rate": 1.4327680000000002e-05,
      "loss": 0.0013,
      "step": 26590
    },
    {
      "epoch": 0.8512,
      "grad_norm": 0.01768575608730316,
      "learning_rate": 1.4325546666666667e-05,
      "loss": 0.0004,
      "step": 26600
    },
    {
      "epoch": 0.85152,
      "grad_norm": 0.023694107308983803,
      "learning_rate": 1.4323413333333333e-05,
      "loss": 0.0003,
      "step": 26610
    },
    {
      "epoch": 0.85184,
      "grad_norm": 0.007684883661568165,
      "learning_rate": 1.4321280000000002e-05,
      "loss": 0.001,
      "step": 26620
    },
    {
      "epoch": 0.85216,
      "grad_norm": 0.007806586567312479,
      "learning_rate": 1.4319146666666669e-05,
      "loss": 0.0009,
      "step": 26630
    },
    {
      "epoch": 0.85248,
      "grad_norm": 0.006505653727799654,
      "learning_rate": 1.4317013333333334e-05,
      "loss": 0.0015,
      "step": 26640
    },
    {
      "epoch": 0.8528,
      "grad_norm": 0.025084037333726883,
      "learning_rate": 1.4314880000000003e-05,
      "loss": 0.0039,
      "step": 26650
    },
    {
      "epoch": 0.85312,
      "grad_norm": 0.004527030047029257,
      "learning_rate": 1.4312746666666668e-05,
      "loss": 0.0003,
      "step": 26660
    },
    {
      "epoch": 0.85344,
      "grad_norm": 0.0026782050263136625,
      "learning_rate": 1.4310613333333334e-05,
      "loss": 0.0371,
      "step": 26670
    },
    {
      "epoch": 0.85376,
      "grad_norm": 0.004616548307240009,
      "learning_rate": 1.430848e-05,
      "loss": 0.0007,
      "step": 26680
    },
    {
      "epoch": 0.85408,
      "grad_norm": 0.007794671226292849,
      "learning_rate": 1.4306346666666668e-05,
      "loss": 0.0004,
      "step": 26690
    },
    {
      "epoch": 0.8544,
      "grad_norm": 0.03900264576077461,
      "learning_rate": 1.4304213333333335e-05,
      "loss": 0.0116,
      "step": 26700
    },
    {
      "epoch": 0.85472,
      "grad_norm": 0.007276811636984348,
      "learning_rate": 1.430208e-05,
      "loss": 0.0003,
      "step": 26710
    },
    {
      "epoch": 0.85504,
      "grad_norm": 0.010058199986815453,
      "learning_rate": 1.4299946666666669e-05,
      "loss": 0.0003,
      "step": 26720
    },
    {
      "epoch": 0.85536,
      "grad_norm": 0.007115711458027363,
      "learning_rate": 1.4297813333333334e-05,
      "loss": 0.0003,
      "step": 26730
    },
    {
      "epoch": 0.85568,
      "grad_norm": 0.0043760621920228004,
      "learning_rate": 1.4295680000000001e-05,
      "loss": 0.0003,
      "step": 26740
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.007664802484214306,
      "learning_rate": 1.4293546666666668e-05,
      "loss": 0.0003,
      "step": 26750
    },
    {
      "epoch": 0.85632,
      "grad_norm": 0.005465338006615639,
      "learning_rate": 1.4291413333333335e-05,
      "loss": 0.0005,
      "step": 26760
    },
    {
      "epoch": 0.85664,
      "grad_norm": 0.010828939266502857,
      "learning_rate": 1.4289280000000001e-05,
      "loss": 0.0006,
      "step": 26770
    },
    {
      "epoch": 0.85696,
      "grad_norm": 0.009435316547751427,
      "learning_rate": 1.4287146666666666e-05,
      "loss": 0.0004,
      "step": 26780
    },
    {
      "epoch": 0.85728,
      "grad_norm": 0.006899289786815643,
      "learning_rate": 1.4285013333333335e-05,
      "loss": 0.0004,
      "step": 26790
    },
    {
      "epoch": 0.8576,
      "grad_norm": 0.005916395224630833,
      "learning_rate": 1.428288e-05,
      "loss": 0.0006,
      "step": 26800
    },
    {
      "epoch": 0.85792,
      "grad_norm": 0.010656091384589672,
      "learning_rate": 1.4280746666666667e-05,
      "loss": 0.0223,
      "step": 26810
    },
    {
      "epoch": 0.85824,
      "grad_norm": 0.02354258857667446,
      "learning_rate": 1.4278613333333336e-05,
      "loss": 0.0004,
      "step": 26820
    },
    {
      "epoch": 0.85856,
      "grad_norm": 0.005986628122627735,
      "learning_rate": 1.4276480000000002e-05,
      "loss": 0.0003,
      "step": 26830
    },
    {
      "epoch": 0.85888,
      "grad_norm": 0.003524961182847619,
      "learning_rate": 1.4274346666666667e-05,
      "loss": 0.0003,
      "step": 26840
    },
    {
      "epoch": 0.8592,
      "grad_norm": 0.07035484910011292,
      "learning_rate": 1.4272213333333334e-05,
      "loss": 0.0305,
      "step": 26850
    },
    {
      "epoch": 0.85952,
      "grad_norm": 0.005269485525786877,
      "learning_rate": 1.4270080000000001e-05,
      "loss": 0.0003,
      "step": 26860
    },
    {
      "epoch": 0.85984,
      "grad_norm": 1.57256019115448,
      "learning_rate": 1.4267946666666668e-05,
      "loss": 0.0014,
      "step": 26870
    },
    {
      "epoch": 0.86016,
      "grad_norm": 0.0060257622972130775,
      "learning_rate": 1.4265813333333334e-05,
      "loss": 0.0117,
      "step": 26880
    },
    {
      "epoch": 0.86048,
      "grad_norm": 0.008695624768733978,
      "learning_rate": 1.4263680000000002e-05,
      "loss": 0.0002,
      "step": 26890
    },
    {
      "epoch": 0.8608,
      "grad_norm": 0.003794765332713723,
      "learning_rate": 1.4261546666666668e-05,
      "loss": 0.0518,
      "step": 26900
    },
    {
      "epoch": 0.86112,
      "grad_norm": 0.004213003907352686,
      "learning_rate": 1.4259413333333335e-05,
      "loss": 0.0004,
      "step": 26910
    },
    {
      "epoch": 0.86144,
      "grad_norm": 0.00492773437872529,
      "learning_rate": 1.4257280000000002e-05,
      "loss": 0.0708,
      "step": 26920
    },
    {
      "epoch": 0.86176,
      "grad_norm": 1.0278958082199097,
      "learning_rate": 1.4255146666666669e-05,
      "loss": 0.0021,
      "step": 26930
    },
    {
      "epoch": 0.86208,
      "grad_norm": 0.0038147151935845613,
      "learning_rate": 1.4253013333333334e-05,
      "loss": 0.0003,
      "step": 26940
    },
    {
      "epoch": 0.8624,
      "grad_norm": 0.004826087038964033,
      "learning_rate": 1.425088e-05,
      "loss": 0.0474,
      "step": 26950
    },
    {
      "epoch": 0.86272,
      "grad_norm": 0.007019148673862219,
      "learning_rate": 1.4248746666666668e-05,
      "loss": 0.0298,
      "step": 26960
    },
    {
      "epoch": 0.86304,
      "grad_norm": 0.010556313209235668,
      "learning_rate": 1.4246613333333334e-05,
      "loss": 0.0006,
      "step": 26970
    },
    {
      "epoch": 0.86336,
      "grad_norm": 0.0029617720283567905,
      "learning_rate": 1.4244480000000001e-05,
      "loss": 0.0282,
      "step": 26980
    },
    {
      "epoch": 0.86368,
      "grad_norm": 0.0040692416951060295,
      "learning_rate": 1.4242346666666668e-05,
      "loss": 0.0003,
      "step": 26990
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.005965874530375004,
      "learning_rate": 1.4240213333333335e-05,
      "loss": 0.0003,
      "step": 27000
    },
    {
      "epoch": 0.86432,
      "grad_norm": 0.00623686658218503,
      "learning_rate": 1.423808e-05,
      "loss": 0.0003,
      "step": 27010
    },
    {
      "epoch": 0.86464,
      "grad_norm": 0.006557415705174208,
      "learning_rate": 1.4235946666666667e-05,
      "loss": 0.041,
      "step": 27020
    },
    {
      "epoch": 0.86496,
      "grad_norm": 0.009575297124683857,
      "learning_rate": 1.4233813333333335e-05,
      "loss": 0.0485,
      "step": 27030
    },
    {
      "epoch": 0.86528,
      "grad_norm": 0.008493509143590927,
      "learning_rate": 1.4231680000000002e-05,
      "loss": 0.0005,
      "step": 27040
    },
    {
      "epoch": 0.8656,
      "grad_norm": 0.005161297973245382,
      "learning_rate": 1.4229546666666667e-05,
      "loss": 0.0068,
      "step": 27050
    },
    {
      "epoch": 0.86592,
      "grad_norm": 0.008798319846391678,
      "learning_rate": 1.4227413333333336e-05,
      "loss": 0.0004,
      "step": 27060
    },
    {
      "epoch": 0.86624,
      "grad_norm": 0.008608561009168625,
      "learning_rate": 1.4225280000000001e-05,
      "loss": 0.037,
      "step": 27070
    },
    {
      "epoch": 0.86656,
      "grad_norm": 0.01856336183845997,
      "learning_rate": 1.4223146666666667e-05,
      "loss": 0.0005,
      "step": 27080
    },
    {
      "epoch": 0.86688,
      "grad_norm": 0.010458028875291348,
      "learning_rate": 1.4221013333333335e-05,
      "loss": 0.0004,
      "step": 27090
    },
    {
      "epoch": 0.8672,
      "grad_norm": 0.014560035429894924,
      "learning_rate": 1.4218880000000002e-05,
      "loss": 0.0004,
      "step": 27100
    },
    {
      "epoch": 0.86752,
      "grad_norm": 0.011431321501731873,
      "learning_rate": 1.4216746666666668e-05,
      "loss": 0.0252,
      "step": 27110
    },
    {
      "epoch": 0.86784,
      "grad_norm": 0.024635523557662964,
      "learning_rate": 1.4214613333333333e-05,
      "loss": 0.0211,
      "step": 27120
    },
    {
      "epoch": 0.86816,
      "grad_norm": 0.010855741798877716,
      "learning_rate": 1.4212480000000002e-05,
      "loss": 0.0006,
      "step": 27130
    },
    {
      "epoch": 0.86848,
      "grad_norm": 0.015444779768586159,
      "learning_rate": 1.4210346666666667e-05,
      "loss": 0.0005,
      "step": 27140
    },
    {
      "epoch": 0.8688,
      "grad_norm": 0.2646641433238983,
      "learning_rate": 1.4208213333333334e-05,
      "loss": 0.0008,
      "step": 27150
    },
    {
      "epoch": 0.86912,
      "grad_norm": 0.004115414340049028,
      "learning_rate": 1.4206080000000001e-05,
      "loss": 0.0008,
      "step": 27160
    },
    {
      "epoch": 0.86944,
      "grad_norm": 0.005955894012004137,
      "learning_rate": 1.4203946666666668e-05,
      "loss": 0.0007,
      "step": 27170
    },
    {
      "epoch": 0.86976,
      "grad_norm": 0.005325105041265488,
      "learning_rate": 1.4201813333333334e-05,
      "loss": 0.0005,
      "step": 27180
    },
    {
      "epoch": 0.87008,
      "grad_norm": 0.004704815335571766,
      "learning_rate": 1.4199680000000001e-05,
      "loss": 0.0038,
      "step": 27190
    },
    {
      "epoch": 0.8704,
      "grad_norm": 0.0051002344116568565,
      "learning_rate": 1.4197546666666668e-05,
      "loss": 0.0013,
      "step": 27200
    },
    {
      "epoch": 0.87072,
      "grad_norm": 0.015587975271046162,
      "learning_rate": 1.4195413333333335e-05,
      "loss": 0.0004,
      "step": 27210
    },
    {
      "epoch": 0.87104,
      "grad_norm": 0.006279230583459139,
      "learning_rate": 1.419328e-05,
      "loss": 0.0004,
      "step": 27220
    },
    {
      "epoch": 0.87136,
      "grad_norm": 0.004992365837097168,
      "learning_rate": 1.419114666666667e-05,
      "loss": 0.0002,
      "step": 27230
    },
    {
      "epoch": 0.87168,
      "grad_norm": 0.008408622816205025,
      "learning_rate": 1.4189013333333335e-05,
      "loss": 0.0101,
      "step": 27240
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.01532751228660345,
      "learning_rate": 1.418688e-05,
      "loss": 0.0004,
      "step": 27250
    },
    {
      "epoch": 0.87232,
      "grad_norm": 0.03640410304069519,
      "learning_rate": 1.4184746666666669e-05,
      "loss": 0.1208,
      "step": 27260
    },
    {
      "epoch": 0.87264,
      "grad_norm": 0.007073512300848961,
      "learning_rate": 1.4182613333333334e-05,
      "loss": 0.0005,
      "step": 27270
    },
    {
      "epoch": 0.87296,
      "grad_norm": 1.4579427242279053,
      "learning_rate": 1.4180480000000001e-05,
      "loss": 0.0025,
      "step": 27280
    },
    {
      "epoch": 0.87328,
      "grad_norm": 0.006649194285273552,
      "learning_rate": 1.4178346666666667e-05,
      "loss": 0.0003,
      "step": 27290
    },
    {
      "epoch": 0.8736,
      "grad_norm": 0.01790522038936615,
      "learning_rate": 1.4176213333333335e-05,
      "loss": 0.0006,
      "step": 27300
    },
    {
      "epoch": 0.87392,
      "grad_norm": 0.005222114734351635,
      "learning_rate": 1.417408e-05,
      "loss": 0.0003,
      "step": 27310
    },
    {
      "epoch": 0.87424,
      "grad_norm": 0.007768855430185795,
      "learning_rate": 1.4171946666666668e-05,
      "loss": 0.0005,
      "step": 27320
    },
    {
      "epoch": 0.87456,
      "grad_norm": 0.00889931246638298,
      "learning_rate": 1.4169813333333335e-05,
      "loss": 0.0304,
      "step": 27330
    },
    {
      "epoch": 0.87488,
      "grad_norm": 2.1462929248809814,
      "learning_rate": 1.4167680000000002e-05,
      "loss": 0.0021,
      "step": 27340
    },
    {
      "epoch": 0.8752,
      "grad_norm": 0.005838701501488686,
      "learning_rate": 1.4165546666666667e-05,
      "loss": 0.0019,
      "step": 27350
    },
    {
      "epoch": 0.87552,
      "grad_norm": 0.007502399384975433,
      "learning_rate": 1.4163413333333333e-05,
      "loss": 0.0004,
      "step": 27360
    },
    {
      "epoch": 0.87584,
      "grad_norm": 0.011504202149808407,
      "learning_rate": 1.4161280000000001e-05,
      "loss": 0.0006,
      "step": 27370
    },
    {
      "epoch": 0.87616,
      "grad_norm": 0.008039179258048534,
      "learning_rate": 1.4159146666666668e-05,
      "loss": 0.0476,
      "step": 27380
    },
    {
      "epoch": 0.87648,
      "grad_norm": 0.007724364288151264,
      "learning_rate": 1.4157013333333334e-05,
      "loss": 0.0003,
      "step": 27390
    },
    {
      "epoch": 0.8768,
      "grad_norm": 1.118118405342102,
      "learning_rate": 1.4154880000000003e-05,
      "loss": 0.0029,
      "step": 27400
    },
    {
      "epoch": 0.87712,
      "grad_norm": 0.026336751878261566,
      "learning_rate": 1.4152746666666668e-05,
      "loss": 0.0005,
      "step": 27410
    },
    {
      "epoch": 0.87744,
      "grad_norm": 0.00802742037922144,
      "learning_rate": 1.4150613333333333e-05,
      "loss": 0.0007,
      "step": 27420
    },
    {
      "epoch": 0.87776,
      "grad_norm": 0.10517211258411407,
      "learning_rate": 1.4148480000000002e-05,
      "loss": 0.0005,
      "step": 27430
    },
    {
      "epoch": 0.87808,
      "grad_norm": 0.010041569359600544,
      "learning_rate": 1.4146346666666668e-05,
      "loss": 0.0004,
      "step": 27440
    },
    {
      "epoch": 0.8784,
      "grad_norm": 0.007159233558923006,
      "learning_rate": 1.4144213333333335e-05,
      "loss": 0.0004,
      "step": 27450
    },
    {
      "epoch": 0.87872,
      "grad_norm": 0.005268790293484926,
      "learning_rate": 1.414208e-05,
      "loss": 0.0195,
      "step": 27460
    },
    {
      "epoch": 0.87904,
      "grad_norm": 0.013985463418066502,
      "learning_rate": 1.4139946666666669e-05,
      "loss": 0.0027,
      "step": 27470
    },
    {
      "epoch": 0.87936,
      "grad_norm": 0.019575845450162888,
      "learning_rate": 1.4137813333333334e-05,
      "loss": 0.0139,
      "step": 27480
    },
    {
      "epoch": 0.87968,
      "grad_norm": 0.26173490285873413,
      "learning_rate": 1.4135680000000001e-05,
      "loss": 0.0007,
      "step": 27490
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.010771551169455051,
      "learning_rate": 1.4133546666666668e-05,
      "loss": 0.0003,
      "step": 27500
    },
    {
      "epoch": 0.88032,
      "grad_norm": 4.69296407699585,
      "learning_rate": 1.4131413333333335e-05,
      "loss": 0.04,
      "step": 27510
    },
    {
      "epoch": 0.88064,
      "grad_norm": 0.006831743288785219,
      "learning_rate": 1.412928e-05,
      "loss": 0.0007,
      "step": 27520
    },
    {
      "epoch": 0.88096,
      "grad_norm": 0.00499434769153595,
      "learning_rate": 1.4127146666666666e-05,
      "loss": 0.0156,
      "step": 27530
    },
    {
      "epoch": 0.88128,
      "grad_norm": 0.004668909125030041,
      "learning_rate": 1.4125013333333335e-05,
      "loss": 0.0003,
      "step": 27540
    },
    {
      "epoch": 0.8816,
      "grad_norm": 0.006714758463203907,
      "learning_rate": 1.412288e-05,
      "loss": 0.0014,
      "step": 27550
    },
    {
      "epoch": 0.88192,
      "grad_norm": 0.0028422228060662746,
      "learning_rate": 1.4120746666666667e-05,
      "loss": 0.0009,
      "step": 27560
    },
    {
      "epoch": 0.88224,
      "grad_norm": 0.007602905388921499,
      "learning_rate": 1.4118613333333336e-05,
      "loss": 0.0004,
      "step": 27570
    },
    {
      "epoch": 0.88256,
      "grad_norm": 0.01328997127711773,
      "learning_rate": 1.4116480000000001e-05,
      "loss": 0.013,
      "step": 27580
    },
    {
      "epoch": 0.88288,
      "grad_norm": 0.01642770692706108,
      "learning_rate": 1.4114346666666667e-05,
      "loss": 0.0005,
      "step": 27590
    },
    {
      "epoch": 0.8832,
      "grad_norm": 0.011123445816338062,
      "learning_rate": 1.4112213333333336e-05,
      "loss": 0.0009,
      "step": 27600
    },
    {
      "epoch": 0.88352,
      "grad_norm": 0.011695516295731068,
      "learning_rate": 1.4110080000000001e-05,
      "loss": 0.0004,
      "step": 27610
    },
    {
      "epoch": 0.88384,
      "grad_norm": 0.005921092350035906,
      "learning_rate": 1.4107946666666668e-05,
      "loss": 0.0003,
      "step": 27620
    },
    {
      "epoch": 0.88416,
      "grad_norm": 0.028019418939948082,
      "learning_rate": 1.4105813333333333e-05,
      "loss": 0.0464,
      "step": 27630
    },
    {
      "epoch": 0.88448,
      "grad_norm": 0.026383664458990097,
      "learning_rate": 1.4103680000000002e-05,
      "loss": 0.0036,
      "step": 27640
    },
    {
      "epoch": 0.8848,
      "grad_norm": 0.00402471236884594,
      "learning_rate": 1.4101546666666668e-05,
      "loss": 0.103,
      "step": 27650
    },
    {
      "epoch": 0.88512,
      "grad_norm": 0.003551408415660262,
      "learning_rate": 1.4099413333333335e-05,
      "loss": 0.0005,
      "step": 27660
    },
    {
      "epoch": 0.88544,
      "grad_norm": 0.011236217804253101,
      "learning_rate": 1.4097280000000002e-05,
      "loss": 0.0005,
      "step": 27670
    },
    {
      "epoch": 0.88576,
      "grad_norm": 0.011168470606207848,
      "learning_rate": 1.4095146666666669e-05,
      "loss": 0.0005,
      "step": 27680
    },
    {
      "epoch": 0.88608,
      "grad_norm": 0.5862883925437927,
      "learning_rate": 1.4093013333333334e-05,
      "loss": 0.0016,
      "step": 27690
    },
    {
      "epoch": 0.8864,
      "grad_norm": 0.012088727205991745,
      "learning_rate": 1.409088e-05,
      "loss": 0.0006,
      "step": 27700
    },
    {
      "epoch": 0.88672,
      "grad_norm": 0.010870126076042652,
      "learning_rate": 1.4088746666666668e-05,
      "loss": 0.0437,
      "step": 27710
    },
    {
      "epoch": 0.88704,
      "grad_norm": 0.005222619511187077,
      "learning_rate": 1.4086613333333334e-05,
      "loss": 0.0015,
      "step": 27720
    },
    {
      "epoch": 0.88736,
      "grad_norm": 0.010785538703203201,
      "learning_rate": 1.408448e-05,
      "loss": 0.0051,
      "step": 27730
    },
    {
      "epoch": 0.88768,
      "grad_norm": 0.006432848051190376,
      "learning_rate": 1.4082346666666668e-05,
      "loss": 0.0015,
      "step": 27740
    },
    {
      "epoch": 0.888,
      "grad_norm": 1.643254280090332,
      "learning_rate": 1.4080213333333335e-05,
      "loss": 0.0484,
      "step": 27750
    },
    {
      "epoch": 0.88832,
      "grad_norm": 1.5486853122711182,
      "learning_rate": 1.407808e-05,
      "loss": 0.0022,
      "step": 27760
    },
    {
      "epoch": 0.88864,
      "grad_norm": 0.011749612167477608,
      "learning_rate": 1.4075946666666669e-05,
      "loss": 0.0005,
      "step": 27770
    },
    {
      "epoch": 0.88896,
      "grad_norm": 0.019832268357276917,
      "learning_rate": 1.4073813333333334e-05,
      "loss": 0.0497,
      "step": 27780
    },
    {
      "epoch": 0.88928,
      "grad_norm": 0.004792878869920969,
      "learning_rate": 1.4071680000000001e-05,
      "loss": 0.0004,
      "step": 27790
    },
    {
      "epoch": 0.8896,
      "grad_norm": 0.005993411410599947,
      "learning_rate": 1.4069546666666667e-05,
      "loss": 0.0008,
      "step": 27800
    },
    {
      "epoch": 0.88992,
      "grad_norm": 0.011587687768042088,
      "learning_rate": 1.4067413333333336e-05,
      "loss": 0.0007,
      "step": 27810
    },
    {
      "epoch": 0.89024,
      "grad_norm": 0.008426412008702755,
      "learning_rate": 1.4065280000000001e-05,
      "loss": 0.0005,
      "step": 27820
    },
    {
      "epoch": 0.89056,
      "grad_norm": 0.007648908533155918,
      "learning_rate": 1.4063146666666666e-05,
      "loss": 0.0003,
      "step": 27830
    },
    {
      "epoch": 0.89088,
      "grad_norm": 0.03591971471905708,
      "learning_rate": 1.4061013333333335e-05,
      "loss": 0.0004,
      "step": 27840
    },
    {
      "epoch": 0.8912,
      "grad_norm": 0.005057110451161861,
      "learning_rate": 1.4058880000000002e-05,
      "loss": 0.0004,
      "step": 27850
    },
    {
      "epoch": 0.89152,
      "grad_norm": 0.004036544356495142,
      "learning_rate": 1.4056746666666668e-05,
      "loss": 0.0645,
      "step": 27860
    },
    {
      "epoch": 0.89184,
      "grad_norm": 0.022705968469381332,
      "learning_rate": 1.4054613333333333e-05,
      "loss": 0.0004,
      "step": 27870
    },
    {
      "epoch": 0.89216,
      "grad_norm": 0.25899311900138855,
      "learning_rate": 1.4052480000000002e-05,
      "loss": 0.0247,
      "step": 27880
    },
    {
      "epoch": 0.89248,
      "grad_norm": 0.006615207996219397,
      "learning_rate": 1.4050346666666667e-05,
      "loss": 0.0004,
      "step": 27890
    },
    {
      "epoch": 0.8928,
      "grad_norm": 0.005822991952300072,
      "learning_rate": 1.4048213333333334e-05,
      "loss": 0.0004,
      "step": 27900
    },
    {
      "epoch": 0.89312,
      "grad_norm": 0.01282818615436554,
      "learning_rate": 1.4046080000000001e-05,
      "loss": 0.0008,
      "step": 27910
    },
    {
      "epoch": 0.89344,
      "grad_norm": 0.005768813192844391,
      "learning_rate": 1.4043946666666668e-05,
      "loss": 0.0005,
      "step": 27920
    },
    {
      "epoch": 0.89376,
      "grad_norm": 0.00660957396030426,
      "learning_rate": 1.4041813333333334e-05,
      "loss": 0.0339,
      "step": 27930
    },
    {
      "epoch": 0.89408,
      "grad_norm": 0.007775739300996065,
      "learning_rate": 1.4039680000000002e-05,
      "loss": 0.0005,
      "step": 27940
    },
    {
      "epoch": 0.8944,
      "grad_norm": 0.007486088667064905,
      "learning_rate": 1.4037546666666668e-05,
      "loss": 0.0005,
      "step": 27950
    },
    {
      "epoch": 0.89472,
      "grad_norm": 0.010848593898117542,
      "learning_rate": 1.4035413333333335e-05,
      "loss": 0.0005,
      "step": 27960
    },
    {
      "epoch": 0.89504,
      "grad_norm": 0.01103323232382536,
      "learning_rate": 1.403328e-05,
      "loss": 0.0005,
      "step": 27970
    },
    {
      "epoch": 0.89536,
      "grad_norm": 0.00951631460338831,
      "learning_rate": 1.4031146666666669e-05,
      "loss": 0.0006,
      "step": 27980
    },
    {
      "epoch": 0.89568,
      "grad_norm": 0.009702356532216072,
      "learning_rate": 1.4029013333333334e-05,
      "loss": 0.0004,
      "step": 27990
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.01122212316840887,
      "learning_rate": 1.402688e-05,
      "loss": 0.0192,
      "step": 28000
    },
    {
      "epoch": 0.89632,
      "grad_norm": 0.007986367680132389,
      "learning_rate": 1.4024746666666669e-05,
      "loss": 0.0404,
      "step": 28010
    },
    {
      "epoch": 0.89664,
      "grad_norm": 0.037363406270742416,
      "learning_rate": 1.4022613333333334e-05,
      "loss": 0.0005,
      "step": 28020
    },
    {
      "epoch": 0.89696,
      "grad_norm": 0.005991462152451277,
      "learning_rate": 1.4020480000000001e-05,
      "loss": 0.0149,
      "step": 28030
    },
    {
      "epoch": 0.89728,
      "grad_norm": 2.565129041671753,
      "learning_rate": 1.4018346666666666e-05,
      "loss": 0.0277,
      "step": 28040
    },
    {
      "epoch": 0.8976,
      "grad_norm": 0.00580891827121377,
      "learning_rate": 1.4016213333333335e-05,
      "loss": 0.0008,
      "step": 28050
    },
    {
      "epoch": 0.89792,
      "grad_norm": 0.01077525969594717,
      "learning_rate": 1.401408e-05,
      "loss": 0.0075,
      "step": 28060
    },
    {
      "epoch": 0.89824,
      "grad_norm": 0.012044047005474567,
      "learning_rate": 1.4011946666666668e-05,
      "loss": 0.0006,
      "step": 28070
    },
    {
      "epoch": 0.89856,
      "grad_norm": 1.6771697998046875,
      "learning_rate": 1.4009813333333335e-05,
      "loss": 0.0024,
      "step": 28080
    },
    {
      "epoch": 0.89888,
      "grad_norm": 0.08713353425264359,
      "learning_rate": 1.4007680000000002e-05,
      "loss": 0.0012,
      "step": 28090
    },
    {
      "epoch": 0.8992,
      "grad_norm": 0.00625432888045907,
      "learning_rate": 1.4005546666666667e-05,
      "loss": 0.0007,
      "step": 28100
    },
    {
      "epoch": 0.89952,
      "grad_norm": 4.134991645812988,
      "learning_rate": 1.4003413333333336e-05,
      "loss": 0.0073,
      "step": 28110
    },
    {
      "epoch": 0.89984,
      "grad_norm": 0.007813146337866783,
      "learning_rate": 1.4001280000000001e-05,
      "loss": 0.009,
      "step": 28120
    },
    {
      "epoch": 0.90016,
      "grad_norm": 0.03085905872285366,
      "learning_rate": 1.3999146666666668e-05,
      "loss": 0.0016,
      "step": 28130
    },
    {
      "epoch": 0.90048,
      "grad_norm": 0.004985417705029249,
      "learning_rate": 1.3997013333333334e-05,
      "loss": 0.0018,
      "step": 28140
    },
    {
      "epoch": 0.9008,
      "grad_norm": 0.01135605201125145,
      "learning_rate": 1.3994880000000002e-05,
      "loss": 0.0038,
      "step": 28150
    },
    {
      "epoch": 0.90112,
      "grad_norm": 0.029248395934700966,
      "learning_rate": 1.3992746666666668e-05,
      "loss": 0.0004,
      "step": 28160
    },
    {
      "epoch": 0.90144,
      "grad_norm": 0.0075722914189100266,
      "learning_rate": 1.3990613333333333e-05,
      "loss": 0.0003,
      "step": 28170
    },
    {
      "epoch": 0.90176,
      "grad_norm": 0.010415400378406048,
      "learning_rate": 1.3988480000000002e-05,
      "loss": 0.0032,
      "step": 28180
    },
    {
      "epoch": 0.90208,
      "grad_norm": 0.004946366883814335,
      "learning_rate": 1.3986346666666667e-05,
      "loss": 0.0005,
      "step": 28190
    },
    {
      "epoch": 0.9024,
      "grad_norm": 7.992459297180176,
      "learning_rate": 1.3984213333333334e-05,
      "loss": 0.0304,
      "step": 28200
    },
    {
      "epoch": 0.90272,
      "grad_norm": 0.0037607632111757994,
      "learning_rate": 1.398208e-05,
      "loss": 0.0062,
      "step": 28210
    },
    {
      "epoch": 0.90304,
      "grad_norm": 0.011458108201622963,
      "learning_rate": 1.3979946666666669e-05,
      "loss": 0.0006,
      "step": 28220
    },
    {
      "epoch": 0.90336,
      "grad_norm": 0.006711646448820829,
      "learning_rate": 1.3977813333333334e-05,
      "loss": 0.0267,
      "step": 28230
    },
    {
      "epoch": 0.90368,
      "grad_norm": 0.14845919609069824,
      "learning_rate": 1.3975680000000001e-05,
      "loss": 0.0636,
      "step": 28240
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.010766081511974335,
      "learning_rate": 1.3973546666666668e-05,
      "loss": 0.0004,
      "step": 28250
    },
    {
      "epoch": 0.90432,
      "grad_norm": 0.012538845650851727,
      "learning_rate": 1.3971413333333335e-05,
      "loss": 0.0013,
      "step": 28260
    },
    {
      "epoch": 0.90464,
      "grad_norm": 0.012636448256671429,
      "learning_rate": 1.396928e-05,
      "loss": 0.0031,
      "step": 28270
    },
    {
      "epoch": 0.90496,
      "grad_norm": 0.008310999721288681,
      "learning_rate": 1.396714666666667e-05,
      "loss": 0.0007,
      "step": 28280
    },
    {
      "epoch": 0.90528,
      "grad_norm": 0.004494406282901764,
      "learning_rate": 1.3965013333333335e-05,
      "loss": 0.0004,
      "step": 28290
    },
    {
      "epoch": 0.9056,
      "grad_norm": 0.020528841763734818,
      "learning_rate": 1.396288e-05,
      "loss": 0.0367,
      "step": 28300
    },
    {
      "epoch": 0.90592,
      "grad_norm": 0.004221379291266203,
      "learning_rate": 1.3960746666666667e-05,
      "loss": 0.004,
      "step": 28310
    },
    {
      "epoch": 0.90624,
      "grad_norm": 0.007340771611779928,
      "learning_rate": 1.3958613333333336e-05,
      "loss": 0.0005,
      "step": 28320
    },
    {
      "epoch": 0.90656,
      "grad_norm": 0.003911011852324009,
      "learning_rate": 1.3956480000000001e-05,
      "loss": 0.0004,
      "step": 28330
    },
    {
      "epoch": 0.90688,
      "grad_norm": 0.011646008118987083,
      "learning_rate": 1.3954346666666667e-05,
      "loss": 0.0073,
      "step": 28340
    },
    {
      "epoch": 0.9072,
      "grad_norm": 0.004226880148053169,
      "learning_rate": 1.3952213333333335e-05,
      "loss": 0.0003,
      "step": 28350
    },
    {
      "epoch": 0.90752,
      "grad_norm": 0.00967468786984682,
      "learning_rate": 1.395008e-05,
      "loss": 0.0346,
      "step": 28360
    },
    {
      "epoch": 0.90784,
      "grad_norm": 0.014687611721456051,
      "learning_rate": 1.3947946666666668e-05,
      "loss": 0.022,
      "step": 28370
    },
    {
      "epoch": 0.90816,
      "grad_norm": 0.12226223200559616,
      "learning_rate": 1.3945813333333333e-05,
      "loss": 0.053,
      "step": 28380
    },
    {
      "epoch": 0.90848,
      "grad_norm": 0.01942499913275242,
      "learning_rate": 1.3943680000000002e-05,
      "loss": 0.0004,
      "step": 28390
    },
    {
      "epoch": 0.9088,
      "grad_norm": 0.003995481878519058,
      "learning_rate": 1.3941546666666667e-05,
      "loss": 0.0007,
      "step": 28400
    },
    {
      "epoch": 0.90912,
      "grad_norm": 0.010470950976014137,
      "learning_rate": 1.3939413333333334e-05,
      "loss": 0.0069,
      "step": 28410
    },
    {
      "epoch": 0.90944,
      "grad_norm": 0.01611749827861786,
      "learning_rate": 1.3937280000000002e-05,
      "loss": 0.0005,
      "step": 28420
    },
    {
      "epoch": 0.90976,
      "grad_norm": 0.19365891814231873,
      "learning_rate": 1.3935146666666669e-05,
      "loss": 0.0008,
      "step": 28430
    },
    {
      "epoch": 0.91008,
      "grad_norm": 0.009384325705468655,
      "learning_rate": 1.3933013333333334e-05,
      "loss": 0.0006,
      "step": 28440
    },
    {
      "epoch": 0.9104,
      "grad_norm": 0.03969305381178856,
      "learning_rate": 1.3930880000000003e-05,
      "loss": 0.0014,
      "step": 28450
    },
    {
      "epoch": 0.91072,
      "grad_norm": 0.012486713007092476,
      "learning_rate": 1.3928746666666668e-05,
      "loss": 0.0004,
      "step": 28460
    },
    {
      "epoch": 0.91104,
      "grad_norm": 0.043481867760419846,
      "learning_rate": 1.3926613333333333e-05,
      "loss": 0.0066,
      "step": 28470
    },
    {
      "epoch": 0.91136,
      "grad_norm": 0.005913292523473501,
      "learning_rate": 1.392448e-05,
      "loss": 0.0004,
      "step": 28480
    },
    {
      "epoch": 0.91168,
      "grad_norm": 0.004332242999225855,
      "learning_rate": 1.3922346666666668e-05,
      "loss": 0.0004,
      "step": 28490
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.022452857345342636,
      "learning_rate": 1.3920213333333335e-05,
      "loss": 0.0004,
      "step": 28500
    },
    {
      "epoch": 0.91232,
      "grad_norm": 0.02644280344247818,
      "learning_rate": 1.391808e-05,
      "loss": 0.0004,
      "step": 28510
    },
    {
      "epoch": 0.91264,
      "grad_norm": 1.958300232887268,
      "learning_rate": 1.3915946666666669e-05,
      "loss": 0.024,
      "step": 28520
    },
    {
      "epoch": 0.91296,
      "grad_norm": 0.0018318819347769022,
      "learning_rate": 1.3913813333333334e-05,
      "loss": 0.0014,
      "step": 28530
    },
    {
      "epoch": 0.91328,
      "grad_norm": 0.008497785776853561,
      "learning_rate": 1.3911680000000001e-05,
      "loss": 0.0008,
      "step": 28540
    },
    {
      "epoch": 0.9136,
      "grad_norm": 0.004949324764311314,
      "learning_rate": 1.3909546666666667e-05,
      "loss": 0.0003,
      "step": 28550
    },
    {
      "epoch": 0.91392,
      "grad_norm": 0.01976737193763256,
      "learning_rate": 1.3907413333333335e-05,
      "loss": 0.0006,
      "step": 28560
    },
    {
      "epoch": 0.91424,
      "grad_norm": 0.004141046199947596,
      "learning_rate": 1.390528e-05,
      "loss": 0.0007,
      "step": 28570
    },
    {
      "epoch": 0.91456,
      "grad_norm": 0.006440572906285524,
      "learning_rate": 1.3903146666666666e-05,
      "loss": 0.0002,
      "step": 28580
    },
    {
      "epoch": 0.91488,
      "grad_norm": 0.004029099829494953,
      "learning_rate": 1.3901013333333335e-05,
      "loss": 0.0016,
      "step": 28590
    },
    {
      "epoch": 0.9152,
      "grad_norm": 0.006926964037120342,
      "learning_rate": 1.3898880000000002e-05,
      "loss": 0.0004,
      "step": 28600
    },
    {
      "epoch": 0.91552,
      "grad_norm": 0.02403980679810047,
      "learning_rate": 1.3896746666666667e-05,
      "loss": 0.0043,
      "step": 28610
    },
    {
      "epoch": 0.91584,
      "grad_norm": 0.005053895525634289,
      "learning_rate": 1.3894613333333336e-05,
      "loss": 0.0003,
      "step": 28620
    },
    {
      "epoch": 0.91616,
      "grad_norm": 0.004897178616374731,
      "learning_rate": 1.3892480000000002e-05,
      "loss": 0.0002,
      "step": 28630
    },
    {
      "epoch": 0.91648,
      "grad_norm": 0.004926925525069237,
      "learning_rate": 1.3890346666666667e-05,
      "loss": 0.0003,
      "step": 28640
    },
    {
      "epoch": 0.9168,
      "grad_norm": 0.007716260384768248,
      "learning_rate": 1.3888213333333334e-05,
      "loss": 0.0003,
      "step": 28650
    },
    {
      "epoch": 0.91712,
      "grad_norm": 0.29790666699409485,
      "learning_rate": 1.3886080000000001e-05,
      "loss": 0.0009,
      "step": 28660
    },
    {
      "epoch": 0.91744,
      "grad_norm": 1.7222446203231812,
      "learning_rate": 1.3883946666666668e-05,
      "loss": 0.0528,
      "step": 28670
    },
    {
      "epoch": 0.91776,
      "grad_norm": 2.2239115238189697,
      "learning_rate": 1.3881813333333334e-05,
      "loss": 0.0031,
      "step": 28680
    },
    {
      "epoch": 0.91808,
      "grad_norm": 0.0044382731430232525,
      "learning_rate": 1.3879680000000002e-05,
      "loss": 0.0003,
      "step": 28690
    },
    {
      "epoch": 0.9184,
      "grad_norm": 0.004359063692390919,
      "learning_rate": 1.3877546666666668e-05,
      "loss": 0.0003,
      "step": 28700
    },
    {
      "epoch": 0.91872,
      "grad_norm": 0.005449594464153051,
      "learning_rate": 1.3875413333333335e-05,
      "loss": 0.0003,
      "step": 28710
    },
    {
      "epoch": 0.91904,
      "grad_norm": 0.013203023932874203,
      "learning_rate": 1.387328e-05,
      "loss": 0.0003,
      "step": 28720
    },
    {
      "epoch": 0.91936,
      "grad_norm": 0.004228352103382349,
      "learning_rate": 1.3871146666666669e-05,
      "loss": 0.001,
      "step": 28730
    },
    {
      "epoch": 0.91968,
      "grad_norm": 0.004077441990375519,
      "learning_rate": 1.3869013333333334e-05,
      "loss": 0.0004,
      "step": 28740
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.002898833714425564,
      "learning_rate": 1.386688e-05,
      "loss": 0.0005,
      "step": 28750
    },
    {
      "epoch": 0.92032,
      "grad_norm": 0.00976494513452053,
      "learning_rate": 1.3864746666666668e-05,
      "loss": 0.0002,
      "step": 28760
    },
    {
      "epoch": 0.92064,
      "grad_norm": 0.005985110066831112,
      "learning_rate": 1.3862613333333334e-05,
      "loss": 0.0002,
      "step": 28770
    },
    {
      "epoch": 0.92096,
      "grad_norm": 0.03799191117286682,
      "learning_rate": 1.386048e-05,
      "loss": 0.0005,
      "step": 28780
    },
    {
      "epoch": 0.92128,
      "grad_norm": 0.010016809217631817,
      "learning_rate": 1.385834666666667e-05,
      "loss": 0.0276,
      "step": 28790
    },
    {
      "epoch": 0.9216,
      "grad_norm": 1.344788670539856,
      "learning_rate": 1.3856213333333335e-05,
      "loss": 0.0016,
      "step": 28800
    },
    {
      "epoch": 0.92192,
      "grad_norm": 0.009371316060423851,
      "learning_rate": 1.385408e-05,
      "loss": 0.0002,
      "step": 28810
    },
    {
      "epoch": 0.92224,
      "grad_norm": 0.007052295841276646,
      "learning_rate": 1.3851946666666667e-05,
      "loss": 0.0002,
      "step": 28820
    },
    {
      "epoch": 0.92256,
      "grad_norm": 0.005396521184593439,
      "learning_rate": 1.3849813333333334e-05,
      "loss": 0.0342,
      "step": 28830
    },
    {
      "epoch": 0.92288,
      "grad_norm": 0.0028189122676849365,
      "learning_rate": 1.3847680000000002e-05,
      "loss": 0.0002,
      "step": 28840
    },
    {
      "epoch": 0.9232,
      "grad_norm": 0.0091567886993289,
      "learning_rate": 1.3845546666666667e-05,
      "loss": 0.0297,
      "step": 28850
    },
    {
      "epoch": 0.92352,
      "grad_norm": 0.007198769599199295,
      "learning_rate": 1.3843413333333336e-05,
      "loss": 0.0004,
      "step": 28860
    },
    {
      "epoch": 0.92384,
      "grad_norm": 0.0055541591718792915,
      "learning_rate": 1.3841280000000001e-05,
      "loss": 0.0004,
      "step": 28870
    },
    {
      "epoch": 0.92416,
      "grad_norm": 0.0063947695307433605,
      "learning_rate": 1.3839146666666668e-05,
      "loss": 0.0018,
      "step": 28880
    },
    {
      "epoch": 0.92448,
      "grad_norm": 0.005637927912175655,
      "learning_rate": 1.3837013333333334e-05,
      "loss": 0.0003,
      "step": 28890
    },
    {
      "epoch": 0.9248,
      "grad_norm": 0.0020720278844237328,
      "learning_rate": 1.3834880000000002e-05,
      "loss": 0.0005,
      "step": 28900
    },
    {
      "epoch": 0.92512,
      "grad_norm": 0.006136929616332054,
      "learning_rate": 1.3832746666666668e-05,
      "loss": 0.0003,
      "step": 28910
    },
    {
      "epoch": 0.92544,
      "grad_norm": 0.00547671178355813,
      "learning_rate": 1.3830613333333333e-05,
      "loss": 0.0006,
      "step": 28920
    },
    {
      "epoch": 0.92576,
      "grad_norm": 0.007665058597922325,
      "learning_rate": 1.3828480000000002e-05,
      "loss": 0.0003,
      "step": 28930
    },
    {
      "epoch": 0.92608,
      "grad_norm": 0.00796232558786869,
      "learning_rate": 1.3826346666666667e-05,
      "loss": 0.0131,
      "step": 28940
    },
    {
      "epoch": 0.9264,
      "grad_norm": 1.7699819803237915,
      "learning_rate": 1.3824213333333334e-05,
      "loss": 0.0421,
      "step": 28950
    },
    {
      "epoch": 0.92672,
      "grad_norm": 0.005679958499968052,
      "learning_rate": 1.3822080000000001e-05,
      "loss": 0.0004,
      "step": 28960
    },
    {
      "epoch": 0.92704,
      "grad_norm": 0.005059768911451101,
      "learning_rate": 1.3819946666666668e-05,
      "loss": 0.0636,
      "step": 28970
    },
    {
      "epoch": 0.92736,
      "grad_norm": 0.008978203870356083,
      "learning_rate": 1.3817813333333334e-05,
      "loss": 0.0005,
      "step": 28980
    },
    {
      "epoch": 0.92768,
      "grad_norm": 0.011851000599563122,
      "learning_rate": 1.3815680000000001e-05,
      "loss": 0.091,
      "step": 28990
    },
    {
      "epoch": 0.928,
      "grad_norm": 3.100641965866089,
      "learning_rate": 1.3813546666666668e-05,
      "loss": 0.0061,
      "step": 29000
    },
    {
      "epoch": 0.92832,
      "grad_norm": 0.017191782593727112,
      "learning_rate": 1.3811413333333335e-05,
      "loss": 0.0004,
      "step": 29010
    },
    {
      "epoch": 0.92864,
      "grad_norm": 0.004810163285583258,
      "learning_rate": 1.380928e-05,
      "loss": 0.0504,
      "step": 29020
    },
    {
      "epoch": 0.92896,
      "grad_norm": 0.010509880259633064,
      "learning_rate": 1.3807146666666669e-05,
      "loss": 0.0003,
      "step": 29030
    },
    {
      "epoch": 0.92928,
      "grad_norm": 0.004608028568327427,
      "learning_rate": 1.3805013333333335e-05,
      "loss": 0.0008,
      "step": 29040
    },
    {
      "epoch": 0.9296,
      "grad_norm": 0.013537413440644741,
      "learning_rate": 1.380288e-05,
      "loss": 0.0006,
      "step": 29050
    },
    {
      "epoch": 0.92992,
      "grad_norm": 0.006334169302135706,
      "learning_rate": 1.3800746666666667e-05,
      "loss": 0.0007,
      "step": 29060
    },
    {
      "epoch": 0.93024,
      "grad_norm": 0.004823296330869198,
      "learning_rate": 1.3798613333333336e-05,
      "loss": 0.0004,
      "step": 29070
    },
    {
      "epoch": 0.93056,
      "grad_norm": 0.004639934282749891,
      "learning_rate": 1.3796480000000001e-05,
      "loss": 0.0119,
      "step": 29080
    },
    {
      "epoch": 0.93088,
      "grad_norm": 1.8537176847457886,
      "learning_rate": 1.3794346666666666e-05,
      "loss": 0.0432,
      "step": 29090
    },
    {
      "epoch": 0.9312,
      "grad_norm": 0.01467435248196125,
      "learning_rate": 1.3792213333333335e-05,
      "loss": 0.0024,
      "step": 29100
    },
    {
      "epoch": 0.93152,
      "grad_norm": 0.007724469061940908,
      "learning_rate": 1.379008e-05,
      "loss": 0.0006,
      "step": 29110
    },
    {
      "epoch": 0.93184,
      "grad_norm": 0.018318742513656616,
      "learning_rate": 1.3787946666666668e-05,
      "loss": 0.0004,
      "step": 29120
    },
    {
      "epoch": 0.93216,
      "grad_norm": 2.148668050765991,
      "learning_rate": 1.3785813333333335e-05,
      "loss": 0.0093,
      "step": 29130
    },
    {
      "epoch": 0.93248,
      "grad_norm": 5.449027061462402,
      "learning_rate": 1.3783680000000002e-05,
      "loss": 0.0171,
      "step": 29140
    },
    {
      "epoch": 0.9328,
      "grad_norm": 0.0066634174436330795,
      "learning_rate": 1.3781546666666667e-05,
      "loss": 0.0004,
      "step": 29150
    },
    {
      "epoch": 0.93312,
      "grad_norm": 0.004372658673673868,
      "learning_rate": 1.3779413333333334e-05,
      "loss": 0.0003,
      "step": 29160
    },
    {
      "epoch": 0.93344,
      "grad_norm": 0.006036639213562012,
      "learning_rate": 1.3777280000000001e-05,
      "loss": 0.046,
      "step": 29170
    },
    {
      "epoch": 0.93376,
      "grad_norm": 0.007008710410445929,
      "learning_rate": 1.3775146666666668e-05,
      "loss": 0.0005,
      "step": 29180
    },
    {
      "epoch": 0.93408,
      "grad_norm": 0.004052163101732731,
      "learning_rate": 1.3773013333333334e-05,
      "loss": 0.0006,
      "step": 29190
    },
    {
      "epoch": 0.9344,
      "grad_norm": 0.006626300048083067,
      "learning_rate": 1.3770880000000003e-05,
      "loss": 0.0005,
      "step": 29200
    },
    {
      "epoch": 0.93472,
      "grad_norm": 0.00489778770133853,
      "learning_rate": 1.3768746666666668e-05,
      "loss": 0.0014,
      "step": 29210
    },
    {
      "epoch": 0.93504,
      "grad_norm": 0.006209782790392637,
      "learning_rate": 1.3766613333333333e-05,
      "loss": 0.0009,
      "step": 29220
    },
    {
      "epoch": 0.93536,
      "grad_norm": 0.034057144075632095,
      "learning_rate": 1.376448e-05,
      "loss": 0.0004,
      "step": 29230
    },
    {
      "epoch": 0.93568,
      "grad_norm": 0.03401898220181465,
      "learning_rate": 1.3762346666666667e-05,
      "loss": 0.0542,
      "step": 29240
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.006560001987963915,
      "learning_rate": 1.3760213333333335e-05,
      "loss": 0.0151,
      "step": 29250
    },
    {
      "epoch": 0.93632,
      "grad_norm": 0.010706830769777298,
      "learning_rate": 1.375808e-05,
      "loss": 0.0009,
      "step": 29260
    },
    {
      "epoch": 0.93664,
      "grad_norm": 0.020083339884877205,
      "learning_rate": 1.3755946666666669e-05,
      "loss": 0.0005,
      "step": 29270
    },
    {
      "epoch": 0.93696,
      "grad_norm": 0.025284431874752045,
      "learning_rate": 1.3753813333333334e-05,
      "loss": 0.0024,
      "step": 29280
    },
    {
      "epoch": 0.93728,
      "grad_norm": 0.004704832099378109,
      "learning_rate": 1.3751680000000001e-05,
      "loss": 0.0003,
      "step": 29290
    },
    {
      "epoch": 0.9376,
      "grad_norm": 0.011754175648093224,
      "learning_rate": 1.3749546666666668e-05,
      "loss": 0.0004,
      "step": 29300
    },
    {
      "epoch": 0.93792,
      "grad_norm": 0.00939231738448143,
      "learning_rate": 1.3747413333333335e-05,
      "loss": 0.055,
      "step": 29310
    },
    {
      "epoch": 0.93824,
      "grad_norm": 0.01456616260111332,
      "learning_rate": 1.374528e-05,
      "loss": 0.0005,
      "step": 29320
    },
    {
      "epoch": 0.93856,
      "grad_norm": 0.04387693107128143,
      "learning_rate": 1.3743146666666666e-05,
      "loss": 0.0005,
      "step": 29330
    },
    {
      "epoch": 0.93888,
      "grad_norm": 0.010708598420023918,
      "learning_rate": 1.3741013333333335e-05,
      "loss": 0.014,
      "step": 29340
    },
    {
      "epoch": 0.9392,
      "grad_norm": 0.005857545882463455,
      "learning_rate": 1.3738880000000002e-05,
      "loss": 0.0412,
      "step": 29350
    },
    {
      "epoch": 0.93952,
      "grad_norm": 0.01202984619885683,
      "learning_rate": 1.3736746666666667e-05,
      "loss": 0.0006,
      "step": 29360
    },
    {
      "epoch": 0.93984,
      "grad_norm": 0.014261065982282162,
      "learning_rate": 1.3734613333333336e-05,
      "loss": 0.0015,
      "step": 29370
    },
    {
      "epoch": 0.94016,
      "grad_norm": 0.008500459603965282,
      "learning_rate": 1.3732480000000001e-05,
      "loss": 0.0008,
      "step": 29380
    },
    {
      "epoch": 0.94048,
      "grad_norm": 0.010587341152131557,
      "learning_rate": 1.3730346666666667e-05,
      "loss": 0.0005,
      "step": 29390
    },
    {
      "epoch": 0.9408,
      "grad_norm": 0.014082754030823708,
      "learning_rate": 1.3728213333333334e-05,
      "loss": 0.0014,
      "step": 29400
    },
    {
      "epoch": 0.94112,
      "grad_norm": 0.022628916427493095,
      "learning_rate": 1.3726080000000001e-05,
      "loss": 0.0076,
      "step": 29410
    },
    {
      "epoch": 0.94144,
      "grad_norm": 0.007437942549586296,
      "learning_rate": 1.3723946666666668e-05,
      "loss": 0.0004,
      "step": 29420
    },
    {
      "epoch": 0.94176,
      "grad_norm": 0.007512358482927084,
      "learning_rate": 1.3721813333333333e-05,
      "loss": 0.0007,
      "step": 29430
    },
    {
      "epoch": 0.94208,
      "grad_norm": 0.01105406042188406,
      "learning_rate": 1.3719680000000002e-05,
      "loss": 0.0071,
      "step": 29440
    },
    {
      "epoch": 0.9424,
      "grad_norm": 0.0038224407471716404,
      "learning_rate": 1.3717546666666667e-05,
      "loss": 0.0347,
      "step": 29450
    },
    {
      "epoch": 0.94272,
      "grad_norm": 0.22827838361263275,
      "learning_rate": 1.3715413333333335e-05,
      "loss": 0.0006,
      "step": 29460
    },
    {
      "epoch": 0.94304,
      "grad_norm": 0.008050646632909775,
      "learning_rate": 1.3713280000000002e-05,
      "loss": 0.0004,
      "step": 29470
    },
    {
      "epoch": 0.94336,
      "grad_norm": 0.020008966326713562,
      "learning_rate": 1.3711146666666669e-05,
      "loss": 0.0005,
      "step": 29480
    },
    {
      "epoch": 0.94368,
      "grad_norm": 0.0075273229740560055,
      "learning_rate": 1.3709013333333334e-05,
      "loss": 0.0154,
      "step": 29490
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.02519235759973526,
      "learning_rate": 1.370688e-05,
      "loss": 0.0006,
      "step": 29500
    },
    {
      "epoch": 0.94432,
      "grad_norm": 0.004528129007667303,
      "learning_rate": 1.3704746666666668e-05,
      "loss": 0.0479,
      "step": 29510
    },
    {
      "epoch": 0.94464,
      "grad_norm": 0.05582689866423607,
      "learning_rate": 1.3702613333333334e-05,
      "loss": 0.0007,
      "step": 29520
    },
    {
      "epoch": 0.94496,
      "grad_norm": 0.01176716573536396,
      "learning_rate": 1.370048e-05,
      "loss": 0.0004,
      "step": 29530
    },
    {
      "epoch": 0.94528,
      "grad_norm": 0.012965734116733074,
      "learning_rate": 1.369834666666667e-05,
      "loss": 0.0149,
      "step": 29540
    },
    {
      "epoch": 0.9456,
      "grad_norm": 0.003657394554466009,
      "learning_rate": 1.3696213333333335e-05,
      "loss": 0.0008,
      "step": 29550
    },
    {
      "epoch": 0.94592,
      "grad_norm": 0.015110238455235958,
      "learning_rate": 1.369408e-05,
      "loss": 0.0004,
      "step": 29560
    },
    {
      "epoch": 0.94624,
      "grad_norm": 0.0033495784737169743,
      "learning_rate": 1.3691946666666667e-05,
      "loss": 0.0147,
      "step": 29570
    },
    {
      "epoch": 0.94656,
      "grad_norm": 0.015009858645498753,
      "learning_rate": 1.3689813333333334e-05,
      "loss": 0.0006,
      "step": 29580
    },
    {
      "epoch": 0.94688,
      "grad_norm": 0.013448046520352364,
      "learning_rate": 1.3687680000000001e-05,
      "loss": 0.0057,
      "step": 29590
    },
    {
      "epoch": 0.9472,
      "grad_norm": 4.93174409866333,
      "learning_rate": 1.3685546666666667e-05,
      "loss": 0.0172,
      "step": 29600
    },
    {
      "epoch": 0.94752,
      "grad_norm": 0.009250367991626263,
      "learning_rate": 1.3683413333333336e-05,
      "loss": 0.0004,
      "step": 29610
    },
    {
      "epoch": 0.94784,
      "grad_norm": 0.004123765043914318,
      "learning_rate": 1.3681280000000001e-05,
      "loss": 0.0146,
      "step": 29620
    },
    {
      "epoch": 0.94816,
      "grad_norm": 3.2883572578430176,
      "learning_rate": 1.3679146666666668e-05,
      "loss": 0.0169,
      "step": 29630
    },
    {
      "epoch": 0.94848,
      "grad_norm": 0.01490712072700262,
      "learning_rate": 1.3677013333333335e-05,
      "loss": 0.0003,
      "step": 29640
    },
    {
      "epoch": 0.9488,
      "grad_norm": 0.01777558960020542,
      "learning_rate": 1.3674880000000002e-05,
      "loss": 0.0004,
      "step": 29650
    },
    {
      "epoch": 0.94912,
      "grad_norm": 0.01601010002195835,
      "learning_rate": 1.3672746666666668e-05,
      "loss": 0.0007,
      "step": 29660
    },
    {
      "epoch": 0.94944,
      "grad_norm": 0.010495693422853947,
      "learning_rate": 1.3670613333333333e-05,
      "loss": 0.0011,
      "step": 29670
    },
    {
      "epoch": 0.94976,
      "grad_norm": 0.015196211636066437,
      "learning_rate": 1.3668480000000002e-05,
      "loss": 0.0013,
      "step": 29680
    },
    {
      "epoch": 0.95008,
      "grad_norm": 0.006130633410066366,
      "learning_rate": 1.3666346666666667e-05,
      "loss": 0.0073,
      "step": 29690
    },
    {
      "epoch": 0.9504,
      "grad_norm": 0.012418385595083237,
      "learning_rate": 1.3664213333333334e-05,
      "loss": 0.001,
      "step": 29700
    },
    {
      "epoch": 0.95072,
      "grad_norm": 0.03446812182664871,
      "learning_rate": 1.3662080000000001e-05,
      "loss": 0.0003,
      "step": 29710
    },
    {
      "epoch": 0.95104,
      "grad_norm": 0.008167588151991367,
      "learning_rate": 1.3659946666666668e-05,
      "loss": 0.0319,
      "step": 29720
    },
    {
      "epoch": 0.95136,
      "grad_norm": 0.008916542865335941,
      "learning_rate": 1.3657813333333334e-05,
      "loss": 0.0004,
      "step": 29730
    },
    {
      "epoch": 0.95168,
      "grad_norm": 0.0038876717444509268,
      "learning_rate": 1.365568e-05,
      "loss": 0.0069,
      "step": 29740
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.02517245151102543,
      "learning_rate": 1.3653546666666668e-05,
      "loss": 0.0341,
      "step": 29750
    },
    {
      "epoch": 0.95232,
      "grad_norm": 0.0178033709526062,
      "learning_rate": 1.3651413333333335e-05,
      "loss": 0.0005,
      "step": 29760
    },
    {
      "epoch": 0.95264,
      "grad_norm": 0.008579776622354984,
      "learning_rate": 1.364928e-05,
      "loss": 0.0126,
      "step": 29770
    },
    {
      "epoch": 0.95296,
      "grad_norm": 0.05026239901781082,
      "learning_rate": 1.3647146666666669e-05,
      "loss": 0.002,
      "step": 29780
    },
    {
      "epoch": 0.95328,
      "grad_norm": 0.008678465150296688,
      "learning_rate": 1.3645013333333334e-05,
      "loss": 0.0003,
      "step": 29790
    },
    {
      "epoch": 0.9536,
      "grad_norm": 0.006592827383428812,
      "learning_rate": 1.364288e-05,
      "loss": 0.0006,
      "step": 29800
    },
    {
      "epoch": 0.95392,
      "grad_norm": 0.03632678836584091,
      "learning_rate": 1.3640746666666668e-05,
      "loss": 0.0456,
      "step": 29810
    },
    {
      "epoch": 0.95424,
      "grad_norm": 0.005846081301569939,
      "learning_rate": 1.3638613333333336e-05,
      "loss": 0.0004,
      "step": 29820
    },
    {
      "epoch": 0.95456,
      "grad_norm": 0.0075959935784339905,
      "learning_rate": 1.3636480000000001e-05,
      "loss": 0.0003,
      "step": 29830
    },
    {
      "epoch": 0.95488,
      "grad_norm": 0.011370779946446419,
      "learning_rate": 1.3634346666666666e-05,
      "loss": 0.0004,
      "step": 29840
    },
    {
      "epoch": 0.9552,
      "grad_norm": 0.004914984107017517,
      "learning_rate": 1.3632213333333335e-05,
      "loss": 0.0003,
      "step": 29850
    },
    {
      "epoch": 0.95552,
      "grad_norm": 0.006098222453147173,
      "learning_rate": 1.363008e-05,
      "loss": 0.0182,
      "step": 29860
    },
    {
      "epoch": 0.95584,
      "grad_norm": 0.010970561765134335,
      "learning_rate": 1.3627946666666668e-05,
      "loss": 0.0182,
      "step": 29870
    },
    {
      "epoch": 0.95616,
      "grad_norm": 0.018774626776576042,
      "learning_rate": 1.3625813333333335e-05,
      "loss": 0.0005,
      "step": 29880
    },
    {
      "epoch": 0.95648,
      "grad_norm": 0.016207700595259666,
      "learning_rate": 1.3623680000000002e-05,
      "loss": 0.0006,
      "step": 29890
    },
    {
      "epoch": 0.9568,
      "grad_norm": 0.021375881507992744,
      "learning_rate": 1.3621546666666667e-05,
      "loss": 0.0054,
      "step": 29900
    },
    {
      "epoch": 0.95712,
      "grad_norm": 0.0055805048905313015,
      "learning_rate": 1.3619413333333334e-05,
      "loss": 0.0104,
      "step": 29910
    },
    {
      "epoch": 0.95744,
      "grad_norm": 0.010873104445636272,
      "learning_rate": 1.3617280000000001e-05,
      "loss": 0.0046,
      "step": 29920
    },
    {
      "epoch": 0.95776,
      "grad_norm": 0.029541971161961555,
      "learning_rate": 1.3615146666666668e-05,
      "loss": 0.0348,
      "step": 29930
    },
    {
      "epoch": 0.95808,
      "grad_norm": 0.01447138749063015,
      "learning_rate": 1.3613013333333334e-05,
      "loss": 0.0008,
      "step": 29940
    },
    {
      "epoch": 0.9584,
      "grad_norm": 0.010578843764960766,
      "learning_rate": 1.3610880000000002e-05,
      "loss": 0.0007,
      "step": 29950
    },
    {
      "epoch": 0.95872,
      "grad_norm": 0.008507356978952885,
      "learning_rate": 1.3608746666666668e-05,
      "loss": 0.0005,
      "step": 29960
    },
    {
      "epoch": 0.95904,
      "grad_norm": 0.006094710435718298,
      "learning_rate": 1.3606613333333333e-05,
      "loss": 0.0309,
      "step": 29970
    },
    {
      "epoch": 0.95936,
      "grad_norm": 0.005058336071670055,
      "learning_rate": 1.3604480000000002e-05,
      "loss": 0.0553,
      "step": 29980
    },
    {
      "epoch": 0.95968,
      "grad_norm": 0.009183024987578392,
      "learning_rate": 1.3602346666666667e-05,
      "loss": 0.0004,
      "step": 29990
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.01758759655058384,
      "learning_rate": 1.3600213333333334e-05,
      "loss": 0.0044,
      "step": 30000
    },
    {
      "epoch": 0.96032,
      "grad_norm": 0.042652737349271774,
      "learning_rate": 1.359808e-05,
      "loss": 0.0004,
      "step": 30010
    },
    {
      "epoch": 0.96064,
      "grad_norm": 0.013143557123839855,
      "learning_rate": 1.3595946666666669e-05,
      "loss": 0.0005,
      "step": 30020
    },
    {
      "epoch": 0.96096,
      "grad_norm": 0.0067819831892848015,
      "learning_rate": 1.3593813333333334e-05,
      "loss": 0.0004,
      "step": 30030
    },
    {
      "epoch": 0.96128,
      "grad_norm": 0.005144335795193911,
      "learning_rate": 1.3591680000000001e-05,
      "loss": 0.0178,
      "step": 30040
    },
    {
      "epoch": 0.9616,
      "grad_norm": 0.0044499593786895275,
      "learning_rate": 1.3589546666666668e-05,
      "loss": 0.001,
      "step": 30050
    },
    {
      "epoch": 0.96192,
      "grad_norm": 0.01485105324536562,
      "learning_rate": 1.3587413333333335e-05,
      "loss": 0.0013,
      "step": 30060
    },
    {
      "epoch": 0.96224,
      "grad_norm": 0.006315840873867273,
      "learning_rate": 1.358528e-05,
      "loss": 0.0009,
      "step": 30070
    },
    {
      "epoch": 0.96256,
      "grad_norm": 0.0059559582732617855,
      "learning_rate": 1.3583146666666666e-05,
      "loss": 0.0061,
      "step": 30080
    },
    {
      "epoch": 0.96288,
      "grad_norm": 0.04391009360551834,
      "learning_rate": 1.3581013333333335e-05,
      "loss": 0.0056,
      "step": 30090
    },
    {
      "epoch": 0.9632,
      "grad_norm": 0.007481875829398632,
      "learning_rate": 1.3578880000000002e-05,
      "loss": 0.0004,
      "step": 30100
    },
    {
      "epoch": 0.96352,
      "grad_norm": 0.013783843256533146,
      "learning_rate": 1.3576746666666667e-05,
      "loss": 0.0003,
      "step": 30110
    },
    {
      "epoch": 0.96384,
      "grad_norm": 0.008086556568741798,
      "learning_rate": 1.3574613333333336e-05,
      "loss": 0.0002,
      "step": 30120
    },
    {
      "epoch": 0.96416,
      "grad_norm": 0.005174408201128244,
      "learning_rate": 1.3572480000000001e-05,
      "loss": 0.0019,
      "step": 30130
    },
    {
      "epoch": 0.96448,
      "grad_norm": 0.00789160467684269,
      "learning_rate": 1.3570346666666667e-05,
      "loss": 0.0006,
      "step": 30140
    },
    {
      "epoch": 0.9648,
      "grad_norm": 0.0046337079256772995,
      "learning_rate": 1.3568213333333335e-05,
      "loss": 0.0004,
      "step": 30150
    },
    {
      "epoch": 0.96512,
      "grad_norm": 0.010076765902340412,
      "learning_rate": 1.356608e-05,
      "loss": 0.0003,
      "step": 30160
    },
    {
      "epoch": 0.96544,
      "grad_norm": 0.03957086801528931,
      "learning_rate": 1.3563946666666668e-05,
      "loss": 0.0004,
      "step": 30170
    },
    {
      "epoch": 0.96576,
      "grad_norm": 0.005494988523423672,
      "learning_rate": 1.3561813333333333e-05,
      "loss": 0.0003,
      "step": 30180
    },
    {
      "epoch": 0.96608,
      "grad_norm": 0.040826763957738876,
      "learning_rate": 1.3559680000000002e-05,
      "loss": 0.0003,
      "step": 30190
    },
    {
      "epoch": 0.9664,
      "grad_norm": 0.0033272842410951853,
      "learning_rate": 1.3557546666666667e-05,
      "loss": 0.0002,
      "step": 30200
    },
    {
      "epoch": 0.96672,
      "grad_norm": 0.004439757205545902,
      "learning_rate": 1.3555413333333334e-05,
      "loss": 0.0004,
      "step": 30210
    },
    {
      "epoch": 0.96704,
      "grad_norm": 0.005777436308562756,
      "learning_rate": 1.3553280000000001e-05,
      "loss": 0.0003,
      "step": 30220
    },
    {
      "epoch": 0.96736,
      "grad_norm": 0.028919367119669914,
      "learning_rate": 1.3551146666666669e-05,
      "loss": 0.0004,
      "step": 30230
    },
    {
      "epoch": 0.96768,
      "grad_norm": 0.004680532030761242,
      "learning_rate": 1.3549013333333334e-05,
      "loss": 0.0002,
      "step": 30240
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.004352845251560211,
      "learning_rate": 1.354688e-05,
      "loss": 0.0002,
      "step": 30250
    },
    {
      "epoch": 0.96832,
      "grad_norm": 0.009200477972626686,
      "learning_rate": 1.3544746666666668e-05,
      "loss": 0.0003,
      "step": 30260
    },
    {
      "epoch": 0.96864,
      "grad_norm": 0.005810340400785208,
      "learning_rate": 1.3542613333333333e-05,
      "loss": 0.0448,
      "step": 30270
    },
    {
      "epoch": 0.96896,
      "grad_norm": 2.3281476497650146,
      "learning_rate": 1.354048e-05,
      "loss": 0.0106,
      "step": 30280
    },
    {
      "epoch": 0.96928,
      "grad_norm": 0.013371186330914497,
      "learning_rate": 1.353834666666667e-05,
      "loss": 0.0005,
      "step": 30290
    },
    {
      "epoch": 0.9696,
      "grad_norm": 4.078163146972656,
      "learning_rate": 1.3536213333333335e-05,
      "loss": 0.0222,
      "step": 30300
    },
    {
      "epoch": 0.96992,
      "grad_norm": 0.011690545827150345,
      "learning_rate": 1.353408e-05,
      "loss": 0.0243,
      "step": 30310
    },
    {
      "epoch": 0.97024,
      "grad_norm": 0.16064724326133728,
      "learning_rate": 1.3531946666666669e-05,
      "loss": 0.0007,
      "step": 30320
    },
    {
      "epoch": 0.97056,
      "grad_norm": 0.013017695397138596,
      "learning_rate": 1.3529813333333334e-05,
      "loss": 0.0004,
      "step": 30330
    },
    {
      "epoch": 0.97088,
      "grad_norm": 0.002499892609193921,
      "learning_rate": 1.3527680000000001e-05,
      "loss": 0.0002,
      "step": 30340
    },
    {
      "epoch": 0.9712,
      "grad_norm": 0.18264853954315186,
      "learning_rate": 1.3525546666666667e-05,
      "loss": 0.0006,
      "step": 30350
    },
    {
      "epoch": 0.97152,
      "grad_norm": 0.017546525225043297,
      "learning_rate": 1.3523413333333335e-05,
      "loss": 0.0026,
      "step": 30360
    },
    {
      "epoch": 0.97184,
      "grad_norm": 0.006077297031879425,
      "learning_rate": 1.352128e-05,
      "loss": 0.0004,
      "step": 30370
    },
    {
      "epoch": 0.97216,
      "grad_norm": 0.0064515620470047,
      "learning_rate": 1.3519146666666668e-05,
      "loss": 0.0003,
      "step": 30380
    },
    {
      "epoch": 0.97248,
      "grad_norm": 0.004672213923186064,
      "learning_rate": 1.3517013333333335e-05,
      "loss": 0.0075,
      "step": 30390
    },
    {
      "epoch": 0.9728,
      "grad_norm": 0.003857241477817297,
      "learning_rate": 1.3514880000000002e-05,
      "loss": 0.0003,
      "step": 30400
    },
    {
      "epoch": 0.97312,
      "grad_norm": 0.010934511199593544,
      "learning_rate": 1.3512746666666667e-05,
      "loss": 0.0004,
      "step": 30410
    },
    {
      "epoch": 0.97344,
      "grad_norm": 0.0046039484441280365,
      "learning_rate": 1.3510613333333333e-05,
      "loss": 0.0306,
      "step": 30420
    },
    {
      "epoch": 0.97376,
      "grad_norm": 0.012501231394708157,
      "learning_rate": 1.3508480000000001e-05,
      "loss": 0.0234,
      "step": 30430
    },
    {
      "epoch": 0.97408,
      "grad_norm": 0.002916343742981553,
      "learning_rate": 1.3506346666666667e-05,
      "loss": 0.0003,
      "step": 30440
    },
    {
      "epoch": 0.9744,
      "grad_norm": 0.004750300198793411,
      "learning_rate": 1.3504213333333334e-05,
      "loss": 0.0004,
      "step": 30450
    },
    {
      "epoch": 0.97472,
      "grad_norm": 0.26874831318855286,
      "learning_rate": 1.3502080000000001e-05,
      "loss": 0.0006,
      "step": 30460
    },
    {
      "epoch": 0.97504,
      "grad_norm": 0.008295970968902111,
      "learning_rate": 1.3499946666666668e-05,
      "loss": 0.0004,
      "step": 30470
    },
    {
      "epoch": 0.97536,
      "grad_norm": 0.004350916016846895,
      "learning_rate": 1.3497813333333333e-05,
      "loss": 0.0004,
      "step": 30480
    },
    {
      "epoch": 0.97568,
      "grad_norm": 0.02162339724600315,
      "learning_rate": 1.3495680000000002e-05,
      "loss": 0.0011,
      "step": 30490
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.002463951474055648,
      "learning_rate": 1.3493546666666668e-05,
      "loss": 0.0208,
      "step": 30500
    },
    {
      "epoch": 0.97632,
      "grad_norm": 0.006205265410244465,
      "learning_rate": 1.3491413333333335e-05,
      "loss": 0.0249,
      "step": 30510
    },
    {
      "epoch": 0.97664,
      "grad_norm": 0.0032865875400602818,
      "learning_rate": 1.348928e-05,
      "loss": 0.043,
      "step": 30520
    },
    {
      "epoch": 0.97696,
      "grad_norm": 0.0057627297937870026,
      "learning_rate": 1.3487146666666669e-05,
      "loss": 0.0006,
      "step": 30530
    },
    {
      "epoch": 0.97728,
      "grad_norm": 0.031544849276542664,
      "learning_rate": 1.3485013333333334e-05,
      "loss": 0.0004,
      "step": 30540
    },
    {
      "epoch": 0.9776,
      "grad_norm": 0.006325156427919865,
      "learning_rate": 1.3482880000000001e-05,
      "loss": 0.0008,
      "step": 30550
    },
    {
      "epoch": 0.97792,
      "grad_norm": 0.010210554115474224,
      "learning_rate": 1.3480746666666668e-05,
      "loss": 0.0181,
      "step": 30560
    },
    {
      "epoch": 0.97824,
      "grad_norm": 0.010540721006691456,
      "learning_rate": 1.3478613333333335e-05,
      "loss": 0.0002,
      "step": 30570
    },
    {
      "epoch": 0.97856,
      "grad_norm": 0.00407407945021987,
      "learning_rate": 1.347648e-05,
      "loss": 0.0004,
      "step": 30580
    },
    {
      "epoch": 0.97888,
      "grad_norm": 0.0032243365421891212,
      "learning_rate": 1.3474346666666666e-05,
      "loss": 0.0014,
      "step": 30590
    },
    {
      "epoch": 0.9792,
      "grad_norm": 0.004214578773826361,
      "learning_rate": 1.3472213333333335e-05,
      "loss": 0.0003,
      "step": 30600
    },
    {
      "epoch": 0.97952,
      "grad_norm": 0.047490209341049194,
      "learning_rate": 1.347008e-05,
      "loss": 0.0004,
      "step": 30610
    },
    {
      "epoch": 0.97984,
      "grad_norm": 0.00532775791361928,
      "learning_rate": 1.3467946666666667e-05,
      "loss": 0.0004,
      "step": 30620
    },
    {
      "epoch": 0.98016,
      "grad_norm": 0.022767623886466026,
      "learning_rate": 1.3465813333333334e-05,
      "loss": 0.0289,
      "step": 30630
    },
    {
      "epoch": 0.98048,
      "grad_norm": 0.0037302931305021048,
      "learning_rate": 1.3463680000000002e-05,
      "loss": 0.0006,
      "step": 30640
    },
    {
      "epoch": 0.9808,
      "grad_norm": 0.0045378184877336025,
      "learning_rate": 1.3461546666666667e-05,
      "loss": 0.0002,
      "step": 30650
    },
    {
      "epoch": 0.98112,
      "grad_norm": 4.182582378387451,
      "learning_rate": 1.3459413333333336e-05,
      "loss": 0.0223,
      "step": 30660
    },
    {
      "epoch": 0.98144,
      "grad_norm": 0.010394949465990067,
      "learning_rate": 1.3457280000000001e-05,
      "loss": 0.0004,
      "step": 30670
    },
    {
      "epoch": 0.98176,
      "grad_norm": 0.007573406677693129,
      "learning_rate": 1.3455146666666668e-05,
      "loss": 0.0003,
      "step": 30680
    },
    {
      "epoch": 0.98208,
      "grad_norm": 0.004684919025748968,
      "learning_rate": 1.3453013333333333e-05,
      "loss": 0.0003,
      "step": 30690
    },
    {
      "epoch": 0.9824,
      "grad_norm": 0.013263133354485035,
      "learning_rate": 1.3450880000000002e-05,
      "loss": 0.0003,
      "step": 30700
    },
    {
      "epoch": 0.98272,
      "grad_norm": 0.016772298142313957,
      "learning_rate": 1.3448746666666668e-05,
      "loss": 0.0006,
      "step": 30710
    },
    {
      "epoch": 0.98304,
      "grad_norm": 0.00543719669803977,
      "learning_rate": 1.3446613333333333e-05,
      "loss": 0.0004,
      "step": 30720
    },
    {
      "epoch": 0.98336,
      "grad_norm": 0.004657902754843235,
      "learning_rate": 1.3444480000000002e-05,
      "loss": 0.0099,
      "step": 30730
    },
    {
      "epoch": 0.98368,
      "grad_norm": 0.04548138007521629,
      "learning_rate": 1.3442346666666669e-05,
      "loss": 0.0493,
      "step": 30740
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.0037120890337973833,
      "learning_rate": 1.3440213333333334e-05,
      "loss": 0.0003,
      "step": 30750
    },
    {
      "epoch": 0.98432,
      "grad_norm": 0.6255123019218445,
      "learning_rate": 1.343808e-05,
      "loss": 0.0277,
      "step": 30760
    },
    {
      "epoch": 0.98464,
      "grad_norm": 0.002476571360602975,
      "learning_rate": 1.3435946666666668e-05,
      "loss": 0.0002,
      "step": 30770
    },
    {
      "epoch": 0.98496,
      "grad_norm": 5.859961986541748,
      "learning_rate": 1.3433813333333334e-05,
      "loss": 0.0165,
      "step": 30780
    },
    {
      "epoch": 0.98528,
      "grad_norm": 0.001814978546462953,
      "learning_rate": 1.343168e-05,
      "loss": 0.0003,
      "step": 30790
    },
    {
      "epoch": 0.9856,
      "grad_norm": 0.006367641035467386,
      "learning_rate": 1.3429546666666668e-05,
      "loss": 0.0004,
      "step": 30800
    },
    {
      "epoch": 0.98592,
      "grad_norm": 0.006263844668865204,
      "learning_rate": 1.3427413333333335e-05,
      "loss": 0.0002,
      "step": 30810
    },
    {
      "epoch": 0.98624,
      "grad_norm": 0.006888781674206257,
      "learning_rate": 1.342528e-05,
      "loss": 0.0011,
      "step": 30820
    },
    {
      "epoch": 0.98656,
      "grad_norm": 0.00932338833808899,
      "learning_rate": 1.3423146666666669e-05,
      "loss": 0.0372,
      "step": 30830
    },
    {
      "epoch": 0.98688,
      "grad_norm": 0.018069829791784286,
      "learning_rate": 1.3421013333333334e-05,
      "loss": 0.0002,
      "step": 30840
    },
    {
      "epoch": 0.9872,
      "grad_norm": 0.002065733540803194,
      "learning_rate": 1.3418880000000002e-05,
      "loss": 0.0003,
      "step": 30850
    },
    {
      "epoch": 0.98752,
      "grad_norm": 0.004195574205368757,
      "learning_rate": 1.3416746666666667e-05,
      "loss": 0.0003,
      "step": 30860
    },
    {
      "epoch": 0.98784,
      "grad_norm": 0.0063221994787454605,
      "learning_rate": 1.3414613333333336e-05,
      "loss": 0.0235,
      "step": 30870
    },
    {
      "epoch": 0.98816,
      "grad_norm": 0.0032494261395186186,
      "learning_rate": 1.3412480000000001e-05,
      "loss": 0.0003,
      "step": 30880
    },
    {
      "epoch": 0.98848,
      "grad_norm": 1.6591322422027588,
      "learning_rate": 1.3410346666666666e-05,
      "loss": 0.0492,
      "step": 30890
    },
    {
      "epoch": 0.9888,
      "grad_norm": 0.004173213616013527,
      "learning_rate": 1.3408213333333335e-05,
      "loss": 0.0054,
      "step": 30900
    },
    {
      "epoch": 0.98912,
      "grad_norm": 0.0022519880440086126,
      "learning_rate": 1.340608e-05,
      "loss": 0.0003,
      "step": 30910
    },
    {
      "epoch": 0.98944,
      "grad_norm": 0.021512826904654503,
      "learning_rate": 1.3403946666666668e-05,
      "loss": 0.0003,
      "step": 30920
    },
    {
      "epoch": 0.98976,
      "grad_norm": 0.016248155385255814,
      "learning_rate": 1.3401813333333333e-05,
      "loss": 0.0003,
      "step": 30930
    },
    {
      "epoch": 0.99008,
      "grad_norm": 0.013474446721374989,
      "learning_rate": 1.3399680000000002e-05,
      "loss": 0.0015,
      "step": 30940
    },
    {
      "epoch": 0.9904,
      "grad_norm": 0.017018424347043037,
      "learning_rate": 1.3397546666666667e-05,
      "loss": 0.0006,
      "step": 30950
    },
    {
      "epoch": 0.99072,
      "grad_norm": 0.003222835250198841,
      "learning_rate": 1.3395413333333334e-05,
      "loss": 0.0002,
      "step": 30960
    },
    {
      "epoch": 0.99104,
      "grad_norm": 0.007028778549283743,
      "learning_rate": 1.3393280000000001e-05,
      "loss": 0.0004,
      "step": 30970
    },
    {
      "epoch": 0.99136,
      "grad_norm": 0.006082909647375345,
      "learning_rate": 1.3391146666666668e-05,
      "loss": 0.0042,
      "step": 30980
    },
    {
      "epoch": 0.99168,
      "grad_norm": 0.005128119140863419,
      "learning_rate": 1.3389013333333334e-05,
      "loss": 0.0002,
      "step": 30990
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.0035313009284436703,
      "learning_rate": 1.3386880000000003e-05,
      "loss": 0.0015,
      "step": 31000
    },
    {
      "epoch": 0.99232,
      "grad_norm": 0.003609102452173829,
      "learning_rate": 1.3384746666666668e-05,
      "loss": 0.0002,
      "step": 31010
    },
    {
      "epoch": 0.99264,
      "grad_norm": 0.004652590025216341,
      "learning_rate": 1.3382613333333335e-05,
      "loss": 0.0003,
      "step": 31020
    },
    {
      "epoch": 0.99296,
      "grad_norm": 0.0024922362063080072,
      "learning_rate": 1.338048e-05,
      "loss": 0.0002,
      "step": 31030
    },
    {
      "epoch": 0.99328,
      "grad_norm": 0.006822152994573116,
      "learning_rate": 1.3378346666666669e-05,
      "loss": 0.0548,
      "step": 31040
    },
    {
      "epoch": 0.9936,
      "grad_norm": 0.002561077941209078,
      "learning_rate": 1.3376213333333334e-05,
      "loss": 0.0002,
      "step": 31050
    },
    {
      "epoch": 0.99392,
      "grad_norm": 0.332916259765625,
      "learning_rate": 1.337408e-05,
      "loss": 0.0007,
      "step": 31060
    },
    {
      "epoch": 0.99424,
      "grad_norm": 0.003498790320008993,
      "learning_rate": 1.3371946666666669e-05,
      "loss": 0.0003,
      "step": 31070
    },
    {
      "epoch": 0.99456,
      "grad_norm": 0.002392089692875743,
      "learning_rate": 1.3369813333333334e-05,
      "loss": 0.0013,
      "step": 31080
    },
    {
      "epoch": 0.99488,
      "grad_norm": 0.0022662023548036814,
      "learning_rate": 1.3367680000000001e-05,
      "loss": 0.0003,
      "step": 31090
    },
    {
      "epoch": 0.9952,
      "grad_norm": 0.00666343467310071,
      "learning_rate": 1.3365546666666666e-05,
      "loss": 0.0003,
      "step": 31100
    },
    {
      "epoch": 0.99552,
      "grad_norm": 0.002542938804253936,
      "learning_rate": 1.3363413333333335e-05,
      "loss": 0.0003,
      "step": 31110
    },
    {
      "epoch": 0.99584,
      "grad_norm": 0.004817556124180555,
      "learning_rate": 1.336128e-05,
      "loss": 0.0541,
      "step": 31120
    },
    {
      "epoch": 0.99616,
      "grad_norm": 0.0038416956085711718,
      "learning_rate": 1.3359146666666668e-05,
      "loss": 0.0004,
      "step": 31130
    },
    {
      "epoch": 0.99648,
      "grad_norm": 0.0048261648043990135,
      "learning_rate": 1.3357013333333335e-05,
      "loss": 0.0002,
      "step": 31140
    },
    {
      "epoch": 0.9968,
      "grad_norm": 0.015800008550286293,
      "learning_rate": 1.3354880000000002e-05,
      "loss": 0.1146,
      "step": 31150
    },
    {
      "epoch": 0.99712,
      "grad_norm": 0.03679948300123215,
      "learning_rate": 1.3352746666666667e-05,
      "loss": 0.0029,
      "step": 31160
    },
    {
      "epoch": 0.99744,
      "grad_norm": 0.00795119907706976,
      "learning_rate": 1.3350613333333336e-05,
      "loss": 0.0005,
      "step": 31170
    },
    {
      "epoch": 0.99776,
      "grad_norm": 0.007090227212756872,
      "learning_rate": 1.3348480000000001e-05,
      "loss": 0.0187,
      "step": 31180
    },
    {
      "epoch": 0.99808,
      "grad_norm": 0.004151808097958565,
      "learning_rate": 1.3346346666666667e-05,
      "loss": 0.0002,
      "step": 31190
    },
    {
      "epoch": 0.9984,
      "grad_norm": 0.022678550332784653,
      "learning_rate": 1.3344213333333334e-05,
      "loss": 0.0032,
      "step": 31200
    },
    {
      "epoch": 0.99872,
      "grad_norm": 0.004876875784248114,
      "learning_rate": 1.3342080000000003e-05,
      "loss": 0.0007,
      "step": 31210
    },
    {
      "epoch": 0.99904,
      "grad_norm": 0.0019875706639140844,
      "learning_rate": 1.3339946666666668e-05,
      "loss": 0.0002,
      "step": 31220
    },
    {
      "epoch": 0.99936,
      "grad_norm": 3.984354257583618,
      "learning_rate": 1.3337813333333333e-05,
      "loss": 0.013,
      "step": 31230
    },
    {
      "epoch": 0.99968,
      "grad_norm": 0.025502502918243408,
      "learning_rate": 1.3335680000000002e-05,
      "loss": 0.0002,
      "step": 31240
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.004356625955551863,
      "learning_rate": 1.3333546666666667e-05,
      "loss": 0.0005,
      "step": 31250
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.0019,
      "eval_f1": 0.001899191538345146,
      "eval_loss": 10.045947074890137,
      "eval_precision": 0.0018855795903119062,
      "eval_recall": 0.001913739185431177,
      "eval_runtime": 38.464,
      "eval_samples_per_second": 259.984,
      "eval_steps_per_second": 16.249,
      "step": 31250
    }
  ],
  "logging_steps": 10,
  "max_steps": 93750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.096115008589952e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
