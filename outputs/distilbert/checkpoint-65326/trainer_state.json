{
  "best_global_step": 65326,
  "best_metric": 0.9973287409108305,
  "best_model_checkpoint": "./outputs/distilbert/checkpoint-65326",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 65326,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0003061568135198849,
      "grad_norm": 0.9974333047866821,
      "learning_rate": 1.999816305911888e-05,
      "loss": 0.6989,
      "step": 10
    },
    {
      "epoch": 0.0006123136270397698,
      "grad_norm": 1.210198998451233,
      "learning_rate": 1.9996122013695415e-05,
      "loss": 0.6778,
      "step": 20
    },
    {
      "epoch": 0.0009184704405596546,
      "grad_norm": 0.9706031084060669,
      "learning_rate": 1.999408096827195e-05,
      "loss": 0.655,
      "step": 30
    },
    {
      "epoch": 0.0012246272540795396,
      "grad_norm": 0.9207198023796082,
      "learning_rate": 1.9992039922848486e-05,
      "loss": 0.6347,
      "step": 40
    },
    {
      "epoch": 0.0015307840675994244,
      "grad_norm": 0.8861068487167358,
      "learning_rate": 1.998999887742502e-05,
      "loss": 0.6156,
      "step": 50
    },
    {
      "epoch": 0.0018369408811193093,
      "grad_norm": 1.0108892917633057,
      "learning_rate": 1.9987957832001553e-05,
      "loss": 0.5923,
      "step": 60
    },
    {
      "epoch": 0.0021430976946391943,
      "grad_norm": 1.6661227941513062,
      "learning_rate": 1.9985916786578086e-05,
      "loss": 0.5693,
      "step": 70
    },
    {
      "epoch": 0.002449254508159079,
      "grad_norm": 1.403397798538208,
      "learning_rate": 1.998387574115462e-05,
      "loss": 0.5414,
      "step": 80
    },
    {
      "epoch": 0.002755411321678964,
      "grad_norm": 1.3924728631973267,
      "learning_rate": 1.9981834695731154e-05,
      "loss": 0.513,
      "step": 90
    },
    {
      "epoch": 0.003061568135198849,
      "grad_norm": 1.3901374340057373,
      "learning_rate": 1.9979793650307687e-05,
      "loss": 0.4984,
      "step": 100
    },
    {
      "epoch": 0.0033677249487187337,
      "grad_norm": 1.0419576168060303,
      "learning_rate": 1.9977752604884224e-05,
      "loss": 0.4531,
      "step": 110
    },
    {
      "epoch": 0.0036738817622386185,
      "grad_norm": 1.3442891836166382,
      "learning_rate": 1.9975711559460758e-05,
      "loss": 0.4185,
      "step": 120
    },
    {
      "epoch": 0.003980038575758503,
      "grad_norm": 1.4431239366531372,
      "learning_rate": 1.9973670514037292e-05,
      "loss": 0.3674,
      "step": 130
    },
    {
      "epoch": 0.004286195389278389,
      "grad_norm": 1.2914921045303345,
      "learning_rate": 1.9971629468613825e-05,
      "loss": 0.345,
      "step": 140
    },
    {
      "epoch": 0.004592352202798273,
      "grad_norm": 1.1134064197540283,
      "learning_rate": 1.996958842319036e-05,
      "loss": 0.2795,
      "step": 150
    },
    {
      "epoch": 0.004898509016318158,
      "grad_norm": 1.0785413980484009,
      "learning_rate": 1.9967547377766893e-05,
      "loss": 0.2526,
      "step": 160
    },
    {
      "epoch": 0.005204665829838043,
      "grad_norm": 0.9583188891410828,
      "learning_rate": 1.9965506332343426e-05,
      "loss": 0.211,
      "step": 170
    },
    {
      "epoch": 0.005510822643357928,
      "grad_norm": 0.8100814819335938,
      "learning_rate": 1.9963465286919963e-05,
      "loss": 0.1682,
      "step": 180
    },
    {
      "epoch": 0.005816979456877812,
      "grad_norm": 1.1890983581542969,
      "learning_rate": 1.9961424241496497e-05,
      "loss": 0.1457,
      "step": 190
    },
    {
      "epoch": 0.006123136270397698,
      "grad_norm": 0.6996516585350037,
      "learning_rate": 1.995938319607303e-05,
      "loss": 0.1005,
      "step": 200
    },
    {
      "epoch": 0.006429293083917583,
      "grad_norm": 0.6529807448387146,
      "learning_rate": 1.9957342150649564e-05,
      "loss": 0.1022,
      "step": 210
    },
    {
      "epoch": 0.006735449897437467,
      "grad_norm": 0.47913074493408203,
      "learning_rate": 1.9955301105226098e-05,
      "loss": 0.0669,
      "step": 220
    },
    {
      "epoch": 0.007041606710957353,
      "grad_norm": 0.33048608899116516,
      "learning_rate": 1.995326005980263e-05,
      "loss": 0.0548,
      "step": 230
    },
    {
      "epoch": 0.007347763524477237,
      "grad_norm": 0.4502743184566498,
      "learning_rate": 1.9951219014379165e-05,
      "loss": 0.0427,
      "step": 240
    },
    {
      "epoch": 0.007653920337997122,
      "grad_norm": 0.6982327103614807,
      "learning_rate": 1.99491779689557e-05,
      "loss": 0.0367,
      "step": 250
    },
    {
      "epoch": 0.007960077151517007,
      "grad_norm": 0.24876922369003296,
      "learning_rate": 1.9947136923532236e-05,
      "loss": 0.0297,
      "step": 260
    },
    {
      "epoch": 0.008266233965036892,
      "grad_norm": 0.2966463267803192,
      "learning_rate": 1.994509587810877e-05,
      "loss": 0.0264,
      "step": 270
    },
    {
      "epoch": 0.008572390778556777,
      "grad_norm": 0.14754994213581085,
      "learning_rate": 1.9943054832685303e-05,
      "loss": 0.0228,
      "step": 280
    },
    {
      "epoch": 0.008878547592076663,
      "grad_norm": 0.3718191087245941,
      "learning_rate": 1.9941013787261837e-05,
      "loss": 0.0495,
      "step": 290
    },
    {
      "epoch": 0.009184704405596546,
      "grad_norm": 0.1351471096277237,
      "learning_rate": 1.993897274183837e-05,
      "loss": 0.0535,
      "step": 300
    },
    {
      "epoch": 0.009490861219116431,
      "grad_norm": 0.8493902087211609,
      "learning_rate": 1.9936931696414904e-05,
      "loss": 0.0182,
      "step": 310
    },
    {
      "epoch": 0.009797018032636317,
      "grad_norm": 0.19311025738716125,
      "learning_rate": 1.9934890650991438e-05,
      "loss": 0.049,
      "step": 320
    },
    {
      "epoch": 0.010103174846156202,
      "grad_norm": 1.7527143955230713,
      "learning_rate": 1.9932849605567975e-05,
      "loss": 0.0552,
      "step": 330
    },
    {
      "epoch": 0.010409331659676085,
      "grad_norm": 0.08417479693889618,
      "learning_rate": 1.993080856014451e-05,
      "loss": 0.0109,
      "step": 340
    },
    {
      "epoch": 0.01071548847319597,
      "grad_norm": 0.18420183658599854,
      "learning_rate": 1.9928767514721042e-05,
      "loss": 0.0095,
      "step": 350
    },
    {
      "epoch": 0.011021645286715856,
      "grad_norm": 0.20446637272834778,
      "learning_rate": 1.9926726469297576e-05,
      "loss": 0.0559,
      "step": 360
    },
    {
      "epoch": 0.011327802100235741,
      "grad_norm": 0.07415866106748581,
      "learning_rate": 1.992468542387411e-05,
      "loss": 0.0109,
      "step": 370
    },
    {
      "epoch": 0.011633958913755625,
      "grad_norm": 0.1365305632352829,
      "learning_rate": 1.9922644378450643e-05,
      "loss": 0.0164,
      "step": 380
    },
    {
      "epoch": 0.01194011572727551,
      "grad_norm": 0.09427438676357269,
      "learning_rate": 1.9920603333027177e-05,
      "loss": 0.0307,
      "step": 390
    },
    {
      "epoch": 0.012246272540795395,
      "grad_norm": 0.039960142225027084,
      "learning_rate": 1.9918562287603714e-05,
      "loss": 0.0077,
      "step": 400
    },
    {
      "epoch": 0.01255242935431528,
      "grad_norm": 0.06740117073059082,
      "learning_rate": 1.9916521242180247e-05,
      "loss": 0.0419,
      "step": 410
    },
    {
      "epoch": 0.012858586167835166,
      "grad_norm": 0.14931178092956543,
      "learning_rate": 1.991448019675678e-05,
      "loss": 0.015,
      "step": 420
    },
    {
      "epoch": 0.01316474298135505,
      "grad_norm": 0.1149183064699173,
      "learning_rate": 1.9912439151333315e-05,
      "loss": 0.0235,
      "step": 430
    },
    {
      "epoch": 0.013470899794874935,
      "grad_norm": 0.05126490071415901,
      "learning_rate": 1.9910398105909848e-05,
      "loss": 0.0114,
      "step": 440
    },
    {
      "epoch": 0.01377705660839482,
      "grad_norm": 0.0734405517578125,
      "learning_rate": 1.9908357060486382e-05,
      "loss": 0.0254,
      "step": 450
    },
    {
      "epoch": 0.014083213421914705,
      "grad_norm": 0.03963712230324745,
      "learning_rate": 1.9906316015062916e-05,
      "loss": 0.0221,
      "step": 460
    },
    {
      "epoch": 0.014389370235434589,
      "grad_norm": 0.06219770386815071,
      "learning_rate": 1.990427496963945e-05,
      "loss": 0.0036,
      "step": 470
    },
    {
      "epoch": 0.014695527048954474,
      "grad_norm": 1.644451379776001,
      "learning_rate": 1.9902233924215986e-05,
      "loss": 0.0458,
      "step": 480
    },
    {
      "epoch": 0.01500168386247436,
      "grad_norm": 0.11131279915571213,
      "learning_rate": 1.990019287879252e-05,
      "loss": 0.0053,
      "step": 490
    },
    {
      "epoch": 0.015307840675994245,
      "grad_norm": 0.026260007172822952,
      "learning_rate": 1.9898151833369054e-05,
      "loss": 0.0027,
      "step": 500
    },
    {
      "epoch": 0.01561399748951413,
      "grad_norm": 0.047258809208869934,
      "learning_rate": 1.9896110787945587e-05,
      "loss": 0.004,
      "step": 510
    },
    {
      "epoch": 0.015920154303034013,
      "grad_norm": 1.8061407804489136,
      "learning_rate": 1.989406974252212e-05,
      "loss": 0.0666,
      "step": 520
    },
    {
      "epoch": 0.0162263111165539,
      "grad_norm": 0.057102810591459274,
      "learning_rate": 1.9892028697098654e-05,
      "loss": 0.0594,
      "step": 530
    },
    {
      "epoch": 0.016532467930073784,
      "grad_norm": 0.03657061979174614,
      "learning_rate": 1.9889987651675188e-05,
      "loss": 0.0495,
      "step": 540
    },
    {
      "epoch": 0.01683862474359367,
      "grad_norm": 0.03635052964091301,
      "learning_rate": 1.9887946606251725e-05,
      "loss": 0.0058,
      "step": 550
    },
    {
      "epoch": 0.017144781557113555,
      "grad_norm": 0.03429824858903885,
      "learning_rate": 1.988590556082826e-05,
      "loss": 0.0111,
      "step": 560
    },
    {
      "epoch": 0.01745093837063344,
      "grad_norm": 0.08982494473457336,
      "learning_rate": 1.9883864515404792e-05,
      "loss": 0.0408,
      "step": 570
    },
    {
      "epoch": 0.017757095184153325,
      "grad_norm": 0.019418131560087204,
      "learning_rate": 1.9881823469981326e-05,
      "loss": 0.0042,
      "step": 580
    },
    {
      "epoch": 0.018063251997673207,
      "grad_norm": 1.843653917312622,
      "learning_rate": 1.987978242455786e-05,
      "loss": 0.0534,
      "step": 590
    },
    {
      "epoch": 0.018369408811193092,
      "grad_norm": 0.0394144132733345,
      "learning_rate": 1.9877741379134393e-05,
      "loss": 0.0435,
      "step": 600
    },
    {
      "epoch": 0.018675565624712977,
      "grad_norm": 0.03195430338382721,
      "learning_rate": 1.9875700333710927e-05,
      "loss": 0.034,
      "step": 610
    },
    {
      "epoch": 0.018981722438232863,
      "grad_norm": 1.134543776512146,
      "learning_rate": 1.9873659288287464e-05,
      "loss": 0.0084,
      "step": 620
    },
    {
      "epoch": 0.019287879251752748,
      "grad_norm": 0.04905609413981438,
      "learning_rate": 1.9871618242863998e-05,
      "loss": 0.0485,
      "step": 630
    },
    {
      "epoch": 0.019594036065272633,
      "grad_norm": 0.04315517470240593,
      "learning_rate": 1.986957719744053e-05,
      "loss": 0.0464,
      "step": 640
    },
    {
      "epoch": 0.01990019287879252,
      "grad_norm": 0.05828101560473442,
      "learning_rate": 1.9867536152017065e-05,
      "loss": 0.0338,
      "step": 650
    },
    {
      "epoch": 0.020206349692312404,
      "grad_norm": 0.03886641189455986,
      "learning_rate": 1.98654951065936e-05,
      "loss": 0.0425,
      "step": 660
    },
    {
      "epoch": 0.020512506505832286,
      "grad_norm": 0.04158514738082886,
      "learning_rate": 1.9863454061170132e-05,
      "loss": 0.0336,
      "step": 670
    },
    {
      "epoch": 0.02081866331935217,
      "grad_norm": 0.04415062442421913,
      "learning_rate": 1.9861413015746666e-05,
      "loss": 0.0426,
      "step": 680
    },
    {
      "epoch": 0.021124820132872056,
      "grad_norm": 0.02721012756228447,
      "learning_rate": 1.98593719703232e-05,
      "loss": 0.0121,
      "step": 690
    },
    {
      "epoch": 0.02143097694639194,
      "grad_norm": 0.03671204298734665,
      "learning_rate": 1.9857330924899737e-05,
      "loss": 0.0028,
      "step": 700
    },
    {
      "epoch": 0.021737133759911827,
      "grad_norm": 0.17157337069511414,
      "learning_rate": 1.985528987947627e-05,
      "loss": 0.0045,
      "step": 710
    },
    {
      "epoch": 0.022043290573431712,
      "grad_norm": 0.0363733135163784,
      "learning_rate": 1.9853248834052804e-05,
      "loss": 0.0031,
      "step": 720
    },
    {
      "epoch": 0.022349447386951597,
      "grad_norm": 0.1775527149438858,
      "learning_rate": 1.9851207788629338e-05,
      "loss": 0.0048,
      "step": 730
    },
    {
      "epoch": 0.022655604200471482,
      "grad_norm": 0.0207065399736166,
      "learning_rate": 1.984916674320587e-05,
      "loss": 0.0778,
      "step": 740
    },
    {
      "epoch": 0.022961761013991368,
      "grad_norm": 0.026320936158299446,
      "learning_rate": 1.9847125697782405e-05,
      "loss": 0.034,
      "step": 750
    },
    {
      "epoch": 0.02326791782751125,
      "grad_norm": 0.16104348003864288,
      "learning_rate": 1.984508465235894e-05,
      "loss": 0.0418,
      "step": 760
    },
    {
      "epoch": 0.023574074641031135,
      "grad_norm": 0.05916861817240715,
      "learning_rate": 1.9843043606935475e-05,
      "loss": 0.0162,
      "step": 770
    },
    {
      "epoch": 0.02388023145455102,
      "grad_norm": 0.029246611520648003,
      "learning_rate": 1.984100256151201e-05,
      "loss": 0.0786,
      "step": 780
    },
    {
      "epoch": 0.024186388268070905,
      "grad_norm": 1.862053394317627,
      "learning_rate": 1.9838961516088543e-05,
      "loss": 0.0361,
      "step": 790
    },
    {
      "epoch": 0.02449254508159079,
      "grad_norm": 0.03759775683283806,
      "learning_rate": 1.9836920470665076e-05,
      "loss": 0.0393,
      "step": 800
    },
    {
      "epoch": 0.024798701895110676,
      "grad_norm": 0.036594558507204056,
      "learning_rate": 1.983487942524161e-05,
      "loss": 0.0036,
      "step": 810
    },
    {
      "epoch": 0.02510485870863056,
      "grad_norm": 0.05593112111091614,
      "learning_rate": 1.9832838379818144e-05,
      "loss": 0.003,
      "step": 820
    },
    {
      "epoch": 0.025411015522150446,
      "grad_norm": 0.04494317248463631,
      "learning_rate": 1.9830797334394677e-05,
      "loss": 0.0044,
      "step": 830
    },
    {
      "epoch": 0.025717172335670332,
      "grad_norm": 0.05253618583083153,
      "learning_rate": 1.9828756288971214e-05,
      "loss": 0.0567,
      "step": 840
    },
    {
      "epoch": 0.026023329149190214,
      "grad_norm": 0.03444987162947655,
      "learning_rate": 1.9826715243547748e-05,
      "loss": 0.0379,
      "step": 850
    },
    {
      "epoch": 0.0263294859627101,
      "grad_norm": 0.4570290744304657,
      "learning_rate": 1.982467419812428e-05,
      "loss": 0.0051,
      "step": 860
    },
    {
      "epoch": 0.026635642776229984,
      "grad_norm": 0.04747558757662773,
      "learning_rate": 1.9822633152700815e-05,
      "loss": 0.0038,
      "step": 870
    },
    {
      "epoch": 0.02694179958974987,
      "grad_norm": 1.8639514446258545,
      "learning_rate": 1.982059210727735e-05,
      "loss": 0.0665,
      "step": 880
    },
    {
      "epoch": 0.027247956403269755,
      "grad_norm": 0.046810735017061234,
      "learning_rate": 1.9818551061853883e-05,
      "loss": 0.0231,
      "step": 890
    },
    {
      "epoch": 0.02755411321678964,
      "grad_norm": 0.08322568237781525,
      "learning_rate": 1.9816510016430416e-05,
      "loss": 0.0359,
      "step": 900
    },
    {
      "epoch": 0.027860270030309525,
      "grad_norm": 0.04088986665010452,
      "learning_rate": 1.981446897100695e-05,
      "loss": 0.0899,
      "step": 910
    },
    {
      "epoch": 0.02816642684382941,
      "grad_norm": 0.05287032201886177,
      "learning_rate": 1.9812427925583487e-05,
      "loss": 0.0029,
      "step": 920
    },
    {
      "epoch": 0.028472583657349296,
      "grad_norm": 0.06948632746934891,
      "learning_rate": 1.981038688016002e-05,
      "loss": 0.0546,
      "step": 930
    },
    {
      "epoch": 0.028778740470869178,
      "grad_norm": 0.04619286209344864,
      "learning_rate": 1.9808345834736554e-05,
      "loss": 0.0241,
      "step": 940
    },
    {
      "epoch": 0.029084897284389063,
      "grad_norm": 0.04320543631911278,
      "learning_rate": 1.9806304789313088e-05,
      "loss": 0.0678,
      "step": 950
    },
    {
      "epoch": 0.029391054097908948,
      "grad_norm": 0.05119870975613594,
      "learning_rate": 1.980426374388962e-05,
      "loss": 0.0036,
      "step": 960
    },
    {
      "epoch": 0.029697210911428833,
      "grad_norm": 0.04786669462919235,
      "learning_rate": 1.9802222698466155e-05,
      "loss": 0.0033,
      "step": 970
    },
    {
      "epoch": 0.03000336772494872,
      "grad_norm": 0.03283308073878288,
      "learning_rate": 1.980018165304269e-05,
      "loss": 0.0037,
      "step": 980
    },
    {
      "epoch": 0.030309524538468604,
      "grad_norm": 0.02795194461941719,
      "learning_rate": 1.9798140607619226e-05,
      "loss": 0.0303,
      "step": 990
    },
    {
      "epoch": 0.03061568135198849,
      "grad_norm": 0.03433491662144661,
      "learning_rate": 1.979609956219576e-05,
      "loss": 0.0114,
      "step": 1000
    },
    {
      "epoch": 0.030921838165508374,
      "grad_norm": 0.04633360356092453,
      "learning_rate": 1.9794058516772293e-05,
      "loss": 0.0037,
      "step": 1010
    },
    {
      "epoch": 0.03122799497902826,
      "grad_norm": 0.02548276074230671,
      "learning_rate": 1.9792017471348827e-05,
      "loss": 0.0021,
      "step": 1020
    },
    {
      "epoch": 0.03153415179254814,
      "grad_norm": 0.021242374554276466,
      "learning_rate": 1.978997642592536e-05,
      "loss": 0.0021,
      "step": 1030
    },
    {
      "epoch": 0.03184030860606803,
      "grad_norm": 2.082730770111084,
      "learning_rate": 1.9787935380501894e-05,
      "loss": 0.0432,
      "step": 1040
    },
    {
      "epoch": 0.03214646541958791,
      "grad_norm": 0.504269003868103,
      "learning_rate": 1.9785894335078428e-05,
      "loss": 0.0035,
      "step": 1050
    },
    {
      "epoch": 0.0324526222331078,
      "grad_norm": 0.03032683953642845,
      "learning_rate": 1.9783853289654965e-05,
      "loss": 0.0064,
      "step": 1060
    },
    {
      "epoch": 0.03275877904662768,
      "grad_norm": 0.02632540836930275,
      "learning_rate": 1.97818122442315e-05,
      "loss": 0.0065,
      "step": 1070
    },
    {
      "epoch": 0.03306493586014757,
      "grad_norm": 0.05930324271321297,
      "learning_rate": 1.9779771198808032e-05,
      "loss": 0.011,
      "step": 1080
    },
    {
      "epoch": 0.03337109267366745,
      "grad_norm": 0.027216259390115738,
      "learning_rate": 1.9777730153384566e-05,
      "loss": 0.0023,
      "step": 1090
    },
    {
      "epoch": 0.03367724948718734,
      "grad_norm": 1.973861813545227,
      "learning_rate": 1.97756891079611e-05,
      "loss": 0.0287,
      "step": 1100
    },
    {
      "epoch": 0.033983406300707224,
      "grad_norm": 0.07724684476852417,
      "learning_rate": 1.9773648062537633e-05,
      "loss": 0.0052,
      "step": 1110
    },
    {
      "epoch": 0.03428956311422711,
      "grad_norm": 0.01990748941898346,
      "learning_rate": 1.9771607017114167e-05,
      "loss": 0.0083,
      "step": 1120
    },
    {
      "epoch": 0.034595719927746994,
      "grad_norm": 0.3768950402736664,
      "learning_rate": 1.97695659716907e-05,
      "loss": 0.0027,
      "step": 1130
    },
    {
      "epoch": 0.03490187674126688,
      "grad_norm": 0.04769674316048622,
      "learning_rate": 1.9767524926267237e-05,
      "loss": 0.0016,
      "step": 1140
    },
    {
      "epoch": 0.035208033554786765,
      "grad_norm": 0.06451092660427094,
      "learning_rate": 1.976548388084377e-05,
      "loss": 0.0014,
      "step": 1150
    },
    {
      "epoch": 0.03551419036830665,
      "grad_norm": 0.022891448810696602,
      "learning_rate": 1.9763442835420305e-05,
      "loss": 0.0018,
      "step": 1160
    },
    {
      "epoch": 0.03582034718182653,
      "grad_norm": 0.01601814478635788,
      "learning_rate": 1.9761401789996838e-05,
      "loss": 0.0027,
      "step": 1170
    },
    {
      "epoch": 0.036126503995346414,
      "grad_norm": 0.029382143169641495,
      "learning_rate": 1.9759360744573372e-05,
      "loss": 0.0079,
      "step": 1180
    },
    {
      "epoch": 0.0364326608088663,
      "grad_norm": 1.9747322797775269,
      "learning_rate": 1.9757319699149905e-05,
      "loss": 0.1049,
      "step": 1190
    },
    {
      "epoch": 0.036738817622386184,
      "grad_norm": 0.02210509032011032,
      "learning_rate": 1.975527865372644e-05,
      "loss": 0.0011,
      "step": 1200
    },
    {
      "epoch": 0.03704497443590607,
      "grad_norm": 0.014964127913117409,
      "learning_rate": 1.9753237608302976e-05,
      "loss": 0.0015,
      "step": 1210
    },
    {
      "epoch": 0.037351131249425955,
      "grad_norm": 0.019934294745326042,
      "learning_rate": 1.975119656287951e-05,
      "loss": 0.0015,
      "step": 1220
    },
    {
      "epoch": 0.03765728806294584,
      "grad_norm": 0.01304638385772705,
      "learning_rate": 1.9749155517456043e-05,
      "loss": 0.0019,
      "step": 1230
    },
    {
      "epoch": 0.037963444876465725,
      "grad_norm": 0.041663698852062225,
      "learning_rate": 1.9747114472032577e-05,
      "loss": 0.0596,
      "step": 1240
    },
    {
      "epoch": 0.03826960168998561,
      "grad_norm": 0.020304877310991287,
      "learning_rate": 1.974507342660911e-05,
      "loss": 0.0391,
      "step": 1250
    },
    {
      "epoch": 0.038575758503505496,
      "grad_norm": 0.06668934226036072,
      "learning_rate": 1.9743032381185644e-05,
      "loss": 0.0237,
      "step": 1260
    },
    {
      "epoch": 0.03888191531702538,
      "grad_norm": 0.01967202126979828,
      "learning_rate": 1.9740991335762178e-05,
      "loss": 0.0027,
      "step": 1270
    },
    {
      "epoch": 0.039188072130545266,
      "grad_norm": 0.009551245719194412,
      "learning_rate": 1.973895029033871e-05,
      "loss": 0.0348,
      "step": 1280
    },
    {
      "epoch": 0.03949422894406515,
      "grad_norm": 0.018014179542660713,
      "learning_rate": 1.973690924491525e-05,
      "loss": 0.0012,
      "step": 1290
    },
    {
      "epoch": 0.03980038575758504,
      "grad_norm": 0.01978304237127304,
      "learning_rate": 1.9734868199491782e-05,
      "loss": 0.003,
      "step": 1300
    },
    {
      "epoch": 0.04010654257110492,
      "grad_norm": 0.020907290279865265,
      "learning_rate": 1.9732827154068316e-05,
      "loss": 0.0011,
      "step": 1310
    },
    {
      "epoch": 0.04041269938462481,
      "grad_norm": 0.027653519064188004,
      "learning_rate": 1.973078610864485e-05,
      "loss": 0.0012,
      "step": 1320
    },
    {
      "epoch": 0.04071885619814469,
      "grad_norm": 0.023029454052448273,
      "learning_rate": 1.9728745063221383e-05,
      "loss": 0.0312,
      "step": 1330
    },
    {
      "epoch": 0.04102501301166457,
      "grad_norm": 0.012275575660169125,
      "learning_rate": 1.9726704017797917e-05,
      "loss": 0.0232,
      "step": 1340
    },
    {
      "epoch": 0.041331169825184456,
      "grad_norm": 0.12335671484470367,
      "learning_rate": 1.972466297237445e-05,
      "loss": 0.0933,
      "step": 1350
    },
    {
      "epoch": 0.04163732663870434,
      "grad_norm": 0.02297367714345455,
      "learning_rate": 1.9722621926950988e-05,
      "loss": 0.0012,
      "step": 1360
    },
    {
      "epoch": 0.04194348345222423,
      "grad_norm": 0.023005954921245575,
      "learning_rate": 1.972058088152752e-05,
      "loss": 0.0012,
      "step": 1370
    },
    {
      "epoch": 0.04224964026574411,
      "grad_norm": 0.05718191713094711,
      "learning_rate": 1.9718539836104055e-05,
      "loss": 0.0373,
      "step": 1380
    },
    {
      "epoch": 0.042555797079264,
      "grad_norm": 0.015443728305399418,
      "learning_rate": 1.971649879068059e-05,
      "loss": 0.042,
      "step": 1390
    },
    {
      "epoch": 0.04286195389278388,
      "grad_norm": 0.033411551266908646,
      "learning_rate": 1.9714457745257122e-05,
      "loss": 0.0615,
      "step": 1400
    },
    {
      "epoch": 0.04316811070630377,
      "grad_norm": 0.0714685320854187,
      "learning_rate": 1.9712416699833656e-05,
      "loss": 0.0041,
      "step": 1410
    },
    {
      "epoch": 0.04347426751982365,
      "grad_norm": 0.22266405820846558,
      "learning_rate": 1.971037565441019e-05,
      "loss": 0.0711,
      "step": 1420
    },
    {
      "epoch": 0.04378042433334354,
      "grad_norm": 0.1240752637386322,
      "learning_rate": 1.9708334608986726e-05,
      "loss": 0.0416,
      "step": 1430
    },
    {
      "epoch": 0.044086581146863424,
      "grad_norm": 0.12002836167812347,
      "learning_rate": 1.970629356356326e-05,
      "loss": 0.05,
      "step": 1440
    },
    {
      "epoch": 0.04439273796038331,
      "grad_norm": 0.060657866299152374,
      "learning_rate": 1.9704252518139794e-05,
      "loss": 0.0455,
      "step": 1450
    },
    {
      "epoch": 0.044698894773903194,
      "grad_norm": 1.8145956993103027,
      "learning_rate": 1.9702211472716327e-05,
      "loss": 0.0762,
      "step": 1460
    },
    {
      "epoch": 0.04500505158742308,
      "grad_norm": 0.06961315870285034,
      "learning_rate": 1.970017042729286e-05,
      "loss": 0.0051,
      "step": 1470
    },
    {
      "epoch": 0.045311208400942965,
      "grad_norm": 0.05865035951137543,
      "learning_rate": 1.9698129381869395e-05,
      "loss": 0.0059,
      "step": 1480
    },
    {
      "epoch": 0.04561736521446285,
      "grad_norm": 0.16215410828590393,
      "learning_rate": 1.969608833644593e-05,
      "loss": 0.0067,
      "step": 1490
    },
    {
      "epoch": 0.045923522027982736,
      "grad_norm": 0.09613839536905289,
      "learning_rate": 1.9694047291022462e-05,
      "loss": 0.0032,
      "step": 1500
    },
    {
      "epoch": 0.04622967884150262,
      "grad_norm": 0.05143032222986221,
      "learning_rate": 1.9692006245599e-05,
      "loss": 0.0031,
      "step": 1510
    },
    {
      "epoch": 0.0465358356550225,
      "grad_norm": 0.022264961153268814,
      "learning_rate": 1.9689965200175533e-05,
      "loss": 0.0016,
      "step": 1520
    },
    {
      "epoch": 0.046841992468542384,
      "grad_norm": 0.033176422119140625,
      "learning_rate": 1.9687924154752066e-05,
      "loss": 0.009,
      "step": 1530
    },
    {
      "epoch": 0.04714814928206227,
      "grad_norm": 0.07657662779092789,
      "learning_rate": 1.96858831093286e-05,
      "loss": 0.0312,
      "step": 1540
    },
    {
      "epoch": 0.047454306095582155,
      "grad_norm": 0.031580597162246704,
      "learning_rate": 1.9683842063905134e-05,
      "loss": 0.0392,
      "step": 1550
    },
    {
      "epoch": 0.04776046290910204,
      "grad_norm": 0.048267610371112823,
      "learning_rate": 1.9681801018481667e-05,
      "loss": 0.0091,
      "step": 1560
    },
    {
      "epoch": 0.048066619722621926,
      "grad_norm": 0.028099972754716873,
      "learning_rate": 1.96797599730582e-05,
      "loss": 0.0016,
      "step": 1570
    },
    {
      "epoch": 0.04837277653614181,
      "grad_norm": 0.05111733451485634,
      "learning_rate": 1.9677718927634738e-05,
      "loss": 0.0506,
      "step": 1580
    },
    {
      "epoch": 0.048678933349661696,
      "grad_norm": 0.15109814703464508,
      "learning_rate": 1.967567788221127e-05,
      "loss": 0.0437,
      "step": 1590
    },
    {
      "epoch": 0.04898509016318158,
      "grad_norm": 1.4330284595489502,
      "learning_rate": 1.9673636836787805e-05,
      "loss": 0.0133,
      "step": 1600
    },
    {
      "epoch": 0.04929124697670147,
      "grad_norm": 2.6039066314697266,
      "learning_rate": 1.967159579136434e-05,
      "loss": 0.0253,
      "step": 1610
    },
    {
      "epoch": 0.04959740379022135,
      "grad_norm": 0.030388809740543365,
      "learning_rate": 1.9669554745940873e-05,
      "loss": 0.0019,
      "step": 1620
    },
    {
      "epoch": 0.04990356060374124,
      "grad_norm": 0.03781277686357498,
      "learning_rate": 1.9667513700517406e-05,
      "loss": 0.0095,
      "step": 1630
    },
    {
      "epoch": 0.05020971741726112,
      "grad_norm": 0.01932525262236595,
      "learning_rate": 1.966547265509394e-05,
      "loss": 0.0013,
      "step": 1640
    },
    {
      "epoch": 0.05051587423078101,
      "grad_norm": 0.23089200258255005,
      "learning_rate": 1.9663431609670477e-05,
      "loss": 0.0028,
      "step": 1650
    },
    {
      "epoch": 0.05082203104430089,
      "grad_norm": 0.01666693016886711,
      "learning_rate": 1.966139056424701e-05,
      "loss": 0.0257,
      "step": 1660
    },
    {
      "epoch": 0.05112818785782078,
      "grad_norm": 0.02308119274675846,
      "learning_rate": 1.9659349518823544e-05,
      "loss": 0.0031,
      "step": 1670
    },
    {
      "epoch": 0.051434344671340664,
      "grad_norm": 0.021714936941862106,
      "learning_rate": 1.9657308473400078e-05,
      "loss": 0.0015,
      "step": 1680
    },
    {
      "epoch": 0.05174050148486055,
      "grad_norm": 0.020455414429306984,
      "learning_rate": 1.965526742797661e-05,
      "loss": 0.0439,
      "step": 1690
    },
    {
      "epoch": 0.05204665829838043,
      "grad_norm": 0.0366525799036026,
      "learning_rate": 1.9653226382553145e-05,
      "loss": 0.0021,
      "step": 1700
    },
    {
      "epoch": 0.05235281511190031,
      "grad_norm": 0.8233904838562012,
      "learning_rate": 1.965118533712968e-05,
      "loss": 0.0044,
      "step": 1710
    },
    {
      "epoch": 0.0526589719254202,
      "grad_norm": 0.010725868865847588,
      "learning_rate": 1.9649144291706212e-05,
      "loss": 0.0015,
      "step": 1720
    },
    {
      "epoch": 0.05296512873894008,
      "grad_norm": 0.01371920295059681,
      "learning_rate": 1.964710324628275e-05,
      "loss": 0.0435,
      "step": 1730
    },
    {
      "epoch": 0.05327128555245997,
      "grad_norm": 0.01529635675251484,
      "learning_rate": 1.9645062200859283e-05,
      "loss": 0.0395,
      "step": 1740
    },
    {
      "epoch": 0.053577442365979853,
      "grad_norm": 0.02208676002919674,
      "learning_rate": 1.9643021155435817e-05,
      "loss": 0.0212,
      "step": 1750
    },
    {
      "epoch": 0.05388359917949974,
      "grad_norm": 1.8153247833251953,
      "learning_rate": 1.964098011001235e-05,
      "loss": 0.065,
      "step": 1760
    },
    {
      "epoch": 0.054189755993019624,
      "grad_norm": 0.023359347134828568,
      "learning_rate": 1.9638939064588884e-05,
      "loss": 0.0015,
      "step": 1770
    },
    {
      "epoch": 0.05449591280653951,
      "grad_norm": 0.02728303335607052,
      "learning_rate": 1.9636898019165418e-05,
      "loss": 0.0422,
      "step": 1780
    },
    {
      "epoch": 0.054802069620059395,
      "grad_norm": 0.02985360473394394,
      "learning_rate": 1.963485697374195e-05,
      "loss": 0.0021,
      "step": 1790
    },
    {
      "epoch": 0.05510822643357928,
      "grad_norm": 0.022745030000805855,
      "learning_rate": 1.9632815928318488e-05,
      "loss": 0.0394,
      "step": 1800
    },
    {
      "epoch": 0.055414383247099165,
      "grad_norm": 0.030933471396565437,
      "learning_rate": 1.9630774882895022e-05,
      "loss": 0.0402,
      "step": 1810
    },
    {
      "epoch": 0.05572054006061905,
      "grad_norm": 0.026695311069488525,
      "learning_rate": 1.9628733837471556e-05,
      "loss": 0.0377,
      "step": 1820
    },
    {
      "epoch": 0.056026696874138936,
      "grad_norm": 0.04021818935871124,
      "learning_rate": 1.962669279204809e-05,
      "loss": 0.0434,
      "step": 1830
    },
    {
      "epoch": 0.05633285368765882,
      "grad_norm": 0.05495753511786461,
      "learning_rate": 1.9624651746624623e-05,
      "loss": 0.0358,
      "step": 1840
    },
    {
      "epoch": 0.056639010501178706,
      "grad_norm": 0.024233892560005188,
      "learning_rate": 1.9622610701201156e-05,
      "loss": 0.0391,
      "step": 1850
    },
    {
      "epoch": 0.05694516731469859,
      "grad_norm": 0.05542755126953125,
      "learning_rate": 1.962056965577769e-05,
      "loss": 0.0802,
      "step": 1860
    },
    {
      "epoch": 0.05725132412821848,
      "grad_norm": 0.07415715605020523,
      "learning_rate": 1.9618528610354227e-05,
      "loss": 0.0032,
      "step": 1870
    },
    {
      "epoch": 0.057557480941738355,
      "grad_norm": 0.08071641623973846,
      "learning_rate": 1.961648756493076e-05,
      "loss": 0.0033,
      "step": 1880
    },
    {
      "epoch": 0.05786363775525824,
      "grad_norm": 0.04122244939208031,
      "learning_rate": 1.9614446519507294e-05,
      "loss": 0.0115,
      "step": 1890
    },
    {
      "epoch": 0.058169794568778126,
      "grad_norm": 0.025809364393353462,
      "learning_rate": 1.9612405474083828e-05,
      "loss": 0.0024,
      "step": 1900
    },
    {
      "epoch": 0.05847595138229801,
      "grad_norm": 0.026154369115829468,
      "learning_rate": 1.9610364428660362e-05,
      "loss": 0.0146,
      "step": 1910
    },
    {
      "epoch": 0.058782108195817896,
      "grad_norm": 0.05064230412244797,
      "learning_rate": 1.9608323383236895e-05,
      "loss": 0.0374,
      "step": 1920
    },
    {
      "epoch": 0.05908826500933778,
      "grad_norm": 0.03847503662109375,
      "learning_rate": 1.960628233781343e-05,
      "loss": 0.0017,
      "step": 1930
    },
    {
      "epoch": 0.05939442182285767,
      "grad_norm": 0.030984021723270416,
      "learning_rate": 1.9604241292389963e-05,
      "loss": 0.0669,
      "step": 1940
    },
    {
      "epoch": 0.05970057863637755,
      "grad_norm": 0.03347090259194374,
      "learning_rate": 1.96022002469665e-05,
      "loss": 0.0367,
      "step": 1950
    },
    {
      "epoch": 0.06000673544989744,
      "grad_norm": 0.022524220868945122,
      "learning_rate": 1.9600159201543033e-05,
      "loss": 0.0309,
      "step": 1960
    },
    {
      "epoch": 0.06031289226341732,
      "grad_norm": 0.029620904475450516,
      "learning_rate": 1.9598118156119567e-05,
      "loss": 0.0183,
      "step": 1970
    },
    {
      "epoch": 0.06061904907693721,
      "grad_norm": 0.06611701846122742,
      "learning_rate": 1.95960771106961e-05,
      "loss": 0.0043,
      "step": 1980
    },
    {
      "epoch": 0.06092520589045709,
      "grad_norm": 0.026263274252414703,
      "learning_rate": 1.9594036065272634e-05,
      "loss": 0.0034,
      "step": 1990
    },
    {
      "epoch": 0.06123136270397698,
      "grad_norm": 0.03673185408115387,
      "learning_rate": 1.9591995019849168e-05,
      "loss": 0.0298,
      "step": 2000
    },
    {
      "epoch": 0.061537519517496864,
      "grad_norm": 0.3381037414073944,
      "learning_rate": 1.95899539744257e-05,
      "loss": 0.0185,
      "step": 2010
    },
    {
      "epoch": 0.06184367633101675,
      "grad_norm": 0.03252138942480087,
      "learning_rate": 1.958791292900224e-05,
      "loss": 0.0027,
      "step": 2020
    },
    {
      "epoch": 0.062149833144536634,
      "grad_norm": 0.03609037771821022,
      "learning_rate": 1.9585871883578772e-05,
      "loss": 0.0108,
      "step": 2030
    },
    {
      "epoch": 0.06245598995805652,
      "grad_norm": 0.03117130883038044,
      "learning_rate": 1.9583830838155306e-05,
      "loss": 0.0017,
      "step": 2040
    },
    {
      "epoch": 0.0627621467715764,
      "grad_norm": 0.02328217774629593,
      "learning_rate": 1.958178979273184e-05,
      "loss": 0.002,
      "step": 2050
    },
    {
      "epoch": 0.06306830358509628,
      "grad_norm": 0.01963431015610695,
      "learning_rate": 1.9579748747308373e-05,
      "loss": 0.0117,
      "step": 2060
    },
    {
      "epoch": 0.06337446039861618,
      "grad_norm": 0.023969898000359535,
      "learning_rate": 1.9577707701884907e-05,
      "loss": 0.0012,
      "step": 2070
    },
    {
      "epoch": 0.06368061721213605,
      "grad_norm": 0.049388621002435684,
      "learning_rate": 1.957566665646144e-05,
      "loss": 0.0018,
      "step": 2080
    },
    {
      "epoch": 0.06398677402565595,
      "grad_norm": 0.03400946035981178,
      "learning_rate": 1.9573625611037977e-05,
      "loss": 0.0459,
      "step": 2090
    },
    {
      "epoch": 0.06429293083917582,
      "grad_norm": 0.5180203914642334,
      "learning_rate": 1.957158456561451e-05,
      "loss": 0.0037,
      "step": 2100
    },
    {
      "epoch": 0.06459908765269572,
      "grad_norm": 0.024017732590436935,
      "learning_rate": 1.9569543520191045e-05,
      "loss": 0.0445,
      "step": 2110
    },
    {
      "epoch": 0.0649052444662156,
      "grad_norm": 0.0629991814494133,
      "learning_rate": 1.956750247476758e-05,
      "loss": 0.101,
      "step": 2120
    },
    {
      "epoch": 0.06521140127973549,
      "grad_norm": 0.05182861536741257,
      "learning_rate": 1.9565461429344112e-05,
      "loss": 0.0021,
      "step": 2130
    },
    {
      "epoch": 0.06551755809325537,
      "grad_norm": 0.05437590926885605,
      "learning_rate": 1.9563420383920646e-05,
      "loss": 0.0022,
      "step": 2140
    },
    {
      "epoch": 0.06582371490677524,
      "grad_norm": 0.03662382438778877,
      "learning_rate": 1.956137933849718e-05,
      "loss": 0.0023,
      "step": 2150
    },
    {
      "epoch": 0.06612987172029514,
      "grad_norm": 0.02180434949696064,
      "learning_rate": 1.9559338293073713e-05,
      "loss": 0.0177,
      "step": 2160
    },
    {
      "epoch": 0.06643602853381501,
      "grad_norm": 0.037896592170000076,
      "learning_rate": 1.955729724765025e-05,
      "loss": 0.0022,
      "step": 2170
    },
    {
      "epoch": 0.0667421853473349,
      "grad_norm": 0.0480453222990036,
      "learning_rate": 1.9555256202226784e-05,
      "loss": 0.0367,
      "step": 2180
    },
    {
      "epoch": 0.06704834216085478,
      "grad_norm": 0.03837267681956291,
      "learning_rate": 1.9553215156803317e-05,
      "loss": 0.034,
      "step": 2190
    },
    {
      "epoch": 0.06735449897437468,
      "grad_norm": 0.03596695140004158,
      "learning_rate": 1.955117411137985e-05,
      "loss": 0.0372,
      "step": 2200
    },
    {
      "epoch": 0.06766065578789456,
      "grad_norm": 0.04505404829978943,
      "learning_rate": 1.9549133065956385e-05,
      "loss": 0.0039,
      "step": 2210
    },
    {
      "epoch": 0.06796681260141445,
      "grad_norm": 0.03462136164307594,
      "learning_rate": 1.9547092020532918e-05,
      "loss": 0.0062,
      "step": 2220
    },
    {
      "epoch": 0.06827296941493433,
      "grad_norm": 0.0298926904797554,
      "learning_rate": 1.9545050975109452e-05,
      "loss": 0.0381,
      "step": 2230
    },
    {
      "epoch": 0.06857912622845422,
      "grad_norm": 0.018446536734700203,
      "learning_rate": 1.954300992968599e-05,
      "loss": 0.002,
      "step": 2240
    },
    {
      "epoch": 0.0688852830419741,
      "grad_norm": 0.04123133793473244,
      "learning_rate": 1.9540968884262523e-05,
      "loss": 0.0898,
      "step": 2250
    },
    {
      "epoch": 0.06919143985549399,
      "grad_norm": 0.04284647852182388,
      "learning_rate": 1.9538927838839056e-05,
      "loss": 0.0029,
      "step": 2260
    },
    {
      "epoch": 0.06949759666901387,
      "grad_norm": 0.04141930490732193,
      "learning_rate": 1.9536886793415586e-05,
      "loss": 0.0024,
      "step": 2270
    },
    {
      "epoch": 0.06980375348253376,
      "grad_norm": 0.025274042040109634,
      "learning_rate": 1.9534845747992124e-05,
      "loss": 0.0757,
      "step": 2280
    },
    {
      "epoch": 0.07010991029605364,
      "grad_norm": 0.017386440187692642,
      "learning_rate": 1.9532804702568657e-05,
      "loss": 0.0309,
      "step": 2290
    },
    {
      "epoch": 0.07041606710957353,
      "grad_norm": 0.06742369383573532,
      "learning_rate": 1.953076365714519e-05,
      "loss": 0.0065,
      "step": 2300
    },
    {
      "epoch": 0.07072222392309341,
      "grad_norm": 0.02464149333536625,
      "learning_rate": 1.9528722611721728e-05,
      "loss": 0.0163,
      "step": 2310
    },
    {
      "epoch": 0.0710283807366133,
      "grad_norm": 0.03722454234957695,
      "learning_rate": 1.952668156629826e-05,
      "loss": 0.0023,
      "step": 2320
    },
    {
      "epoch": 0.07133453755013318,
      "grad_norm": 2.1602373123168945,
      "learning_rate": 1.9524640520874795e-05,
      "loss": 0.0657,
      "step": 2330
    },
    {
      "epoch": 0.07164069436365306,
      "grad_norm": 0.042927857488393784,
      "learning_rate": 1.9522599475451325e-05,
      "loss": 0.0024,
      "step": 2340
    },
    {
      "epoch": 0.07194685117717295,
      "grad_norm": 0.034442681819200516,
      "learning_rate": 1.9520558430027862e-05,
      "loss": 0.0385,
      "step": 2350
    },
    {
      "epoch": 0.07225300799069283,
      "grad_norm": 0.00888397078961134,
      "learning_rate": 1.9518517384604396e-05,
      "loss": 0.0025,
      "step": 2360
    },
    {
      "epoch": 0.07255916480421272,
      "grad_norm": 0.07692990452051163,
      "learning_rate": 1.951647633918093e-05,
      "loss": 0.0019,
      "step": 2370
    },
    {
      "epoch": 0.0728653216177326,
      "grad_norm": 0.03797830641269684,
      "learning_rate": 1.9514435293757463e-05,
      "loss": 0.0205,
      "step": 2380
    },
    {
      "epoch": 0.07317147843125249,
      "grad_norm": 0.027464279904961586,
      "learning_rate": 1.9512394248334e-05,
      "loss": 0.0323,
      "step": 2390
    },
    {
      "epoch": 0.07347763524477237,
      "grad_norm": 0.025993237271904945,
      "learning_rate": 1.9510353202910534e-05,
      "loss": 0.0014,
      "step": 2400
    },
    {
      "epoch": 0.07378379205829226,
      "grad_norm": 0.014790171757340431,
      "learning_rate": 1.9508312157487064e-05,
      "loss": 0.0764,
      "step": 2410
    },
    {
      "epoch": 0.07408994887181214,
      "grad_norm": 0.03548157587647438,
      "learning_rate": 1.9506271112063598e-05,
      "loss": 0.0018,
      "step": 2420
    },
    {
      "epoch": 0.07439610568533203,
      "grad_norm": 0.07266993075609207,
      "learning_rate": 1.9504230066640135e-05,
      "loss": 0.0722,
      "step": 2430
    },
    {
      "epoch": 0.07470226249885191,
      "grad_norm": 0.07026302069425583,
      "learning_rate": 1.950218902121667e-05,
      "loss": 0.0279,
      "step": 2440
    },
    {
      "epoch": 0.0750084193123718,
      "grad_norm": 0.05054788663983345,
      "learning_rate": 1.9500147975793202e-05,
      "loss": 0.0049,
      "step": 2450
    },
    {
      "epoch": 0.07531457612589168,
      "grad_norm": 0.05976199358701706,
      "learning_rate": 1.949810693036974e-05,
      "loss": 0.0039,
      "step": 2460
    },
    {
      "epoch": 0.07562073293941157,
      "grad_norm": 0.05187717452645302,
      "learning_rate": 1.9496065884946273e-05,
      "loss": 0.0394,
      "step": 2470
    },
    {
      "epoch": 0.07592688975293145,
      "grad_norm": 0.029169833287596703,
      "learning_rate": 1.9494024839522807e-05,
      "loss": 0.0488,
      "step": 2480
    },
    {
      "epoch": 0.07623304656645134,
      "grad_norm": 0.16461455821990967,
      "learning_rate": 1.9491983794099337e-05,
      "loss": 0.0371,
      "step": 2490
    },
    {
      "epoch": 0.07653920337997122,
      "grad_norm": 0.08523259311914444,
      "learning_rate": 1.9489942748675874e-05,
      "loss": 0.0262,
      "step": 2500
    },
    {
      "epoch": 0.0768453601934911,
      "grad_norm": 0.043491777032613754,
      "learning_rate": 1.9487901703252407e-05,
      "loss": 0.0333,
      "step": 2510
    },
    {
      "epoch": 0.07715151700701099,
      "grad_norm": 0.049385424703359604,
      "learning_rate": 1.948586065782894e-05,
      "loss": 0.0528,
      "step": 2520
    },
    {
      "epoch": 0.07745767382053087,
      "grad_norm": 0.03599780425429344,
      "learning_rate": 1.9483819612405475e-05,
      "loss": 0.034,
      "step": 2530
    },
    {
      "epoch": 0.07776383063405076,
      "grad_norm": 0.033512845635414124,
      "learning_rate": 1.9481778566982012e-05,
      "loss": 0.0068,
      "step": 2540
    },
    {
      "epoch": 0.07806998744757064,
      "grad_norm": 0.028978697955608368,
      "learning_rate": 1.9479737521558545e-05,
      "loss": 0.037,
      "step": 2550
    },
    {
      "epoch": 0.07837614426109053,
      "grad_norm": 0.06601372361183167,
      "learning_rate": 1.9477696476135076e-05,
      "loss": 0.0129,
      "step": 2560
    },
    {
      "epoch": 0.07868230107461041,
      "grad_norm": 0.02949846349656582,
      "learning_rate": 1.9475655430711613e-05,
      "loss": 0.0023,
      "step": 2570
    },
    {
      "epoch": 0.0789884578881303,
      "grad_norm": 0.02798270992934704,
      "learning_rate": 1.9473614385288146e-05,
      "loss": 0.0018,
      "step": 2580
    },
    {
      "epoch": 0.07929461470165018,
      "grad_norm": 0.04100263491272926,
      "learning_rate": 1.947157333986468e-05,
      "loss": 0.089,
      "step": 2590
    },
    {
      "epoch": 0.07960077151517007,
      "grad_norm": 0.014078976586461067,
      "learning_rate": 1.9469532294441214e-05,
      "loss": 0.0464,
      "step": 2600
    },
    {
      "epoch": 0.07990692832868995,
      "grad_norm": 0.02636593021452427,
      "learning_rate": 1.946749124901775e-05,
      "loss": 0.0138,
      "step": 2610
    },
    {
      "epoch": 0.08021308514220984,
      "grad_norm": 0.05804256722331047,
      "learning_rate": 1.9465450203594284e-05,
      "loss": 0.0761,
      "step": 2620
    },
    {
      "epoch": 0.08051924195572972,
      "grad_norm": 0.03261030837893486,
      "learning_rate": 1.9463409158170815e-05,
      "loss": 0.0278,
      "step": 2630
    },
    {
      "epoch": 0.08082539876924962,
      "grad_norm": 0.2658296525478363,
      "learning_rate": 1.9461368112747348e-05,
      "loss": 0.0035,
      "step": 2640
    },
    {
      "epoch": 0.0811315555827695,
      "grad_norm": 0.07259374856948853,
      "learning_rate": 1.9459327067323885e-05,
      "loss": 0.0035,
      "step": 2650
    },
    {
      "epoch": 0.08143771239628939,
      "grad_norm": 0.0296124629676342,
      "learning_rate": 1.945728602190042e-05,
      "loss": 0.007,
      "step": 2660
    },
    {
      "epoch": 0.08174386920980926,
      "grad_norm": 0.0226160679012537,
      "learning_rate": 1.9455244976476953e-05,
      "loss": 0.0024,
      "step": 2670
    },
    {
      "epoch": 0.08205002602332914,
      "grad_norm": 2.1857664585113525,
      "learning_rate": 1.945320393105349e-05,
      "loss": 0.1192,
      "step": 2680
    },
    {
      "epoch": 0.08235618283684903,
      "grad_norm": 0.037349309772253036,
      "learning_rate": 1.9451162885630023e-05,
      "loss": 0.0028,
      "step": 2690
    },
    {
      "epoch": 0.08266233965036891,
      "grad_norm": 0.04313023388385773,
      "learning_rate": 1.9449121840206554e-05,
      "loss": 0.0214,
      "step": 2700
    },
    {
      "epoch": 0.0829684964638888,
      "grad_norm": 0.02017097920179367,
      "learning_rate": 1.9447080794783087e-05,
      "loss": 0.0022,
      "step": 2710
    },
    {
      "epoch": 0.08327465327740868,
      "grad_norm": 0.3614009618759155,
      "learning_rate": 1.9445039749359624e-05,
      "loss": 0.045,
      "step": 2720
    },
    {
      "epoch": 0.08358081009092858,
      "grad_norm": 0.02789418213069439,
      "learning_rate": 1.9442998703936158e-05,
      "loss": 0.0024,
      "step": 2730
    },
    {
      "epoch": 0.08388696690444845,
      "grad_norm": 0.034305233508348465,
      "learning_rate": 1.944095765851269e-05,
      "loss": 0.0236,
      "step": 2740
    },
    {
      "epoch": 0.08419312371796835,
      "grad_norm": 0.036661408841609955,
      "learning_rate": 1.9438916613089225e-05,
      "loss": 0.0413,
      "step": 2750
    },
    {
      "epoch": 0.08449928053148822,
      "grad_norm": 0.03528358414769173,
      "learning_rate": 1.9436875567665762e-05,
      "loss": 0.0124,
      "step": 2760
    },
    {
      "epoch": 0.08480543734500812,
      "grad_norm": 0.06597333401441574,
      "learning_rate": 1.9434834522242292e-05,
      "loss": 0.002,
      "step": 2770
    },
    {
      "epoch": 0.085111594158528,
      "grad_norm": 0.03685956075787544,
      "learning_rate": 1.9432793476818826e-05,
      "loss": 0.0292,
      "step": 2780
    },
    {
      "epoch": 0.08541775097204789,
      "grad_norm": 0.06608784198760986,
      "learning_rate": 1.9430752431395363e-05,
      "loss": 0.06,
      "step": 2790
    },
    {
      "epoch": 0.08572390778556777,
      "grad_norm": 0.03714873269200325,
      "learning_rate": 1.9428711385971897e-05,
      "loss": 0.0313,
      "step": 2800
    },
    {
      "epoch": 0.08603006459908766,
      "grad_norm": 0.04683186113834381,
      "learning_rate": 1.942667034054843e-05,
      "loss": 0.0023,
      "step": 2810
    },
    {
      "epoch": 0.08633622141260754,
      "grad_norm": 0.023166067898273468,
      "learning_rate": 1.9424629295124964e-05,
      "loss": 0.002,
      "step": 2820
    },
    {
      "epoch": 0.08664237822612743,
      "grad_norm": 0.07198893278837204,
      "learning_rate": 1.94225882497015e-05,
      "loss": 0.0123,
      "step": 2830
    },
    {
      "epoch": 0.0869485350396473,
      "grad_norm": 0.029795490205287933,
      "learning_rate": 1.942054720427803e-05,
      "loss": 0.0175,
      "step": 2840
    },
    {
      "epoch": 0.0872546918531672,
      "grad_norm": 0.4326009154319763,
      "learning_rate": 1.9418506158854565e-05,
      "loss": 0.0033,
      "step": 2850
    },
    {
      "epoch": 0.08756084866668708,
      "grad_norm": 0.03364157676696777,
      "learning_rate": 1.94164651134311e-05,
      "loss": 0.0016,
      "step": 2860
    },
    {
      "epoch": 0.08786700548020696,
      "grad_norm": 0.023973682895302773,
      "learning_rate": 1.9414424068007636e-05,
      "loss": 0.0393,
      "step": 2870
    },
    {
      "epoch": 0.08817316229372685,
      "grad_norm": 0.2145889401435852,
      "learning_rate": 1.941238302258417e-05,
      "loss": 0.0493,
      "step": 2880
    },
    {
      "epoch": 0.08847931910724673,
      "grad_norm": 0.06714137643575668,
      "learning_rate": 1.9410341977160703e-05,
      "loss": 0.0016,
      "step": 2890
    },
    {
      "epoch": 0.08878547592076662,
      "grad_norm": 0.08314927667379379,
      "learning_rate": 1.940830093173724e-05,
      "loss": 0.0019,
      "step": 2900
    },
    {
      "epoch": 0.0890916327342865,
      "grad_norm": 0.01583927869796753,
      "learning_rate": 1.940625988631377e-05,
      "loss": 0.0013,
      "step": 2910
    },
    {
      "epoch": 0.08939778954780639,
      "grad_norm": 0.0629771277308464,
      "learning_rate": 1.9404218840890304e-05,
      "loss": 0.0742,
      "step": 2920
    },
    {
      "epoch": 0.08970394636132627,
      "grad_norm": 2.5394983291625977,
      "learning_rate": 1.9402177795466837e-05,
      "loss": 0.0426,
      "step": 2930
    },
    {
      "epoch": 0.09001010317484616,
      "grad_norm": 0.017266497015953064,
      "learning_rate": 1.9400136750043375e-05,
      "loss": 0.0017,
      "step": 2940
    },
    {
      "epoch": 0.09031625998836604,
      "grad_norm": 1.9186532497406006,
      "learning_rate": 1.9398095704619908e-05,
      "loss": 0.0426,
      "step": 2950
    },
    {
      "epoch": 0.09062241680188593,
      "grad_norm": 0.026254259049892426,
      "learning_rate": 1.9396054659196442e-05,
      "loss": 0.0298,
      "step": 2960
    },
    {
      "epoch": 0.09092857361540581,
      "grad_norm": 0.015201645903289318,
      "learning_rate": 1.9394013613772975e-05,
      "loss": 0.038,
      "step": 2970
    },
    {
      "epoch": 0.0912347304289257,
      "grad_norm": 0.019683074206113815,
      "learning_rate": 1.9391972568349512e-05,
      "loss": 0.0035,
      "step": 2980
    },
    {
      "epoch": 0.09154088724244558,
      "grad_norm": 0.032325975596904755,
      "learning_rate": 1.9389931522926043e-05,
      "loss": 0.0014,
      "step": 2990
    },
    {
      "epoch": 0.09184704405596547,
      "grad_norm": 0.03277690336108208,
      "learning_rate": 1.9387890477502576e-05,
      "loss": 0.0019,
      "step": 3000
    },
    {
      "epoch": 0.09215320086948535,
      "grad_norm": 0.04077408090233803,
      "learning_rate": 1.9385849432079113e-05,
      "loss": 0.0406,
      "step": 3010
    },
    {
      "epoch": 0.09245935768300524,
      "grad_norm": 2.470364570617676,
      "learning_rate": 1.9383808386655647e-05,
      "loss": 0.0302,
      "step": 3020
    },
    {
      "epoch": 0.09276551449652512,
      "grad_norm": 0.046877145767211914,
      "learning_rate": 1.938176734123218e-05,
      "loss": 0.0015,
      "step": 3030
    },
    {
      "epoch": 0.093071671310045,
      "grad_norm": 0.03808177262544632,
      "learning_rate": 1.9379726295808714e-05,
      "loss": 0.0568,
      "step": 3040
    },
    {
      "epoch": 0.09337782812356489,
      "grad_norm": 0.02783725969493389,
      "learning_rate": 1.937768525038525e-05,
      "loss": 0.0295,
      "step": 3050
    },
    {
      "epoch": 0.09368398493708477,
      "grad_norm": 0.06141775846481323,
      "learning_rate": 1.937564420496178e-05,
      "loss": 0.0018,
      "step": 3060
    },
    {
      "epoch": 0.09399014175060466,
      "grad_norm": 0.3899517059326172,
      "learning_rate": 1.9373603159538315e-05,
      "loss": 0.003,
      "step": 3070
    },
    {
      "epoch": 0.09429629856412454,
      "grad_norm": 0.016005253419280052,
      "learning_rate": 1.937156211411485e-05,
      "loss": 0.0014,
      "step": 3080
    },
    {
      "epoch": 0.09460245537764443,
      "grad_norm": 0.03911297768354416,
      "learning_rate": 1.9369521068691386e-05,
      "loss": 0.075,
      "step": 3090
    },
    {
      "epoch": 0.09490861219116431,
      "grad_norm": 0.026740901172161102,
      "learning_rate": 1.936748002326792e-05,
      "loss": 0.0029,
      "step": 3100
    },
    {
      "epoch": 0.0952147690046842,
      "grad_norm": 0.03697754815220833,
      "learning_rate": 1.9365438977844453e-05,
      "loss": 0.0029,
      "step": 3110
    },
    {
      "epoch": 0.09552092581820408,
      "grad_norm": 0.045956119894981384,
      "learning_rate": 1.936339793242099e-05,
      "loss": 0.0018,
      "step": 3120
    },
    {
      "epoch": 0.09582708263172397,
      "grad_norm": 0.011529899202287197,
      "learning_rate": 1.936135688699752e-05,
      "loss": 0.0012,
      "step": 3130
    },
    {
      "epoch": 0.09613323944524385,
      "grad_norm": 0.017613045871257782,
      "learning_rate": 1.9359315841574054e-05,
      "loss": 0.0029,
      "step": 3140
    },
    {
      "epoch": 0.09643939625876374,
      "grad_norm": 0.026129120960831642,
      "learning_rate": 1.9357274796150588e-05,
      "loss": 0.0014,
      "step": 3150
    },
    {
      "epoch": 0.09674555307228362,
      "grad_norm": 0.02021288126707077,
      "learning_rate": 1.9355233750727125e-05,
      "loss": 0.0406,
      "step": 3160
    },
    {
      "epoch": 0.09705170988580351,
      "grad_norm": 0.029439855366945267,
      "learning_rate": 1.935319270530366e-05,
      "loss": 0.0014,
      "step": 3170
    },
    {
      "epoch": 0.09735786669932339,
      "grad_norm": 1.9291514158248901,
      "learning_rate": 1.9351151659880192e-05,
      "loss": 0.0374,
      "step": 3180
    },
    {
      "epoch": 0.09766402351284328,
      "grad_norm": 0.09324202686548233,
      "learning_rate": 1.9349110614456726e-05,
      "loss": 0.0473,
      "step": 3190
    },
    {
      "epoch": 0.09797018032636316,
      "grad_norm": 0.03199344128370285,
      "learning_rate": 1.934706956903326e-05,
      "loss": 0.0409,
      "step": 3200
    },
    {
      "epoch": 0.09827633713988305,
      "grad_norm": 0.13017752766609192,
      "learning_rate": 1.9345028523609793e-05,
      "loss": 0.0334,
      "step": 3210
    },
    {
      "epoch": 0.09858249395340293,
      "grad_norm": 0.0496969148516655,
      "learning_rate": 1.9342987478186327e-05,
      "loss": 0.0023,
      "step": 3220
    },
    {
      "epoch": 0.09888865076692281,
      "grad_norm": 0.04638974741101265,
      "learning_rate": 1.9340946432762864e-05,
      "loss": 0.0023,
      "step": 3230
    },
    {
      "epoch": 0.0991948075804427,
      "grad_norm": 0.5241334438323975,
      "learning_rate": 1.9338905387339397e-05,
      "loss": 0.0028,
      "step": 3240
    },
    {
      "epoch": 0.09950096439396258,
      "grad_norm": 0.019545525312423706,
      "learning_rate": 1.933686434191593e-05,
      "loss": 0.0378,
      "step": 3250
    },
    {
      "epoch": 0.09980712120748247,
      "grad_norm": 0.04015631228685379,
      "learning_rate": 1.9334823296492465e-05,
      "loss": 0.0016,
      "step": 3260
    },
    {
      "epoch": 0.10011327802100235,
      "grad_norm": 0.04943796247243881,
      "learning_rate": 1.9332782251069e-05,
      "loss": 0.0416,
      "step": 3270
    },
    {
      "epoch": 0.10041943483452224,
      "grad_norm": 0.07761599123477936,
      "learning_rate": 1.9330741205645532e-05,
      "loss": 0.019,
      "step": 3280
    },
    {
      "epoch": 0.10072559164804212,
      "grad_norm": 0.07115767151117325,
      "learning_rate": 1.9328700160222066e-05,
      "loss": 0.0079,
      "step": 3290
    },
    {
      "epoch": 0.10103174846156202,
      "grad_norm": 0.04768160730600357,
      "learning_rate": 1.93266591147986e-05,
      "loss": 0.0414,
      "step": 3300
    },
    {
      "epoch": 0.1013379052750819,
      "grad_norm": 1.7935137748718262,
      "learning_rate": 1.9324618069375136e-05,
      "loss": 0.0283,
      "step": 3310
    },
    {
      "epoch": 0.10164406208860179,
      "grad_norm": 0.0262307021766901,
      "learning_rate": 1.932257702395167e-05,
      "loss": 0.0033,
      "step": 3320
    },
    {
      "epoch": 0.10195021890212166,
      "grad_norm": 0.012636978179216385,
      "learning_rate": 1.9320535978528204e-05,
      "loss": 0.0665,
      "step": 3330
    },
    {
      "epoch": 0.10225637571564156,
      "grad_norm": 0.049117766320705414,
      "learning_rate": 1.9318494933104737e-05,
      "loss": 0.0293,
      "step": 3340
    },
    {
      "epoch": 0.10256253252916143,
      "grad_norm": 0.021465249359607697,
      "learning_rate": 1.931645388768127e-05,
      "loss": 0.1023,
      "step": 3350
    },
    {
      "epoch": 0.10286868934268133,
      "grad_norm": 0.1518334597349167,
      "learning_rate": 1.9314412842257805e-05,
      "loss": 0.0333,
      "step": 3360
    },
    {
      "epoch": 0.1031748461562012,
      "grad_norm": 0.06431401520967484,
      "learning_rate": 1.9312371796834338e-05,
      "loss": 0.0263,
      "step": 3370
    },
    {
      "epoch": 0.1034810029697211,
      "grad_norm": 0.3078431487083435,
      "learning_rate": 1.9310330751410875e-05,
      "loss": 0.0069,
      "step": 3380
    },
    {
      "epoch": 0.10378715978324098,
      "grad_norm": 0.09664568305015564,
      "learning_rate": 1.930828970598741e-05,
      "loss": 0.0317,
      "step": 3390
    },
    {
      "epoch": 0.10409331659676085,
      "grad_norm": 0.04732168838381767,
      "learning_rate": 1.9306248660563942e-05,
      "loss": 0.0033,
      "step": 3400
    },
    {
      "epoch": 0.10439947341028075,
      "grad_norm": 0.03634103760123253,
      "learning_rate": 1.9304207615140476e-05,
      "loss": 0.0051,
      "step": 3410
    },
    {
      "epoch": 0.10470563022380062,
      "grad_norm": 0.015817658975720406,
      "learning_rate": 1.930216656971701e-05,
      "loss": 0.0023,
      "step": 3420
    },
    {
      "epoch": 0.10501178703732052,
      "grad_norm": 0.024142682552337646,
      "learning_rate": 1.9300125524293543e-05,
      "loss": 0.0387,
      "step": 3430
    },
    {
      "epoch": 0.1053179438508404,
      "grad_norm": 0.014096264727413654,
      "learning_rate": 1.9298084478870077e-05,
      "loss": 0.0016,
      "step": 3440
    },
    {
      "epoch": 0.10562410066436029,
      "grad_norm": 0.0197993665933609,
      "learning_rate": 1.9296043433446614e-05,
      "loss": 0.0018,
      "step": 3450
    },
    {
      "epoch": 0.10593025747788017,
      "grad_norm": 0.024088725447654724,
      "learning_rate": 1.9294002388023148e-05,
      "loss": 0.0012,
      "step": 3460
    },
    {
      "epoch": 0.10623641429140006,
      "grad_norm": 0.08513765782117844,
      "learning_rate": 1.929196134259968e-05,
      "loss": 0.0012,
      "step": 3470
    },
    {
      "epoch": 0.10654257110491994,
      "grad_norm": 0.04064653813838959,
      "learning_rate": 1.9289920297176215e-05,
      "loss": 0.0023,
      "step": 3480
    },
    {
      "epoch": 0.10684872791843983,
      "grad_norm": 0.010172720067203045,
      "learning_rate": 1.928787925175275e-05,
      "loss": 0.0009,
      "step": 3490
    },
    {
      "epoch": 0.10715488473195971,
      "grad_norm": 0.015883108600974083,
      "learning_rate": 1.9285838206329282e-05,
      "loss": 0.0209,
      "step": 3500
    },
    {
      "epoch": 0.1074610415454796,
      "grad_norm": 0.011813269928097725,
      "learning_rate": 1.9283797160905816e-05,
      "loss": 0.001,
      "step": 3510
    },
    {
      "epoch": 0.10776719835899948,
      "grad_norm": 0.006919823121279478,
      "learning_rate": 1.928175611548235e-05,
      "loss": 0.0007,
      "step": 3520
    },
    {
      "epoch": 0.10807335517251937,
      "grad_norm": 0.011531500145792961,
      "learning_rate": 1.9279715070058887e-05,
      "loss": 0.0012,
      "step": 3530
    },
    {
      "epoch": 0.10837951198603925,
      "grad_norm": 0.01598931849002838,
      "learning_rate": 1.927767402463542e-05,
      "loss": 0.0008,
      "step": 3540
    },
    {
      "epoch": 0.10868566879955914,
      "grad_norm": 0.17043299973011017,
      "learning_rate": 1.9275632979211954e-05,
      "loss": 0.0012,
      "step": 3550
    },
    {
      "epoch": 0.10899182561307902,
      "grad_norm": 2.893181800842285,
      "learning_rate": 1.9273591933788488e-05,
      "loss": 0.0321,
      "step": 3560
    },
    {
      "epoch": 0.10929798242659891,
      "grad_norm": 0.0076902820728719234,
      "learning_rate": 1.927155088836502e-05,
      "loss": 0.0018,
      "step": 3570
    },
    {
      "epoch": 0.10960413924011879,
      "grad_norm": 0.017700552940368652,
      "learning_rate": 1.9269509842941555e-05,
      "loss": 0.045,
      "step": 3580
    },
    {
      "epoch": 0.10991029605363867,
      "grad_norm": 0.010619825683534145,
      "learning_rate": 1.926746879751809e-05,
      "loss": 0.0008,
      "step": 3590
    },
    {
      "epoch": 0.11021645286715856,
      "grad_norm": 0.012145407497882843,
      "learning_rate": 1.9265427752094626e-05,
      "loss": 0.0014,
      "step": 3600
    },
    {
      "epoch": 0.11052260968067844,
      "grad_norm": 0.01474121306091547,
      "learning_rate": 1.926338670667116e-05,
      "loss": 0.0447,
      "step": 3610
    },
    {
      "epoch": 0.11082876649419833,
      "grad_norm": 0.02121051959693432,
      "learning_rate": 1.9261345661247693e-05,
      "loss": 0.0008,
      "step": 3620
    },
    {
      "epoch": 0.11113492330771821,
      "grad_norm": 2.6930458545684814,
      "learning_rate": 1.9259304615824226e-05,
      "loss": 0.0443,
      "step": 3630
    },
    {
      "epoch": 0.1114410801212381,
      "grad_norm": 0.02106969803571701,
      "learning_rate": 1.925726357040076e-05,
      "loss": 0.0007,
      "step": 3640
    },
    {
      "epoch": 0.11174723693475798,
      "grad_norm": 0.013241751119494438,
      "learning_rate": 1.9255222524977294e-05,
      "loss": 0.001,
      "step": 3650
    },
    {
      "epoch": 0.11205339374827787,
      "grad_norm": 0.01731834001839161,
      "learning_rate": 1.9253181479553827e-05,
      "loss": 0.0048,
      "step": 3660
    },
    {
      "epoch": 0.11235955056179775,
      "grad_norm": 0.009209496900439262,
      "learning_rate": 1.925114043413036e-05,
      "loss": 0.002,
      "step": 3670
    },
    {
      "epoch": 0.11266570737531764,
      "grad_norm": 0.06493919342756271,
      "learning_rate": 1.9249099388706898e-05,
      "loss": 0.0009,
      "step": 3680
    },
    {
      "epoch": 0.11297186418883752,
      "grad_norm": 0.01730375736951828,
      "learning_rate": 1.9247058343283432e-05,
      "loss": 0.0495,
      "step": 3690
    },
    {
      "epoch": 0.11327802100235741,
      "grad_norm": 0.013678450137376785,
      "learning_rate": 1.9245017297859965e-05,
      "loss": 0.0022,
      "step": 3700
    },
    {
      "epoch": 0.11358417781587729,
      "grad_norm": 2.502418279647827,
      "learning_rate": 1.92429762524365e-05,
      "loss": 0.0113,
      "step": 3710
    },
    {
      "epoch": 0.11389033462939718,
      "grad_norm": 0.016498969867825508,
      "learning_rate": 1.9240935207013033e-05,
      "loss": 0.0007,
      "step": 3720
    },
    {
      "epoch": 0.11419649144291706,
      "grad_norm": 0.01013309508562088,
      "learning_rate": 1.9238894161589566e-05,
      "loss": 0.0061,
      "step": 3730
    },
    {
      "epoch": 0.11450264825643695,
      "grad_norm": 0.03845459595322609,
      "learning_rate": 1.92368531161661e-05,
      "loss": 0.0011,
      "step": 3740
    },
    {
      "epoch": 0.11480880506995683,
      "grad_norm": 0.0072001139633357525,
      "learning_rate": 1.9234812070742637e-05,
      "loss": 0.0007,
      "step": 3750
    },
    {
      "epoch": 0.11511496188347671,
      "grad_norm": 0.03745834901928902,
      "learning_rate": 1.923277102531917e-05,
      "loss": 0.0253,
      "step": 3760
    },
    {
      "epoch": 0.1154211186969966,
      "grad_norm": 0.01457346510142088,
      "learning_rate": 1.9230729979895704e-05,
      "loss": 0.0006,
      "step": 3770
    },
    {
      "epoch": 0.11572727551051648,
      "grad_norm": 0.024991199374198914,
      "learning_rate": 1.9228688934472238e-05,
      "loss": 0.1125,
      "step": 3780
    },
    {
      "epoch": 0.11603343232403637,
      "grad_norm": 0.011882920749485493,
      "learning_rate": 1.922664788904877e-05,
      "loss": 0.0054,
      "step": 3790
    },
    {
      "epoch": 0.11633958913755625,
      "grad_norm": 0.022139742970466614,
      "learning_rate": 1.9224606843625305e-05,
      "loss": 0.0514,
      "step": 3800
    },
    {
      "epoch": 0.11664574595107614,
      "grad_norm": 0.026598894968628883,
      "learning_rate": 1.922256579820184e-05,
      "loss": 0.0039,
      "step": 3810
    },
    {
      "epoch": 0.11695190276459602,
      "grad_norm": 0.16169987618923187,
      "learning_rate": 1.9220524752778376e-05,
      "loss": 0.0013,
      "step": 3820
    },
    {
      "epoch": 0.11725805957811591,
      "grad_norm": 1.7263715267181396,
      "learning_rate": 1.921848370735491e-05,
      "loss": 0.0055,
      "step": 3830
    },
    {
      "epoch": 0.11756421639163579,
      "grad_norm": 0.008367812260985374,
      "learning_rate": 1.9216442661931443e-05,
      "loss": 0.0014,
      "step": 3840
    },
    {
      "epoch": 0.11787037320515568,
      "grad_norm": 0.015180612914264202,
      "learning_rate": 1.9214401616507977e-05,
      "loss": 0.0009,
      "step": 3850
    },
    {
      "epoch": 0.11817653001867556,
      "grad_norm": 0.021907223388552666,
      "learning_rate": 1.921236057108451e-05,
      "loss": 0.0438,
      "step": 3860
    },
    {
      "epoch": 0.11848268683219546,
      "grad_norm": 1.6337134838104248,
      "learning_rate": 1.9210319525661044e-05,
      "loss": 0.0052,
      "step": 3870
    },
    {
      "epoch": 0.11878884364571533,
      "grad_norm": 0.010945292189717293,
      "learning_rate": 1.9208278480237578e-05,
      "loss": 0.0018,
      "step": 3880
    },
    {
      "epoch": 0.11909500045923523,
      "grad_norm": 0.3670174777507782,
      "learning_rate": 1.920623743481411e-05,
      "loss": 0.0637,
      "step": 3890
    },
    {
      "epoch": 0.1194011572727551,
      "grad_norm": 0.009031219407916069,
      "learning_rate": 1.920419638939065e-05,
      "loss": 0.0388,
      "step": 3900
    },
    {
      "epoch": 0.119707314086275,
      "grad_norm": 0.0131283113732934,
      "learning_rate": 1.9202155343967182e-05,
      "loss": 0.0015,
      "step": 3910
    },
    {
      "epoch": 0.12001347089979487,
      "grad_norm": 1.8808602094650269,
      "learning_rate": 1.9200114298543716e-05,
      "loss": 0.0341,
      "step": 3920
    },
    {
      "epoch": 0.12031962771331475,
      "grad_norm": 0.0250078272074461,
      "learning_rate": 1.919807325312025e-05,
      "loss": 0.0205,
      "step": 3930
    },
    {
      "epoch": 0.12062578452683465,
      "grad_norm": 0.17076759040355682,
      "learning_rate": 1.9196032207696783e-05,
      "loss": 0.0013,
      "step": 3940
    },
    {
      "epoch": 0.12093194134035452,
      "grad_norm": 0.0279097780585289,
      "learning_rate": 1.9193991162273317e-05,
      "loss": 0.0188,
      "step": 3950
    },
    {
      "epoch": 0.12123809815387442,
      "grad_norm": 0.014465012587606907,
      "learning_rate": 1.919195011684985e-05,
      "loss": 0.0013,
      "step": 3960
    },
    {
      "epoch": 0.1215442549673943,
      "grad_norm": 0.033774420619010925,
      "learning_rate": 1.9189909071426387e-05,
      "loss": 0.0024,
      "step": 3970
    },
    {
      "epoch": 0.12185041178091419,
      "grad_norm": 0.012990061193704605,
      "learning_rate": 1.918786802600292e-05,
      "loss": 0.0027,
      "step": 3980
    },
    {
      "epoch": 0.12215656859443406,
      "grad_norm": 1.136115550994873,
      "learning_rate": 1.9185826980579455e-05,
      "loss": 0.0068,
      "step": 3990
    },
    {
      "epoch": 0.12246272540795396,
      "grad_norm": 1.9209346771240234,
      "learning_rate": 1.9183785935155988e-05,
      "loss": 0.0442,
      "step": 4000
    },
    {
      "epoch": 0.12276888222147384,
      "grad_norm": 0.014627309516072273,
      "learning_rate": 1.9181744889732522e-05,
      "loss": 0.0013,
      "step": 4010
    },
    {
      "epoch": 0.12307503903499373,
      "grad_norm": 1.980027437210083,
      "learning_rate": 1.9179703844309056e-05,
      "loss": 0.0551,
      "step": 4020
    },
    {
      "epoch": 0.1233811958485136,
      "grad_norm": 0.08382782340049744,
      "learning_rate": 1.917766279888559e-05,
      "loss": 0.0018,
      "step": 4030
    },
    {
      "epoch": 0.1236873526620335,
      "grad_norm": 0.022669661790132523,
      "learning_rate": 1.9175621753462126e-05,
      "loss": 0.0014,
      "step": 4040
    },
    {
      "epoch": 0.12399350947555338,
      "grad_norm": 1.8608160018920898,
      "learning_rate": 1.917358070803866e-05,
      "loss": 0.0716,
      "step": 4050
    },
    {
      "epoch": 0.12429966628907327,
      "grad_norm": 0.08441630005836487,
      "learning_rate": 1.9171539662615194e-05,
      "loss": 0.0019,
      "step": 4060
    },
    {
      "epoch": 0.12460582310259315,
      "grad_norm": 0.01505955494940281,
      "learning_rate": 1.9169498617191727e-05,
      "loss": 0.0316,
      "step": 4070
    },
    {
      "epoch": 0.12491197991611304,
      "grad_norm": 0.267500638961792,
      "learning_rate": 1.916745757176826e-05,
      "loss": 0.0021,
      "step": 4080
    },
    {
      "epoch": 0.12521813672963292,
      "grad_norm": 0.00947416853159666,
      "learning_rate": 1.9165416526344794e-05,
      "loss": 0.0017,
      "step": 4090
    },
    {
      "epoch": 0.1255242935431528,
      "grad_norm": 0.020076803863048553,
      "learning_rate": 1.9163375480921328e-05,
      "loss": 0.0811,
      "step": 4100
    },
    {
      "epoch": 0.12583045035667267,
      "grad_norm": 0.02571515366435051,
      "learning_rate": 1.9161334435497862e-05,
      "loss": 0.0018,
      "step": 4110
    },
    {
      "epoch": 0.12613660717019257,
      "grad_norm": 0.014040068723261356,
      "learning_rate": 1.91592933900744e-05,
      "loss": 0.0706,
      "step": 4120
    },
    {
      "epoch": 0.12644276398371246,
      "grad_norm": 0.022016616538167,
      "learning_rate": 1.9157252344650932e-05,
      "loss": 0.0031,
      "step": 4130
    },
    {
      "epoch": 0.12674892079723235,
      "grad_norm": 0.03422234579920769,
      "learning_rate": 1.9155211299227466e-05,
      "loss": 0.0017,
      "step": 4140
    },
    {
      "epoch": 0.12705507761075222,
      "grad_norm": 0.021167200058698654,
      "learning_rate": 1.9153170253804e-05,
      "loss": 0.0262,
      "step": 4150
    },
    {
      "epoch": 0.1273612344242721,
      "grad_norm": 0.015346840023994446,
      "learning_rate": 1.9151129208380533e-05,
      "loss": 0.0014,
      "step": 4160
    },
    {
      "epoch": 0.127667391237792,
      "grad_norm": 0.04340361803770065,
      "learning_rate": 1.9149088162957067e-05,
      "loss": 0.0457,
      "step": 4170
    },
    {
      "epoch": 0.1279735480513119,
      "grad_norm": 0.014781034551560879,
      "learning_rate": 1.91470471175336e-05,
      "loss": 0.0017,
      "step": 4180
    },
    {
      "epoch": 0.12827970486483176,
      "grad_norm": 0.03162868320941925,
      "learning_rate": 1.9145006072110138e-05,
      "loss": 0.0012,
      "step": 4190
    },
    {
      "epoch": 0.12858586167835165,
      "grad_norm": 0.023521175608038902,
      "learning_rate": 1.914296502668667e-05,
      "loss": 0.0663,
      "step": 4200
    },
    {
      "epoch": 0.12889201849187154,
      "grad_norm": 0.0483454130589962,
      "learning_rate": 1.9140923981263205e-05,
      "loss": 0.0016,
      "step": 4210
    },
    {
      "epoch": 0.12919817530539143,
      "grad_norm": 0.014021907933056355,
      "learning_rate": 1.913888293583974e-05,
      "loss": 0.0754,
      "step": 4220
    },
    {
      "epoch": 0.1295043321189113,
      "grad_norm": 0.04294809699058533,
      "learning_rate": 1.9136841890416272e-05,
      "loss": 0.0013,
      "step": 4230
    },
    {
      "epoch": 0.1298104889324312,
      "grad_norm": 0.021183544769883156,
      "learning_rate": 1.9134800844992806e-05,
      "loss": 0.0315,
      "step": 4240
    },
    {
      "epoch": 0.13011664574595108,
      "grad_norm": 0.03988204523921013,
      "learning_rate": 1.913275979956934e-05,
      "loss": 0.0488,
      "step": 4250
    },
    {
      "epoch": 0.13042280255947097,
      "grad_norm": 0.04548485949635506,
      "learning_rate": 1.9130718754145877e-05,
      "loss": 0.0276,
      "step": 4260
    },
    {
      "epoch": 0.13072895937299084,
      "grad_norm": 0.0345330536365509,
      "learning_rate": 1.912867770872241e-05,
      "loss": 0.0021,
      "step": 4270
    },
    {
      "epoch": 0.13103511618651073,
      "grad_norm": 0.31821209192276,
      "learning_rate": 1.9126636663298944e-05,
      "loss": 0.0414,
      "step": 4280
    },
    {
      "epoch": 0.13134127300003062,
      "grad_norm": 0.041313059628009796,
      "learning_rate": 1.9124595617875477e-05,
      "loss": 0.0282,
      "step": 4290
    },
    {
      "epoch": 0.1316474298135505,
      "grad_norm": 0.038131967186927795,
      "learning_rate": 1.912255457245201e-05,
      "loss": 0.0022,
      "step": 4300
    },
    {
      "epoch": 0.13195358662707038,
      "grad_norm": 0.035894766449928284,
      "learning_rate": 1.9120513527028545e-05,
      "loss": 0.0019,
      "step": 4310
    },
    {
      "epoch": 0.13225974344059027,
      "grad_norm": 0.08845444023609161,
      "learning_rate": 1.911847248160508e-05,
      "loss": 0.0018,
      "step": 4320
    },
    {
      "epoch": 0.13256590025411016,
      "grad_norm": 0.02563236653804779,
      "learning_rate": 1.9116431436181612e-05,
      "loss": 0.0046,
      "step": 4330
    },
    {
      "epoch": 0.13287205706763003,
      "grad_norm": 0.022687381133437157,
      "learning_rate": 1.911439039075815e-05,
      "loss": 0.0111,
      "step": 4340
    },
    {
      "epoch": 0.13317821388114992,
      "grad_norm": 0.013648474588990211,
      "learning_rate": 1.9112349345334683e-05,
      "loss": 0.0472,
      "step": 4350
    },
    {
      "epoch": 0.1334843706946698,
      "grad_norm": 0.03321778401732445,
      "learning_rate": 1.9110308299911216e-05,
      "loss": 0.034,
      "step": 4360
    },
    {
      "epoch": 0.1337905275081897,
      "grad_norm": 0.007883496582508087,
      "learning_rate": 1.910826725448775e-05,
      "loss": 0.0016,
      "step": 4370
    },
    {
      "epoch": 0.13409668432170957,
      "grad_norm": 0.0263653676956892,
      "learning_rate": 1.9106226209064284e-05,
      "loss": 0.0054,
      "step": 4380
    },
    {
      "epoch": 0.13440284113522946,
      "grad_norm": 0.01770882122218609,
      "learning_rate": 1.9104185163640817e-05,
      "loss": 0.0016,
      "step": 4390
    },
    {
      "epoch": 0.13470899794874935,
      "grad_norm": 2.6236088275909424,
      "learning_rate": 1.910214411821735e-05,
      "loss": 0.026,
      "step": 4400
    },
    {
      "epoch": 0.13501515476226925,
      "grad_norm": 0.052111756056547165,
      "learning_rate": 1.9100103072793888e-05,
      "loss": 0.0375,
      "step": 4410
    },
    {
      "epoch": 0.1353213115757891,
      "grad_norm": 0.02992982231080532,
      "learning_rate": 1.909806202737042e-05,
      "loss": 0.0016,
      "step": 4420
    },
    {
      "epoch": 0.135627468389309,
      "grad_norm": 0.013829671777784824,
      "learning_rate": 1.9096020981946955e-05,
      "loss": 0.0244,
      "step": 4430
    },
    {
      "epoch": 0.1359336252028289,
      "grad_norm": 0.025794742628932,
      "learning_rate": 1.909397993652349e-05,
      "loss": 0.0013,
      "step": 4440
    },
    {
      "epoch": 0.1362397820163488,
      "grad_norm": 0.11069045960903168,
      "learning_rate": 1.9091938891100023e-05,
      "loss": 0.0015,
      "step": 4450
    },
    {
      "epoch": 0.13654593882986865,
      "grad_norm": 0.09818360209465027,
      "learning_rate": 1.9089897845676556e-05,
      "loss": 0.0035,
      "step": 4460
    },
    {
      "epoch": 0.13685209564338854,
      "grad_norm": 0.020777324214577675,
      "learning_rate": 1.908785680025309e-05,
      "loss": 0.0183,
      "step": 4470
    },
    {
      "epoch": 0.13715825245690844,
      "grad_norm": 0.007057108450680971,
      "learning_rate": 1.9085815754829627e-05,
      "loss": 0.0013,
      "step": 4480
    },
    {
      "epoch": 0.1374644092704283,
      "grad_norm": 0.013372950255870819,
      "learning_rate": 1.908377470940616e-05,
      "loss": 0.0415,
      "step": 4490
    },
    {
      "epoch": 0.1377705660839482,
      "grad_norm": 0.014728088863193989,
      "learning_rate": 1.9081733663982694e-05,
      "loss": 0.0208,
      "step": 4500
    },
    {
      "epoch": 0.13807672289746808,
      "grad_norm": 0.13458062708377838,
      "learning_rate": 1.9079692618559228e-05,
      "loss": 0.0029,
      "step": 4510
    },
    {
      "epoch": 0.13838287971098798,
      "grad_norm": 0.005414801184087992,
      "learning_rate": 1.907765157313576e-05,
      "loss": 0.0462,
      "step": 4520
    },
    {
      "epoch": 0.13868903652450784,
      "grad_norm": 0.0206400528550148,
      "learning_rate": 1.9075610527712295e-05,
      "loss": 0.0013,
      "step": 4530
    },
    {
      "epoch": 0.13899519333802773,
      "grad_norm": 0.01870591565966606,
      "learning_rate": 1.907356948228883e-05,
      "loss": 0.0013,
      "step": 4540
    },
    {
      "epoch": 0.13930135015154763,
      "grad_norm": 0.022449353709816933,
      "learning_rate": 1.9071528436865362e-05,
      "loss": 0.0218,
      "step": 4550
    },
    {
      "epoch": 0.13960750696506752,
      "grad_norm": 0.01793011836707592,
      "learning_rate": 1.90694873914419e-05,
      "loss": 0.0371,
      "step": 4560
    },
    {
      "epoch": 0.13991366377858738,
      "grad_norm": 0.016085583716630936,
      "learning_rate": 1.9067446346018433e-05,
      "loss": 0.0393,
      "step": 4570
    },
    {
      "epoch": 0.14021982059210727,
      "grad_norm": 0.03480951860547066,
      "learning_rate": 1.9065405300594967e-05,
      "loss": 0.0054,
      "step": 4580
    },
    {
      "epoch": 0.14052597740562717,
      "grad_norm": 0.05890097841620445,
      "learning_rate": 1.90633642551715e-05,
      "loss": 0.002,
      "step": 4590
    },
    {
      "epoch": 0.14083213421914706,
      "grad_norm": 0.017729686573147774,
      "learning_rate": 1.9061323209748034e-05,
      "loss": 0.0013,
      "step": 4600
    },
    {
      "epoch": 0.14113829103266692,
      "grad_norm": 0.06542191654443741,
      "learning_rate": 1.9059282164324568e-05,
      "loss": 0.0012,
      "step": 4610
    },
    {
      "epoch": 0.14144444784618682,
      "grad_norm": 0.03890085965394974,
      "learning_rate": 1.90572411189011e-05,
      "loss": 0.0402,
      "step": 4620
    },
    {
      "epoch": 0.1417506046597067,
      "grad_norm": 0.03893327713012695,
      "learning_rate": 1.905520007347764e-05,
      "loss": 0.0368,
      "step": 4630
    },
    {
      "epoch": 0.1420567614732266,
      "grad_norm": 0.03112918511033058,
      "learning_rate": 1.9053159028054172e-05,
      "loss": 0.0178,
      "step": 4640
    },
    {
      "epoch": 0.14236291828674646,
      "grad_norm": 0.03517039865255356,
      "learning_rate": 1.9051117982630706e-05,
      "loss": 0.0529,
      "step": 4650
    },
    {
      "epoch": 0.14266907510026636,
      "grad_norm": 1.9643657207489014,
      "learning_rate": 1.904907693720724e-05,
      "loss": 0.0771,
      "step": 4660
    },
    {
      "epoch": 0.14297523191378625,
      "grad_norm": 0.07387746870517731,
      "learning_rate": 1.9047035891783773e-05,
      "loss": 0.0024,
      "step": 4670
    },
    {
      "epoch": 0.1432813887273061,
      "grad_norm": 0.047524429857730865,
      "learning_rate": 1.9044994846360307e-05,
      "loss": 0.0151,
      "step": 4680
    },
    {
      "epoch": 0.143587545540826,
      "grad_norm": 0.02896254137158394,
      "learning_rate": 1.904295380093684e-05,
      "loss": 0.0053,
      "step": 4690
    },
    {
      "epoch": 0.1438937023543459,
      "grad_norm": 0.029207007959485054,
      "learning_rate": 1.9040912755513377e-05,
      "loss": 0.0018,
      "step": 4700
    },
    {
      "epoch": 0.1441998591678658,
      "grad_norm": 0.04941345006227493,
      "learning_rate": 1.903887171008991e-05,
      "loss": 0.0015,
      "step": 4710
    },
    {
      "epoch": 0.14450601598138565,
      "grad_norm": 0.028586825355887413,
      "learning_rate": 1.9036830664666445e-05,
      "loss": 0.0019,
      "step": 4720
    },
    {
      "epoch": 0.14481217279490555,
      "grad_norm": 0.045165594667196274,
      "learning_rate": 1.9034789619242978e-05,
      "loss": 0.0038,
      "step": 4730
    },
    {
      "epoch": 0.14511832960842544,
      "grad_norm": 0.015917742624878883,
      "learning_rate": 1.9032748573819512e-05,
      "loss": 0.0459,
      "step": 4740
    },
    {
      "epoch": 0.14542448642194533,
      "grad_norm": 0.021839642897248268,
      "learning_rate": 1.9030707528396045e-05,
      "loss": 0.0013,
      "step": 4750
    },
    {
      "epoch": 0.1457306432354652,
      "grad_norm": 0.0368155911564827,
      "learning_rate": 1.902866648297258e-05,
      "loss": 0.0177,
      "step": 4760
    },
    {
      "epoch": 0.1460368000489851,
      "grad_norm": 0.020475510507822037,
      "learning_rate": 1.9026625437549113e-05,
      "loss": 0.0794,
      "step": 4770
    },
    {
      "epoch": 0.14634295686250498,
      "grad_norm": 0.03183145448565483,
      "learning_rate": 1.902458439212565e-05,
      "loss": 0.0419,
      "step": 4780
    },
    {
      "epoch": 0.14664911367602487,
      "grad_norm": 0.03974402695894241,
      "learning_rate": 1.9022543346702183e-05,
      "loss": 0.0172,
      "step": 4790
    },
    {
      "epoch": 0.14695527048954474,
      "grad_norm": 0.04947920888662338,
      "learning_rate": 1.9020502301278717e-05,
      "loss": 0.0291,
      "step": 4800
    },
    {
      "epoch": 0.14726142730306463,
      "grad_norm": 0.02675933577120304,
      "learning_rate": 1.901846125585525e-05,
      "loss": 0.0026,
      "step": 4810
    },
    {
      "epoch": 0.14756758411658452,
      "grad_norm": 0.1974976807832718,
      "learning_rate": 1.9016420210431784e-05,
      "loss": 0.0023,
      "step": 4820
    },
    {
      "epoch": 0.14787374093010439,
      "grad_norm": 0.04347475990653038,
      "learning_rate": 1.9014379165008318e-05,
      "loss": 0.0015,
      "step": 4830
    },
    {
      "epoch": 0.14817989774362428,
      "grad_norm": 0.021855071187019348,
      "learning_rate": 1.901233811958485e-05,
      "loss": 0.0019,
      "step": 4840
    },
    {
      "epoch": 0.14848605455714417,
      "grad_norm": 1.9220905303955078,
      "learning_rate": 1.901029707416139e-05,
      "loss": 0.0433,
      "step": 4850
    },
    {
      "epoch": 0.14879221137066406,
      "grad_norm": 1.1020408868789673,
      "learning_rate": 1.9008256028737922e-05,
      "loss": 0.0819,
      "step": 4860
    },
    {
      "epoch": 0.14909836818418393,
      "grad_norm": 0.018557371571660042,
      "learning_rate": 1.9006214983314456e-05,
      "loss": 0.0318,
      "step": 4870
    },
    {
      "epoch": 0.14940452499770382,
      "grad_norm": 0.08081702142953873,
      "learning_rate": 1.900417393789099e-05,
      "loss": 0.0356,
      "step": 4880
    },
    {
      "epoch": 0.1497106818112237,
      "grad_norm": 0.10665816068649292,
      "learning_rate": 1.9002132892467523e-05,
      "loss": 0.0045,
      "step": 4890
    },
    {
      "epoch": 0.1500168386247436,
      "grad_norm": 0.03387590870261192,
      "learning_rate": 1.9000091847044057e-05,
      "loss": 0.0721,
      "step": 4900
    },
    {
      "epoch": 0.15032299543826347,
      "grad_norm": 0.09573212265968323,
      "learning_rate": 1.899805080162059e-05,
      "loss": 0.0035,
      "step": 4910
    },
    {
      "epoch": 0.15062915225178336,
      "grad_norm": 1.2251561880111694,
      "learning_rate": 1.8996009756197124e-05,
      "loss": 0.0299,
      "step": 4920
    },
    {
      "epoch": 0.15093530906530325,
      "grad_norm": 0.043268412351608276,
      "learning_rate": 1.899396871077366e-05,
      "loss": 0.0024,
      "step": 4930
    },
    {
      "epoch": 0.15124146587882314,
      "grad_norm": 0.029315216466784477,
      "learning_rate": 1.8991927665350195e-05,
      "loss": 0.0645,
      "step": 4940
    },
    {
      "epoch": 0.151547622692343,
      "grad_norm": 0.02133418619632721,
      "learning_rate": 1.898988661992673e-05,
      "loss": 0.0073,
      "step": 4950
    },
    {
      "epoch": 0.1518537795058629,
      "grad_norm": 0.015830835327506065,
      "learning_rate": 1.8987845574503262e-05,
      "loss": 0.0035,
      "step": 4960
    },
    {
      "epoch": 0.1521599363193828,
      "grad_norm": 0.048116911202669144,
      "learning_rate": 1.8985804529079796e-05,
      "loss": 0.0024,
      "step": 4970
    },
    {
      "epoch": 0.15246609313290269,
      "grad_norm": 0.05672036483883858,
      "learning_rate": 1.898376348365633e-05,
      "loss": 0.0931,
      "step": 4980
    },
    {
      "epoch": 0.15277224994642255,
      "grad_norm": 0.07808572053909302,
      "learning_rate": 1.8981722438232863e-05,
      "loss": 0.0031,
      "step": 4990
    },
    {
      "epoch": 0.15307840675994244,
      "grad_norm": 0.12932413816452026,
      "learning_rate": 1.89796813928094e-05,
      "loss": 0.0032,
      "step": 5000
    },
    {
      "epoch": 0.15338456357346233,
      "grad_norm": 0.11760911345481873,
      "learning_rate": 1.8977640347385934e-05,
      "loss": 0.003,
      "step": 5010
    },
    {
      "epoch": 0.1536907203869822,
      "grad_norm": 0.03739708289504051,
      "learning_rate": 1.8975599301962467e-05,
      "loss": 0.0027,
      "step": 5020
    },
    {
      "epoch": 0.1539968772005021,
      "grad_norm": 0.054987870156764984,
      "learning_rate": 1.8973558256539e-05,
      "loss": 0.0642,
      "step": 5030
    },
    {
      "epoch": 0.15430303401402198,
      "grad_norm": 0.036914579570293427,
      "learning_rate": 1.8971517211115535e-05,
      "loss": 0.0134,
      "step": 5040
    },
    {
      "epoch": 0.15460919082754188,
      "grad_norm": 0.044105421751737595,
      "learning_rate": 1.896947616569207e-05,
      "loss": 0.0028,
      "step": 5050
    },
    {
      "epoch": 0.15491534764106174,
      "grad_norm": 0.04453005641698837,
      "learning_rate": 1.8967435120268602e-05,
      "loss": 0.0026,
      "step": 5060
    },
    {
      "epoch": 0.15522150445458163,
      "grad_norm": 0.041740234941244125,
      "learning_rate": 1.896539407484514e-05,
      "loss": 0.0042,
      "step": 5070
    },
    {
      "epoch": 0.15552766126810152,
      "grad_norm": 0.03557770326733589,
      "learning_rate": 1.8963353029421673e-05,
      "loss": 0.0374,
      "step": 5080
    },
    {
      "epoch": 0.15583381808162142,
      "grad_norm": 0.06018274649977684,
      "learning_rate": 1.8961311983998206e-05,
      "loss": 0.0596,
      "step": 5090
    },
    {
      "epoch": 0.15613997489514128,
      "grad_norm": 0.0068565355613827705,
      "learning_rate": 1.895927093857474e-05,
      "loss": 0.0118,
      "step": 5100
    },
    {
      "epoch": 0.15644613170866117,
      "grad_norm": 0.05953652784228325,
      "learning_rate": 1.8957229893151274e-05,
      "loss": 0.0043,
      "step": 5110
    },
    {
      "epoch": 0.15675228852218107,
      "grad_norm": 0.05492262914776802,
      "learning_rate": 1.8955188847727807e-05,
      "loss": 0.0026,
      "step": 5120
    },
    {
      "epoch": 0.15705844533570096,
      "grad_norm": 0.027350254356861115,
      "learning_rate": 1.895314780230434e-05,
      "loss": 0.002,
      "step": 5130
    },
    {
      "epoch": 0.15736460214922082,
      "grad_norm": 0.3922604024410248,
      "learning_rate": 1.8951106756880875e-05,
      "loss": 0.0046,
      "step": 5140
    },
    {
      "epoch": 0.15767075896274071,
      "grad_norm": 0.023469548672437668,
      "learning_rate": 1.894906571145741e-05,
      "loss": 0.0813,
      "step": 5150
    },
    {
      "epoch": 0.1579769157762606,
      "grad_norm": 0.044744864106178284,
      "learning_rate": 1.8947024666033945e-05,
      "loss": 0.0378,
      "step": 5160
    },
    {
      "epoch": 0.1582830725897805,
      "grad_norm": 0.022526709362864494,
      "learning_rate": 1.894498362061048e-05,
      "loss": 0.0018,
      "step": 5170
    },
    {
      "epoch": 0.15858922940330036,
      "grad_norm": 0.09258610755205154,
      "learning_rate": 1.8942942575187012e-05,
      "loss": 0.0024,
      "step": 5180
    },
    {
      "epoch": 0.15889538621682026,
      "grad_norm": 0.02874869480729103,
      "learning_rate": 1.8940901529763546e-05,
      "loss": 0.0021,
      "step": 5190
    },
    {
      "epoch": 0.15920154303034015,
      "grad_norm": 0.012268481776118279,
      "learning_rate": 1.893886048434008e-05,
      "loss": 0.0015,
      "step": 5200
    },
    {
      "epoch": 0.15950769984386,
      "grad_norm": 1.7177457809448242,
      "learning_rate": 1.8936819438916613e-05,
      "loss": 0.0537,
      "step": 5210
    },
    {
      "epoch": 0.1598138566573799,
      "grad_norm": 0.05202754586935043,
      "learning_rate": 1.893477839349315e-05,
      "loss": 0.0896,
      "step": 5220
    },
    {
      "epoch": 0.1601200134708998,
      "grad_norm": 0.04205973818898201,
      "learning_rate": 1.8932737348069684e-05,
      "loss": 0.0182,
      "step": 5230
    },
    {
      "epoch": 0.1604261702844197,
      "grad_norm": 0.4879322946071625,
      "learning_rate": 1.8930696302646218e-05,
      "loss": 0.0035,
      "step": 5240
    },
    {
      "epoch": 0.16073232709793955,
      "grad_norm": 0.06610298156738281,
      "learning_rate": 1.892865525722275e-05,
      "loss": 0.0013,
      "step": 5250
    },
    {
      "epoch": 0.16103848391145945,
      "grad_norm": 0.028011346235871315,
      "learning_rate": 1.8926614211799285e-05,
      "loss": 0.0534,
      "step": 5260
    },
    {
      "epoch": 0.16134464072497934,
      "grad_norm": 0.07006485015153885,
      "learning_rate": 1.892457316637582e-05,
      "loss": 0.0018,
      "step": 5270
    },
    {
      "epoch": 0.16165079753849923,
      "grad_norm": 0.03550814464688301,
      "learning_rate": 1.8922532120952352e-05,
      "loss": 0.0016,
      "step": 5280
    },
    {
      "epoch": 0.1619569543520191,
      "grad_norm": 0.05204137787222862,
      "learning_rate": 1.892049107552889e-05,
      "loss": 0.0018,
      "step": 5290
    },
    {
      "epoch": 0.162263111165539,
      "grad_norm": 0.03075997903943062,
      "learning_rate": 1.8918450030105423e-05,
      "loss": 0.0313,
      "step": 5300
    },
    {
      "epoch": 0.16256926797905888,
      "grad_norm": 0.018818117678165436,
      "learning_rate": 1.8916408984681957e-05,
      "loss": 0.0031,
      "step": 5310
    },
    {
      "epoch": 0.16287542479257877,
      "grad_norm": 0.028071211650967598,
      "learning_rate": 1.891436793925849e-05,
      "loss": 0.0015,
      "step": 5320
    },
    {
      "epoch": 0.16318158160609864,
      "grad_norm": 0.03036673180758953,
      "learning_rate": 1.8912326893835024e-05,
      "loss": 0.0364,
      "step": 5330
    },
    {
      "epoch": 0.16348773841961853,
      "grad_norm": 0.029340803623199463,
      "learning_rate": 1.8910285848411558e-05,
      "loss": 0.0017,
      "step": 5340
    },
    {
      "epoch": 0.16379389523313842,
      "grad_norm": 0.026825077831745148,
      "learning_rate": 1.890824480298809e-05,
      "loss": 0.0024,
      "step": 5350
    },
    {
      "epoch": 0.16410005204665828,
      "grad_norm": 0.05060260370373726,
      "learning_rate": 1.8906203757564625e-05,
      "loss": 0.001,
      "step": 5360
    },
    {
      "epoch": 0.16440620886017818,
      "grad_norm": 0.040304627269506454,
      "learning_rate": 1.8904162712141162e-05,
      "loss": 0.0015,
      "step": 5370
    },
    {
      "epoch": 0.16471236567369807,
      "grad_norm": 0.00790970865637064,
      "learning_rate": 1.8902121666717696e-05,
      "loss": 0.0677,
      "step": 5380
    },
    {
      "epoch": 0.16501852248721796,
      "grad_norm": 0.009238837286829948,
      "learning_rate": 1.890008062129423e-05,
      "loss": 0.0584,
      "step": 5390
    },
    {
      "epoch": 0.16532467930073783,
      "grad_norm": 0.04501296579837799,
      "learning_rate": 1.8898039575870763e-05,
      "loss": 0.0015,
      "step": 5400
    },
    {
      "epoch": 0.16563083611425772,
      "grad_norm": 0.017950009554624557,
      "learning_rate": 1.8895998530447296e-05,
      "loss": 0.0339,
      "step": 5410
    },
    {
      "epoch": 0.1659369929277776,
      "grad_norm": 0.02001938782632351,
      "learning_rate": 1.889395748502383e-05,
      "loss": 0.0332,
      "step": 5420
    },
    {
      "epoch": 0.1662431497412975,
      "grad_norm": 0.07536108046770096,
      "learning_rate": 1.8891916439600364e-05,
      "loss": 0.0021,
      "step": 5430
    },
    {
      "epoch": 0.16654930655481737,
      "grad_norm": 0.02779720351099968,
      "learning_rate": 1.88898753941769e-05,
      "loss": 0.0464,
      "step": 5440
    },
    {
      "epoch": 0.16685546336833726,
      "grad_norm": 0.057071853429079056,
      "learning_rate": 1.8887834348753434e-05,
      "loss": 0.0392,
      "step": 5450
    },
    {
      "epoch": 0.16716162018185715,
      "grad_norm": 0.04953811690211296,
      "learning_rate": 1.8885793303329968e-05,
      "loss": 0.0036,
      "step": 5460
    },
    {
      "epoch": 0.16746777699537704,
      "grad_norm": 0.05071161687374115,
      "learning_rate": 1.8883752257906502e-05,
      "loss": 0.0021,
      "step": 5470
    },
    {
      "epoch": 0.1677739338088969,
      "grad_norm": 0.05119885876774788,
      "learning_rate": 1.8881711212483035e-05,
      "loss": 0.0035,
      "step": 5480
    },
    {
      "epoch": 0.1680800906224168,
      "grad_norm": 0.048513393849134445,
      "learning_rate": 1.887967016705957e-05,
      "loss": 0.0329,
      "step": 5490
    },
    {
      "epoch": 0.1683862474359367,
      "grad_norm": 0.01384235080331564,
      "learning_rate": 1.8877629121636103e-05,
      "loss": 0.0396,
      "step": 5500
    },
    {
      "epoch": 0.16869240424945658,
      "grad_norm": 0.04771682620048523,
      "learning_rate": 1.887558807621264e-05,
      "loss": 0.0017,
      "step": 5510
    },
    {
      "epoch": 0.16899856106297645,
      "grad_norm": 0.039353616535663605,
      "learning_rate": 1.8873547030789173e-05,
      "loss": 0.0026,
      "step": 5520
    },
    {
      "epoch": 0.16930471787649634,
      "grad_norm": 0.03427180275321007,
      "learning_rate": 1.8871505985365707e-05,
      "loss": 0.0365,
      "step": 5530
    },
    {
      "epoch": 0.16961087469001623,
      "grad_norm": 0.2785862386226654,
      "learning_rate": 1.886946493994224e-05,
      "loss": 0.03,
      "step": 5540
    },
    {
      "epoch": 0.1699170315035361,
      "grad_norm": 0.030238166451454163,
      "learning_rate": 1.8867423894518774e-05,
      "loss": 0.0087,
      "step": 5550
    },
    {
      "epoch": 0.170223188317056,
      "grad_norm": 0.02266070246696472,
      "learning_rate": 1.8865382849095308e-05,
      "loss": 0.0016,
      "step": 5560
    },
    {
      "epoch": 0.17052934513057588,
      "grad_norm": 0.01505981758236885,
      "learning_rate": 1.886334180367184e-05,
      "loss": 0.0101,
      "step": 5570
    },
    {
      "epoch": 0.17083550194409577,
      "grad_norm": 0.017793655395507812,
      "learning_rate": 1.8861300758248375e-05,
      "loss": 0.0257,
      "step": 5580
    },
    {
      "epoch": 0.17114165875761564,
      "grad_norm": 0.061193305999040604,
      "learning_rate": 1.8859259712824912e-05,
      "loss": 0.0726,
      "step": 5590
    },
    {
      "epoch": 0.17144781557113553,
      "grad_norm": 0.032005250453948975,
      "learning_rate": 1.8857218667401446e-05,
      "loss": 0.0017,
      "step": 5600
    },
    {
      "epoch": 0.17175397238465542,
      "grad_norm": 0.017489971593022346,
      "learning_rate": 1.885517762197798e-05,
      "loss": 0.0226,
      "step": 5610
    },
    {
      "epoch": 0.17206012919817532,
      "grad_norm": 0.006149949040263891,
      "learning_rate": 1.8853136576554513e-05,
      "loss": 0.0036,
      "step": 5620
    },
    {
      "epoch": 0.17236628601169518,
      "grad_norm": 0.04424675181508064,
      "learning_rate": 1.8851095531131047e-05,
      "loss": 0.002,
      "step": 5630
    },
    {
      "epoch": 0.17267244282521507,
      "grad_norm": 0.01981060951948166,
      "learning_rate": 1.884905448570758e-05,
      "loss": 0.0383,
      "step": 5640
    },
    {
      "epoch": 0.17297859963873496,
      "grad_norm": 0.02585795521736145,
      "learning_rate": 1.8847013440284114e-05,
      "loss": 0.0021,
      "step": 5650
    },
    {
      "epoch": 0.17328475645225486,
      "grad_norm": 0.9509594440460205,
      "learning_rate": 1.884497239486065e-05,
      "loss": 0.0136,
      "step": 5660
    },
    {
      "epoch": 0.17359091326577472,
      "grad_norm": 0.05100397393107414,
      "learning_rate": 1.8842931349437185e-05,
      "loss": 0.0336,
      "step": 5670
    },
    {
      "epoch": 0.1738970700792946,
      "grad_norm": 0.053470004349946976,
      "learning_rate": 1.884089030401372e-05,
      "loss": 0.0152,
      "step": 5680
    },
    {
      "epoch": 0.1742032268928145,
      "grad_norm": 0.04515252262353897,
      "learning_rate": 1.8838849258590252e-05,
      "loss": 0.0019,
      "step": 5690
    },
    {
      "epoch": 0.1745093837063344,
      "grad_norm": 2.6083927154541016,
      "learning_rate": 1.8836808213166786e-05,
      "loss": 0.0179,
      "step": 5700
    },
    {
      "epoch": 0.17481554051985426,
      "grad_norm": 0.03219544515013695,
      "learning_rate": 1.883476716774332e-05,
      "loss": 0.0015,
      "step": 5710
    },
    {
      "epoch": 0.17512169733337415,
      "grad_norm": 0.0320294052362442,
      "learning_rate": 1.8832726122319853e-05,
      "loss": 0.0708,
      "step": 5720
    },
    {
      "epoch": 0.17542785414689405,
      "grad_norm": 0.025415785610675812,
      "learning_rate": 1.883068507689639e-05,
      "loss": 0.0066,
      "step": 5730
    },
    {
      "epoch": 0.1757340109604139,
      "grad_norm": 0.046432048082351685,
      "learning_rate": 1.8828644031472924e-05,
      "loss": 0.0387,
      "step": 5740
    },
    {
      "epoch": 0.1760401677739338,
      "grad_norm": 0.026584774255752563,
      "learning_rate": 1.8826602986049457e-05,
      "loss": 0.003,
      "step": 5750
    },
    {
      "epoch": 0.1763463245874537,
      "grad_norm": 0.06204685568809509,
      "learning_rate": 1.882456194062599e-05,
      "loss": 0.0615,
      "step": 5760
    },
    {
      "epoch": 0.1766524814009736,
      "grad_norm": 0.0597386360168457,
      "learning_rate": 1.8822520895202525e-05,
      "loss": 0.0598,
      "step": 5770
    },
    {
      "epoch": 0.17695863821449345,
      "grad_norm": 0.12909609079360962,
      "learning_rate": 1.8820479849779058e-05,
      "loss": 0.0682,
      "step": 5780
    },
    {
      "epoch": 0.17726479502801334,
      "grad_norm": 0.03661501035094261,
      "learning_rate": 1.8818438804355592e-05,
      "loss": 0.0036,
      "step": 5790
    },
    {
      "epoch": 0.17757095184153324,
      "grad_norm": 0.04254002496600151,
      "learning_rate": 1.8816397758932126e-05,
      "loss": 0.0026,
      "step": 5800
    },
    {
      "epoch": 0.17787710865505313,
      "grad_norm": 0.035318128764629364,
      "learning_rate": 1.8814356713508663e-05,
      "loss": 0.0024,
      "step": 5810
    },
    {
      "epoch": 0.178183265468573,
      "grad_norm": 0.03937433287501335,
      "learning_rate": 1.8812315668085196e-05,
      "loss": 0.0018,
      "step": 5820
    },
    {
      "epoch": 0.17848942228209289,
      "grad_norm": 0.026011688634753227,
      "learning_rate": 1.881027462266173e-05,
      "loss": 0.0014,
      "step": 5830
    },
    {
      "epoch": 0.17879557909561278,
      "grad_norm": 0.025795379653573036,
      "learning_rate": 1.8808233577238264e-05,
      "loss": 0.0013,
      "step": 5840
    },
    {
      "epoch": 0.17910173590913267,
      "grad_norm": 0.022937150672078133,
      "learning_rate": 1.8806192531814797e-05,
      "loss": 0.0325,
      "step": 5850
    },
    {
      "epoch": 0.17940789272265253,
      "grad_norm": 0.025827310979366302,
      "learning_rate": 1.880415148639133e-05,
      "loss": 0.0104,
      "step": 5860
    },
    {
      "epoch": 0.17971404953617243,
      "grad_norm": 0.36796310544013977,
      "learning_rate": 1.8802110440967864e-05,
      "loss": 0.0323,
      "step": 5870
    },
    {
      "epoch": 0.18002020634969232,
      "grad_norm": 1.7617721557617188,
      "learning_rate": 1.88000693955444e-05,
      "loss": 0.0683,
      "step": 5880
    },
    {
      "epoch": 0.1803263631632122,
      "grad_norm": 0.035314761102199554,
      "learning_rate": 1.8798028350120935e-05,
      "loss": 0.0704,
      "step": 5890
    },
    {
      "epoch": 0.18063251997673208,
      "grad_norm": 0.11806751042604446,
      "learning_rate": 1.879598730469747e-05,
      "loss": 0.0038,
      "step": 5900
    },
    {
      "epoch": 0.18093867679025197,
      "grad_norm": 0.27844443917274475,
      "learning_rate": 1.8793946259274002e-05,
      "loss": 0.0053,
      "step": 5910
    },
    {
      "epoch": 0.18124483360377186,
      "grad_norm": 0.013133211992681026,
      "learning_rate": 1.8791905213850536e-05,
      "loss": 0.0182,
      "step": 5920
    },
    {
      "epoch": 0.18155099041729172,
      "grad_norm": 0.036527540534734726,
      "learning_rate": 1.878986416842707e-05,
      "loss": 0.0016,
      "step": 5930
    },
    {
      "epoch": 0.18185714723081162,
      "grad_norm": 1.8794571161270142,
      "learning_rate": 1.8787823123003603e-05,
      "loss": 0.0299,
      "step": 5940
    },
    {
      "epoch": 0.1821633040443315,
      "grad_norm": 0.023506853729486465,
      "learning_rate": 1.878578207758014e-05,
      "loss": 0.0149,
      "step": 5950
    },
    {
      "epoch": 0.1824694608578514,
      "grad_norm": 0.02343442104756832,
      "learning_rate": 1.8783741032156674e-05,
      "loss": 0.0379,
      "step": 5960
    },
    {
      "epoch": 0.18277561767137127,
      "grad_norm": 0.029098067432641983,
      "learning_rate": 1.8781699986733208e-05,
      "loss": 0.0026,
      "step": 5970
    },
    {
      "epoch": 0.18308177448489116,
      "grad_norm": 0.013827583752572536,
      "learning_rate": 1.877965894130974e-05,
      "loss": 0.094,
      "step": 5980
    },
    {
      "epoch": 0.18338793129841105,
      "grad_norm": 0.05865263193845749,
      "learning_rate": 1.8777617895886275e-05,
      "loss": 0.015,
      "step": 5990
    },
    {
      "epoch": 0.18369408811193094,
      "grad_norm": 0.028225915506482124,
      "learning_rate": 1.877557685046281e-05,
      "loss": 0.02,
      "step": 6000
    },
    {
      "epoch": 0.1840002449254508,
      "grad_norm": 0.043252747505903244,
      "learning_rate": 1.8773535805039342e-05,
      "loss": 0.0528,
      "step": 6010
    },
    {
      "epoch": 0.1843064017389707,
      "grad_norm": 0.05955737829208374,
      "learning_rate": 1.8771494759615876e-05,
      "loss": 0.0024,
      "step": 6020
    },
    {
      "epoch": 0.1846125585524906,
      "grad_norm": 0.02886589616537094,
      "learning_rate": 1.8769453714192413e-05,
      "loss": 0.0391,
      "step": 6030
    },
    {
      "epoch": 0.18491871536601048,
      "grad_norm": 0.03500129655003548,
      "learning_rate": 1.8767412668768947e-05,
      "loss": 0.0027,
      "step": 6040
    },
    {
      "epoch": 0.18522487217953035,
      "grad_norm": 0.042934004217386246,
      "learning_rate": 1.876537162334548e-05,
      "loss": 0.0365,
      "step": 6050
    },
    {
      "epoch": 0.18553102899305024,
      "grad_norm": 0.03616267815232277,
      "learning_rate": 1.8763330577922014e-05,
      "loss": 0.0013,
      "step": 6060
    },
    {
      "epoch": 0.18583718580657013,
      "grad_norm": 0.06767594814300537,
      "learning_rate": 1.8761289532498547e-05,
      "loss": 0.0369,
      "step": 6070
    },
    {
      "epoch": 0.18614334262009,
      "grad_norm": 0.060796916484832764,
      "learning_rate": 1.875924848707508e-05,
      "loss": 0.0131,
      "step": 6080
    },
    {
      "epoch": 0.1864494994336099,
      "grad_norm": 0.11447477340698242,
      "learning_rate": 1.8757207441651615e-05,
      "loss": 0.0026,
      "step": 6090
    },
    {
      "epoch": 0.18675565624712978,
      "grad_norm": 0.013370892964303493,
      "learning_rate": 1.8755166396228152e-05,
      "loss": 0.0022,
      "step": 6100
    },
    {
      "epoch": 0.18706181306064967,
      "grad_norm": 0.03942393139004707,
      "learning_rate": 1.8753125350804685e-05,
      "loss": 0.0115,
      "step": 6110
    },
    {
      "epoch": 0.18736796987416954,
      "grad_norm": 0.04104551300406456,
      "learning_rate": 1.875108430538122e-05,
      "loss": 0.0019,
      "step": 6120
    },
    {
      "epoch": 0.18767412668768943,
      "grad_norm": 1.640230417251587,
      "learning_rate": 1.874904325995775e-05,
      "loss": 0.0724,
      "step": 6130
    },
    {
      "epoch": 0.18798028350120932,
      "grad_norm": 0.11570549011230469,
      "learning_rate": 1.8747002214534286e-05,
      "loss": 0.0364,
      "step": 6140
    },
    {
      "epoch": 0.18828644031472921,
      "grad_norm": 0.025296557694673538,
      "learning_rate": 1.874496116911082e-05,
      "loss": 0.0266,
      "step": 6150
    },
    {
      "epoch": 0.18859259712824908,
      "grad_norm": 0.023418942466378212,
      "learning_rate": 1.8742920123687354e-05,
      "loss": 0.0133,
      "step": 6160
    },
    {
      "epoch": 0.18889875394176897,
      "grad_norm": 1.7291430234909058,
      "learning_rate": 1.8740879078263887e-05,
      "loss": 0.0362,
      "step": 6170
    },
    {
      "epoch": 0.18920491075528886,
      "grad_norm": 0.025694062933325768,
      "learning_rate": 1.8738838032840424e-05,
      "loss": 0.0284,
      "step": 6180
    },
    {
      "epoch": 0.18951106756880876,
      "grad_norm": 0.08815578371286392,
      "learning_rate": 1.8736796987416958e-05,
      "loss": 0.0212,
      "step": 6190
    },
    {
      "epoch": 0.18981722438232862,
      "grad_norm": 0.04825523495674133,
      "learning_rate": 1.8734755941993488e-05,
      "loss": 0.0043,
      "step": 6200
    },
    {
      "epoch": 0.1901233811958485,
      "grad_norm": 0.05778671056032181,
      "learning_rate": 1.8732714896570025e-05,
      "loss": 0.0025,
      "step": 6210
    },
    {
      "epoch": 0.1904295380093684,
      "grad_norm": 0.016163159161806107,
      "learning_rate": 1.873067385114656e-05,
      "loss": 0.0019,
      "step": 6220
    },
    {
      "epoch": 0.1907356948228883,
      "grad_norm": 0.05917194485664368,
      "learning_rate": 1.8728632805723093e-05,
      "loss": 0.0674,
      "step": 6230
    },
    {
      "epoch": 0.19104185163640816,
      "grad_norm": 0.04896353557705879,
      "learning_rate": 1.8726591760299626e-05,
      "loss": 0.0045,
      "step": 6240
    },
    {
      "epoch": 0.19134800844992805,
      "grad_norm": 0.04488444700837135,
      "learning_rate": 1.8724550714876163e-05,
      "loss": 0.0348,
      "step": 6250
    },
    {
      "epoch": 0.19165416526344795,
      "grad_norm": 0.03117789700627327,
      "learning_rate": 1.8722509669452697e-05,
      "loss": 0.0324,
      "step": 6260
    },
    {
      "epoch": 0.1919603220769678,
      "grad_norm": 0.04543665051460266,
      "learning_rate": 1.8720468624029227e-05,
      "loss": 0.0373,
      "step": 6270
    },
    {
      "epoch": 0.1922664788904877,
      "grad_norm": 0.07328961789608002,
      "learning_rate": 1.871842757860576e-05,
      "loss": 0.0167,
      "step": 6280
    },
    {
      "epoch": 0.1925726357040076,
      "grad_norm": 0.05420069769024849,
      "learning_rate": 1.8716386533182298e-05,
      "loss": 0.0022,
      "step": 6290
    },
    {
      "epoch": 0.1928787925175275,
      "grad_norm": 0.07149515300989151,
      "learning_rate": 1.871434548775883e-05,
      "loss": 0.0021,
      "step": 6300
    },
    {
      "epoch": 0.19318494933104735,
      "grad_norm": 0.05859476700425148,
      "learning_rate": 1.8712304442335365e-05,
      "loss": 0.0369,
      "step": 6310
    },
    {
      "epoch": 0.19349110614456724,
      "grad_norm": 0.06919286400079727,
      "learning_rate": 1.8710263396911902e-05,
      "loss": 0.0379,
      "step": 6320
    },
    {
      "epoch": 0.19379726295808714,
      "grad_norm": 0.06804241240024567,
      "learning_rate": 1.8708222351488436e-05,
      "loss": 0.0284,
      "step": 6330
    },
    {
      "epoch": 0.19410341977160703,
      "grad_norm": 2.3983817100524902,
      "learning_rate": 1.8706181306064966e-05,
      "loss": 0.0336,
      "step": 6340
    },
    {
      "epoch": 0.1944095765851269,
      "grad_norm": 0.04061480984091759,
      "learning_rate": 1.87041402606415e-05,
      "loss": 0.01,
      "step": 6350
    },
    {
      "epoch": 0.19471573339864678,
      "grad_norm": 0.040158454328775406,
      "learning_rate": 1.8702099215218037e-05,
      "loss": 0.0017,
      "step": 6360
    },
    {
      "epoch": 0.19502189021216668,
      "grad_norm": 0.027812836691737175,
      "learning_rate": 1.870005816979457e-05,
      "loss": 0.014,
      "step": 6370
    },
    {
      "epoch": 0.19532804702568657,
      "grad_norm": 0.0117054907605052,
      "learning_rate": 1.8698017124371104e-05,
      "loss": 0.0043,
      "step": 6380
    },
    {
      "epoch": 0.19563420383920643,
      "grad_norm": 1.6982065439224243,
      "learning_rate": 1.8695976078947638e-05,
      "loss": 0.0341,
      "step": 6390
    },
    {
      "epoch": 0.19594036065272633,
      "grad_norm": 0.04284704476594925,
      "learning_rate": 1.8693935033524175e-05,
      "loss": 0.0036,
      "step": 6400
    },
    {
      "epoch": 0.19624651746624622,
      "grad_norm": 0.02501424215734005,
      "learning_rate": 1.869189398810071e-05,
      "loss": 0.0266,
      "step": 6410
    },
    {
      "epoch": 0.1965526742797661,
      "grad_norm": 0.06797371059656143,
      "learning_rate": 1.868985294267724e-05,
      "loss": 0.0337,
      "step": 6420
    },
    {
      "epoch": 0.19685883109328597,
      "grad_norm": 0.06816691160202026,
      "learning_rate": 1.8687811897253776e-05,
      "loss": 0.0904,
      "step": 6430
    },
    {
      "epoch": 0.19716498790680587,
      "grad_norm": 0.10661373287439346,
      "learning_rate": 1.868577085183031e-05,
      "loss": 0.0043,
      "step": 6440
    },
    {
      "epoch": 0.19747114472032576,
      "grad_norm": 0.08060073852539062,
      "learning_rate": 1.8683729806406843e-05,
      "loss": 0.0437,
      "step": 6450
    },
    {
      "epoch": 0.19777730153384562,
      "grad_norm": 0.1896498054265976,
      "learning_rate": 1.8681688760983377e-05,
      "loss": 0.0672,
      "step": 6460
    },
    {
      "epoch": 0.19808345834736552,
      "grad_norm": 0.056045956909656525,
      "learning_rate": 1.8679647715559914e-05,
      "loss": 0.0028,
      "step": 6470
    },
    {
      "epoch": 0.1983896151608854,
      "grad_norm": 0.07076028734445572,
      "learning_rate": 1.8677606670136447e-05,
      "loss": 0.0041,
      "step": 6480
    },
    {
      "epoch": 0.1986957719744053,
      "grad_norm": 0.06107696145772934,
      "learning_rate": 1.8675565624712977e-05,
      "loss": 0.0022,
      "step": 6490
    },
    {
      "epoch": 0.19900192878792516,
      "grad_norm": 0.03742504119873047,
      "learning_rate": 1.867352457928951e-05,
      "loss": 0.0041,
      "step": 6500
    },
    {
      "epoch": 0.19930808560144506,
      "grad_norm": 0.04338102415204048,
      "learning_rate": 1.8671483533866048e-05,
      "loss": 0.0023,
      "step": 6510
    },
    {
      "epoch": 0.19961424241496495,
      "grad_norm": 0.04413209483027458,
      "learning_rate": 1.8669442488442582e-05,
      "loss": 0.0016,
      "step": 6520
    },
    {
      "epoch": 0.19992039922848484,
      "grad_norm": 0.02094869129359722,
      "learning_rate": 1.8667401443019115e-05,
      "loss": 0.0179,
      "step": 6530
    },
    {
      "epoch": 0.2002265560420047,
      "grad_norm": 0.037196867167949677,
      "learning_rate": 1.8665360397595652e-05,
      "loss": 0.0013,
      "step": 6540
    },
    {
      "epoch": 0.2005327128555246,
      "grad_norm": 0.013149739243090153,
      "learning_rate": 1.8663319352172186e-05,
      "loss": 0.0012,
      "step": 6550
    },
    {
      "epoch": 0.2008388696690445,
      "grad_norm": 0.020259004086256027,
      "learning_rate": 1.8661278306748716e-05,
      "loss": 0.0012,
      "step": 6560
    },
    {
      "epoch": 0.20114502648256438,
      "grad_norm": 0.018590161576867104,
      "learning_rate": 1.865923726132525e-05,
      "loss": 0.0017,
      "step": 6570
    },
    {
      "epoch": 0.20145118329608425,
      "grad_norm": 0.019004203379154205,
      "learning_rate": 1.8657196215901787e-05,
      "loss": 0.0007,
      "step": 6580
    },
    {
      "epoch": 0.20175734010960414,
      "grad_norm": 0.02503756806254387,
      "learning_rate": 1.865515517047832e-05,
      "loss": 0.0405,
      "step": 6590
    },
    {
      "epoch": 0.20206349692312403,
      "grad_norm": 0.01808919385075569,
      "learning_rate": 1.8653114125054854e-05,
      "loss": 0.001,
      "step": 6600
    },
    {
      "epoch": 0.2023696537366439,
      "grad_norm": 0.007608950138092041,
      "learning_rate": 1.8651073079631388e-05,
      "loss": 0.0011,
      "step": 6610
    },
    {
      "epoch": 0.2026758105501638,
      "grad_norm": 0.02922482043504715,
      "learning_rate": 1.8649032034207925e-05,
      "loss": 0.0107,
      "step": 6620
    },
    {
      "epoch": 0.20298196736368368,
      "grad_norm": 0.014290792867541313,
      "learning_rate": 1.8646990988784455e-05,
      "loss": 0.0393,
      "step": 6630
    },
    {
      "epoch": 0.20328812417720357,
      "grad_norm": 0.05093520134687424,
      "learning_rate": 1.864494994336099e-05,
      "loss": 0.037,
      "step": 6640
    },
    {
      "epoch": 0.20359428099072344,
      "grad_norm": 0.03697948530316353,
      "learning_rate": 1.8642908897937526e-05,
      "loss": 0.0302,
      "step": 6650
    },
    {
      "epoch": 0.20390043780424333,
      "grad_norm": 0.01851886510848999,
      "learning_rate": 1.864086785251406e-05,
      "loss": 0.0011,
      "step": 6660
    },
    {
      "epoch": 0.20420659461776322,
      "grad_norm": 0.07193048298358917,
      "learning_rate": 1.8638826807090593e-05,
      "loss": 0.0814,
      "step": 6670
    },
    {
      "epoch": 0.2045127514312831,
      "grad_norm": 0.05480964854359627,
      "learning_rate": 1.8636785761667127e-05,
      "loss": 0.0378,
      "step": 6680
    },
    {
      "epoch": 0.20481890824480298,
      "grad_norm": 2.1065731048583984,
      "learning_rate": 1.8634744716243664e-05,
      "loss": 0.0166,
      "step": 6690
    },
    {
      "epoch": 0.20512506505832287,
      "grad_norm": 2.139986753463745,
      "learning_rate": 1.8632703670820194e-05,
      "loss": 0.0114,
      "step": 6700
    },
    {
      "epoch": 0.20543122187184276,
      "grad_norm": 1.7250068187713623,
      "learning_rate": 1.8630662625396728e-05,
      "loss": 0.0299,
      "step": 6710
    },
    {
      "epoch": 0.20573737868536265,
      "grad_norm": 0.031095018610358238,
      "learning_rate": 1.862862157997326e-05,
      "loss": 0.0053,
      "step": 6720
    },
    {
      "epoch": 0.20604353549888252,
      "grad_norm": 0.06654815375804901,
      "learning_rate": 1.86265805345498e-05,
      "loss": 0.03,
      "step": 6730
    },
    {
      "epoch": 0.2063496923124024,
      "grad_norm": 1.690326452255249,
      "learning_rate": 1.8624539489126332e-05,
      "loss": 0.0314,
      "step": 6740
    },
    {
      "epoch": 0.2066558491259223,
      "grad_norm": 0.02289530448615551,
      "learning_rate": 1.8622498443702866e-05,
      "loss": 0.0343,
      "step": 6750
    },
    {
      "epoch": 0.2069620059394422,
      "grad_norm": 0.045544642955064774,
      "learning_rate": 1.8620457398279403e-05,
      "loss": 0.0943,
      "step": 6760
    },
    {
      "epoch": 0.20726816275296206,
      "grad_norm": 0.10027480125427246,
      "learning_rate": 1.8618416352855933e-05,
      "loss": 0.0037,
      "step": 6770
    },
    {
      "epoch": 0.20757431956648195,
      "grad_norm": 0.0681086927652359,
      "learning_rate": 1.8616375307432467e-05,
      "loss": 0.0038,
      "step": 6780
    },
    {
      "epoch": 0.20788047638000184,
      "grad_norm": 0.163964182138443,
      "learning_rate": 1.8614334262009e-05,
      "loss": 0.0045,
      "step": 6790
    },
    {
      "epoch": 0.2081866331935217,
      "grad_norm": 0.04110425338149071,
      "learning_rate": 1.8612293216585537e-05,
      "loss": 0.0714,
      "step": 6800
    },
    {
      "epoch": 0.2084927900070416,
      "grad_norm": 0.054031047970056534,
      "learning_rate": 1.861025217116207e-05,
      "loss": 0.0032,
      "step": 6810
    },
    {
      "epoch": 0.2087989468205615,
      "grad_norm": 0.029585931450128555,
      "learning_rate": 1.8608211125738605e-05,
      "loss": 0.0331,
      "step": 6820
    },
    {
      "epoch": 0.20910510363408139,
      "grad_norm": 1.6370360851287842,
      "learning_rate": 1.860617008031514e-05,
      "loss": 0.0673,
      "step": 6830
    },
    {
      "epoch": 0.20941126044760125,
      "grad_norm": 0.04037797451019287,
      "learning_rate": 1.8604129034891672e-05,
      "loss": 0.0308,
      "step": 6840
    },
    {
      "epoch": 0.20971741726112114,
      "grad_norm": 0.10856137424707413,
      "learning_rate": 1.8602087989468206e-05,
      "loss": 0.031,
      "step": 6850
    },
    {
      "epoch": 0.21002357407464103,
      "grad_norm": 0.04469097778201103,
      "learning_rate": 1.860004694404474e-05,
      "loss": 0.0031,
      "step": 6860
    },
    {
      "epoch": 0.21032973088816093,
      "grad_norm": 0.07308807969093323,
      "learning_rate": 1.8598005898621276e-05,
      "loss": 0.0357,
      "step": 6870
    },
    {
      "epoch": 0.2106358877016808,
      "grad_norm": 0.1291627287864685,
      "learning_rate": 1.859596485319781e-05,
      "loss": 0.0278,
      "step": 6880
    },
    {
      "epoch": 0.21094204451520068,
      "grad_norm": 0.6601887345314026,
      "learning_rate": 1.8593923807774344e-05,
      "loss": 0.0063,
      "step": 6890
    },
    {
      "epoch": 0.21124820132872058,
      "grad_norm": 0.06769999116659164,
      "learning_rate": 1.8591882762350877e-05,
      "loss": 0.0031,
      "step": 6900
    },
    {
      "epoch": 0.21155435814224047,
      "grad_norm": 0.045693833380937576,
      "learning_rate": 1.8589841716927414e-05,
      "loss": 0.0329,
      "step": 6910
    },
    {
      "epoch": 0.21186051495576033,
      "grad_norm": 0.02896982617676258,
      "learning_rate": 1.8587800671503945e-05,
      "loss": 0.0025,
      "step": 6920
    },
    {
      "epoch": 0.21216667176928022,
      "grad_norm": 0.13244254887104034,
      "learning_rate": 1.8585759626080478e-05,
      "loss": 0.0258,
      "step": 6930
    },
    {
      "epoch": 0.21247282858280012,
      "grad_norm": 0.015942493453621864,
      "learning_rate": 1.8583718580657012e-05,
      "loss": 0.0406,
      "step": 6940
    },
    {
      "epoch": 0.21277898539632,
      "grad_norm": 2.412450075149536,
      "learning_rate": 1.858167753523355e-05,
      "loss": 0.0504,
      "step": 6950
    },
    {
      "epoch": 0.21308514220983987,
      "grad_norm": 1.845724105834961,
      "learning_rate": 1.8579636489810082e-05,
      "loss": 0.0247,
      "step": 6960
    },
    {
      "epoch": 0.21339129902335977,
      "grad_norm": 0.06607940047979355,
      "learning_rate": 1.8577595444386616e-05,
      "loss": 0.0345,
      "step": 6970
    },
    {
      "epoch": 0.21369745583687966,
      "grad_norm": 1.8723098039627075,
      "learning_rate": 1.8575554398963153e-05,
      "loss": 0.0398,
      "step": 6980
    },
    {
      "epoch": 0.21400361265039952,
      "grad_norm": 0.04982445016503334,
      "learning_rate": 1.8573513353539683e-05,
      "loss": 0.0055,
      "step": 6990
    },
    {
      "epoch": 0.21430976946391941,
      "grad_norm": 0.09329033643007278,
      "learning_rate": 1.8571472308116217e-05,
      "loss": 0.0032,
      "step": 7000
    },
    {
      "epoch": 0.2146159262774393,
      "grad_norm": 0.03967650607228279,
      "learning_rate": 1.856943126269275e-05,
      "loss": 0.0686,
      "step": 7010
    },
    {
      "epoch": 0.2149220830909592,
      "grad_norm": 0.08720547705888748,
      "learning_rate": 1.8567390217269288e-05,
      "loss": 0.0026,
      "step": 7020
    },
    {
      "epoch": 0.21522823990447906,
      "grad_norm": 0.021490558981895447,
      "learning_rate": 1.856534917184582e-05,
      "loss": 0.0361,
      "step": 7030
    },
    {
      "epoch": 0.21553439671799896,
      "grad_norm": 0.03711554408073425,
      "learning_rate": 1.8563308126422355e-05,
      "loss": 0.0034,
      "step": 7040
    },
    {
      "epoch": 0.21584055353151885,
      "grad_norm": 0.06153939664363861,
      "learning_rate": 1.856126708099889e-05,
      "loss": 0.0016,
      "step": 7050
    },
    {
      "epoch": 0.21614671034503874,
      "grad_norm": 0.01633494347333908,
      "learning_rate": 1.8559226035575422e-05,
      "loss": 0.0031,
      "step": 7060
    },
    {
      "epoch": 0.2164528671585586,
      "grad_norm": 0.04663754627108574,
      "learning_rate": 1.8557184990151956e-05,
      "loss": 0.0016,
      "step": 7070
    },
    {
      "epoch": 0.2167590239720785,
      "grad_norm": 0.045078810304403305,
      "learning_rate": 1.855514394472849e-05,
      "loss": 0.0037,
      "step": 7080
    },
    {
      "epoch": 0.2170651807855984,
      "grad_norm": 0.04268136993050575,
      "learning_rate": 1.8553102899305027e-05,
      "loss": 0.0015,
      "step": 7090
    },
    {
      "epoch": 0.21737133759911828,
      "grad_norm": 0.011804375797510147,
      "learning_rate": 1.855106185388156e-05,
      "loss": 0.0009,
      "step": 7100
    },
    {
      "epoch": 0.21767749441263815,
      "grad_norm": 0.03364551439881325,
      "learning_rate": 1.8549020808458094e-05,
      "loss": 0.0011,
      "step": 7110
    },
    {
      "epoch": 0.21798365122615804,
      "grad_norm": 0.01652861014008522,
      "learning_rate": 1.8546979763034628e-05,
      "loss": 0.0963,
      "step": 7120
    },
    {
      "epoch": 0.21828980803967793,
      "grad_norm": 0.03122052177786827,
      "learning_rate": 1.854493871761116e-05,
      "loss": 0.0824,
      "step": 7130
    },
    {
      "epoch": 0.21859596485319782,
      "grad_norm": 0.03861328959465027,
      "learning_rate": 1.8542897672187695e-05,
      "loss": 0.0334,
      "step": 7140
    },
    {
      "epoch": 0.21890212166671769,
      "grad_norm": 0.07103051990270615,
      "learning_rate": 1.854085662676423e-05,
      "loss": 0.0026,
      "step": 7150
    },
    {
      "epoch": 0.21920827848023758,
      "grad_norm": 0.08783640712499619,
      "learning_rate": 1.8538815581340762e-05,
      "loss": 0.0031,
      "step": 7160
    },
    {
      "epoch": 0.21951443529375747,
      "grad_norm": 0.07472580671310425,
      "learning_rate": 1.85367745359173e-05,
      "loss": 0.0325,
      "step": 7170
    },
    {
      "epoch": 0.21982059210727734,
      "grad_norm": 0.06073496863245964,
      "learning_rate": 1.8534733490493833e-05,
      "loss": 0.0018,
      "step": 7180
    },
    {
      "epoch": 0.22012674892079723,
      "grad_norm": 0.0836755707859993,
      "learning_rate": 1.8532692445070366e-05,
      "loss": 0.0023,
      "step": 7190
    },
    {
      "epoch": 0.22043290573431712,
      "grad_norm": 0.020056957378983498,
      "learning_rate": 1.85306513996469e-05,
      "loss": 0.0016,
      "step": 7200
    },
    {
      "epoch": 0.220739062547837,
      "grad_norm": 0.011609957553446293,
      "learning_rate": 1.8528610354223434e-05,
      "loss": 0.0011,
      "step": 7210
    },
    {
      "epoch": 0.22104521936135688,
      "grad_norm": 0.01236325316131115,
      "learning_rate": 1.8526569308799967e-05,
      "loss": 0.0017,
      "step": 7220
    },
    {
      "epoch": 0.22135137617487677,
      "grad_norm": 0.024923153221607208,
      "learning_rate": 1.85245282633765e-05,
      "loss": 0.0021,
      "step": 7230
    },
    {
      "epoch": 0.22165753298839666,
      "grad_norm": 0.02495826780796051,
      "learning_rate": 1.8522487217953038e-05,
      "loss": 0.0018,
      "step": 7240
    },
    {
      "epoch": 0.22196368980191655,
      "grad_norm": 0.015577445738017559,
      "learning_rate": 1.8520446172529572e-05,
      "loss": 0.0014,
      "step": 7250
    },
    {
      "epoch": 0.22226984661543642,
      "grad_norm": 0.015463766641914845,
      "learning_rate": 1.8518405127106105e-05,
      "loss": 0.0041,
      "step": 7260
    },
    {
      "epoch": 0.2225760034289563,
      "grad_norm": 1.8121933937072754,
      "learning_rate": 1.851636408168264e-05,
      "loss": 0.0346,
      "step": 7270
    },
    {
      "epoch": 0.2228821602424762,
      "grad_norm": 0.017813237383961678,
      "learning_rate": 1.8514323036259173e-05,
      "loss": 0.0009,
      "step": 7280
    },
    {
      "epoch": 0.2231883170559961,
      "grad_norm": 1.942501187324524,
      "learning_rate": 1.8512281990835706e-05,
      "loss": 0.0421,
      "step": 7290
    },
    {
      "epoch": 0.22349447386951596,
      "grad_norm": 0.038779761642217636,
      "learning_rate": 1.851024094541224e-05,
      "loss": 0.0346,
      "step": 7300
    },
    {
      "epoch": 0.22380063068303585,
      "grad_norm": 0.04977310448884964,
      "learning_rate": 1.8508199899988777e-05,
      "loss": 0.0177,
      "step": 7310
    },
    {
      "epoch": 0.22410678749655574,
      "grad_norm": 0.042300693690776825,
      "learning_rate": 1.850615885456531e-05,
      "loss": 0.006,
      "step": 7320
    },
    {
      "epoch": 0.2244129443100756,
      "grad_norm": 0.029485318809747696,
      "learning_rate": 1.8504117809141844e-05,
      "loss": 0.008,
      "step": 7330
    },
    {
      "epoch": 0.2247191011235955,
      "grad_norm": 0.01672615483403206,
      "learning_rate": 1.8502076763718378e-05,
      "loss": 0.0129,
      "step": 7340
    },
    {
      "epoch": 0.2250252579371154,
      "grad_norm": 0.012209858745336533,
      "learning_rate": 1.850003571829491e-05,
      "loss": 0.013,
      "step": 7350
    },
    {
      "epoch": 0.22533141475063528,
      "grad_norm": 0.03413420170545578,
      "learning_rate": 1.8497994672871445e-05,
      "loss": 0.0859,
      "step": 7360
    },
    {
      "epoch": 0.22563757156415515,
      "grad_norm": 0.010607179254293442,
      "learning_rate": 1.849595362744798e-05,
      "loss": 0.0012,
      "step": 7370
    },
    {
      "epoch": 0.22594372837767504,
      "grad_norm": 0.05143110081553459,
      "learning_rate": 1.8493912582024512e-05,
      "loss": 0.0382,
      "step": 7380
    },
    {
      "epoch": 0.22624988519119493,
      "grad_norm": 0.6275815367698669,
      "learning_rate": 1.849187153660105e-05,
      "loss": 0.0357,
      "step": 7390
    },
    {
      "epoch": 0.22655604200471482,
      "grad_norm": 0.049696363508701324,
      "learning_rate": 1.8489830491177583e-05,
      "loss": 0.0019,
      "step": 7400
    },
    {
      "epoch": 0.2268621988182347,
      "grad_norm": 0.005163305439054966,
      "learning_rate": 1.8487789445754117e-05,
      "loss": 0.0367,
      "step": 7410
    },
    {
      "epoch": 0.22716835563175458,
      "grad_norm": 0.12214087694883347,
      "learning_rate": 1.848574840033065e-05,
      "loss": 0.0019,
      "step": 7420
    },
    {
      "epoch": 0.22747451244527447,
      "grad_norm": 0.030170926824212074,
      "learning_rate": 1.8483707354907184e-05,
      "loss": 0.0386,
      "step": 7430
    },
    {
      "epoch": 0.22778066925879437,
      "grad_norm": 0.07902099192142487,
      "learning_rate": 1.8481666309483718e-05,
      "loss": 0.0597,
      "step": 7440
    },
    {
      "epoch": 0.22808682607231423,
      "grad_norm": 0.05944393202662468,
      "learning_rate": 1.847962526406025e-05,
      "loss": 0.0019,
      "step": 7450
    },
    {
      "epoch": 0.22839298288583412,
      "grad_norm": 0.05360764265060425,
      "learning_rate": 1.847758421863679e-05,
      "loss": 0.0018,
      "step": 7460
    },
    {
      "epoch": 0.22869913969935401,
      "grad_norm": 0.03122910112142563,
      "learning_rate": 1.8475543173213322e-05,
      "loss": 0.002,
      "step": 7470
    },
    {
      "epoch": 0.2290052965128739,
      "grad_norm": 0.2044658213853836,
      "learning_rate": 1.8473502127789856e-05,
      "loss": 0.0343,
      "step": 7480
    },
    {
      "epoch": 0.22931145332639377,
      "grad_norm": 0.05448998510837555,
      "learning_rate": 1.847146108236639e-05,
      "loss": 0.0013,
      "step": 7490
    },
    {
      "epoch": 0.22961761013991366,
      "grad_norm": 0.06399122625589371,
      "learning_rate": 1.8469420036942923e-05,
      "loss": 0.0351,
      "step": 7500
    },
    {
      "epoch": 0.22992376695343356,
      "grad_norm": 0.04871206358075142,
      "learning_rate": 1.8467378991519457e-05,
      "loss": 0.0401,
      "step": 7510
    },
    {
      "epoch": 0.23022992376695342,
      "grad_norm": 0.09149695932865143,
      "learning_rate": 1.846533794609599e-05,
      "loss": 0.0055,
      "step": 7520
    },
    {
      "epoch": 0.2305360805804733,
      "grad_norm": 0.03112289123237133,
      "learning_rate": 1.8463296900672524e-05,
      "loss": 0.0018,
      "step": 7530
    },
    {
      "epoch": 0.2308422373939932,
      "grad_norm": 0.022983117029070854,
      "learning_rate": 1.846125585524906e-05,
      "loss": 0.0019,
      "step": 7540
    },
    {
      "epoch": 0.2311483942075131,
      "grad_norm": 0.48608824610710144,
      "learning_rate": 1.8459214809825595e-05,
      "loss": 0.0387,
      "step": 7550
    },
    {
      "epoch": 0.23145455102103296,
      "grad_norm": 0.10303007811307907,
      "learning_rate": 1.8457173764402128e-05,
      "loss": 0.0025,
      "step": 7560
    },
    {
      "epoch": 0.23176070783455285,
      "grad_norm": 0.07261840254068375,
      "learning_rate": 1.8455132718978662e-05,
      "loss": 0.0021,
      "step": 7570
    },
    {
      "epoch": 0.23206686464807275,
      "grad_norm": 1.6904433965682983,
      "learning_rate": 1.8453091673555196e-05,
      "loss": 0.0306,
      "step": 7580
    },
    {
      "epoch": 0.23237302146159264,
      "grad_norm": 0.05668766424059868,
      "learning_rate": 1.845105062813173e-05,
      "loss": 0.0015,
      "step": 7590
    },
    {
      "epoch": 0.2326791782751125,
      "grad_norm": 0.02531835436820984,
      "learning_rate": 1.8449009582708263e-05,
      "loss": 0.0012,
      "step": 7600
    },
    {
      "epoch": 0.2329853350886324,
      "grad_norm": 0.026771225035190582,
      "learning_rate": 1.84469685372848e-05,
      "loss": 0.012,
      "step": 7610
    },
    {
      "epoch": 0.2332914919021523,
      "grad_norm": 0.011535380966961384,
      "learning_rate": 1.8444927491861333e-05,
      "loss": 0.0078,
      "step": 7620
    },
    {
      "epoch": 0.23359764871567218,
      "grad_norm": 0.031165041029453278,
      "learning_rate": 1.8442886446437867e-05,
      "loss": 0.0096,
      "step": 7630
    },
    {
      "epoch": 0.23390380552919204,
      "grad_norm": 0.0338580496609211,
      "learning_rate": 1.84408454010144e-05,
      "loss": 0.0063,
      "step": 7640
    },
    {
      "epoch": 0.23420996234271194,
      "grad_norm": 0.11262533068656921,
      "learning_rate": 1.8438804355590934e-05,
      "loss": 0.0023,
      "step": 7650
    },
    {
      "epoch": 0.23451611915623183,
      "grad_norm": 0.015121321193873882,
      "learning_rate": 1.8436763310167468e-05,
      "loss": 0.001,
      "step": 7660
    },
    {
      "epoch": 0.23482227596975172,
      "grad_norm": 0.015263655222952366,
      "learning_rate": 1.8434722264744002e-05,
      "loss": 0.0453,
      "step": 7670
    },
    {
      "epoch": 0.23512843278327158,
      "grad_norm": 0.025427933782339096,
      "learning_rate": 1.843268121932054e-05,
      "loss": 0.0019,
      "step": 7680
    },
    {
      "epoch": 0.23543458959679148,
      "grad_norm": 0.024662701413035393,
      "learning_rate": 1.8430640173897072e-05,
      "loss": 0.001,
      "step": 7690
    },
    {
      "epoch": 0.23574074641031137,
      "grad_norm": 0.010494749993085861,
      "learning_rate": 1.8428599128473606e-05,
      "loss": 0.0012,
      "step": 7700
    },
    {
      "epoch": 0.23604690322383123,
      "grad_norm": 0.040464986115694046,
      "learning_rate": 1.842655808305014e-05,
      "loss": 0.0013,
      "step": 7710
    },
    {
      "epoch": 0.23635306003735113,
      "grad_norm": 0.029487580060958862,
      "learning_rate": 1.8424517037626673e-05,
      "loss": 0.0393,
      "step": 7720
    },
    {
      "epoch": 0.23665921685087102,
      "grad_norm": 0.025138990953564644,
      "learning_rate": 1.8422475992203207e-05,
      "loss": 0.0007,
      "step": 7730
    },
    {
      "epoch": 0.2369653736643909,
      "grad_norm": 0.007703683339059353,
      "learning_rate": 1.842043494677974e-05,
      "loss": 0.0015,
      "step": 7740
    },
    {
      "epoch": 0.23727153047791077,
      "grad_norm": 0.021186556667089462,
      "learning_rate": 1.8418393901356274e-05,
      "loss": 0.001,
      "step": 7750
    },
    {
      "epoch": 0.23757768729143067,
      "grad_norm": 0.010472436435520649,
      "learning_rate": 1.841635285593281e-05,
      "loss": 0.001,
      "step": 7760
    },
    {
      "epoch": 0.23788384410495056,
      "grad_norm": 0.011579906567931175,
      "learning_rate": 1.8414311810509345e-05,
      "loss": 0.0007,
      "step": 7770
    },
    {
      "epoch": 0.23819000091847045,
      "grad_norm": 0.005797022022306919,
      "learning_rate": 1.841227076508588e-05,
      "loss": 0.0006,
      "step": 7780
    },
    {
      "epoch": 0.23849615773199032,
      "grad_norm": 0.03864511102437973,
      "learning_rate": 1.8410229719662412e-05,
      "loss": 0.051,
      "step": 7790
    },
    {
      "epoch": 0.2388023145455102,
      "grad_norm": 0.011070509441196918,
      "learning_rate": 1.8408188674238946e-05,
      "loss": 0.0007,
      "step": 7800
    },
    {
      "epoch": 0.2391084713590301,
      "grad_norm": 0.10163416713476181,
      "learning_rate": 1.840614762881548e-05,
      "loss": 0.0021,
      "step": 7810
    },
    {
      "epoch": 0.23941462817255,
      "grad_norm": 0.012897283770143986,
      "learning_rate": 1.8404106583392013e-05,
      "loss": 0.0007,
      "step": 7820
    },
    {
      "epoch": 0.23972078498606986,
      "grad_norm": 0.013223614543676376,
      "learning_rate": 1.840206553796855e-05,
      "loss": 0.0009,
      "step": 7830
    },
    {
      "epoch": 0.24002694179958975,
      "grad_norm": 0.006904455367475748,
      "learning_rate": 1.8400024492545084e-05,
      "loss": 0.0007,
      "step": 7840
    },
    {
      "epoch": 0.24033309861310964,
      "grad_norm": 0.02723930962383747,
      "learning_rate": 1.8397983447121617e-05,
      "loss": 0.0292,
      "step": 7850
    },
    {
      "epoch": 0.2406392554266295,
      "grad_norm": 0.016276422888040543,
      "learning_rate": 1.839594240169815e-05,
      "loss": 0.0009,
      "step": 7860
    },
    {
      "epoch": 0.2409454122401494,
      "grad_norm": 0.02553418092429638,
      "learning_rate": 1.8393901356274685e-05,
      "loss": 0.0011,
      "step": 7870
    },
    {
      "epoch": 0.2412515690536693,
      "grad_norm": 0.024224145337939262,
      "learning_rate": 1.839186031085122e-05,
      "loss": 0.0007,
      "step": 7880
    },
    {
      "epoch": 0.24155772586718918,
      "grad_norm": 0.05486689880490303,
      "learning_rate": 1.8389819265427752e-05,
      "loss": 0.0766,
      "step": 7890
    },
    {
      "epoch": 0.24186388268070905,
      "grad_norm": 0.007476446684449911,
      "learning_rate": 1.838777822000429e-05,
      "loss": 0.0293,
      "step": 7900
    },
    {
      "epoch": 0.24217003949422894,
      "grad_norm": 0.06022157892584801,
      "learning_rate": 1.8385737174580823e-05,
      "loss": 0.0293,
      "step": 7910
    },
    {
      "epoch": 0.24247619630774883,
      "grad_norm": 0.05349547788500786,
      "learning_rate": 1.8383696129157356e-05,
      "loss": 0.0024,
      "step": 7920
    },
    {
      "epoch": 0.24278235312126872,
      "grad_norm": 0.010648829862475395,
      "learning_rate": 1.838165508373389e-05,
      "loss": 0.0015,
      "step": 7930
    },
    {
      "epoch": 0.2430885099347886,
      "grad_norm": 0.02199636399745941,
      "learning_rate": 1.8379614038310424e-05,
      "loss": 0.0072,
      "step": 7940
    },
    {
      "epoch": 0.24339466674830848,
      "grad_norm": 1.743725061416626,
      "learning_rate": 1.8377572992886957e-05,
      "loss": 0.0352,
      "step": 7950
    },
    {
      "epoch": 0.24370082356182837,
      "grad_norm": 0.021879471838474274,
      "learning_rate": 1.837553194746349e-05,
      "loss": 0.0111,
      "step": 7960
    },
    {
      "epoch": 0.24400698037534826,
      "grad_norm": 0.047079309821128845,
      "learning_rate": 1.8373490902040025e-05,
      "loss": 0.0095,
      "step": 7970
    },
    {
      "epoch": 0.24431313718886813,
      "grad_norm": 0.027765175327658653,
      "learning_rate": 1.837144985661656e-05,
      "loss": 0.0022,
      "step": 7980
    },
    {
      "epoch": 0.24461929400238802,
      "grad_norm": 1.9793314933776855,
      "learning_rate": 1.8369408811193095e-05,
      "loss": 0.0127,
      "step": 7990
    },
    {
      "epoch": 0.2449254508159079,
      "grad_norm": 1.808535099029541,
      "learning_rate": 1.836736776576963e-05,
      "loss": 0.0404,
      "step": 8000
    },
    {
      "epoch": 0.2452316076294278,
      "grad_norm": 0.09587884694337845,
      "learning_rate": 1.8365326720346163e-05,
      "loss": 0.0013,
      "step": 8010
    },
    {
      "epoch": 0.24553776444294767,
      "grad_norm": 0.03635767847299576,
      "learning_rate": 1.8363285674922696e-05,
      "loss": 0.0082,
      "step": 8020
    },
    {
      "epoch": 0.24584392125646756,
      "grad_norm": 0.01571640372276306,
      "learning_rate": 1.836124462949923e-05,
      "loss": 0.0045,
      "step": 8030
    },
    {
      "epoch": 0.24615007806998745,
      "grad_norm": 0.027567433193325996,
      "learning_rate": 1.8359203584075763e-05,
      "loss": 0.0406,
      "step": 8040
    },
    {
      "epoch": 0.24645623488350732,
      "grad_norm": 0.05168287828564644,
      "learning_rate": 1.83571625386523e-05,
      "loss": 0.0367,
      "step": 8050
    },
    {
      "epoch": 0.2467623916970272,
      "grad_norm": 0.04138904809951782,
      "learning_rate": 1.8355121493228834e-05,
      "loss": 0.0332,
      "step": 8060
    },
    {
      "epoch": 0.2470685485105471,
      "grad_norm": 0.020995182916522026,
      "learning_rate": 1.8353080447805368e-05,
      "loss": 0.0016,
      "step": 8070
    },
    {
      "epoch": 0.247374705324067,
      "grad_norm": 0.01581183262169361,
      "learning_rate": 1.83510394023819e-05,
      "loss": 0.0021,
      "step": 8080
    },
    {
      "epoch": 0.24768086213758686,
      "grad_norm": 0.015367155894637108,
      "learning_rate": 1.8348998356958435e-05,
      "loss": 0.061,
      "step": 8090
    },
    {
      "epoch": 0.24798701895110675,
      "grad_norm": 0.043909598141908646,
      "learning_rate": 1.834695731153497e-05,
      "loss": 0.0019,
      "step": 8100
    },
    {
      "epoch": 0.24829317576462664,
      "grad_norm": 0.02778778411448002,
      "learning_rate": 1.8344916266111502e-05,
      "loss": 0.0023,
      "step": 8110
    },
    {
      "epoch": 0.24859933257814654,
      "grad_norm": 0.0683727115392685,
      "learning_rate": 1.834287522068804e-05,
      "loss": 0.0012,
      "step": 8120
    },
    {
      "epoch": 0.2489054893916664,
      "grad_norm": 0.021149756386876106,
      "learning_rate": 1.8340834175264573e-05,
      "loss": 0.0353,
      "step": 8130
    },
    {
      "epoch": 0.2492116462051863,
      "grad_norm": 0.032774247229099274,
      "learning_rate": 1.8338793129841107e-05,
      "loss": 0.0063,
      "step": 8140
    },
    {
      "epoch": 0.24951780301870619,
      "grad_norm": 3.5536961555480957,
      "learning_rate": 1.833675208441764e-05,
      "loss": 0.0779,
      "step": 8150
    },
    {
      "epoch": 0.24982395983222608,
      "grad_norm": 0.03358786553144455,
      "learning_rate": 1.8334711038994174e-05,
      "loss": 0.0093,
      "step": 8160
    },
    {
      "epoch": 0.25013011664574597,
      "grad_norm": 0.05562552064657211,
      "learning_rate": 1.8332669993570708e-05,
      "loss": 0.0014,
      "step": 8170
    },
    {
      "epoch": 0.25043627345926583,
      "grad_norm": 0.021678902208805084,
      "learning_rate": 1.833062894814724e-05,
      "loss": 0.008,
      "step": 8180
    },
    {
      "epoch": 0.2507424302727857,
      "grad_norm": 0.01513944286853075,
      "learning_rate": 1.8328587902723775e-05,
      "loss": 0.0009,
      "step": 8190
    },
    {
      "epoch": 0.2510485870863056,
      "grad_norm": 0.04832962527871132,
      "learning_rate": 1.8326546857300312e-05,
      "loss": 0.0831,
      "step": 8200
    },
    {
      "epoch": 0.2513547438998255,
      "grad_norm": 0.019168071448802948,
      "learning_rate": 1.8324505811876846e-05,
      "loss": 0.0034,
      "step": 8210
    },
    {
      "epoch": 0.25166090071334535,
      "grad_norm": 0.019574197009205818,
      "learning_rate": 1.832246476645338e-05,
      "loss": 0.0296,
      "step": 8220
    },
    {
      "epoch": 0.25196705752686527,
      "grad_norm": 0.056986115872859955,
      "learning_rate": 1.8320423721029913e-05,
      "loss": 0.04,
      "step": 8230
    },
    {
      "epoch": 0.25227321434038513,
      "grad_norm": 0.043852586299180984,
      "learning_rate": 1.8318382675606447e-05,
      "loss": 0.0021,
      "step": 8240
    },
    {
      "epoch": 0.25257937115390505,
      "grad_norm": 0.04181910306215286,
      "learning_rate": 1.831634163018298e-05,
      "loss": 0.0091,
      "step": 8250
    },
    {
      "epoch": 0.2528855279674249,
      "grad_norm": 0.09952341020107269,
      "learning_rate": 1.8314300584759514e-05,
      "loss": 0.0021,
      "step": 8260
    },
    {
      "epoch": 0.2531916847809448,
      "grad_norm": 0.01676361821591854,
      "learning_rate": 1.831225953933605e-05,
      "loss": 0.0013,
      "step": 8270
    },
    {
      "epoch": 0.2534978415944647,
      "grad_norm": 0.0014853053726255894,
      "learning_rate": 1.8310218493912585e-05,
      "loss": 0.0012,
      "step": 8280
    },
    {
      "epoch": 0.25380399840798457,
      "grad_norm": 0.019185969606041908,
      "learning_rate": 1.8308177448489118e-05,
      "loss": 0.0462,
      "step": 8290
    },
    {
      "epoch": 0.25411015522150443,
      "grad_norm": 0.02865474857389927,
      "learning_rate": 1.8306136403065652e-05,
      "loss": 0.0011,
      "step": 8300
    },
    {
      "epoch": 0.25441631203502435,
      "grad_norm": 0.09263914078474045,
      "learning_rate": 1.8304095357642185e-05,
      "loss": 0.0014,
      "step": 8310
    },
    {
      "epoch": 0.2547224688485442,
      "grad_norm": 0.015383576974272728,
      "learning_rate": 1.830205431221872e-05,
      "loss": 0.0015,
      "step": 8320
    },
    {
      "epoch": 0.25502862566206413,
      "grad_norm": 0.06747309863567352,
      "learning_rate": 1.8300013266795253e-05,
      "loss": 0.0345,
      "step": 8330
    },
    {
      "epoch": 0.255334782475584,
      "grad_norm": 0.06001116335391998,
      "learning_rate": 1.829797222137179e-05,
      "loss": 0.0293,
      "step": 8340
    },
    {
      "epoch": 0.25564093928910386,
      "grad_norm": 0.04705117642879486,
      "learning_rate": 1.8295931175948323e-05,
      "loss": 0.0021,
      "step": 8350
    },
    {
      "epoch": 0.2559470961026238,
      "grad_norm": 0.01600058563053608,
      "learning_rate": 1.8293890130524857e-05,
      "loss": 0.0355,
      "step": 8360
    },
    {
      "epoch": 0.25625325291614365,
      "grad_norm": 0.035927869379520416,
      "learning_rate": 1.829184908510139e-05,
      "loss": 0.0014,
      "step": 8370
    },
    {
      "epoch": 0.2565594097296635,
      "grad_norm": 0.033379122614860535,
      "learning_rate": 1.8289808039677924e-05,
      "loss": 0.0331,
      "step": 8380
    },
    {
      "epoch": 0.25686556654318343,
      "grad_norm": 0.03771183267235756,
      "learning_rate": 1.8287766994254458e-05,
      "loss": 0.0018,
      "step": 8390
    },
    {
      "epoch": 0.2571717233567033,
      "grad_norm": 1.865390658378601,
      "learning_rate": 1.828572594883099e-05,
      "loss": 0.0369,
      "step": 8400
    },
    {
      "epoch": 0.25747788017022316,
      "grad_norm": 0.04992459714412689,
      "learning_rate": 1.8283684903407525e-05,
      "loss": 0.0399,
      "step": 8410
    },
    {
      "epoch": 0.2577840369837431,
      "grad_norm": 0.015833791345357895,
      "learning_rate": 1.8281643857984062e-05,
      "loss": 0.0017,
      "step": 8420
    },
    {
      "epoch": 0.25809019379726295,
      "grad_norm": 0.003288840176537633,
      "learning_rate": 1.8279602812560596e-05,
      "loss": 0.0118,
      "step": 8430
    },
    {
      "epoch": 0.25839635061078287,
      "grad_norm": 1.6007776260375977,
      "learning_rate": 1.827756176713713e-05,
      "loss": 0.0305,
      "step": 8440
    },
    {
      "epoch": 0.25870250742430273,
      "grad_norm": 0.02362184040248394,
      "learning_rate": 1.8275520721713663e-05,
      "loss": 0.0244,
      "step": 8450
    },
    {
      "epoch": 0.2590086642378226,
      "grad_norm": 0.01862517185509205,
      "learning_rate": 1.8273479676290197e-05,
      "loss": 0.0015,
      "step": 8460
    },
    {
      "epoch": 0.2593148210513425,
      "grad_norm": 0.20674201846122742,
      "learning_rate": 1.827143863086673e-05,
      "loss": 0.0334,
      "step": 8470
    },
    {
      "epoch": 0.2596209778648624,
      "grad_norm": 0.05853305384516716,
      "learning_rate": 1.8269397585443264e-05,
      "loss": 0.0022,
      "step": 8480
    },
    {
      "epoch": 0.25992713467838224,
      "grad_norm": 0.032104309648275375,
      "learning_rate": 1.82673565400198e-05,
      "loss": 0.0026,
      "step": 8490
    },
    {
      "epoch": 0.26023329149190216,
      "grad_norm": 0.04381415247917175,
      "learning_rate": 1.8265315494596335e-05,
      "loss": 0.0016,
      "step": 8500
    },
    {
      "epoch": 0.26053944830542203,
      "grad_norm": 0.038835182785987854,
      "learning_rate": 1.826327444917287e-05,
      "loss": 0.0017,
      "step": 8510
    },
    {
      "epoch": 0.26084560511894195,
      "grad_norm": 0.031131351366639137,
      "learning_rate": 1.8261233403749402e-05,
      "loss": 0.001,
      "step": 8520
    },
    {
      "epoch": 0.2611517619324618,
      "grad_norm": 0.015584825538098812,
      "learning_rate": 1.8259192358325936e-05,
      "loss": 0.0143,
      "step": 8530
    },
    {
      "epoch": 0.2614579187459817,
      "grad_norm": 0.0115163279697299,
      "learning_rate": 1.825715131290247e-05,
      "loss": 0.0892,
      "step": 8540
    },
    {
      "epoch": 0.2617640755595016,
      "grad_norm": 0.007900646887719631,
      "learning_rate": 1.8255110267479003e-05,
      "loss": 0.047,
      "step": 8550
    },
    {
      "epoch": 0.26207023237302146,
      "grad_norm": 1.4340656995773315,
      "learning_rate": 1.825306922205554e-05,
      "loss": 0.0063,
      "step": 8560
    },
    {
      "epoch": 0.2623763891865413,
      "grad_norm": 0.7124714255332947,
      "learning_rate": 1.8251028176632074e-05,
      "loss": 0.0034,
      "step": 8570
    },
    {
      "epoch": 0.26268254600006125,
      "grad_norm": 1.5002225637435913,
      "learning_rate": 1.8248987131208607e-05,
      "loss": 0.0055,
      "step": 8580
    },
    {
      "epoch": 0.2629887028135811,
      "grad_norm": 0.03673460707068443,
      "learning_rate": 1.824694608578514e-05,
      "loss": 0.0383,
      "step": 8590
    },
    {
      "epoch": 0.263294859627101,
      "grad_norm": 0.029500802978873253,
      "learning_rate": 1.8244905040361675e-05,
      "loss": 0.0013,
      "step": 8600
    },
    {
      "epoch": 0.2636010164406209,
      "grad_norm": 0.01699875108897686,
      "learning_rate": 1.824286399493821e-05,
      "loss": 0.0009,
      "step": 8610
    },
    {
      "epoch": 0.26390717325414076,
      "grad_norm": 0.006251886952668428,
      "learning_rate": 1.8240822949514742e-05,
      "loss": 0.0012,
      "step": 8620
    },
    {
      "epoch": 0.2642133300676607,
      "grad_norm": 0.623140275478363,
      "learning_rate": 1.8238781904091276e-05,
      "loss": 0.0025,
      "step": 8630
    },
    {
      "epoch": 0.26451948688118054,
      "grad_norm": 0.016196519136428833,
      "learning_rate": 1.8236740858667813e-05,
      "loss": 0.0455,
      "step": 8640
    },
    {
      "epoch": 0.2648256436947004,
      "grad_norm": 0.03173931688070297,
      "learning_rate": 1.8234699813244346e-05,
      "loss": 0.0012,
      "step": 8650
    },
    {
      "epoch": 0.2651318005082203,
      "grad_norm": 1.69187331199646,
      "learning_rate": 1.823265876782088e-05,
      "loss": 0.0723,
      "step": 8660
    },
    {
      "epoch": 0.2654379573217402,
      "grad_norm": 0.009312156587839127,
      "learning_rate": 1.8230617722397414e-05,
      "loss": 0.0016,
      "step": 8670
    },
    {
      "epoch": 0.26574411413526006,
      "grad_norm": 0.046147316694259644,
      "learning_rate": 1.8228576676973947e-05,
      "loss": 0.0326,
      "step": 8680
    },
    {
      "epoch": 0.26605027094878,
      "grad_norm": 0.026112288236618042,
      "learning_rate": 1.822653563155048e-05,
      "loss": 0.0342,
      "step": 8690
    },
    {
      "epoch": 0.26635642776229984,
      "grad_norm": 0.022105976939201355,
      "learning_rate": 1.8224494586127015e-05,
      "loss": 0.0016,
      "step": 8700
    },
    {
      "epoch": 0.26666258457581976,
      "grad_norm": 0.023961110040545464,
      "learning_rate": 1.822245354070355e-05,
      "loss": 0.0407,
      "step": 8710
    },
    {
      "epoch": 0.2669687413893396,
      "grad_norm": 0.37830841541290283,
      "learning_rate": 1.8220412495280085e-05,
      "loss": 0.0026,
      "step": 8720
    },
    {
      "epoch": 0.2672748982028595,
      "grad_norm": 0.05669960379600525,
      "learning_rate": 1.821837144985662e-05,
      "loss": 0.0208,
      "step": 8730
    },
    {
      "epoch": 0.2675810550163794,
      "grad_norm": 0.5449520945549011,
      "learning_rate": 1.8216330404433152e-05,
      "loss": 0.0026,
      "step": 8740
    },
    {
      "epoch": 0.2678872118298993,
      "grad_norm": 0.058562181890010834,
      "learning_rate": 1.8214289359009686e-05,
      "loss": 0.0235,
      "step": 8750
    },
    {
      "epoch": 0.26819336864341914,
      "grad_norm": 0.02195630595088005,
      "learning_rate": 1.821224831358622e-05,
      "loss": 0.0013,
      "step": 8760
    },
    {
      "epoch": 0.26849952545693906,
      "grad_norm": 0.03310186788439751,
      "learning_rate": 1.8210207268162753e-05,
      "loss": 0.034,
      "step": 8770
    },
    {
      "epoch": 0.2688056822704589,
      "grad_norm": 0.0441301092505455,
      "learning_rate": 1.8208166222739287e-05,
      "loss": 0.0429,
      "step": 8780
    },
    {
      "epoch": 0.2691118390839788,
      "grad_norm": 0.04086499288678169,
      "learning_rate": 1.8206125177315824e-05,
      "loss": 0.0019,
      "step": 8790
    },
    {
      "epoch": 0.2694179958974987,
      "grad_norm": 0.08659084141254425,
      "learning_rate": 1.8204084131892358e-05,
      "loss": 0.0021,
      "step": 8800
    },
    {
      "epoch": 0.26972415271101857,
      "grad_norm": 0.3911530673503876,
      "learning_rate": 1.820204308646889e-05,
      "loss": 0.0022,
      "step": 8810
    },
    {
      "epoch": 0.2700303095245385,
      "grad_norm": 0.02532285638153553,
      "learning_rate": 1.8200002041045425e-05,
      "loss": 0.0494,
      "step": 8820
    },
    {
      "epoch": 0.27033646633805836,
      "grad_norm": 0.047602392733097076,
      "learning_rate": 1.819796099562196e-05,
      "loss": 0.0015,
      "step": 8830
    },
    {
      "epoch": 0.2706426231515782,
      "grad_norm": 0.06840820610523224,
      "learning_rate": 1.8195919950198492e-05,
      "loss": 0.0617,
      "step": 8840
    },
    {
      "epoch": 0.27094877996509814,
      "grad_norm": 0.020002953708171844,
      "learning_rate": 1.8193878904775026e-05,
      "loss": 0.0017,
      "step": 8850
    },
    {
      "epoch": 0.271254936778618,
      "grad_norm": 0.0324845165014267,
      "learning_rate": 1.8191837859351563e-05,
      "loss": 0.0691,
      "step": 8860
    },
    {
      "epoch": 0.27156109359213787,
      "grad_norm": 0.03939194977283478,
      "learning_rate": 1.8189796813928097e-05,
      "loss": 0.0023,
      "step": 8870
    },
    {
      "epoch": 0.2718672504056578,
      "grad_norm": 0.021221883594989777,
      "learning_rate": 1.818775576850463e-05,
      "loss": 0.0305,
      "step": 8880
    },
    {
      "epoch": 0.27217340721917765,
      "grad_norm": 0.024163739755749702,
      "learning_rate": 1.8185714723081164e-05,
      "loss": 0.0024,
      "step": 8890
    },
    {
      "epoch": 0.2724795640326976,
      "grad_norm": 0.06899023056030273,
      "learning_rate": 1.8183673677657698e-05,
      "loss": 0.002,
      "step": 8900
    },
    {
      "epoch": 0.27278572084621744,
      "grad_norm": 0.07261723279953003,
      "learning_rate": 1.818163263223423e-05,
      "loss": 0.0259,
      "step": 8910
    },
    {
      "epoch": 0.2730918776597373,
      "grad_norm": 0.03104311414062977,
      "learning_rate": 1.8179591586810765e-05,
      "loss": 0.0014,
      "step": 8920
    },
    {
      "epoch": 0.2733980344732572,
      "grad_norm": 0.016239367425441742,
      "learning_rate": 1.8177550541387302e-05,
      "loss": 0.0016,
      "step": 8930
    },
    {
      "epoch": 0.2737041912867771,
      "grad_norm": 0.041266582906246185,
      "learning_rate": 1.8175509495963836e-05,
      "loss": 0.0014,
      "step": 8940
    },
    {
      "epoch": 0.27401034810029695,
      "grad_norm": 0.027223946526646614,
      "learning_rate": 1.817346845054037e-05,
      "loss": 0.0126,
      "step": 8950
    },
    {
      "epoch": 0.27431650491381687,
      "grad_norm": 0.008418180048465729,
      "learning_rate": 1.8171427405116903e-05,
      "loss": 0.0009,
      "step": 8960
    },
    {
      "epoch": 0.27462266172733674,
      "grad_norm": 0.009707478806376457,
      "learning_rate": 1.8169386359693436e-05,
      "loss": 0.0008,
      "step": 8970
    },
    {
      "epoch": 0.2749288185408566,
      "grad_norm": 0.03141162917017937,
      "learning_rate": 1.816734531426997e-05,
      "loss": 0.0336,
      "step": 8980
    },
    {
      "epoch": 0.2752349753543765,
      "grad_norm": 0.012197824195027351,
      "learning_rate": 1.8165304268846504e-05,
      "loss": 0.0012,
      "step": 8990
    },
    {
      "epoch": 0.2755411321678964,
      "grad_norm": 0.04451422765851021,
      "learning_rate": 1.8163263223423037e-05,
      "loss": 0.0456,
      "step": 9000
    },
    {
      "epoch": 0.2758472889814163,
      "grad_norm": 0.033887188881635666,
      "learning_rate": 1.8161222177999574e-05,
      "loss": 0.0403,
      "step": 9010
    },
    {
      "epoch": 0.27615344579493617,
      "grad_norm": 0.0451064370572567,
      "learning_rate": 1.8159181132576108e-05,
      "loss": 0.0013,
      "step": 9020
    },
    {
      "epoch": 0.27645960260845603,
      "grad_norm": 0.05005475506186485,
      "learning_rate": 1.8157140087152642e-05,
      "loss": 0.0014,
      "step": 9030
    },
    {
      "epoch": 0.27676575942197595,
      "grad_norm": 0.04385243356227875,
      "learning_rate": 1.8155099041729175e-05,
      "loss": 0.0362,
      "step": 9040
    },
    {
      "epoch": 0.2770719162354958,
      "grad_norm": 0.028475547209382057,
      "learning_rate": 1.815305799630571e-05,
      "loss": 0.0035,
      "step": 9050
    },
    {
      "epoch": 0.2773780730490157,
      "grad_norm": 0.02302945777773857,
      "learning_rate": 1.8151016950882243e-05,
      "loss": 0.0397,
      "step": 9060
    },
    {
      "epoch": 0.2776842298625356,
      "grad_norm": 0.12916360795497894,
      "learning_rate": 1.8148975905458776e-05,
      "loss": 0.0038,
      "step": 9070
    },
    {
      "epoch": 0.27799038667605547,
      "grad_norm": 0.02627643011510372,
      "learning_rate": 1.8146934860035313e-05,
      "loss": 0.0757,
      "step": 9080
    },
    {
      "epoch": 0.2782965434895754,
      "grad_norm": 0.08028371632099152,
      "learning_rate": 1.8144893814611847e-05,
      "loss": 0.0342,
      "step": 9090
    },
    {
      "epoch": 0.27860270030309525,
      "grad_norm": 0.0627799704670906,
      "learning_rate": 1.814285276918838e-05,
      "loss": 0.0854,
      "step": 9100
    },
    {
      "epoch": 0.2789088571166151,
      "grad_norm": 0.04729251191020012,
      "learning_rate": 1.8140811723764914e-05,
      "loss": 0.009,
      "step": 9110
    },
    {
      "epoch": 0.27921501393013504,
      "grad_norm": 0.10435112565755844,
      "learning_rate": 1.8138770678341448e-05,
      "loss": 0.0025,
      "step": 9120
    },
    {
      "epoch": 0.2795211707436549,
      "grad_norm": 0.01520226988941431,
      "learning_rate": 1.813672963291798e-05,
      "loss": 0.0021,
      "step": 9130
    },
    {
      "epoch": 0.27982732755717477,
      "grad_norm": 0.027973463758826256,
      "learning_rate": 1.8134688587494515e-05,
      "loss": 0.0341,
      "step": 9140
    },
    {
      "epoch": 0.2801334843706947,
      "grad_norm": 0.03634990379214287,
      "learning_rate": 1.8132647542071052e-05,
      "loss": 0.0405,
      "step": 9150
    },
    {
      "epoch": 0.28043964118421455,
      "grad_norm": 0.045740190893411636,
      "learning_rate": 1.8130606496647586e-05,
      "loss": 0.0244,
      "step": 9160
    },
    {
      "epoch": 0.2807457979977344,
      "grad_norm": 0.0901079848408699,
      "learning_rate": 1.812856545122412e-05,
      "loss": 0.0029,
      "step": 9170
    },
    {
      "epoch": 0.28105195481125433,
      "grad_norm": 0.05426408722996712,
      "learning_rate": 1.8126524405800653e-05,
      "loss": 0.0022,
      "step": 9180
    },
    {
      "epoch": 0.2813581116247742,
      "grad_norm": 0.05062730237841606,
      "learning_rate": 1.8124483360377187e-05,
      "loss": 0.0378,
      "step": 9190
    },
    {
      "epoch": 0.2816642684382941,
      "grad_norm": 2.685981035232544,
      "learning_rate": 1.812244231495372e-05,
      "loss": 0.0448,
      "step": 9200
    },
    {
      "epoch": 0.281970425251814,
      "grad_norm": 0.032896656543016434,
      "learning_rate": 1.8120401269530254e-05,
      "loss": 0.0022,
      "step": 9210
    },
    {
      "epoch": 0.28227658206533385,
      "grad_norm": 0.020542200654745102,
      "learning_rate": 1.8118360224106788e-05,
      "loss": 0.0018,
      "step": 9220
    },
    {
      "epoch": 0.28258273887885377,
      "grad_norm": 0.06806250661611557,
      "learning_rate": 1.8116319178683325e-05,
      "loss": 0.0042,
      "step": 9230
    },
    {
      "epoch": 0.28288889569237363,
      "grad_norm": 0.03679191693663597,
      "learning_rate": 1.811427813325986e-05,
      "loss": 0.0663,
      "step": 9240
    },
    {
      "epoch": 0.2831950525058935,
      "grad_norm": 0.029490366578102112,
      "learning_rate": 1.8112237087836392e-05,
      "loss": 0.0041,
      "step": 9250
    },
    {
      "epoch": 0.2835012093194134,
      "grad_norm": 0.14540857076644897,
      "learning_rate": 1.8110196042412926e-05,
      "loss": 0.0034,
      "step": 9260
    },
    {
      "epoch": 0.2838073661329333,
      "grad_norm": 0.040829092264175415,
      "learning_rate": 1.810815499698946e-05,
      "loss": 0.067,
      "step": 9270
    },
    {
      "epoch": 0.2841135229464532,
      "grad_norm": 0.04545585811138153,
      "learning_rate": 1.8106113951565993e-05,
      "loss": 0.0022,
      "step": 9280
    },
    {
      "epoch": 0.28441967975997307,
      "grad_norm": 0.04549149423837662,
      "learning_rate": 1.8104072906142527e-05,
      "loss": 0.0024,
      "step": 9290
    },
    {
      "epoch": 0.28472583657349293,
      "grad_norm": 0.047819092869758606,
      "learning_rate": 1.8102031860719064e-05,
      "loss": 0.0016,
      "step": 9300
    },
    {
      "epoch": 0.28503199338701285,
      "grad_norm": 0.012422666884958744,
      "learning_rate": 1.8099990815295597e-05,
      "loss": 0.0106,
      "step": 9310
    },
    {
      "epoch": 0.2853381502005327,
      "grad_norm": 0.1092182993888855,
      "learning_rate": 1.809794976987213e-05,
      "loss": 0.0016,
      "step": 9320
    },
    {
      "epoch": 0.2856443070140526,
      "grad_norm": 0.012054306454956532,
      "learning_rate": 1.8095908724448665e-05,
      "loss": 0.0012,
      "step": 9330
    },
    {
      "epoch": 0.2859504638275725,
      "grad_norm": 0.03899214044213295,
      "learning_rate": 1.8093867679025198e-05,
      "loss": 0.025,
      "step": 9340
    },
    {
      "epoch": 0.28625662064109236,
      "grad_norm": 0.042194608598947525,
      "learning_rate": 1.8091826633601732e-05,
      "loss": 0.0383,
      "step": 9350
    },
    {
      "epoch": 0.2865627774546122,
      "grad_norm": 0.015548709779977798,
      "learning_rate": 1.8089785588178266e-05,
      "loss": 0.0026,
      "step": 9360
    },
    {
      "epoch": 0.28686893426813215,
      "grad_norm": 0.044675182551145554,
      "learning_rate": 1.8087744542754803e-05,
      "loss": 0.0431,
      "step": 9370
    },
    {
      "epoch": 0.287175091081652,
      "grad_norm": 0.047539565712213516,
      "learning_rate": 1.8085703497331336e-05,
      "loss": 0.0341,
      "step": 9380
    },
    {
      "epoch": 0.28748124789517193,
      "grad_norm": 0.022743873298168182,
      "learning_rate": 1.808366245190787e-05,
      "loss": 0.0019,
      "step": 9390
    },
    {
      "epoch": 0.2877874047086918,
      "grad_norm": 0.02489650622010231,
      "learning_rate": 1.8081621406484403e-05,
      "loss": 0.0016,
      "step": 9400
    },
    {
      "epoch": 0.28809356152221166,
      "grad_norm": 0.030668064951896667,
      "learning_rate": 1.8079580361060937e-05,
      "loss": 0.0015,
      "step": 9410
    },
    {
      "epoch": 0.2883997183357316,
      "grad_norm": 0.015079001896083355,
      "learning_rate": 1.807753931563747e-05,
      "loss": 0.0016,
      "step": 9420
    },
    {
      "epoch": 0.28870587514925145,
      "grad_norm": 0.015072179026901722,
      "learning_rate": 1.8075498270214004e-05,
      "loss": 0.0347,
      "step": 9430
    },
    {
      "epoch": 0.2890120319627713,
      "grad_norm": 0.01622241735458374,
      "learning_rate": 1.8073457224790538e-05,
      "loss": 0.0104,
      "step": 9440
    },
    {
      "epoch": 0.28931818877629123,
      "grad_norm": 0.04402654990553856,
      "learning_rate": 1.8071416179367075e-05,
      "loss": 0.0074,
      "step": 9450
    },
    {
      "epoch": 0.2896243455898111,
      "grad_norm": 0.027406224980950356,
      "learning_rate": 1.806937513394361e-05,
      "loss": 0.0167,
      "step": 9460
    },
    {
      "epoch": 0.28993050240333096,
      "grad_norm": 0.018305664882063866,
      "learning_rate": 1.8067334088520142e-05,
      "loss": 0.0018,
      "step": 9470
    },
    {
      "epoch": 0.2902366592168509,
      "grad_norm": 0.014024626463651657,
      "learning_rate": 1.8065293043096676e-05,
      "loss": 0.0011,
      "step": 9480
    },
    {
      "epoch": 0.29054281603037074,
      "grad_norm": 0.01461335550993681,
      "learning_rate": 1.806325199767321e-05,
      "loss": 0.0011,
      "step": 9490
    },
    {
      "epoch": 0.29084897284389066,
      "grad_norm": 0.05463148653507233,
      "learning_rate": 1.8061210952249743e-05,
      "loss": 0.0619,
      "step": 9500
    },
    {
      "epoch": 0.2911551296574105,
      "grad_norm": 0.011354664340615273,
      "learning_rate": 1.8059169906826277e-05,
      "loss": 0.0017,
      "step": 9510
    },
    {
      "epoch": 0.2914612864709304,
      "grad_norm": 0.032419126480817795,
      "learning_rate": 1.8057128861402814e-05,
      "loss": 0.0056,
      "step": 9520
    },
    {
      "epoch": 0.2917674432844503,
      "grad_norm": 3.0368223190307617,
      "learning_rate": 1.8055087815979348e-05,
      "loss": 0.0478,
      "step": 9530
    },
    {
      "epoch": 0.2920736000979702,
      "grad_norm": 0.00215341174043715,
      "learning_rate": 1.805304677055588e-05,
      "loss": 0.0326,
      "step": 9540
    },
    {
      "epoch": 0.29237975691149004,
      "grad_norm": 0.02726287581026554,
      "learning_rate": 1.8051005725132415e-05,
      "loss": 0.0013,
      "step": 9550
    },
    {
      "epoch": 0.29268591372500996,
      "grad_norm": 0.03915156051516533,
      "learning_rate": 1.804896467970895e-05,
      "loss": 0.0013,
      "step": 9560
    },
    {
      "epoch": 0.2929920705385298,
      "grad_norm": 0.03781455382704735,
      "learning_rate": 1.8046923634285482e-05,
      "loss": 0.0014,
      "step": 9570
    },
    {
      "epoch": 0.29329822735204975,
      "grad_norm": 0.01693749614059925,
      "learning_rate": 1.8044882588862016e-05,
      "loss": 0.0009,
      "step": 9580
    },
    {
      "epoch": 0.2936043841655696,
      "grad_norm": 0.022776184603571892,
      "learning_rate": 1.8042841543438553e-05,
      "loss": 0.0493,
      "step": 9590
    },
    {
      "epoch": 0.2939105409790895,
      "grad_norm": 0.009962853044271469,
      "learning_rate": 1.8040800498015087e-05,
      "loss": 0.0009,
      "step": 9600
    },
    {
      "epoch": 0.2942166977926094,
      "grad_norm": 0.04268172010779381,
      "learning_rate": 1.803875945259162e-05,
      "loss": 0.0008,
      "step": 9610
    },
    {
      "epoch": 0.29452285460612926,
      "grad_norm": 0.013753412291407585,
      "learning_rate": 1.8036718407168154e-05,
      "loss": 0.0145,
      "step": 9620
    },
    {
      "epoch": 0.2948290114196491,
      "grad_norm": 0.026293274015188217,
      "learning_rate": 1.8034677361744687e-05,
      "loss": 0.0458,
      "step": 9630
    },
    {
      "epoch": 0.29513516823316904,
      "grad_norm": 0.1458149403333664,
      "learning_rate": 1.803263631632122e-05,
      "loss": 0.0437,
      "step": 9640
    },
    {
      "epoch": 0.2954413250466889,
      "grad_norm": 0.023879248648881912,
      "learning_rate": 1.8030595270897755e-05,
      "loss": 0.0461,
      "step": 9650
    },
    {
      "epoch": 0.29574748186020877,
      "grad_norm": 0.040962155908346176,
      "learning_rate": 1.802855422547429e-05,
      "loss": 0.0012,
      "step": 9660
    },
    {
      "epoch": 0.2960536386737287,
      "grad_norm": 0.04692521691322327,
      "learning_rate": 1.8026513180050825e-05,
      "loss": 0.0666,
      "step": 9670
    },
    {
      "epoch": 0.29635979548724856,
      "grad_norm": 0.04680822044610977,
      "learning_rate": 1.802447213462736e-05,
      "loss": 0.0337,
      "step": 9680
    },
    {
      "epoch": 0.2966659523007685,
      "grad_norm": 0.043500322848558426,
      "learning_rate": 1.8022431089203893e-05,
      "loss": 0.0027,
      "step": 9690
    },
    {
      "epoch": 0.29697210911428834,
      "grad_norm": 0.0966358482837677,
      "learning_rate": 1.8020390043780426e-05,
      "loss": 0.0329,
      "step": 9700
    },
    {
      "epoch": 0.2972782659278082,
      "grad_norm": 0.08700764179229736,
      "learning_rate": 1.801834899835696e-05,
      "loss": 0.003,
      "step": 9710
    },
    {
      "epoch": 0.2975844227413281,
      "grad_norm": 0.07097772508859634,
      "learning_rate": 1.8016307952933494e-05,
      "loss": 0.0799,
      "step": 9720
    },
    {
      "epoch": 0.297890579554848,
      "grad_norm": 0.054944563657045364,
      "learning_rate": 1.8014266907510027e-05,
      "loss": 0.0024,
      "step": 9730
    },
    {
      "epoch": 0.29819673636836785,
      "grad_norm": 0.09153614938259125,
      "learning_rate": 1.8012225862086564e-05,
      "loss": 0.0372,
      "step": 9740
    },
    {
      "epoch": 0.2985028931818878,
      "grad_norm": 0.01657891273498535,
      "learning_rate": 1.8010184816663098e-05,
      "loss": 0.0014,
      "step": 9750
    },
    {
      "epoch": 0.29880904999540764,
      "grad_norm": 0.02213437668979168,
      "learning_rate": 1.800814377123963e-05,
      "loss": 0.0389,
      "step": 9760
    },
    {
      "epoch": 0.29911520680892756,
      "grad_norm": 1.685510277748108,
      "learning_rate": 1.8006102725816165e-05,
      "loss": 0.0698,
      "step": 9770
    },
    {
      "epoch": 0.2994213636224474,
      "grad_norm": 0.040716543793678284,
      "learning_rate": 1.80040616803927e-05,
      "loss": 0.0021,
      "step": 9780
    },
    {
      "epoch": 0.2997275204359673,
      "grad_norm": 0.04384768754243851,
      "learning_rate": 1.8002020634969233e-05,
      "loss": 0.0437,
      "step": 9790
    },
    {
      "epoch": 0.3000336772494872,
      "grad_norm": 0.040757909417152405,
      "learning_rate": 1.7999979589545766e-05,
      "loss": 0.0046,
      "step": 9800
    },
    {
      "epoch": 0.30033983406300707,
      "grad_norm": 1.6872042417526245,
      "learning_rate": 1.7997938544122303e-05,
      "loss": 0.0318,
      "step": 9810
    },
    {
      "epoch": 0.30064599087652694,
      "grad_norm": 0.023690788075327873,
      "learning_rate": 1.7995897498698837e-05,
      "loss": 0.0017,
      "step": 9820
    },
    {
      "epoch": 0.30095214769004686,
      "grad_norm": 0.04462547227740288,
      "learning_rate": 1.799385645327537e-05,
      "loss": 0.0361,
      "step": 9830
    },
    {
      "epoch": 0.3012583045035667,
      "grad_norm": 0.04216669499874115,
      "learning_rate": 1.7991815407851904e-05,
      "loss": 0.0019,
      "step": 9840
    },
    {
      "epoch": 0.3015644613170866,
      "grad_norm": 0.020322054624557495,
      "learning_rate": 1.7989774362428438e-05,
      "loss": 0.0018,
      "step": 9850
    },
    {
      "epoch": 0.3018706181306065,
      "grad_norm": 0.03522899001836777,
      "learning_rate": 1.798773331700497e-05,
      "loss": 0.0361,
      "step": 9860
    },
    {
      "epoch": 0.30217677494412637,
      "grad_norm": 0.03715666010975838,
      "learning_rate": 1.7985692271581505e-05,
      "loss": 0.0018,
      "step": 9870
    },
    {
      "epoch": 0.3024829317576463,
      "grad_norm": 0.05285253748297691,
      "learning_rate": 1.798365122615804e-05,
      "loss": 0.0688,
      "step": 9880
    },
    {
      "epoch": 0.30278908857116615,
      "grad_norm": 0.06195135787129402,
      "learning_rate": 1.7981610180734576e-05,
      "loss": 0.0028,
      "step": 9890
    },
    {
      "epoch": 0.303095245384686,
      "grad_norm": 0.016253698617219925,
      "learning_rate": 1.797956913531111e-05,
      "loss": 0.0019,
      "step": 9900
    },
    {
      "epoch": 0.30340140219820594,
      "grad_norm": 0.056582316756248474,
      "learning_rate": 1.7977528089887643e-05,
      "loss": 0.0105,
      "step": 9910
    },
    {
      "epoch": 0.3037075590117258,
      "grad_norm": 0.04502103477716446,
      "learning_rate": 1.7975487044464173e-05,
      "loss": 0.0244,
      "step": 9920
    },
    {
      "epoch": 0.30401371582524567,
      "grad_norm": 0.07438615709543228,
      "learning_rate": 1.797344599904071e-05,
      "loss": 0.0025,
      "step": 9930
    },
    {
      "epoch": 0.3043198726387656,
      "grad_norm": 0.021512433886528015,
      "learning_rate": 1.7971404953617244e-05,
      "loss": 0.029,
      "step": 9940
    },
    {
      "epoch": 0.30462602945228545,
      "grad_norm": 0.05190360173583031,
      "learning_rate": 1.7969363908193778e-05,
      "loss": 0.0021,
      "step": 9950
    },
    {
      "epoch": 0.30493218626580537,
      "grad_norm": 0.008838432841002941,
      "learning_rate": 1.7967322862770315e-05,
      "loss": 0.0018,
      "step": 9960
    },
    {
      "epoch": 0.30523834307932524,
      "grad_norm": 0.07849107682704926,
      "learning_rate": 1.796528181734685e-05,
      "loss": 0.0016,
      "step": 9970
    },
    {
      "epoch": 0.3055444998928451,
      "grad_norm": 0.021749308332800865,
      "learning_rate": 1.7963240771923382e-05,
      "loss": 0.0016,
      "step": 9980
    },
    {
      "epoch": 0.305850656706365,
      "grad_norm": 0.05610028654336929,
      "learning_rate": 1.7961199726499912e-05,
      "loss": 0.0669,
      "step": 9990
    },
    {
      "epoch": 0.3061568135198849,
      "grad_norm": 0.06305058300495148,
      "learning_rate": 1.795915868107645e-05,
      "loss": 0.0671,
      "step": 10000
    },
    {
      "epoch": 0.30646297033340475,
      "grad_norm": 0.19520920515060425,
      "learning_rate": 1.7957117635652983e-05,
      "loss": 0.0029,
      "step": 10010
    },
    {
      "epoch": 0.30676912714692467,
      "grad_norm": 0.06873688101768494,
      "learning_rate": 1.7955076590229517e-05,
      "loss": 0.0019,
      "step": 10020
    },
    {
      "epoch": 0.30707528396044453,
      "grad_norm": 0.049505747854709625,
      "learning_rate": 1.795303554480605e-05,
      "loss": 0.0026,
      "step": 10030
    },
    {
      "epoch": 0.3073814407739644,
      "grad_norm": 0.024241283535957336,
      "learning_rate": 1.7950994499382587e-05,
      "loss": 0.0301,
      "step": 10040
    },
    {
      "epoch": 0.3076875975874843,
      "grad_norm": 0.026712460443377495,
      "learning_rate": 1.794895345395912e-05,
      "loss": 0.038,
      "step": 10050
    },
    {
      "epoch": 0.3079937544010042,
      "grad_norm": 0.007421521004289389,
      "learning_rate": 1.794691240853565e-05,
      "loss": 0.0017,
      "step": 10060
    },
    {
      "epoch": 0.3082999112145241,
      "grad_norm": 0.028248589485883713,
      "learning_rate": 1.7944871363112188e-05,
      "loss": 0.0023,
      "step": 10070
    },
    {
      "epoch": 0.30860606802804397,
      "grad_norm": 0.029141351580619812,
      "learning_rate": 1.7942830317688722e-05,
      "loss": 0.0013,
      "step": 10080
    },
    {
      "epoch": 0.30891222484156383,
      "grad_norm": 0.022490927949547768,
      "learning_rate": 1.7940789272265255e-05,
      "loss": 0.0375,
      "step": 10090
    },
    {
      "epoch": 0.30921838165508375,
      "grad_norm": 0.037260979413986206,
      "learning_rate": 1.793874822684179e-05,
      "loss": 0.0018,
      "step": 10100
    },
    {
      "epoch": 0.3095245384686036,
      "grad_norm": 0.0438789539039135,
      "learning_rate": 1.7936707181418326e-05,
      "loss": 0.0017,
      "step": 10110
    },
    {
      "epoch": 0.3098306952821235,
      "grad_norm": 0.046435657888650894,
      "learning_rate": 1.793466613599486e-05,
      "loss": 0.0026,
      "step": 10120
    },
    {
      "epoch": 0.3101368520956434,
      "grad_norm": 0.033911753445863724,
      "learning_rate": 1.793262509057139e-05,
      "loss": 0.0025,
      "step": 10130
    },
    {
      "epoch": 0.31044300890916326,
      "grad_norm": 0.005009335931390524,
      "learning_rate": 1.7930584045147924e-05,
      "loss": 0.002,
      "step": 10140
    },
    {
      "epoch": 0.3107491657226832,
      "grad_norm": 0.017127515748143196,
      "learning_rate": 1.792854299972446e-05,
      "loss": 0.0009,
      "step": 10150
    },
    {
      "epoch": 0.31105532253620305,
      "grad_norm": 0.07275170832872391,
      "learning_rate": 1.7926501954300994e-05,
      "loss": 0.001,
      "step": 10160
    },
    {
      "epoch": 0.3113614793497229,
      "grad_norm": 0.019438864663243294,
      "learning_rate": 1.7924460908877528e-05,
      "loss": 0.0009,
      "step": 10170
    },
    {
      "epoch": 0.31166763616324283,
      "grad_norm": 0.01792716421186924,
      "learning_rate": 1.7922419863454065e-05,
      "loss": 0.0351,
      "step": 10180
    },
    {
      "epoch": 0.3119737929767627,
      "grad_norm": 0.022991932928562164,
      "learning_rate": 1.79203788180306e-05,
      "loss": 0.0096,
      "step": 10190
    },
    {
      "epoch": 0.31227994979028256,
      "grad_norm": 0.03682200610637665,
      "learning_rate": 1.791833777260713e-05,
      "loss": 0.106,
      "step": 10200
    },
    {
      "epoch": 0.3125861066038025,
      "grad_norm": 0.06127488985657692,
      "learning_rate": 1.7916296727183663e-05,
      "loss": 0.0019,
      "step": 10210
    },
    {
      "epoch": 0.31289226341732235,
      "grad_norm": 0.018117254599928856,
      "learning_rate": 1.79142556817602e-05,
      "loss": 0.0341,
      "step": 10220
    },
    {
      "epoch": 0.3131984202308422,
      "grad_norm": 0.03788107633590698,
      "learning_rate": 1.7912214636336733e-05,
      "loss": 0.0022,
      "step": 10230
    },
    {
      "epoch": 0.31350457704436213,
      "grad_norm": 0.06311838328838348,
      "learning_rate": 1.7910173590913267e-05,
      "loss": 0.0152,
      "step": 10240
    },
    {
      "epoch": 0.313810733857882,
      "grad_norm": 0.08651996403932571,
      "learning_rate": 1.79081325454898e-05,
      "loss": 0.0015,
      "step": 10250
    },
    {
      "epoch": 0.3141168906714019,
      "grad_norm": 0.025065137073397636,
      "learning_rate": 1.7906091500066338e-05,
      "loss": 0.0017,
      "step": 10260
    },
    {
      "epoch": 0.3144230474849218,
      "grad_norm": 0.01709883287549019,
      "learning_rate": 1.790405045464287e-05,
      "loss": 0.0017,
      "step": 10270
    },
    {
      "epoch": 0.31472920429844164,
      "grad_norm": 0.03358670324087143,
      "learning_rate": 1.79020094092194e-05,
      "loss": 0.0336,
      "step": 10280
    },
    {
      "epoch": 0.31503536111196156,
      "grad_norm": 0.023509439080953598,
      "learning_rate": 1.789996836379594e-05,
      "loss": 0.0014,
      "step": 10290
    },
    {
      "epoch": 0.31534151792548143,
      "grad_norm": 0.0468730665743351,
      "learning_rate": 1.7897927318372472e-05,
      "loss": 0.0012,
      "step": 10300
    },
    {
      "epoch": 0.3156476747390013,
      "grad_norm": 0.015528536401689053,
      "learning_rate": 1.7895886272949006e-05,
      "loss": 0.0011,
      "step": 10310
    },
    {
      "epoch": 0.3159538315525212,
      "grad_norm": 0.025343509390950203,
      "learning_rate": 1.789384522752554e-05,
      "loss": 0.0395,
      "step": 10320
    },
    {
      "epoch": 0.3162599883660411,
      "grad_norm": 0.02128319814801216,
      "learning_rate": 1.7891804182102076e-05,
      "loss": 0.0041,
      "step": 10330
    },
    {
      "epoch": 0.316566145179561,
      "grad_norm": 0.01673983782529831,
      "learning_rate": 1.788976313667861e-05,
      "loss": 0.1051,
      "step": 10340
    },
    {
      "epoch": 0.31687230199308086,
      "grad_norm": 0.05123567581176758,
      "learning_rate": 1.788772209125514e-05,
      "loss": 0.0146,
      "step": 10350
    },
    {
      "epoch": 0.3171784588066007,
      "grad_norm": 0.05122429504990578,
      "learning_rate": 1.7885681045831674e-05,
      "loss": 0.0036,
      "step": 10360
    },
    {
      "epoch": 0.31748461562012065,
      "grad_norm": 0.04227795451879501,
      "learning_rate": 1.788364000040821e-05,
      "loss": 0.0018,
      "step": 10370
    },
    {
      "epoch": 0.3177907724336405,
      "grad_norm": 0.060926999896764755,
      "learning_rate": 1.7881598954984745e-05,
      "loss": 0.0014,
      "step": 10380
    },
    {
      "epoch": 0.3180969292471604,
      "grad_norm": 0.025453222915530205,
      "learning_rate": 1.787955790956128e-05,
      "loss": 0.0381,
      "step": 10390
    },
    {
      "epoch": 0.3184030860606803,
      "grad_norm": 0.040994372218847275,
      "learning_rate": 1.7877516864137815e-05,
      "loss": 0.0096,
      "step": 10400
    },
    {
      "epoch": 0.31870924287420016,
      "grad_norm": 0.03855001926422119,
      "learning_rate": 1.787547581871435e-05,
      "loss": 0.0342,
      "step": 10410
    },
    {
      "epoch": 0.31901539968772,
      "grad_norm": 0.056189510971307755,
      "learning_rate": 1.787343477329088e-05,
      "loss": 0.0017,
      "step": 10420
    },
    {
      "epoch": 0.31932155650123994,
      "grad_norm": 0.04585723951458931,
      "learning_rate": 1.7871393727867413e-05,
      "loss": 0.0017,
      "step": 10430
    },
    {
      "epoch": 0.3196277133147598,
      "grad_norm": 0.016933083534240723,
      "learning_rate": 1.786935268244395e-05,
      "loss": 0.0015,
      "step": 10440
    },
    {
      "epoch": 0.31993387012827973,
      "grad_norm": 0.02202925831079483,
      "learning_rate": 1.7867311637020484e-05,
      "loss": 0.0318,
      "step": 10450
    },
    {
      "epoch": 0.3202400269417996,
      "grad_norm": 0.050321485847234726,
      "learning_rate": 1.7865270591597017e-05,
      "loss": 0.0321,
      "step": 10460
    },
    {
      "epoch": 0.32054618375531946,
      "grad_norm": 0.02007410302758217,
      "learning_rate": 1.786322954617355e-05,
      "loss": 0.0015,
      "step": 10470
    },
    {
      "epoch": 0.3208523405688394,
      "grad_norm": 0.04429145157337189,
      "learning_rate": 1.7861188500750088e-05,
      "loss": 0.0011,
      "step": 10480
    },
    {
      "epoch": 0.32115849738235924,
      "grad_norm": 0.02156665176153183,
      "learning_rate": 1.7859147455326618e-05,
      "loss": 0.0012,
      "step": 10490
    },
    {
      "epoch": 0.3214646541958791,
      "grad_norm": 0.023408735170960426,
      "learning_rate": 1.7857106409903152e-05,
      "loss": 0.001,
      "step": 10500
    },
    {
      "epoch": 0.321770811009399,
      "grad_norm": 1.60866117477417,
      "learning_rate": 1.785506536447969e-05,
      "loss": 0.0062,
      "step": 10510
    },
    {
      "epoch": 0.3220769678229189,
      "grad_norm": 0.03430253267288208,
      "learning_rate": 1.7853024319056222e-05,
      "loss": 0.0013,
      "step": 10520
    },
    {
      "epoch": 0.3223831246364388,
      "grad_norm": 0.0037413223180919886,
      "learning_rate": 1.7850983273632756e-05,
      "loss": 0.0448,
      "step": 10530
    },
    {
      "epoch": 0.3226892814499587,
      "grad_norm": 0.042463112622499466,
      "learning_rate": 1.784894222820929e-05,
      "loss": 0.035,
      "step": 10540
    },
    {
      "epoch": 0.32299543826347854,
      "grad_norm": 0.02815174125134945,
      "learning_rate": 1.7846901182785827e-05,
      "loss": 0.0594,
      "step": 10550
    },
    {
      "epoch": 0.32330159507699846,
      "grad_norm": 0.018457699567079544,
      "learning_rate": 1.7844860137362357e-05,
      "loss": 0.0017,
      "step": 10560
    },
    {
      "epoch": 0.3236077518905183,
      "grad_norm": 0.029786545783281326,
      "learning_rate": 1.784281909193889e-05,
      "loss": 0.0012,
      "step": 10570
    },
    {
      "epoch": 0.3239139087040382,
      "grad_norm": 1.730644702911377,
      "learning_rate": 1.7840778046515424e-05,
      "loss": 0.0606,
      "step": 10580
    },
    {
      "epoch": 0.3242200655175581,
      "grad_norm": 0.2876411974430084,
      "learning_rate": 1.783873700109196e-05,
      "loss": 0.0605,
      "step": 10590
    },
    {
      "epoch": 0.324526222331078,
      "grad_norm": 0.48382458090782166,
      "learning_rate": 1.7836695955668495e-05,
      "loss": 0.0033,
      "step": 10600
    },
    {
      "epoch": 0.32483237914459784,
      "grad_norm": 0.07578862458467484,
      "learning_rate": 1.783465491024503e-05,
      "loss": 0.0439,
      "step": 10610
    },
    {
      "epoch": 0.32513853595811776,
      "grad_norm": 0.02364085242152214,
      "learning_rate": 1.7832613864821566e-05,
      "loss": 0.0025,
      "step": 10620
    },
    {
      "epoch": 0.3254446927716376,
      "grad_norm": 0.00898872222751379,
      "learning_rate": 1.7830572819398096e-05,
      "loss": 0.002,
      "step": 10630
    },
    {
      "epoch": 0.32575084958515754,
      "grad_norm": 0.005913572385907173,
      "learning_rate": 1.782853177397463e-05,
      "loss": 0.001,
      "step": 10640
    },
    {
      "epoch": 0.3260570063986774,
      "grad_norm": 0.04799184203147888,
      "learning_rate": 1.7826490728551163e-05,
      "loss": 0.0012,
      "step": 10650
    },
    {
      "epoch": 0.32636316321219727,
      "grad_norm": 0.02100125327706337,
      "learning_rate": 1.78244496831277e-05,
      "loss": 0.0008,
      "step": 10660
    },
    {
      "epoch": 0.3266693200257172,
      "grad_norm": 0.05108589679002762,
      "learning_rate": 1.7822408637704234e-05,
      "loss": 0.0428,
      "step": 10670
    },
    {
      "epoch": 0.32697547683923706,
      "grad_norm": 0.025003569200634956,
      "learning_rate": 1.7820367592280768e-05,
      "loss": 0.0019,
      "step": 10680
    },
    {
      "epoch": 0.3272816336527569,
      "grad_norm": 0.03374476358294487,
      "learning_rate": 1.78183265468573e-05,
      "loss": 0.0011,
      "step": 10690
    },
    {
      "epoch": 0.32758779046627684,
      "grad_norm": 0.028423622250556946,
      "learning_rate": 1.7816285501433835e-05,
      "loss": 0.0008,
      "step": 10700
    },
    {
      "epoch": 0.3278939472797967,
      "grad_norm": 0.1037571057677269,
      "learning_rate": 1.781424445601037e-05,
      "loss": 0.0337,
      "step": 10710
    },
    {
      "epoch": 0.32820010409331657,
      "grad_norm": 0.01478256843984127,
      "learning_rate": 1.7812203410586902e-05,
      "loss": 0.0156,
      "step": 10720
    },
    {
      "epoch": 0.3285062609068365,
      "grad_norm": 0.10085092484951019,
      "learning_rate": 1.781016236516344e-05,
      "loss": 0.0402,
      "step": 10730
    },
    {
      "epoch": 0.32881241772035635,
      "grad_norm": 0.046507496386766434,
      "learning_rate": 1.7808121319739973e-05,
      "loss": 0.0286,
      "step": 10740
    },
    {
      "epoch": 0.3291185745338763,
      "grad_norm": 0.028549423441290855,
      "learning_rate": 1.7806080274316506e-05,
      "loss": 0.0016,
      "step": 10750
    },
    {
      "epoch": 0.32942473134739614,
      "grad_norm": 0.014783780090510845,
      "learning_rate": 1.780403922889304e-05,
      "loss": 0.0433,
      "step": 10760
    },
    {
      "epoch": 0.329730888160916,
      "grad_norm": 0.05369236692786217,
      "learning_rate": 1.7801998183469574e-05,
      "loss": 0.0018,
      "step": 10770
    },
    {
      "epoch": 0.3300370449744359,
      "grad_norm": 0.03555240109562874,
      "learning_rate": 1.7799957138046107e-05,
      "loss": 0.0024,
      "step": 10780
    },
    {
      "epoch": 0.3303432017879558,
      "grad_norm": 0.025332719087600708,
      "learning_rate": 1.779791609262264e-05,
      "loss": 0.0325,
      "step": 10790
    },
    {
      "epoch": 0.33064935860147565,
      "grad_norm": 0.01471951138228178,
      "learning_rate": 1.7795875047199175e-05,
      "loss": 0.0009,
      "step": 10800
    },
    {
      "epoch": 0.33095551541499557,
      "grad_norm": 2.0194849967956543,
      "learning_rate": 1.7793834001775712e-05,
      "loss": 0.0404,
      "step": 10810
    },
    {
      "epoch": 0.33126167222851544,
      "grad_norm": 1.7425169944763184,
      "learning_rate": 1.7791792956352245e-05,
      "loss": 0.0328,
      "step": 10820
    },
    {
      "epoch": 0.33156782904203536,
      "grad_norm": 0.06502985954284668,
      "learning_rate": 1.778975191092878e-05,
      "loss": 0.0419,
      "step": 10830
    },
    {
      "epoch": 0.3318739858555552,
      "grad_norm": 0.04157678410410881,
      "learning_rate": 1.7787710865505316e-05,
      "loss": 0.039,
      "step": 10840
    },
    {
      "epoch": 0.3321801426690751,
      "grad_norm": 0.010717798955738544,
      "learning_rate": 1.7785669820081846e-05,
      "loss": 0.0364,
      "step": 10850
    },
    {
      "epoch": 0.332486299482595,
      "grad_norm": 0.031858332455158234,
      "learning_rate": 1.778362877465838e-05,
      "loss": 0.0363,
      "step": 10860
    },
    {
      "epoch": 0.33279245629611487,
      "grad_norm": 0.06263845413923264,
      "learning_rate": 1.7781587729234914e-05,
      "loss": 0.0027,
      "step": 10870
    },
    {
      "epoch": 0.33309861310963473,
      "grad_norm": 1.6452012062072754,
      "learning_rate": 1.777954668381145e-05,
      "loss": 0.0658,
      "step": 10880
    },
    {
      "epoch": 0.33340476992315465,
      "grad_norm": 0.9447057247161865,
      "learning_rate": 1.7777505638387984e-05,
      "loss": 0.031,
      "step": 10890
    },
    {
      "epoch": 0.3337109267366745,
      "grad_norm": 0.042518872767686844,
      "learning_rate": 1.7775464592964518e-05,
      "loss": 0.0039,
      "step": 10900
    },
    {
      "epoch": 0.3340170835501944,
      "grad_norm": 0.06987086683511734,
      "learning_rate": 1.777342354754105e-05,
      "loss": 0.0032,
      "step": 10910
    },
    {
      "epoch": 0.3343232403637143,
      "grad_norm": 0.041736356914043427,
      "learning_rate": 1.7771382502117585e-05,
      "loss": 0.0024,
      "step": 10920
    },
    {
      "epoch": 0.33462939717723417,
      "grad_norm": 0.041308432817459106,
      "learning_rate": 1.776934145669412e-05,
      "loss": 0.0022,
      "step": 10930
    },
    {
      "epoch": 0.3349355539907541,
      "grad_norm": 0.021166305989027023,
      "learning_rate": 1.7767300411270652e-05,
      "loss": 0.0014,
      "step": 10940
    },
    {
      "epoch": 0.33524171080427395,
      "grad_norm": 0.024036867544054985,
      "learning_rate": 1.776525936584719e-05,
      "loss": 0.0012,
      "step": 10950
    },
    {
      "epoch": 0.3355478676177938,
      "grad_norm": 0.038761746138334274,
      "learning_rate": 1.7763218320423723e-05,
      "loss": 0.0016,
      "step": 10960
    },
    {
      "epoch": 0.33585402443131374,
      "grad_norm": 0.04432668536901474,
      "learning_rate": 1.7761177275000257e-05,
      "loss": 0.0461,
      "step": 10970
    },
    {
      "epoch": 0.3361601812448336,
      "grad_norm": 0.03417384624481201,
      "learning_rate": 1.775913622957679e-05,
      "loss": 0.0016,
      "step": 10980
    },
    {
      "epoch": 0.33646633805835346,
      "grad_norm": 0.02066570147871971,
      "learning_rate": 1.7757095184153324e-05,
      "loss": 0.0343,
      "step": 10990
    },
    {
      "epoch": 0.3367724948718734,
      "grad_norm": 0.03924468904733658,
      "learning_rate": 1.7755054138729858e-05,
      "loss": 0.0328,
      "step": 11000
    },
    {
      "epoch": 0.33707865168539325,
      "grad_norm": 0.06726635992527008,
      "learning_rate": 1.775301309330639e-05,
      "loss": 0.0025,
      "step": 11010
    },
    {
      "epoch": 0.33738480849891317,
      "grad_norm": 0.030113669112324715,
      "learning_rate": 1.7750972047882925e-05,
      "loss": 0.0374,
      "step": 11020
    },
    {
      "epoch": 0.33769096531243303,
      "grad_norm": 0.04823658615350723,
      "learning_rate": 1.7748931002459462e-05,
      "loss": 0.0014,
      "step": 11030
    },
    {
      "epoch": 0.3379971221259529,
      "grad_norm": 1.8309359550476074,
      "learning_rate": 1.7746889957035996e-05,
      "loss": 0.0658,
      "step": 11040
    },
    {
      "epoch": 0.3383032789394728,
      "grad_norm": 0.02747470512986183,
      "learning_rate": 1.774484891161253e-05,
      "loss": 0.0023,
      "step": 11050
    },
    {
      "epoch": 0.3386094357529927,
      "grad_norm": 0.029036149382591248,
      "learning_rate": 1.7742807866189063e-05,
      "loss": 0.0335,
      "step": 11060
    },
    {
      "epoch": 0.33891559256651255,
      "grad_norm": 0.027602944523096085,
      "learning_rate": 1.7740766820765597e-05,
      "loss": 0.0014,
      "step": 11070
    },
    {
      "epoch": 0.33922174938003247,
      "grad_norm": 0.039086684584617615,
      "learning_rate": 1.773872577534213e-05,
      "loss": 0.0422,
      "step": 11080
    },
    {
      "epoch": 0.33952790619355233,
      "grad_norm": 0.06905126571655273,
      "learning_rate": 1.7736684729918664e-05,
      "loss": 0.0121,
      "step": 11090
    },
    {
      "epoch": 0.3398340630070722,
      "grad_norm": 0.03363274782896042,
      "learning_rate": 1.77346436844952e-05,
      "loss": 0.0019,
      "step": 11100
    },
    {
      "epoch": 0.3401402198205921,
      "grad_norm": 0.11805882304906845,
      "learning_rate": 1.7732602639071735e-05,
      "loss": 0.0097,
      "step": 11110
    },
    {
      "epoch": 0.340446376634112,
      "grad_norm": 0.017639633268117905,
      "learning_rate": 1.7730561593648268e-05,
      "loss": 0.0017,
      "step": 11120
    },
    {
      "epoch": 0.3407525334476319,
      "grad_norm": 0.05236702412366867,
      "learning_rate": 1.7728520548224802e-05,
      "loss": 0.111,
      "step": 11130
    },
    {
      "epoch": 0.34105869026115176,
      "grad_norm": 0.10737938433885574,
      "learning_rate": 1.7726479502801336e-05,
      "loss": 0.002,
      "step": 11140
    },
    {
      "epoch": 0.34136484707467163,
      "grad_norm": 0.047601789236068726,
      "learning_rate": 1.772443845737787e-05,
      "loss": 0.0325,
      "step": 11150
    },
    {
      "epoch": 0.34167100388819155,
      "grad_norm": 0.042916957288980484,
      "learning_rate": 1.7722397411954403e-05,
      "loss": 0.0035,
      "step": 11160
    },
    {
      "epoch": 0.3419771607017114,
      "grad_norm": 0.04639723524451256,
      "learning_rate": 1.7720356366530936e-05,
      "loss": 0.0026,
      "step": 11170
    },
    {
      "epoch": 0.3422833175152313,
      "grad_norm": 0.03542499616742134,
      "learning_rate": 1.7718315321107473e-05,
      "loss": 0.0372,
      "step": 11180
    },
    {
      "epoch": 0.3425894743287512,
      "grad_norm": 0.015837159007787704,
      "learning_rate": 1.7716274275684007e-05,
      "loss": 0.0307,
      "step": 11190
    },
    {
      "epoch": 0.34289563114227106,
      "grad_norm": 0.06896734237670898,
      "learning_rate": 1.771423323026054e-05,
      "loss": 0.0019,
      "step": 11200
    },
    {
      "epoch": 0.343201787955791,
      "grad_norm": 0.020962990820407867,
      "learning_rate": 1.7712192184837074e-05,
      "loss": 0.0014,
      "step": 11210
    },
    {
      "epoch": 0.34350794476931085,
      "grad_norm": 0.0789683610200882,
      "learning_rate": 1.7710151139413608e-05,
      "loss": 0.0019,
      "step": 11220
    },
    {
      "epoch": 0.3438141015828307,
      "grad_norm": 0.019824888557195663,
      "learning_rate": 1.7708110093990142e-05,
      "loss": 0.0013,
      "step": 11230
    },
    {
      "epoch": 0.34412025839635063,
      "grad_norm": 0.01922537013888359,
      "learning_rate": 1.7706069048566675e-05,
      "loss": 0.0025,
      "step": 11240
    },
    {
      "epoch": 0.3444264152098705,
      "grad_norm": 0.04303089156746864,
      "learning_rate": 1.7704028003143212e-05,
      "loss": 0.0367,
      "step": 11250
    },
    {
      "epoch": 0.34473257202339036,
      "grad_norm": 0.049327220767736435,
      "learning_rate": 1.7701986957719746e-05,
      "loss": 0.0012,
      "step": 11260
    },
    {
      "epoch": 0.3450387288369103,
      "grad_norm": 0.0418405644595623,
      "learning_rate": 1.769994591229628e-05,
      "loss": 0.0021,
      "step": 11270
    },
    {
      "epoch": 0.34534488565043014,
      "grad_norm": 0.029834406450390816,
      "learning_rate": 1.7697904866872813e-05,
      "loss": 0.0011,
      "step": 11280
    },
    {
      "epoch": 0.34565104246395,
      "grad_norm": 0.016147015616297722,
      "learning_rate": 1.7695863821449347e-05,
      "loss": 0.0045,
      "step": 11290
    },
    {
      "epoch": 0.34595719927746993,
      "grad_norm": 0.04842892661690712,
      "learning_rate": 1.769382277602588e-05,
      "loss": 0.0739,
      "step": 11300
    },
    {
      "epoch": 0.3462633560909898,
      "grad_norm": 0.008501023054122925,
      "learning_rate": 1.7691781730602414e-05,
      "loss": 0.0028,
      "step": 11310
    },
    {
      "epoch": 0.3465695129045097,
      "grad_norm": 0.054002273827791214,
      "learning_rate": 1.768974068517895e-05,
      "loss": 0.004,
      "step": 11320
    },
    {
      "epoch": 0.3468756697180296,
      "grad_norm": 5.222442626953125,
      "learning_rate": 1.7687699639755485e-05,
      "loss": 0.1175,
      "step": 11330
    },
    {
      "epoch": 0.34718182653154944,
      "grad_norm": 0.09261909127235413,
      "learning_rate": 1.768565859433202e-05,
      "loss": 0.0713,
      "step": 11340
    },
    {
      "epoch": 0.34748798334506936,
      "grad_norm": 0.08180230110883713,
      "learning_rate": 1.7683617548908552e-05,
      "loss": 0.0324,
      "step": 11350
    },
    {
      "epoch": 0.3477941401585892,
      "grad_norm": 0.06646127998828888,
      "learning_rate": 1.7681576503485086e-05,
      "loss": 0.037,
      "step": 11360
    },
    {
      "epoch": 0.3481002969721091,
      "grad_norm": 1.503400444984436,
      "learning_rate": 1.767953545806162e-05,
      "loss": 0.0167,
      "step": 11370
    },
    {
      "epoch": 0.348406453785629,
      "grad_norm": 0.0192978885024786,
      "learning_rate": 1.7677494412638153e-05,
      "loss": 0.0567,
      "step": 11380
    },
    {
      "epoch": 0.3487126105991489,
      "grad_norm": 1.6532824039459229,
      "learning_rate": 1.7675453367214687e-05,
      "loss": 0.0513,
      "step": 11390
    },
    {
      "epoch": 0.3490187674126688,
      "grad_norm": 0.027995213866233826,
      "learning_rate": 1.7673412321791224e-05,
      "loss": 0.0022,
      "step": 11400
    },
    {
      "epoch": 0.34932492422618866,
      "grad_norm": 0.03520561009645462,
      "learning_rate": 1.7671371276367757e-05,
      "loss": 0.0018,
      "step": 11410
    },
    {
      "epoch": 0.3496310810397085,
      "grad_norm": 0.013280617073178291,
      "learning_rate": 1.766933023094429e-05,
      "loss": 0.0019,
      "step": 11420
    },
    {
      "epoch": 0.34993723785322844,
      "grad_norm": 0.034314244985580444,
      "learning_rate": 1.7667289185520825e-05,
      "loss": 0.0016,
      "step": 11430
    },
    {
      "epoch": 0.3502433946667483,
      "grad_norm": 0.009172050282359123,
      "learning_rate": 1.766524814009736e-05,
      "loss": 0.042,
      "step": 11440
    },
    {
      "epoch": 0.3505495514802682,
      "grad_norm": 0.10959140956401825,
      "learning_rate": 1.7663207094673892e-05,
      "loss": 0.0328,
      "step": 11450
    },
    {
      "epoch": 0.3508557082937881,
      "grad_norm": 0.054676562547683716,
      "learning_rate": 1.7661166049250426e-05,
      "loss": 0.0349,
      "step": 11460
    },
    {
      "epoch": 0.35116186510730796,
      "grad_norm": 0.028644513338804245,
      "learning_rate": 1.7659125003826963e-05,
      "loss": 0.0025,
      "step": 11470
    },
    {
      "epoch": 0.3514680219208278,
      "grad_norm": 0.02861580066382885,
      "learning_rate": 1.7657083958403496e-05,
      "loss": 0.0022,
      "step": 11480
    },
    {
      "epoch": 0.35177417873434774,
      "grad_norm": 0.031778570264577866,
      "learning_rate": 1.765504291298003e-05,
      "loss": 0.0021,
      "step": 11490
    },
    {
      "epoch": 0.3520803355478676,
      "grad_norm": 0.14869895577430725,
      "learning_rate": 1.7653001867556564e-05,
      "loss": 0.0018,
      "step": 11500
    },
    {
      "epoch": 0.3523864923613875,
      "grad_norm": 0.08941836655139923,
      "learning_rate": 1.7650960822133097e-05,
      "loss": 0.0018,
      "step": 11510
    },
    {
      "epoch": 0.3526926491749074,
      "grad_norm": 0.10013434290885925,
      "learning_rate": 1.764891977670963e-05,
      "loss": 0.0017,
      "step": 11520
    },
    {
      "epoch": 0.35299880598842726,
      "grad_norm": 0.06523703783750534,
      "learning_rate": 1.7646878731286165e-05,
      "loss": 0.039,
      "step": 11530
    },
    {
      "epoch": 0.3533049628019472,
      "grad_norm": 0.08795066177845001,
      "learning_rate": 1.76448376858627e-05,
      "loss": 0.002,
      "step": 11540
    },
    {
      "epoch": 0.35361111961546704,
      "grad_norm": 0.019302673637866974,
      "learning_rate": 1.7642796640439235e-05,
      "loss": 0.0358,
      "step": 11550
    },
    {
      "epoch": 0.3539172764289869,
      "grad_norm": 0.03519282117486,
      "learning_rate": 1.764075559501577e-05,
      "loss": 0.0319,
      "step": 11560
    },
    {
      "epoch": 0.3542234332425068,
      "grad_norm": 0.05409332737326622,
      "learning_rate": 1.7638714549592303e-05,
      "loss": 0.0275,
      "step": 11570
    },
    {
      "epoch": 0.3545295900560267,
      "grad_norm": 0.03080766461789608,
      "learning_rate": 1.7636673504168836e-05,
      "loss": 0.0022,
      "step": 11580
    },
    {
      "epoch": 0.3548357468695466,
      "grad_norm": 0.016747813671827316,
      "learning_rate": 1.763463245874537e-05,
      "loss": 0.0013,
      "step": 11590
    },
    {
      "epoch": 0.3551419036830665,
      "grad_norm": 0.03079608455300331,
      "learning_rate": 1.7632591413321903e-05,
      "loss": 0.002,
      "step": 11600
    },
    {
      "epoch": 0.35544806049658634,
      "grad_norm": 0.015274613164365292,
      "learning_rate": 1.7630550367898437e-05,
      "loss": 0.0229,
      "step": 11610
    },
    {
      "epoch": 0.35575421731010626,
      "grad_norm": 0.024980273097753525,
      "learning_rate": 1.7628509322474974e-05,
      "loss": 0.0014,
      "step": 11620
    },
    {
      "epoch": 0.3560603741236261,
      "grad_norm": 0.010886164382100105,
      "learning_rate": 1.7626468277051508e-05,
      "loss": 0.0048,
      "step": 11630
    },
    {
      "epoch": 0.356366530937146,
      "grad_norm": 0.035018473863601685,
      "learning_rate": 1.762442723162804e-05,
      "loss": 0.0025,
      "step": 11640
    },
    {
      "epoch": 0.3566726877506659,
      "grad_norm": 0.033462993800640106,
      "learning_rate": 1.7622386186204575e-05,
      "loss": 0.001,
      "step": 11650
    },
    {
      "epoch": 0.35697884456418577,
      "grad_norm": 0.034158844500780106,
      "learning_rate": 1.762034514078111e-05,
      "loss": 0.001,
      "step": 11660
    },
    {
      "epoch": 0.35728500137770564,
      "grad_norm": 0.02091940864920616,
      "learning_rate": 1.7618304095357642e-05,
      "loss": 0.0009,
      "step": 11670
    },
    {
      "epoch": 0.35759115819122556,
      "grad_norm": 0.019705427810549736,
      "learning_rate": 1.7616263049934176e-05,
      "loss": 0.0399,
      "step": 11680
    },
    {
      "epoch": 0.3578973150047454,
      "grad_norm": 0.019887784495949745,
      "learning_rate": 1.7614222004510713e-05,
      "loss": 0.0335,
      "step": 11690
    },
    {
      "epoch": 0.35820347181826534,
      "grad_norm": 0.024474894627928734,
      "learning_rate": 1.7612180959087247e-05,
      "loss": 0.036,
      "step": 11700
    },
    {
      "epoch": 0.3585096286317852,
      "grad_norm": 0.04917604848742485,
      "learning_rate": 1.761013991366378e-05,
      "loss": 0.0029,
      "step": 11710
    },
    {
      "epoch": 0.35881578544530507,
      "grad_norm": 0.033272307366132736,
      "learning_rate": 1.7608098868240314e-05,
      "loss": 0.0011,
      "step": 11720
    },
    {
      "epoch": 0.359121942258825,
      "grad_norm": 0.19008252024650574,
      "learning_rate": 1.7606057822816848e-05,
      "loss": 0.0436,
      "step": 11730
    },
    {
      "epoch": 0.35942809907234485,
      "grad_norm": 0.04973885044455528,
      "learning_rate": 1.760401677739338e-05,
      "loss": 0.0017,
      "step": 11740
    },
    {
      "epoch": 0.3597342558858647,
      "grad_norm": 0.017073506489396095,
      "learning_rate": 1.7601975731969915e-05,
      "loss": 0.0014,
      "step": 11750
    },
    {
      "epoch": 0.36004041269938464,
      "grad_norm": 0.009747548960149288,
      "learning_rate": 1.7599934686546452e-05,
      "loss": 0.0007,
      "step": 11760
    },
    {
      "epoch": 0.3603465695129045,
      "grad_norm": 0.028553979471325874,
      "learning_rate": 1.7597893641122986e-05,
      "loss": 0.0006,
      "step": 11770
    },
    {
      "epoch": 0.3606527263264244,
      "grad_norm": 0.019500350579619408,
      "learning_rate": 1.759585259569952e-05,
      "loss": 0.0006,
      "step": 11780
    },
    {
      "epoch": 0.3609588831399443,
      "grad_norm": 0.026938917115330696,
      "learning_rate": 1.7593811550276053e-05,
      "loss": 0.0327,
      "step": 11790
    },
    {
      "epoch": 0.36126503995346415,
      "grad_norm": 0.03587546944618225,
      "learning_rate": 1.7591770504852587e-05,
      "loss": 0.0009,
      "step": 11800
    },
    {
      "epoch": 0.36157119676698407,
      "grad_norm": 0.03288710117340088,
      "learning_rate": 1.758972945942912e-05,
      "loss": 0.0014,
      "step": 11810
    },
    {
      "epoch": 0.36187735358050394,
      "grad_norm": 0.026555482298135757,
      "learning_rate": 1.7587688414005654e-05,
      "loss": 0.0007,
      "step": 11820
    },
    {
      "epoch": 0.3621835103940238,
      "grad_norm": 0.009071022272109985,
      "learning_rate": 1.7585647368582187e-05,
      "loss": 0.0012,
      "step": 11830
    },
    {
      "epoch": 0.3624896672075437,
      "grad_norm": 0.02367115579545498,
      "learning_rate": 1.7583606323158724e-05,
      "loss": 0.0937,
      "step": 11840
    },
    {
      "epoch": 0.3627958240210636,
      "grad_norm": 1.8171284198760986,
      "learning_rate": 1.7581565277735258e-05,
      "loss": 0.0624,
      "step": 11850
    },
    {
      "epoch": 0.36310198083458345,
      "grad_norm": 0.01316633727401495,
      "learning_rate": 1.7579524232311792e-05,
      "loss": 0.0396,
      "step": 11860
    },
    {
      "epoch": 0.36340813764810337,
      "grad_norm": 0.07031617313623428,
      "learning_rate": 1.7577483186888325e-05,
      "loss": 0.0117,
      "step": 11870
    },
    {
      "epoch": 0.36371429446162323,
      "grad_norm": 0.05806499719619751,
      "learning_rate": 1.757544214146486e-05,
      "loss": 0.0267,
      "step": 11880
    },
    {
      "epoch": 0.36402045127514315,
      "grad_norm": 0.06271999329328537,
      "learning_rate": 1.7573401096041393e-05,
      "loss": 0.0661,
      "step": 11890
    },
    {
      "epoch": 0.364326608088663,
      "grad_norm": 0.11428623646497726,
      "learning_rate": 1.7571360050617926e-05,
      "loss": 0.0287,
      "step": 11900
    },
    {
      "epoch": 0.3646327649021829,
      "grad_norm": 0.07397312670946121,
      "learning_rate": 1.7569319005194463e-05,
      "loss": 0.0027,
      "step": 11910
    },
    {
      "epoch": 0.3649389217157028,
      "grad_norm": 0.049083162099123,
      "learning_rate": 1.7567277959770997e-05,
      "loss": 0.0041,
      "step": 11920
    },
    {
      "epoch": 0.36524507852922267,
      "grad_norm": 0.030406035482883453,
      "learning_rate": 1.756523691434753e-05,
      "loss": 0.0354,
      "step": 11930
    },
    {
      "epoch": 0.36555123534274253,
      "grad_norm": 0.047867145389318466,
      "learning_rate": 1.7563195868924064e-05,
      "loss": 0.0578,
      "step": 11940
    },
    {
      "epoch": 0.36585739215626245,
      "grad_norm": 0.06936131417751312,
      "learning_rate": 1.7561154823500598e-05,
      "loss": 0.0201,
      "step": 11950
    },
    {
      "epoch": 0.3661635489697823,
      "grad_norm": 0.10096479952335358,
      "learning_rate": 1.755911377807713e-05,
      "loss": 0.0276,
      "step": 11960
    },
    {
      "epoch": 0.3664697057833022,
      "grad_norm": 0.13139104843139648,
      "learning_rate": 1.7557072732653665e-05,
      "loss": 0.0041,
      "step": 11970
    },
    {
      "epoch": 0.3667758625968221,
      "grad_norm": 0.049023427069187164,
      "learning_rate": 1.7555031687230202e-05,
      "loss": 0.0035,
      "step": 11980
    },
    {
      "epoch": 0.36708201941034196,
      "grad_norm": 0.04078824073076248,
      "learning_rate": 1.7552990641806736e-05,
      "loss": 0.0026,
      "step": 11990
    },
    {
      "epoch": 0.3673881762238619,
      "grad_norm": 0.04398959130048752,
      "learning_rate": 1.755094959638327e-05,
      "loss": 0.0152,
      "step": 12000
    },
    {
      "epoch": 0.36769433303738175,
      "grad_norm": 0.35555413365364075,
      "learning_rate": 1.7548908550959803e-05,
      "loss": 0.003,
      "step": 12010
    },
    {
      "epoch": 0.3680004898509016,
      "grad_norm": 0.039982374757528305,
      "learning_rate": 1.7546867505536337e-05,
      "loss": 0.0394,
      "step": 12020
    },
    {
      "epoch": 0.36830664666442153,
      "grad_norm": 0.051180023699998856,
      "learning_rate": 1.754482646011287e-05,
      "loss": 0.0285,
      "step": 12030
    },
    {
      "epoch": 0.3686128034779414,
      "grad_norm": 0.003990381024777889,
      "learning_rate": 1.7542785414689404e-05,
      "loss": 0.0022,
      "step": 12040
    },
    {
      "epoch": 0.36891896029146126,
      "grad_norm": 0.05637151002883911,
      "learning_rate": 1.7540744369265938e-05,
      "loss": 0.002,
      "step": 12050
    },
    {
      "epoch": 0.3692251171049812,
      "grad_norm": 0.05135265365242958,
      "learning_rate": 1.7538703323842475e-05,
      "loss": 0.0016,
      "step": 12060
    },
    {
      "epoch": 0.36953127391850105,
      "grad_norm": 0.03396831452846527,
      "learning_rate": 1.753666227841901e-05,
      "loss": 0.0601,
      "step": 12070
    },
    {
      "epoch": 0.36983743073202097,
      "grad_norm": 0.05214151740074158,
      "learning_rate": 1.7534621232995542e-05,
      "loss": 0.0041,
      "step": 12080
    },
    {
      "epoch": 0.37014358754554083,
      "grad_norm": 0.05189814418554306,
      "learning_rate": 1.7532580187572076e-05,
      "loss": 0.0268,
      "step": 12090
    },
    {
      "epoch": 0.3704497443590607,
      "grad_norm": 0.021366046741604805,
      "learning_rate": 1.753053914214861e-05,
      "loss": 0.002,
      "step": 12100
    },
    {
      "epoch": 0.3707559011725806,
      "grad_norm": 0.0681316927075386,
      "learning_rate": 1.7528498096725143e-05,
      "loss": 0.0023,
      "step": 12110
    },
    {
      "epoch": 0.3710620579861005,
      "grad_norm": 0.025987129658460617,
      "learning_rate": 1.7526457051301677e-05,
      "loss": 0.0228,
      "step": 12120
    },
    {
      "epoch": 0.37136821479962034,
      "grad_norm": 0.040308013558387756,
      "learning_rate": 1.7524416005878214e-05,
      "loss": 0.0021,
      "step": 12130
    },
    {
      "epoch": 0.37167437161314026,
      "grad_norm": 0.041839033365249634,
      "learning_rate": 1.7522374960454747e-05,
      "loss": 0.0026,
      "step": 12140
    },
    {
      "epoch": 0.37198052842666013,
      "grad_norm": 0.055155303329229355,
      "learning_rate": 1.752033391503128e-05,
      "loss": 0.0014,
      "step": 12150
    },
    {
      "epoch": 0.37228668524018,
      "grad_norm": 0.021476952359080315,
      "learning_rate": 1.7518292869607815e-05,
      "loss": 0.0389,
      "step": 12160
    },
    {
      "epoch": 0.3725928420536999,
      "grad_norm": 0.025648538023233414,
      "learning_rate": 1.751625182418435e-05,
      "loss": 0.0014,
      "step": 12170
    },
    {
      "epoch": 0.3728989988672198,
      "grad_norm": 0.012515462003648281,
      "learning_rate": 1.7514210778760882e-05,
      "loss": 0.0335,
      "step": 12180
    },
    {
      "epoch": 0.3732051556807397,
      "grad_norm": 2.7386975288391113,
      "learning_rate": 1.7512169733337416e-05,
      "loss": 0.0107,
      "step": 12190
    },
    {
      "epoch": 0.37351131249425956,
      "grad_norm": 0.07655363529920578,
      "learning_rate": 1.7510128687913953e-05,
      "loss": 0.006,
      "step": 12200
    },
    {
      "epoch": 0.3738174693077794,
      "grad_norm": 0.015934379771351814,
      "learning_rate": 1.7508087642490486e-05,
      "loss": 0.0375,
      "step": 12210
    },
    {
      "epoch": 0.37412362612129935,
      "grad_norm": 0.044340286403894424,
      "learning_rate": 1.750604659706702e-05,
      "loss": 0.0012,
      "step": 12220
    },
    {
      "epoch": 0.3744297829348192,
      "grad_norm": 0.027738112956285477,
      "learning_rate": 1.7504005551643554e-05,
      "loss": 0.001,
      "step": 12230
    },
    {
      "epoch": 0.3747359397483391,
      "grad_norm": 0.053542859852313995,
      "learning_rate": 1.7501964506220087e-05,
      "loss": 0.0014,
      "step": 12240
    },
    {
      "epoch": 0.375042096561859,
      "grad_norm": 0.025997668504714966,
      "learning_rate": 1.749992346079662e-05,
      "loss": 0.0333,
      "step": 12250
    },
    {
      "epoch": 0.37534825337537886,
      "grad_norm": 0.02498629316687584,
      "learning_rate": 1.7497882415373154e-05,
      "loss": 0.0008,
      "step": 12260
    },
    {
      "epoch": 0.3756544101888988,
      "grad_norm": 0.029913488775491714,
      "learning_rate": 1.7495841369949688e-05,
      "loss": 0.0017,
      "step": 12270
    },
    {
      "epoch": 0.37596056700241864,
      "grad_norm": 1.892536997795105,
      "learning_rate": 1.7493800324526225e-05,
      "loss": 0.0343,
      "step": 12280
    },
    {
      "epoch": 0.3762667238159385,
      "grad_norm": 0.035309258848428726,
      "learning_rate": 1.749175927910276e-05,
      "loss": 0.0437,
      "step": 12290
    },
    {
      "epoch": 0.37657288062945843,
      "grad_norm": 0.00564960902556777,
      "learning_rate": 1.7489718233679292e-05,
      "loss": 0.0633,
      "step": 12300
    },
    {
      "epoch": 0.3768790374429783,
      "grad_norm": 0.039364319294691086,
      "learning_rate": 1.7487677188255826e-05,
      "loss": 0.0437,
      "step": 12310
    },
    {
      "epoch": 0.37718519425649816,
      "grad_norm": 0.02558041363954544,
      "learning_rate": 1.748563614283236e-05,
      "loss": 0.0029,
      "step": 12320
    },
    {
      "epoch": 0.3774913510700181,
      "grad_norm": 0.09339267015457153,
      "learning_rate": 1.7483595097408893e-05,
      "loss": 0.0025,
      "step": 12330
    },
    {
      "epoch": 0.37779750788353794,
      "grad_norm": 0.09922680258750916,
      "learning_rate": 1.7481554051985427e-05,
      "loss": 0.0021,
      "step": 12340
    },
    {
      "epoch": 0.3781036646970578,
      "grad_norm": 0.022783398628234863,
      "learning_rate": 1.7479513006561964e-05,
      "loss": 0.0025,
      "step": 12350
    },
    {
      "epoch": 0.3784098215105777,
      "grad_norm": 0.008867920376360416,
      "learning_rate": 1.7477471961138498e-05,
      "loss": 0.031,
      "step": 12360
    },
    {
      "epoch": 0.3787159783240976,
      "grad_norm": 0.03499045968055725,
      "learning_rate": 1.747543091571503e-05,
      "loss": 0.0021,
      "step": 12370
    },
    {
      "epoch": 0.3790221351376175,
      "grad_norm": 0.012548143044114113,
      "learning_rate": 1.7473389870291565e-05,
      "loss": 0.0014,
      "step": 12380
    },
    {
      "epoch": 0.3793282919511374,
      "grad_norm": 0.02324303239583969,
      "learning_rate": 1.74713488248681e-05,
      "loss": 0.0009,
      "step": 12390
    },
    {
      "epoch": 0.37963444876465724,
      "grad_norm": 0.09217123687267303,
      "learning_rate": 1.7469307779444632e-05,
      "loss": 0.0017,
      "step": 12400
    },
    {
      "epoch": 0.37994060557817716,
      "grad_norm": 0.010761336423456669,
      "learning_rate": 1.7467266734021166e-05,
      "loss": 0.0009,
      "step": 12410
    },
    {
      "epoch": 0.380246762391697,
      "grad_norm": 0.05227310210466385,
      "learning_rate": 1.74652256885977e-05,
      "loss": 0.0013,
      "step": 12420
    },
    {
      "epoch": 0.3805529192052169,
      "grad_norm": 1.8157321214675903,
      "learning_rate": 1.7463184643174237e-05,
      "loss": 0.0647,
      "step": 12430
    },
    {
      "epoch": 0.3808590760187368,
      "grad_norm": 0.03426196798682213,
      "learning_rate": 1.746114359775077e-05,
      "loss": 0.0347,
      "step": 12440
    },
    {
      "epoch": 0.3811652328322567,
      "grad_norm": 0.02586415596306324,
      "learning_rate": 1.7459102552327304e-05,
      "loss": 0.0014,
      "step": 12450
    },
    {
      "epoch": 0.3814713896457766,
      "grad_norm": 0.011361973360180855,
      "learning_rate": 1.7457061506903838e-05,
      "loss": 0.0016,
      "step": 12460
    },
    {
      "epoch": 0.38177754645929646,
      "grad_norm": 0.019273070618510246,
      "learning_rate": 1.745502046148037e-05,
      "loss": 0.0015,
      "step": 12470
    },
    {
      "epoch": 0.3820837032728163,
      "grad_norm": 0.01569528877735138,
      "learning_rate": 1.7452979416056905e-05,
      "loss": 0.0418,
      "step": 12480
    },
    {
      "epoch": 0.38238986008633624,
      "grad_norm": 1.5128895044326782,
      "learning_rate": 1.745093837063344e-05,
      "loss": 0.1113,
      "step": 12490
    },
    {
      "epoch": 0.3826960168998561,
      "grad_norm": 0.11427513509988785,
      "learning_rate": 1.7448897325209976e-05,
      "loss": 0.0039,
      "step": 12500
    },
    {
      "epoch": 0.38300217371337597,
      "grad_norm": 0.13620106875896454,
      "learning_rate": 1.744685627978651e-05,
      "loss": 0.0044,
      "step": 12510
    },
    {
      "epoch": 0.3833083305268959,
      "grad_norm": 0.08537543565034866,
      "learning_rate": 1.7444815234363043e-05,
      "loss": 0.0039,
      "step": 12520
    },
    {
      "epoch": 0.38361448734041576,
      "grad_norm": 0.0527745857834816,
      "learning_rate": 1.7442774188939576e-05,
      "loss": 0.0438,
      "step": 12530
    },
    {
      "epoch": 0.3839206441539356,
      "grad_norm": 0.02066088281571865,
      "learning_rate": 1.744073314351611e-05,
      "loss": 0.0282,
      "step": 12540
    },
    {
      "epoch": 0.38422680096745554,
      "grad_norm": 0.060596201568841934,
      "learning_rate": 1.7438692098092644e-05,
      "loss": 0.0026,
      "step": 12550
    },
    {
      "epoch": 0.3845329577809754,
      "grad_norm": 0.04738183692097664,
      "learning_rate": 1.7436651052669177e-05,
      "loss": 0.0023,
      "step": 12560
    },
    {
      "epoch": 0.3848391145944953,
      "grad_norm": 0.03968313708901405,
      "learning_rate": 1.7434610007245714e-05,
      "loss": 0.002,
      "step": 12570
    },
    {
      "epoch": 0.3851452714080152,
      "grad_norm": 0.006997080985456705,
      "learning_rate": 1.7432568961822248e-05,
      "loss": 0.0368,
      "step": 12580
    },
    {
      "epoch": 0.38545142822153505,
      "grad_norm": 0.4356972873210907,
      "learning_rate": 1.7430527916398782e-05,
      "loss": 0.0025,
      "step": 12590
    },
    {
      "epoch": 0.385757585035055,
      "grad_norm": 0.027688875794410706,
      "learning_rate": 1.7428486870975315e-05,
      "loss": 0.0013,
      "step": 12600
    },
    {
      "epoch": 0.38606374184857484,
      "grad_norm": 0.03687868267297745,
      "learning_rate": 1.742644582555185e-05,
      "loss": 0.0307,
      "step": 12610
    },
    {
      "epoch": 0.3863698986620947,
      "grad_norm": 0.1420048475265503,
      "learning_rate": 1.7424404780128383e-05,
      "loss": 0.0297,
      "step": 12620
    },
    {
      "epoch": 0.3866760554756146,
      "grad_norm": 0.07679887115955353,
      "learning_rate": 1.7422363734704916e-05,
      "loss": 0.0854,
      "step": 12630
    },
    {
      "epoch": 0.3869822122891345,
      "grad_norm": 0.07292316854000092,
      "learning_rate": 1.742032268928145e-05,
      "loss": 0.0228,
      "step": 12640
    },
    {
      "epoch": 0.3872883691026544,
      "grad_norm": 0.03763597086071968,
      "learning_rate": 1.7418281643857987e-05,
      "loss": 0.0034,
      "step": 12650
    },
    {
      "epoch": 0.38759452591617427,
      "grad_norm": 0.1291840672492981,
      "learning_rate": 1.741624059843452e-05,
      "loss": 0.0289,
      "step": 12660
    },
    {
      "epoch": 0.38790068272969414,
      "grad_norm": 0.09288887679576874,
      "learning_rate": 1.7414199553011054e-05,
      "loss": 0.0035,
      "step": 12670
    },
    {
      "epoch": 0.38820683954321406,
      "grad_norm": 0.03942070156335831,
      "learning_rate": 1.7412158507587588e-05,
      "loss": 0.0024,
      "step": 12680
    },
    {
      "epoch": 0.3885129963567339,
      "grad_norm": 0.02683218941092491,
      "learning_rate": 1.741011746216412e-05,
      "loss": 0.0278,
      "step": 12690
    },
    {
      "epoch": 0.3888191531702538,
      "grad_norm": 0.029945995658636093,
      "learning_rate": 1.7408076416740655e-05,
      "loss": 0.0377,
      "step": 12700
    },
    {
      "epoch": 0.3891253099837737,
      "grad_norm": 0.016977651044726372,
      "learning_rate": 1.740603537131719e-05,
      "loss": 0.0032,
      "step": 12710
    },
    {
      "epoch": 0.38943146679729357,
      "grad_norm": 0.0323110856115818,
      "learning_rate": 1.7403994325893726e-05,
      "loss": 0.0021,
      "step": 12720
    },
    {
      "epoch": 0.38973762361081343,
      "grad_norm": 0.018039319664239883,
      "learning_rate": 1.740195328047026e-05,
      "loss": 0.0023,
      "step": 12730
    },
    {
      "epoch": 0.39004378042433335,
      "grad_norm": 0.03642741218209267,
      "learning_rate": 1.7399912235046793e-05,
      "loss": 0.0454,
      "step": 12740
    },
    {
      "epoch": 0.3903499372378532,
      "grad_norm": 0.028347773477435112,
      "learning_rate": 1.7397871189623327e-05,
      "loss": 0.0018,
      "step": 12750
    },
    {
      "epoch": 0.39065609405137314,
      "grad_norm": 0.0328017957508564,
      "learning_rate": 1.739583014419986e-05,
      "loss": 0.0031,
      "step": 12760
    },
    {
      "epoch": 0.390962250864893,
      "grad_norm": 0.021331600844860077,
      "learning_rate": 1.7393789098776394e-05,
      "loss": 0.0015,
      "step": 12770
    },
    {
      "epoch": 0.39126840767841287,
      "grad_norm": 0.11371178179979324,
      "learning_rate": 1.7391748053352928e-05,
      "loss": 0.0201,
      "step": 12780
    },
    {
      "epoch": 0.3915745644919328,
      "grad_norm": 0.03787752240896225,
      "learning_rate": 1.7389707007929465e-05,
      "loss": 0.0013,
      "step": 12790
    },
    {
      "epoch": 0.39188072130545265,
      "grad_norm": 0.01324195135384798,
      "learning_rate": 1.7387665962506e-05,
      "loss": 0.0013,
      "step": 12800
    },
    {
      "epoch": 0.3921868781189725,
      "grad_norm": 0.022800719365477562,
      "learning_rate": 1.7385624917082532e-05,
      "loss": 0.0369,
      "step": 12810
    },
    {
      "epoch": 0.39249303493249244,
      "grad_norm": 1.7447785139083862,
      "learning_rate": 1.7383583871659066e-05,
      "loss": 0.0226,
      "step": 12820
    },
    {
      "epoch": 0.3927991917460123,
      "grad_norm": 0.0059712668880820274,
      "learning_rate": 1.73815428262356e-05,
      "loss": 0.0014,
      "step": 12830
    },
    {
      "epoch": 0.3931053485595322,
      "grad_norm": 0.024389823898673058,
      "learning_rate": 1.7379501780812133e-05,
      "loss": 0.0015,
      "step": 12840
    },
    {
      "epoch": 0.3934115053730521,
      "grad_norm": 0.02005002833902836,
      "learning_rate": 1.7377460735388667e-05,
      "loss": 0.0094,
      "step": 12850
    },
    {
      "epoch": 0.39371766218657195,
      "grad_norm": 1.7149500846862793,
      "learning_rate": 1.73754196899652e-05,
      "loss": 0.0063,
      "step": 12860
    },
    {
      "epoch": 0.39402381900009187,
      "grad_norm": 0.029014481231570244,
      "learning_rate": 1.7373378644541737e-05,
      "loss": 0.0436,
      "step": 12870
    },
    {
      "epoch": 0.39432997581361173,
      "grad_norm": 0.01533776056021452,
      "learning_rate": 1.737133759911827e-05,
      "loss": 0.0013,
      "step": 12880
    },
    {
      "epoch": 0.3946361326271316,
      "grad_norm": 0.03011702001094818,
      "learning_rate": 1.7369296553694805e-05,
      "loss": 0.0009,
      "step": 12890
    },
    {
      "epoch": 0.3949422894406515,
      "grad_norm": 0.023746883496642113,
      "learning_rate": 1.7367255508271338e-05,
      "loss": 0.001,
      "step": 12900
    },
    {
      "epoch": 0.3952484462541714,
      "grad_norm": 0.02066190540790558,
      "learning_rate": 1.7365214462847872e-05,
      "loss": 0.0397,
      "step": 12910
    },
    {
      "epoch": 0.39555460306769125,
      "grad_norm": 0.05540316924452782,
      "learning_rate": 1.7363173417424406e-05,
      "loss": 0.0015,
      "step": 12920
    },
    {
      "epoch": 0.39586075988121117,
      "grad_norm": 0.06697019189596176,
      "learning_rate": 1.736113237200094e-05,
      "loss": 0.001,
      "step": 12930
    },
    {
      "epoch": 0.39616691669473103,
      "grad_norm": 0.0025737257674336433,
      "learning_rate": 1.7359091326577476e-05,
      "loss": 0.0008,
      "step": 12940
    },
    {
      "epoch": 0.39647307350825095,
      "grad_norm": 0.011635717935860157,
      "learning_rate": 1.735705028115401e-05,
      "loss": 0.001,
      "step": 12950
    },
    {
      "epoch": 0.3967792303217708,
      "grad_norm": 0.0037493703421205282,
      "learning_rate": 1.7355009235730543e-05,
      "loss": 0.0013,
      "step": 12960
    },
    {
      "epoch": 0.3970853871352907,
      "grad_norm": 0.044972848147153854,
      "learning_rate": 1.7352968190307077e-05,
      "loss": 0.0011,
      "step": 12970
    },
    {
      "epoch": 0.3973915439488106,
      "grad_norm": 0.03398454561829567,
      "learning_rate": 1.735092714488361e-05,
      "loss": 0.0017,
      "step": 12980
    },
    {
      "epoch": 0.39769770076233046,
      "grad_norm": 0.007108081132173538,
      "learning_rate": 1.7348886099460144e-05,
      "loss": 0.0007,
      "step": 12990
    },
    {
      "epoch": 0.39800385757585033,
      "grad_norm": 0.004983383696526289,
      "learning_rate": 1.7346845054036678e-05,
      "loss": 0.0361,
      "step": 13000
    },
    {
      "epoch": 0.39831001438937025,
      "grad_norm": 0.017121216282248497,
      "learning_rate": 1.7344804008613215e-05,
      "loss": 0.0008,
      "step": 13010
    },
    {
      "epoch": 0.3986161712028901,
      "grad_norm": 0.028370598331093788,
      "learning_rate": 1.734276296318975e-05,
      "loss": 0.001,
      "step": 13020
    },
    {
      "epoch": 0.39892232801641003,
      "grad_norm": 0.016204509884119034,
      "learning_rate": 1.7340721917766282e-05,
      "loss": 0.0005,
      "step": 13030
    },
    {
      "epoch": 0.3992284848299299,
      "grad_norm": 0.014671177603304386,
      "learning_rate": 1.7338680872342816e-05,
      "loss": 0.0388,
      "step": 13040
    },
    {
      "epoch": 0.39953464164344976,
      "grad_norm": 0.019898945465683937,
      "learning_rate": 1.733663982691935e-05,
      "loss": 0.0005,
      "step": 13050
    },
    {
      "epoch": 0.3998407984569697,
      "grad_norm": 0.008701713755726814,
      "learning_rate": 1.7334598781495883e-05,
      "loss": 0.0007,
      "step": 13060
    },
    {
      "epoch": 0.40014695527048955,
      "grad_norm": 0.02901396155357361,
      "learning_rate": 1.7332557736072417e-05,
      "loss": 0.001,
      "step": 13070
    },
    {
      "epoch": 0.4004531120840094,
      "grad_norm": 0.01703355461359024,
      "learning_rate": 1.733051669064895e-05,
      "loss": 0.0009,
      "step": 13080
    },
    {
      "epoch": 0.40075926889752933,
      "grad_norm": 0.017934974282979965,
      "learning_rate": 1.7328475645225488e-05,
      "loss": 0.0007,
      "step": 13090
    },
    {
      "epoch": 0.4010654257110492,
      "grad_norm": 0.021163512021303177,
      "learning_rate": 1.732643459980202e-05,
      "loss": 0.0007,
      "step": 13100
    },
    {
      "epoch": 0.40137158252456906,
      "grad_norm": 0.008510412648320198,
      "learning_rate": 1.7324393554378555e-05,
      "loss": 0.0005,
      "step": 13110
    },
    {
      "epoch": 0.401677739338089,
      "grad_norm": 0.021980058401823044,
      "learning_rate": 1.732235250895509e-05,
      "loss": 0.0007,
      "step": 13120
    },
    {
      "epoch": 0.40198389615160884,
      "grad_norm": 0.0092857601121068,
      "learning_rate": 1.7320311463531622e-05,
      "loss": 0.0004,
      "step": 13130
    },
    {
      "epoch": 0.40229005296512876,
      "grad_norm": 0.01686960831284523,
      "learning_rate": 1.7318270418108156e-05,
      "loss": 0.0005,
      "step": 13140
    },
    {
      "epoch": 0.40259620977864863,
      "grad_norm": 0.015177356079220772,
      "learning_rate": 1.731622937268469e-05,
      "loss": 0.0003,
      "step": 13150
    },
    {
      "epoch": 0.4029023665921685,
      "grad_norm": 2.232616424560547,
      "learning_rate": 1.7314188327261227e-05,
      "loss": 0.045,
      "step": 13160
    },
    {
      "epoch": 0.4032085234056884,
      "grad_norm": 0.005213399883359671,
      "learning_rate": 1.731214728183776e-05,
      "loss": 0.0645,
      "step": 13170
    },
    {
      "epoch": 0.4035146802192083,
      "grad_norm": 0.010763485915958881,
      "learning_rate": 1.7310106236414294e-05,
      "loss": 0.0005,
      "step": 13180
    },
    {
      "epoch": 0.40382083703272814,
      "grad_norm": 0.026875125244259834,
      "learning_rate": 1.7308065190990827e-05,
      "loss": 0.0007,
      "step": 13190
    },
    {
      "epoch": 0.40412699384624806,
      "grad_norm": 0.004248061217367649,
      "learning_rate": 1.730602414556736e-05,
      "loss": 0.0093,
      "step": 13200
    },
    {
      "epoch": 0.4044331506597679,
      "grad_norm": 0.014590227976441383,
      "learning_rate": 1.7303983100143895e-05,
      "loss": 0.0733,
      "step": 13210
    },
    {
      "epoch": 0.4047393074732878,
      "grad_norm": 0.018798109143972397,
      "learning_rate": 1.730194205472043e-05,
      "loss": 0.0442,
      "step": 13220
    },
    {
      "epoch": 0.4050454642868077,
      "grad_norm": 0.041893620043992996,
      "learning_rate": 1.7299901009296965e-05,
      "loss": 0.0175,
      "step": 13230
    },
    {
      "epoch": 0.4053516211003276,
      "grad_norm": 0.014016383327543736,
      "learning_rate": 1.72978599638735e-05,
      "loss": 0.0018,
      "step": 13240
    },
    {
      "epoch": 0.4056577779138475,
      "grad_norm": 0.02930566854774952,
      "learning_rate": 1.7295818918450033e-05,
      "loss": 0.0025,
      "step": 13250
    },
    {
      "epoch": 0.40596393472736736,
      "grad_norm": 0.024118656292557716,
      "learning_rate": 1.7293777873026566e-05,
      "loss": 0.037,
      "step": 13260
    },
    {
      "epoch": 0.4062700915408872,
      "grad_norm": 0.03761260583996773,
      "learning_rate": 1.72917368276031e-05,
      "loss": 0.0016,
      "step": 13270
    },
    {
      "epoch": 0.40657624835440714,
      "grad_norm": 0.024843178689479828,
      "learning_rate": 1.7289695782179634e-05,
      "loss": 0.0367,
      "step": 13280
    },
    {
      "epoch": 0.406882405167927,
      "grad_norm": 0.013953672721982002,
      "learning_rate": 1.7287654736756167e-05,
      "loss": 0.0361,
      "step": 13290
    },
    {
      "epoch": 0.4071885619814469,
      "grad_norm": 0.08355022966861725,
      "learning_rate": 1.72856136913327e-05,
      "loss": 0.0689,
      "step": 13300
    },
    {
      "epoch": 0.4074947187949668,
      "grad_norm": 0.041482385247945786,
      "learning_rate": 1.7283572645909238e-05,
      "loss": 0.0327,
      "step": 13310
    },
    {
      "epoch": 0.40780087560848666,
      "grad_norm": 0.06888268887996674,
      "learning_rate": 1.728153160048577e-05,
      "loss": 0.0048,
      "step": 13320
    },
    {
      "epoch": 0.4081070324220066,
      "grad_norm": 0.06002923846244812,
      "learning_rate": 1.7279490555062305e-05,
      "loss": 0.0028,
      "step": 13330
    },
    {
      "epoch": 0.40841318923552644,
      "grad_norm": 0.032711874693632126,
      "learning_rate": 1.727744950963884e-05,
      "loss": 0.0015,
      "step": 13340
    },
    {
      "epoch": 0.4087193460490463,
      "grad_norm": 0.06502450257539749,
      "learning_rate": 1.7275408464215373e-05,
      "loss": 0.0016,
      "step": 13350
    },
    {
      "epoch": 0.4090255028625662,
      "grad_norm": 0.02610551193356514,
      "learning_rate": 1.7273367418791906e-05,
      "loss": 0.0017,
      "step": 13360
    },
    {
      "epoch": 0.4093316596760861,
      "grad_norm": 0.036403294652700424,
      "learning_rate": 1.727132637336844e-05,
      "loss": 0.002,
      "step": 13370
    },
    {
      "epoch": 0.40963781648960595,
      "grad_norm": 0.01181733701378107,
      "learning_rate": 1.7269285327944977e-05,
      "loss": 0.003,
      "step": 13380
    },
    {
      "epoch": 0.4099439733031259,
      "grad_norm": 0.009224451147019863,
      "learning_rate": 1.726724428252151e-05,
      "loss": 0.0008,
      "step": 13390
    },
    {
      "epoch": 0.41025013011664574,
      "grad_norm": 0.013040359131991863,
      "learning_rate": 1.7265203237098044e-05,
      "loss": 0.0425,
      "step": 13400
    },
    {
      "epoch": 0.4105562869301656,
      "grad_norm": 0.020342040807008743,
      "learning_rate": 1.7263162191674578e-05,
      "loss": 0.001,
      "step": 13410
    },
    {
      "epoch": 0.4108624437436855,
      "grad_norm": 0.06358363479375839,
      "learning_rate": 1.726112114625111e-05,
      "loss": 0.0404,
      "step": 13420
    },
    {
      "epoch": 0.4111686005572054,
      "grad_norm": 0.03626146912574768,
      "learning_rate": 1.7259080100827645e-05,
      "loss": 0.0359,
      "step": 13430
    },
    {
      "epoch": 0.4114747573707253,
      "grad_norm": 0.06184408441185951,
      "learning_rate": 1.725703905540418e-05,
      "loss": 0.0021,
      "step": 13440
    },
    {
      "epoch": 0.4117809141842452,
      "grad_norm": 0.16055135428905487,
      "learning_rate": 1.7254998009980716e-05,
      "loss": 0.0423,
      "step": 13450
    },
    {
      "epoch": 0.41208707099776504,
      "grad_norm": 0.03996892645955086,
      "learning_rate": 1.725295696455725e-05,
      "loss": 0.0023,
      "step": 13460
    },
    {
      "epoch": 0.41239322781128496,
      "grad_norm": 0.049882784485816956,
      "learning_rate": 1.7250915919133783e-05,
      "loss": 0.0081,
      "step": 13470
    },
    {
      "epoch": 0.4126993846248048,
      "grad_norm": 0.014471798203885555,
      "learning_rate": 1.7248874873710317e-05,
      "loss": 0.0013,
      "step": 13480
    },
    {
      "epoch": 0.4130055414383247,
      "grad_norm": 0.01942191831767559,
      "learning_rate": 1.724683382828685e-05,
      "loss": 0.0037,
      "step": 13490
    },
    {
      "epoch": 0.4133116982518446,
      "grad_norm": 0.03587773069739342,
      "learning_rate": 1.7244792782863384e-05,
      "loss": 0.0009,
      "step": 13500
    },
    {
      "epoch": 0.41361785506536447,
      "grad_norm": 0.07149451225996017,
      "learning_rate": 1.7242751737439918e-05,
      "loss": 0.0729,
      "step": 13510
    },
    {
      "epoch": 0.4139240118788844,
      "grad_norm": 0.023588113486766815,
      "learning_rate": 1.724071069201645e-05,
      "loss": 0.0397,
      "step": 13520
    },
    {
      "epoch": 0.41423016869240425,
      "grad_norm": 0.07459532469511032,
      "learning_rate": 1.7238669646592988e-05,
      "loss": 0.0364,
      "step": 13530
    },
    {
      "epoch": 0.4145363255059241,
      "grad_norm": 0.0997173935174942,
      "learning_rate": 1.7236628601169522e-05,
      "loss": 0.0026,
      "step": 13540
    },
    {
      "epoch": 0.41484248231944404,
      "grad_norm": 0.07540003955364227,
      "learning_rate": 1.7234587555746056e-05,
      "loss": 0.0316,
      "step": 13550
    },
    {
      "epoch": 0.4151486391329639,
      "grad_norm": 0.0732162594795227,
      "learning_rate": 1.723254651032259e-05,
      "loss": 0.0566,
      "step": 13560
    },
    {
      "epoch": 0.41545479594648377,
      "grad_norm": 0.15982258319854736,
      "learning_rate": 1.7230505464899123e-05,
      "loss": 0.0036,
      "step": 13570
    },
    {
      "epoch": 0.4157609527600037,
      "grad_norm": 0.06913579255342484,
      "learning_rate": 1.7228464419475657e-05,
      "loss": 0.0022,
      "step": 13580
    },
    {
      "epoch": 0.41606710957352355,
      "grad_norm": 0.0449552945792675,
      "learning_rate": 1.722642337405219e-05,
      "loss": 0.0025,
      "step": 13590
    },
    {
      "epoch": 0.4163732663870434,
      "grad_norm": 0.0464593842625618,
      "learning_rate": 1.7224382328628727e-05,
      "loss": 0.0025,
      "step": 13600
    },
    {
      "epoch": 0.41667942320056334,
      "grad_norm": 0.020508302375674248,
      "learning_rate": 1.722234128320526e-05,
      "loss": 0.0387,
      "step": 13610
    },
    {
      "epoch": 0.4169855800140832,
      "grad_norm": 0.04527447372674942,
      "learning_rate": 1.7220300237781794e-05,
      "loss": 0.0819,
      "step": 13620
    },
    {
      "epoch": 0.4172917368276031,
      "grad_norm": 0.09652113914489746,
      "learning_rate": 1.7218259192358325e-05,
      "loss": 0.0284,
      "step": 13630
    },
    {
      "epoch": 0.417597893641123,
      "grad_norm": 0.12612207233905792,
      "learning_rate": 1.7216218146934862e-05,
      "loss": 0.0553,
      "step": 13640
    },
    {
      "epoch": 0.41790405045464285,
      "grad_norm": 0.14018021523952484,
      "learning_rate": 1.7214177101511395e-05,
      "loss": 0.0258,
      "step": 13650
    },
    {
      "epoch": 0.41821020726816277,
      "grad_norm": 0.10414731502532959,
      "learning_rate": 1.721213605608793e-05,
      "loss": 0.0291,
      "step": 13660
    },
    {
      "epoch": 0.41851636408168263,
      "grad_norm": 0.07094987481832504,
      "learning_rate": 1.7210095010664463e-05,
      "loss": 0.0049,
      "step": 13670
    },
    {
      "epoch": 0.4188225208952025,
      "grad_norm": 0.018960177898406982,
      "learning_rate": 1.7208053965241e-05,
      "loss": 0.0048,
      "step": 13680
    },
    {
      "epoch": 0.4191286777087224,
      "grad_norm": 0.13911248743534088,
      "learning_rate": 1.7206012919817533e-05,
      "loss": 0.0315,
      "step": 13690
    },
    {
      "epoch": 0.4194348345222423,
      "grad_norm": 0.11968480050563812,
      "learning_rate": 1.7203971874394067e-05,
      "loss": 0.0044,
      "step": 13700
    },
    {
      "epoch": 0.4197409913357622,
      "grad_norm": 0.03818435221910477,
      "learning_rate": 1.72019308289706e-05,
      "loss": 0.0029,
      "step": 13710
    },
    {
      "epoch": 0.42004714814928207,
      "grad_norm": 0.0941721647977829,
      "learning_rate": 1.7199889783547134e-05,
      "loss": 0.0018,
      "step": 13720
    },
    {
      "epoch": 0.42035330496280193,
      "grad_norm": 0.05158545449376106,
      "learning_rate": 1.7197848738123668e-05,
      "loss": 0.0017,
      "step": 13730
    },
    {
      "epoch": 0.42065946177632185,
      "grad_norm": 0.008436966687440872,
      "learning_rate": 1.71958076927002e-05,
      "loss": 0.0343,
      "step": 13740
    },
    {
      "epoch": 0.4209656185898417,
      "grad_norm": 0.023385073989629745,
      "learning_rate": 1.719376664727674e-05,
      "loss": 0.0018,
      "step": 13750
    },
    {
      "epoch": 0.4212717754033616,
      "grad_norm": 0.04189608618617058,
      "learning_rate": 1.7191725601853272e-05,
      "loss": 0.0343,
      "step": 13760
    },
    {
      "epoch": 0.4215779322168815,
      "grad_norm": 0.03278929367661476,
      "learning_rate": 1.7189684556429806e-05,
      "loss": 0.0028,
      "step": 13770
    },
    {
      "epoch": 0.42188408903040137,
      "grad_norm": 0.050572723150253296,
      "learning_rate": 1.7187643511006336e-05,
      "loss": 0.0321,
      "step": 13780
    },
    {
      "epoch": 0.42219024584392123,
      "grad_norm": 0.0343455895781517,
      "learning_rate": 1.7185602465582873e-05,
      "loss": 0.0013,
      "step": 13790
    },
    {
      "epoch": 0.42249640265744115,
      "grad_norm": 0.017284512519836426,
      "learning_rate": 1.7183561420159407e-05,
      "loss": 0.0349,
      "step": 13800
    },
    {
      "epoch": 0.422802559470961,
      "grad_norm": 0.049310263246297836,
      "learning_rate": 1.718152037473594e-05,
      "loss": 0.0013,
      "step": 13810
    },
    {
      "epoch": 0.42310871628448093,
      "grad_norm": 0.03483196720480919,
      "learning_rate": 1.7179479329312478e-05,
      "loss": 0.0291,
      "step": 13820
    },
    {
      "epoch": 0.4234148730980008,
      "grad_norm": 0.021162444725632668,
      "learning_rate": 1.717743828388901e-05,
      "loss": 0.0036,
      "step": 13830
    },
    {
      "epoch": 0.42372102991152066,
      "grad_norm": 0.03592943772673607,
      "learning_rate": 1.7175397238465545e-05,
      "loss": 0.0015,
      "step": 13840
    },
    {
      "epoch": 0.4240271867250406,
      "grad_norm": 0.010101842693984509,
      "learning_rate": 1.7173356193042075e-05,
      "loss": 0.0016,
      "step": 13850
    },
    {
      "epoch": 0.42433334353856045,
      "grad_norm": 0.012762129306793213,
      "learning_rate": 1.7171315147618612e-05,
      "loss": 0.0012,
      "step": 13860
    },
    {
      "epoch": 0.4246395003520803,
      "grad_norm": 0.018138663843274117,
      "learning_rate": 1.7169274102195146e-05,
      "loss": 0.0787,
      "step": 13870
    },
    {
      "epoch": 0.42494565716560023,
      "grad_norm": 0.027732281014323235,
      "learning_rate": 1.716723305677168e-05,
      "loss": 0.0014,
      "step": 13880
    },
    {
      "epoch": 0.4252518139791201,
      "grad_norm": 0.013365021906793118,
      "learning_rate": 1.7165192011348213e-05,
      "loss": 0.0317,
      "step": 13890
    },
    {
      "epoch": 0.42555797079264,
      "grad_norm": 0.0394446887075901,
      "learning_rate": 1.716315096592475e-05,
      "loss": 0.0096,
      "step": 13900
    },
    {
      "epoch": 0.4258641276061599,
      "grad_norm": 0.036550331860780716,
      "learning_rate": 1.7161109920501284e-05,
      "loss": 0.0017,
      "step": 13910
    },
    {
      "epoch": 0.42617028441967975,
      "grad_norm": 0.04344826936721802,
      "learning_rate": 1.7159068875077814e-05,
      "loss": 0.0363,
      "step": 13920
    },
    {
      "epoch": 0.42647644123319967,
      "grad_norm": 0.038319047540426254,
      "learning_rate": 1.715702782965435e-05,
      "loss": 0.0018,
      "step": 13930
    },
    {
      "epoch": 0.42678259804671953,
      "grad_norm": 0.062277767807245255,
      "learning_rate": 1.7154986784230885e-05,
      "loss": 0.0014,
      "step": 13940
    },
    {
      "epoch": 0.4270887548602394,
      "grad_norm": 0.007329456973820925,
      "learning_rate": 1.7152945738807418e-05,
      "loss": 0.0012,
      "step": 13950
    },
    {
      "epoch": 0.4273949116737593,
      "grad_norm": 0.03218545764684677,
      "learning_rate": 1.7150904693383952e-05,
      "loss": 0.0015,
      "step": 13960
    },
    {
      "epoch": 0.4277010684872792,
      "grad_norm": 0.03474677726626396,
      "learning_rate": 1.714886364796049e-05,
      "loss": 0.0012,
      "step": 13970
    },
    {
      "epoch": 0.42800722530079904,
      "grad_norm": 0.02366570010781288,
      "learning_rate": 1.7146822602537023e-05,
      "loss": 0.0008,
      "step": 13980
    },
    {
      "epoch": 0.42831338211431896,
      "grad_norm": 0.03445171192288399,
      "learning_rate": 1.7144781557113553e-05,
      "loss": 0.0017,
      "step": 13990
    },
    {
      "epoch": 0.42861953892783883,
      "grad_norm": 0.018522143363952637,
      "learning_rate": 1.7142740511690087e-05,
      "loss": 0.0385,
      "step": 14000
    },
    {
      "epoch": 0.42892569574135875,
      "grad_norm": 0.013177400454878807,
      "learning_rate": 1.7140699466266624e-05,
      "loss": 0.0007,
      "step": 14010
    },
    {
      "epoch": 0.4292318525548786,
      "grad_norm": 0.015419865027070045,
      "learning_rate": 1.7138658420843157e-05,
      "loss": 0.0339,
      "step": 14020
    },
    {
      "epoch": 0.4295380093683985,
      "grad_norm": 0.022038908675312996,
      "learning_rate": 1.713661737541969e-05,
      "loss": 0.0014,
      "step": 14030
    },
    {
      "epoch": 0.4298441661819184,
      "grad_norm": 0.0042106076143682,
      "learning_rate": 1.7134576329996228e-05,
      "loss": 0.0013,
      "step": 14040
    },
    {
      "epoch": 0.43015032299543826,
      "grad_norm": 0.026037929579615593,
      "learning_rate": 1.713253528457276e-05,
      "loss": 0.0018,
      "step": 14050
    },
    {
      "epoch": 0.4304564798089581,
      "grad_norm": 0.01761901192367077,
      "learning_rate": 1.7130494239149292e-05,
      "loss": 0.0009,
      "step": 14060
    },
    {
      "epoch": 0.43076263662247805,
      "grad_norm": 0.010029174387454987,
      "learning_rate": 1.7128453193725825e-05,
      "loss": 0.0014,
      "step": 14070
    },
    {
      "epoch": 0.4310687934359979,
      "grad_norm": 0.02225399762392044,
      "learning_rate": 1.7126412148302362e-05,
      "loss": 0.0015,
      "step": 14080
    },
    {
      "epoch": 0.43137495024951783,
      "grad_norm": 0.04234590381383896,
      "learning_rate": 1.7124371102878896e-05,
      "loss": 0.0375,
      "step": 14090
    },
    {
      "epoch": 0.4316811070630377,
      "grad_norm": 0.019008168950676918,
      "learning_rate": 1.712233005745543e-05,
      "loss": 0.0064,
      "step": 14100
    },
    {
      "epoch": 0.43198726387655756,
      "grad_norm": 0.018771613016724586,
      "learning_rate": 1.7120289012031963e-05,
      "loss": 0.0352,
      "step": 14110
    },
    {
      "epoch": 0.4322934206900775,
      "grad_norm": 0.02855629101395607,
      "learning_rate": 1.71182479666085e-05,
      "loss": 0.0011,
      "step": 14120
    },
    {
      "epoch": 0.43259957750359734,
      "grad_norm": 0.03727998211979866,
      "learning_rate": 1.711620692118503e-05,
      "loss": 0.0319,
      "step": 14130
    },
    {
      "epoch": 0.4329057343171172,
      "grad_norm": 0.015372811816632748,
      "learning_rate": 1.7114165875761564e-05,
      "loss": 0.0013,
      "step": 14140
    },
    {
      "epoch": 0.43321189113063713,
      "grad_norm": 0.030658850446343422,
      "learning_rate": 1.71121248303381e-05,
      "loss": 0.001,
      "step": 14150
    },
    {
      "epoch": 0.433518047944157,
      "grad_norm": 0.04144599661231041,
      "learning_rate": 1.7110083784914635e-05,
      "loss": 0.0337,
      "step": 14160
    },
    {
      "epoch": 0.43382420475767686,
      "grad_norm": 0.03922419995069504,
      "learning_rate": 1.710804273949117e-05,
      "loss": 0.034,
      "step": 14170
    },
    {
      "epoch": 0.4341303615711968,
      "grad_norm": 0.9989309310913086,
      "learning_rate": 1.7106001694067702e-05,
      "loss": 0.004,
      "step": 14180
    },
    {
      "epoch": 0.43443651838471664,
      "grad_norm": 0.06167001277208328,
      "learning_rate": 1.710396064864424e-05,
      "loss": 0.001,
      "step": 14190
    },
    {
      "epoch": 0.43474267519823656,
      "grad_norm": 0.005559343378990889,
      "learning_rate": 1.7101919603220773e-05,
      "loss": 0.0011,
      "step": 14200
    },
    {
      "epoch": 0.4350488320117564,
      "grad_norm": 0.024648014456033707,
      "learning_rate": 1.7099878557797303e-05,
      "loss": 0.0734,
      "step": 14210
    },
    {
      "epoch": 0.4353549888252763,
      "grad_norm": 0.03917298838496208,
      "learning_rate": 1.7097837512373837e-05,
      "loss": 0.033,
      "step": 14220
    },
    {
      "epoch": 0.4356611456387962,
      "grad_norm": 0.012468679808080196,
      "learning_rate": 1.7095796466950374e-05,
      "loss": 0.0023,
      "step": 14230
    },
    {
      "epoch": 0.4359673024523161,
      "grad_norm": 0.036399953067302704,
      "learning_rate": 1.7093755421526908e-05,
      "loss": 0.0358,
      "step": 14240
    },
    {
      "epoch": 0.43627345926583594,
      "grad_norm": 0.047420158982276917,
      "learning_rate": 1.709171437610344e-05,
      "loss": 0.0026,
      "step": 14250
    },
    {
      "epoch": 0.43657961607935586,
      "grad_norm": 0.09645397216081619,
      "learning_rate": 1.7089673330679978e-05,
      "loss": 0.0341,
      "step": 14260
    },
    {
      "epoch": 0.4368857728928757,
      "grad_norm": 0.06561264395713806,
      "learning_rate": 1.7087632285256512e-05,
      "loss": 0.0335,
      "step": 14270
    },
    {
      "epoch": 0.43719192970639564,
      "grad_norm": 0.1457759141921997,
      "learning_rate": 1.7085591239833042e-05,
      "loss": 0.0027,
      "step": 14280
    },
    {
      "epoch": 0.4374980865199155,
      "grad_norm": 0.05894651263952255,
      "learning_rate": 1.7083550194409576e-05,
      "loss": 0.0018,
      "step": 14290
    },
    {
      "epoch": 0.43780424333343537,
      "grad_norm": 0.07131081819534302,
      "learning_rate": 1.7081509148986113e-05,
      "loss": 0.0301,
      "step": 14300
    },
    {
      "epoch": 0.4381104001469553,
      "grad_norm": 0.06951110810041428,
      "learning_rate": 1.7079468103562646e-05,
      "loss": 0.0021,
      "step": 14310
    },
    {
      "epoch": 0.43841655696047516,
      "grad_norm": 0.05127936229109764,
      "learning_rate": 1.707742705813918e-05,
      "loss": 0.0431,
      "step": 14320
    },
    {
      "epoch": 0.438722713773995,
      "grad_norm": 0.04886745661497116,
      "learning_rate": 1.7075386012715714e-05,
      "loss": 0.008,
      "step": 14330
    },
    {
      "epoch": 0.43902887058751494,
      "grad_norm": 0.06518134474754333,
      "learning_rate": 1.707334496729225e-05,
      "loss": 0.0336,
      "step": 14340
    },
    {
      "epoch": 0.4393350274010348,
      "grad_norm": 0.009550577960908413,
      "learning_rate": 1.707130392186878e-05,
      "loss": 0.0012,
      "step": 14350
    },
    {
      "epoch": 0.43964118421455467,
      "grad_norm": 0.018840763717889786,
      "learning_rate": 1.7069262876445315e-05,
      "loss": 0.0027,
      "step": 14360
    },
    {
      "epoch": 0.4399473410280746,
      "grad_norm": 0.03894738852977753,
      "learning_rate": 1.706722183102185e-05,
      "loss": 0.0233,
      "step": 14370
    },
    {
      "epoch": 0.44025349784159445,
      "grad_norm": 0.03249390795826912,
      "learning_rate": 1.7065180785598385e-05,
      "loss": 0.0344,
      "step": 14380
    },
    {
      "epoch": 0.4405596546551144,
      "grad_norm": 0.05712727829813957,
      "learning_rate": 1.706313974017492e-05,
      "loss": 0.0013,
      "step": 14390
    },
    {
      "epoch": 0.44086581146863424,
      "grad_norm": 1.6787183284759521,
      "learning_rate": 1.7061098694751453e-05,
      "loss": 0.0311,
      "step": 14400
    },
    {
      "epoch": 0.4411719682821541,
      "grad_norm": 0.046816110610961914,
      "learning_rate": 1.705905764932799e-05,
      "loss": 0.0383,
      "step": 14410
    },
    {
      "epoch": 0.441478125095674,
      "grad_norm": 0.10483372211456299,
      "learning_rate": 1.705701660390452e-05,
      "loss": 0.0016,
      "step": 14420
    },
    {
      "epoch": 0.4417842819091939,
      "grad_norm": 1.6379071474075317,
      "learning_rate": 1.7054975558481054e-05,
      "loss": 0.03,
      "step": 14430
    },
    {
      "epoch": 0.44209043872271375,
      "grad_norm": 1.6240603923797607,
      "learning_rate": 1.7052934513057587e-05,
      "loss": 0.0576,
      "step": 14440
    },
    {
      "epoch": 0.44239659553623367,
      "grad_norm": 0.08261857181787491,
      "learning_rate": 1.7050893467634124e-05,
      "loss": 0.0023,
      "step": 14450
    },
    {
      "epoch": 0.44270275234975354,
      "grad_norm": 0.05107329040765762,
      "learning_rate": 1.7048852422210658e-05,
      "loss": 0.0025,
      "step": 14460
    },
    {
      "epoch": 0.4430089091632734,
      "grad_norm": 0.043531518429517746,
      "learning_rate": 1.704681137678719e-05,
      "loss": 0.0019,
      "step": 14470
    },
    {
      "epoch": 0.4433150659767933,
      "grad_norm": 3.2401692867279053,
      "learning_rate": 1.704477033136373e-05,
      "loss": 0.0104,
      "step": 14480
    },
    {
      "epoch": 0.4436212227903132,
      "grad_norm": 0.009329061955213547,
      "learning_rate": 1.704272928594026e-05,
      "loss": 0.0013,
      "step": 14490
    },
    {
      "epoch": 0.4439273796038331,
      "grad_norm": 0.0347653366625309,
      "learning_rate": 1.7040688240516792e-05,
      "loss": 0.001,
      "step": 14500
    },
    {
      "epoch": 0.44423353641735297,
      "grad_norm": 3.9793343544006348,
      "learning_rate": 1.7038647195093326e-05,
      "loss": 0.0753,
      "step": 14510
    },
    {
      "epoch": 0.44453969323087283,
      "grad_norm": 0.01628471165895462,
      "learning_rate": 1.7036606149669863e-05,
      "loss": 0.0008,
      "step": 14520
    },
    {
      "epoch": 0.44484585004439275,
      "grad_norm": 0.021868187934160233,
      "learning_rate": 1.7034565104246397e-05,
      "loss": 0.0008,
      "step": 14530
    },
    {
      "epoch": 0.4451520068579126,
      "grad_norm": 0.02775588445365429,
      "learning_rate": 1.703252405882293e-05,
      "loss": 0.047,
      "step": 14540
    },
    {
      "epoch": 0.4454581636714325,
      "grad_norm": 0.012014751322567463,
      "learning_rate": 1.7030483013399464e-05,
      "loss": 0.0011,
      "step": 14550
    },
    {
      "epoch": 0.4457643204849524,
      "grad_norm": 0.02571992389857769,
      "learning_rate": 1.7028441967975998e-05,
      "loss": 0.0009,
      "step": 14560
    },
    {
      "epoch": 0.44607047729847227,
      "grad_norm": 0.01977350376546383,
      "learning_rate": 1.702640092255253e-05,
      "loss": 0.0024,
      "step": 14570
    },
    {
      "epoch": 0.4463766341119922,
      "grad_norm": 0.03450237959623337,
      "learning_rate": 1.7024359877129065e-05,
      "loss": 0.001,
      "step": 14580
    },
    {
      "epoch": 0.44668279092551205,
      "grad_norm": 0.01383562758564949,
      "learning_rate": 1.7022318831705602e-05,
      "loss": 0.0007,
      "step": 14590
    },
    {
      "epoch": 0.4469889477390319,
      "grad_norm": 0.012951759621500969,
      "learning_rate": 1.7020277786282136e-05,
      "loss": 0.0011,
      "step": 14600
    },
    {
      "epoch": 0.44729510455255184,
      "grad_norm": 0.030469676479697227,
      "learning_rate": 1.701823674085867e-05,
      "loss": 0.0217,
      "step": 14610
    },
    {
      "epoch": 0.4476012613660717,
      "grad_norm": 0.05374892055988312,
      "learning_rate": 1.7016195695435203e-05,
      "loss": 0.0009,
      "step": 14620
    },
    {
      "epoch": 0.44790741817959157,
      "grad_norm": 0.0006231529987417161,
      "learning_rate": 1.7014154650011737e-05,
      "loss": 0.0015,
      "step": 14630
    },
    {
      "epoch": 0.4482135749931115,
      "grad_norm": 0.01391630806028843,
      "learning_rate": 1.701211360458827e-05,
      "loss": 0.0009,
      "step": 14640
    },
    {
      "epoch": 0.44851973180663135,
      "grad_norm": 0.013801084831357002,
      "learning_rate": 1.7010072559164804e-05,
      "loss": 0.0013,
      "step": 14650
    },
    {
      "epoch": 0.4488258886201512,
      "grad_norm": 0.01298227347433567,
      "learning_rate": 1.7008031513741338e-05,
      "loss": 0.0007,
      "step": 14660
    },
    {
      "epoch": 0.44913204543367113,
      "grad_norm": 0.01111909281462431,
      "learning_rate": 1.7005990468317875e-05,
      "loss": 0.001,
      "step": 14670
    },
    {
      "epoch": 0.449438202247191,
      "grad_norm": 0.029747720807790756,
      "learning_rate": 1.7003949422894408e-05,
      "loss": 0.0006,
      "step": 14680
    },
    {
      "epoch": 0.4497443590607109,
      "grad_norm": 0.019510319456458092,
      "learning_rate": 1.7001908377470942e-05,
      "loss": 0.0005,
      "step": 14690
    },
    {
      "epoch": 0.4500505158742308,
      "grad_norm": 0.007571983616799116,
      "learning_rate": 1.6999867332047476e-05,
      "loss": 0.0004,
      "step": 14700
    },
    {
      "epoch": 0.45035667268775065,
      "grad_norm": 0.01973188854753971,
      "learning_rate": 1.699782628662401e-05,
      "loss": 0.0391,
      "step": 14710
    },
    {
      "epoch": 0.45066282950127057,
      "grad_norm": 0.025542551651597023,
      "learning_rate": 1.6995785241200543e-05,
      "loss": 0.0729,
      "step": 14720
    },
    {
      "epoch": 0.45096898631479043,
      "grad_norm": 0.029632683843374252,
      "learning_rate": 1.6993744195777076e-05,
      "loss": 0.0009,
      "step": 14730
    },
    {
      "epoch": 0.4512751431283103,
      "grad_norm": 0.022876115515828133,
      "learning_rate": 1.6991703150353613e-05,
      "loss": 0.001,
      "step": 14740
    },
    {
      "epoch": 0.4515812999418302,
      "grad_norm": 0.16835449635982513,
      "learning_rate": 1.6989662104930147e-05,
      "loss": 0.0394,
      "step": 14750
    },
    {
      "epoch": 0.4518874567553501,
      "grad_norm": 0.018393758684396744,
      "learning_rate": 1.698762105950668e-05,
      "loss": 0.0163,
      "step": 14760
    },
    {
      "epoch": 0.45219361356887,
      "grad_norm": 0.024347808212041855,
      "learning_rate": 1.6985580014083214e-05,
      "loss": 0.0364,
      "step": 14770
    },
    {
      "epoch": 0.45249977038238987,
      "grad_norm": 0.02042451873421669,
      "learning_rate": 1.6983538968659748e-05,
      "loss": 0.0348,
      "step": 14780
    },
    {
      "epoch": 0.45280592719590973,
      "grad_norm": 0.0286537054926157,
      "learning_rate": 1.698149792323628e-05,
      "loss": 0.0026,
      "step": 14790
    },
    {
      "epoch": 0.45311208400942965,
      "grad_norm": 0.006424678489565849,
      "learning_rate": 1.6979456877812815e-05,
      "loss": 0.0014,
      "step": 14800
    },
    {
      "epoch": 0.4534182408229495,
      "grad_norm": 0.014409121125936508,
      "learning_rate": 1.6977415832389352e-05,
      "loss": 0.0007,
      "step": 14810
    },
    {
      "epoch": 0.4537243976364694,
      "grad_norm": 0.010129537433385849,
      "learning_rate": 1.6975374786965886e-05,
      "loss": 0.0012,
      "step": 14820
    },
    {
      "epoch": 0.4540305544499893,
      "grad_norm": 0.02730824053287506,
      "learning_rate": 1.697333374154242e-05,
      "loss": 0.0374,
      "step": 14830
    },
    {
      "epoch": 0.45433671126350916,
      "grad_norm": 0.004792750813066959,
      "learning_rate": 1.6971292696118953e-05,
      "loss": 0.0748,
      "step": 14840
    },
    {
      "epoch": 0.454642868077029,
      "grad_norm": 0.017333898693323135,
      "learning_rate": 1.6969251650695487e-05,
      "loss": 0.002,
      "step": 14850
    },
    {
      "epoch": 0.45494902489054895,
      "grad_norm": 0.046089865267276764,
      "learning_rate": 1.696721060527202e-05,
      "loss": 0.0017,
      "step": 14860
    },
    {
      "epoch": 0.4552551817040688,
      "grad_norm": 0.03128078952431679,
      "learning_rate": 1.6965169559848554e-05,
      "loss": 0.002,
      "step": 14870
    },
    {
      "epoch": 0.45556133851758873,
      "grad_norm": 0.01356244832277298,
      "learning_rate": 1.6963128514425088e-05,
      "loss": 0.0295,
      "step": 14880
    },
    {
      "epoch": 0.4558674953311086,
      "grad_norm": 0.059560757130384445,
      "learning_rate": 1.6961087469001625e-05,
      "loss": 0.07,
      "step": 14890
    },
    {
      "epoch": 0.45617365214462846,
      "grad_norm": 0.06105031445622444,
      "learning_rate": 1.695904642357816e-05,
      "loss": 0.002,
      "step": 14900
    },
    {
      "epoch": 0.4564798089581484,
      "grad_norm": 0.03818010166287422,
      "learning_rate": 1.6957005378154692e-05,
      "loss": 0.0623,
      "step": 14910
    },
    {
      "epoch": 0.45678596577166825,
      "grad_norm": 0.033837806433439255,
      "learning_rate": 1.6954964332731226e-05,
      "loss": 0.0058,
      "step": 14920
    },
    {
      "epoch": 0.4570921225851881,
      "grad_norm": 0.023186203092336655,
      "learning_rate": 1.695292328730776e-05,
      "loss": 0.0023,
      "step": 14930
    },
    {
      "epoch": 0.45739827939870803,
      "grad_norm": 0.01635892689228058,
      "learning_rate": 1.6950882241884293e-05,
      "loss": 0.0013,
      "step": 14940
    },
    {
      "epoch": 0.4577044362122279,
      "grad_norm": 0.04236400127410889,
      "learning_rate": 1.6948841196460827e-05,
      "loss": 0.0749,
      "step": 14950
    },
    {
      "epoch": 0.4580105930257478,
      "grad_norm": 0.07371502369642258,
      "learning_rate": 1.6946800151037364e-05,
      "loss": 0.0016,
      "step": 14960
    },
    {
      "epoch": 0.4583167498392677,
      "grad_norm": 0.04756318777799606,
      "learning_rate": 1.6944759105613897e-05,
      "loss": 0.0023,
      "step": 14970
    },
    {
      "epoch": 0.45862290665278754,
      "grad_norm": 0.05480935052037239,
      "learning_rate": 1.694271806019043e-05,
      "loss": 0.0018,
      "step": 14980
    },
    {
      "epoch": 0.45892906346630746,
      "grad_norm": 0.08169454336166382,
      "learning_rate": 1.6940677014766965e-05,
      "loss": 0.0014,
      "step": 14990
    },
    {
      "epoch": 0.4592352202798273,
      "grad_norm": 0.023957718163728714,
      "learning_rate": 1.69386359693435e-05,
      "loss": 0.0011,
      "step": 15000
    },
    {
      "epoch": 0.4595413770933472,
      "grad_norm": 0.01955759897828102,
      "learning_rate": 1.6936594923920032e-05,
      "loss": 0.0014,
      "step": 15010
    },
    {
      "epoch": 0.4598475339068671,
      "grad_norm": 0.005641256459057331,
      "learning_rate": 1.6934553878496566e-05,
      "loss": 0.0007,
      "step": 15020
    },
    {
      "epoch": 0.460153690720387,
      "grad_norm": 0.023266365751624107,
      "learning_rate": 1.69325128330731e-05,
      "loss": 0.043,
      "step": 15030
    },
    {
      "epoch": 0.46045984753390684,
      "grad_norm": 0.01611342467367649,
      "learning_rate": 1.6930471787649636e-05,
      "loss": 0.0485,
      "step": 15040
    },
    {
      "epoch": 0.46076600434742676,
      "grad_norm": 0.06241210177540779,
      "learning_rate": 1.692843074222617e-05,
      "loss": 0.0028,
      "step": 15050
    },
    {
      "epoch": 0.4610721611609466,
      "grad_norm": 0.048192765563726425,
      "learning_rate": 1.6926389696802704e-05,
      "loss": 0.0017,
      "step": 15060
    },
    {
      "epoch": 0.46137831797446655,
      "grad_norm": 0.07265794277191162,
      "learning_rate": 1.6924348651379237e-05,
      "loss": 0.0015,
      "step": 15070
    },
    {
      "epoch": 0.4616844747879864,
      "grad_norm": 0.020427711308002472,
      "learning_rate": 1.692230760595577e-05,
      "loss": 0.0013,
      "step": 15080
    },
    {
      "epoch": 0.4619906316015063,
      "grad_norm": 0.013092665001749992,
      "learning_rate": 1.6920266560532305e-05,
      "loss": 0.0047,
      "step": 15090
    },
    {
      "epoch": 0.4622967884150262,
      "grad_norm": 0.032542649656534195,
      "learning_rate": 1.6918225515108838e-05,
      "loss": 0.0368,
      "step": 15100
    },
    {
      "epoch": 0.46260294522854606,
      "grad_norm": 0.030238494277000427,
      "learning_rate": 1.6916184469685375e-05,
      "loss": 0.0016,
      "step": 15110
    },
    {
      "epoch": 0.4629091020420659,
      "grad_norm": 0.06385776400566101,
      "learning_rate": 1.691414342426191e-05,
      "loss": 0.0383,
      "step": 15120
    },
    {
      "epoch": 0.46321525885558584,
      "grad_norm": 0.03609488159418106,
      "learning_rate": 1.6912102378838443e-05,
      "loss": 0.0361,
      "step": 15130
    },
    {
      "epoch": 0.4635214156691057,
      "grad_norm": 0.055512476712465286,
      "learning_rate": 1.6910061333414976e-05,
      "loss": 0.0017,
      "step": 15140
    },
    {
      "epoch": 0.4638275724826256,
      "grad_norm": 0.029890859499573708,
      "learning_rate": 1.690802028799151e-05,
      "loss": 0.0019,
      "step": 15150
    },
    {
      "epoch": 0.4641337292961455,
      "grad_norm": 0.1427723467350006,
      "learning_rate": 1.6905979242568043e-05,
      "loss": 0.0023,
      "step": 15160
    },
    {
      "epoch": 0.46443988610966536,
      "grad_norm": 0.03073163703083992,
      "learning_rate": 1.6903938197144577e-05,
      "loss": 0.0014,
      "step": 15170
    },
    {
      "epoch": 0.4647460429231853,
      "grad_norm": 0.027549486607313156,
      "learning_rate": 1.6901897151721114e-05,
      "loss": 0.0317,
      "step": 15180
    },
    {
      "epoch": 0.46505219973670514,
      "grad_norm": 0.0476105697453022,
      "learning_rate": 1.6899856106297648e-05,
      "loss": 0.0037,
      "step": 15190
    },
    {
      "epoch": 0.465358356550225,
      "grad_norm": 0.07839110493659973,
      "learning_rate": 1.689781506087418e-05,
      "loss": 0.0031,
      "step": 15200
    },
    {
      "epoch": 0.4656645133637449,
      "grad_norm": 0.00638966029509902,
      "learning_rate": 1.6895774015450715e-05,
      "loss": 0.012,
      "step": 15210
    },
    {
      "epoch": 0.4659706701772648,
      "grad_norm": 0.026799475774168968,
      "learning_rate": 1.689373297002725e-05,
      "loss": 0.001,
      "step": 15220
    },
    {
      "epoch": 0.46627682699078465,
      "grad_norm": 0.024317067116498947,
      "learning_rate": 1.6891691924603782e-05,
      "loss": 0.0011,
      "step": 15230
    },
    {
      "epoch": 0.4665829838043046,
      "grad_norm": 0.016433876007795334,
      "learning_rate": 1.6889650879180316e-05,
      "loss": 0.0009,
      "step": 15240
    },
    {
      "epoch": 0.46688914061782444,
      "grad_norm": 0.042593106627464294,
      "learning_rate": 1.688760983375685e-05,
      "loss": 0.0335,
      "step": 15250
    },
    {
      "epoch": 0.46719529743134436,
      "grad_norm": 0.029439875856041908,
      "learning_rate": 1.6885568788333387e-05,
      "loss": 0.0009,
      "step": 15260
    },
    {
      "epoch": 0.4675014542448642,
      "grad_norm": 0.3304702043533325,
      "learning_rate": 1.688352774290992e-05,
      "loss": 0.0375,
      "step": 15270
    },
    {
      "epoch": 0.4678076110583841,
      "grad_norm": 5.26072359085083,
      "learning_rate": 1.6881486697486454e-05,
      "loss": 0.025,
      "step": 15280
    },
    {
      "epoch": 0.468113767871904,
      "grad_norm": 0.014686609618365765,
      "learning_rate": 1.6879445652062988e-05,
      "loss": 0.0011,
      "step": 15290
    },
    {
      "epoch": 0.46841992468542387,
      "grad_norm": 0.2947682738304138,
      "learning_rate": 1.687740460663952e-05,
      "loss": 0.0343,
      "step": 15300
    },
    {
      "epoch": 0.46872608149894374,
      "grad_norm": 0.04175977408885956,
      "learning_rate": 1.6875363561216055e-05,
      "loss": 0.0015,
      "step": 15310
    },
    {
      "epoch": 0.46903223831246366,
      "grad_norm": 0.03206614404916763,
      "learning_rate": 1.687332251579259e-05,
      "loss": 0.0013,
      "step": 15320
    },
    {
      "epoch": 0.4693383951259835,
      "grad_norm": 0.028017861768603325,
      "learning_rate": 1.6871281470369126e-05,
      "loss": 0.0327,
      "step": 15330
    },
    {
      "epoch": 0.46964455193950344,
      "grad_norm": 0.15253151953220367,
      "learning_rate": 1.686924042494566e-05,
      "loss": 0.0693,
      "step": 15340
    },
    {
      "epoch": 0.4699507087530233,
      "grad_norm": 0.053223494440317154,
      "learning_rate": 1.6867199379522193e-05,
      "loss": 0.0028,
      "step": 15350
    },
    {
      "epoch": 0.47025686556654317,
      "grad_norm": 4.553812026977539,
      "learning_rate": 1.6865158334098727e-05,
      "loss": 0.0382,
      "step": 15360
    },
    {
      "epoch": 0.4705630223800631,
      "grad_norm": 0.000561527325771749,
      "learning_rate": 1.686311728867526e-05,
      "loss": 0.0015,
      "step": 15370
    },
    {
      "epoch": 0.47086917919358295,
      "grad_norm": 0.08984958380460739,
      "learning_rate": 1.6861076243251794e-05,
      "loss": 0.0019,
      "step": 15380
    },
    {
      "epoch": 0.4711753360071028,
      "grad_norm": 0.02212432399392128,
      "learning_rate": 1.6859035197828327e-05,
      "loss": 0.001,
      "step": 15390
    },
    {
      "epoch": 0.47148149282062274,
      "grad_norm": 0.010173480957746506,
      "learning_rate": 1.6856994152404864e-05,
      "loss": 0.0448,
      "step": 15400
    },
    {
      "epoch": 0.4717876496341426,
      "grad_norm": 0.001005297526717186,
      "learning_rate": 1.6854953106981398e-05,
      "loss": 0.0207,
      "step": 15410
    },
    {
      "epoch": 0.47209380644766247,
      "grad_norm": 0.026597701013088226,
      "learning_rate": 1.6852912061557932e-05,
      "loss": 0.0018,
      "step": 15420
    },
    {
      "epoch": 0.4723999632611824,
      "grad_norm": 0.036702558398246765,
      "learning_rate": 1.6850871016134465e-05,
      "loss": 0.0156,
      "step": 15430
    },
    {
      "epoch": 0.47270612007470225,
      "grad_norm": 0.03397683426737785,
      "learning_rate": 1.6848829970711e-05,
      "loss": 0.0015,
      "step": 15440
    },
    {
      "epoch": 0.47301227688822217,
      "grad_norm": 0.0412059985101223,
      "learning_rate": 1.6846788925287533e-05,
      "loss": 0.0338,
      "step": 15450
    },
    {
      "epoch": 0.47331843370174204,
      "grad_norm": 0.0296346265822649,
      "learning_rate": 1.6844747879864066e-05,
      "loss": 0.002,
      "step": 15460
    },
    {
      "epoch": 0.4736245905152619,
      "grad_norm": 0.026698870584368706,
      "learning_rate": 1.68427068344406e-05,
      "loss": 0.0017,
      "step": 15470
    },
    {
      "epoch": 0.4739307473287818,
      "grad_norm": 0.03346116095781326,
      "learning_rate": 1.6840665789017137e-05,
      "loss": 0.0017,
      "step": 15480
    },
    {
      "epoch": 0.4742369041423017,
      "grad_norm": 3.613192319869995,
      "learning_rate": 1.683862474359367e-05,
      "loss": 0.0801,
      "step": 15490
    },
    {
      "epoch": 0.47454306095582155,
      "grad_norm": 0.01974920742213726,
      "learning_rate": 1.6836583698170204e-05,
      "loss": 0.0311,
      "step": 15500
    },
    {
      "epoch": 0.47484921776934147,
      "grad_norm": 0.036161068826913834,
      "learning_rate": 1.6834542652746738e-05,
      "loss": 0.0366,
      "step": 15510
    },
    {
      "epoch": 0.47515537458286133,
      "grad_norm": 0.037598226219415665,
      "learning_rate": 1.683250160732327e-05,
      "loss": 0.0022,
      "step": 15520
    },
    {
      "epoch": 0.47546153139638125,
      "grad_norm": 0.0017591177020221949,
      "learning_rate": 1.6830460561899805e-05,
      "loss": 0.0264,
      "step": 15530
    },
    {
      "epoch": 0.4757676882099011,
      "grad_norm": 1.9473052024841309,
      "learning_rate": 1.682841951647634e-05,
      "loss": 0.0378,
      "step": 15540
    },
    {
      "epoch": 0.476073845023421,
      "grad_norm": 0.028805356472730637,
      "learning_rate": 1.6826378471052876e-05,
      "loss": 0.0033,
      "step": 15550
    },
    {
      "epoch": 0.4763800018369409,
      "grad_norm": 0.04321574419736862,
      "learning_rate": 1.682433742562941e-05,
      "loss": 0.004,
      "step": 15560
    },
    {
      "epoch": 0.47668615865046077,
      "grad_norm": 0.020115042105317116,
      "learning_rate": 1.6822296380205943e-05,
      "loss": 0.0018,
      "step": 15570
    },
    {
      "epoch": 0.47699231546398063,
      "grad_norm": 1.8348431587219238,
      "learning_rate": 1.6820255334782477e-05,
      "loss": 0.0066,
      "step": 15580
    },
    {
      "epoch": 0.47729847227750055,
      "grad_norm": 0.02867690660059452,
      "learning_rate": 1.681821428935901e-05,
      "loss": 0.0376,
      "step": 15590
    },
    {
      "epoch": 0.4776046290910204,
      "grad_norm": 0.04470261558890343,
      "learning_rate": 1.6816173243935544e-05,
      "loss": 0.0016,
      "step": 15600
    },
    {
      "epoch": 0.4779107859045403,
      "grad_norm": 0.038094211369752884,
      "learning_rate": 1.6814132198512078e-05,
      "loss": 0.0018,
      "step": 15610
    },
    {
      "epoch": 0.4782169427180602,
      "grad_norm": 0.05992033705115318,
      "learning_rate": 1.6812091153088615e-05,
      "loss": 0.0011,
      "step": 15620
    },
    {
      "epoch": 0.47852309953158007,
      "grad_norm": 0.013471383601427078,
      "learning_rate": 1.681005010766515e-05,
      "loss": 0.0014,
      "step": 15630
    },
    {
      "epoch": 0.4788292563451,
      "grad_norm": 0.009380892850458622,
      "learning_rate": 1.6808009062241682e-05,
      "loss": 0.0008,
      "step": 15640
    },
    {
      "epoch": 0.47913541315861985,
      "grad_norm": 0.07269982248544693,
      "learning_rate": 1.6805968016818216e-05,
      "loss": 0.0792,
      "step": 15650
    },
    {
      "epoch": 0.4794415699721397,
      "grad_norm": 0.06711164116859436,
      "learning_rate": 1.680392697139475e-05,
      "loss": 0.0014,
      "step": 15660
    },
    {
      "epoch": 0.47974772678565963,
      "grad_norm": 0.06711643934249878,
      "learning_rate": 1.6801885925971283e-05,
      "loss": 0.0304,
      "step": 15670
    },
    {
      "epoch": 0.4800538835991795,
      "grad_norm": 0.010790006257593632,
      "learning_rate": 1.6799844880547817e-05,
      "loss": 0.0016,
      "step": 15680
    },
    {
      "epoch": 0.48036004041269936,
      "grad_norm": 0.007425785530358553,
      "learning_rate": 1.679780383512435e-05,
      "loss": 0.0014,
      "step": 15690
    },
    {
      "epoch": 0.4806661972262193,
      "grad_norm": 0.05247770622372627,
      "learning_rate": 1.6795762789700887e-05,
      "loss": 0.0013,
      "step": 15700
    },
    {
      "epoch": 0.48097235403973915,
      "grad_norm": 0.013909654691815376,
      "learning_rate": 1.679372174427742e-05,
      "loss": 0.017,
      "step": 15710
    },
    {
      "epoch": 0.481278510853259,
      "grad_norm": 0.03523440286517143,
      "learning_rate": 1.6791680698853955e-05,
      "loss": 0.0014,
      "step": 15720
    },
    {
      "epoch": 0.48158466766677893,
      "grad_norm": 0.04040147736668587,
      "learning_rate": 1.6789639653430488e-05,
      "loss": 0.0362,
      "step": 15730
    },
    {
      "epoch": 0.4818908244802988,
      "grad_norm": 0.028905535116791725,
      "learning_rate": 1.6787598608007022e-05,
      "loss": 0.0064,
      "step": 15740
    },
    {
      "epoch": 0.4821969812938187,
      "grad_norm": 0.012326544150710106,
      "learning_rate": 1.6785557562583556e-05,
      "loss": 0.0009,
      "step": 15750
    },
    {
      "epoch": 0.4825031381073386,
      "grad_norm": 0.08507464081048965,
      "learning_rate": 1.678351651716009e-05,
      "loss": 0.001,
      "step": 15760
    },
    {
      "epoch": 0.48280929492085845,
      "grad_norm": 0.015180686488747597,
      "learning_rate": 1.6781475471736626e-05,
      "loss": 0.0393,
      "step": 15770
    },
    {
      "epoch": 0.48311545173437836,
      "grad_norm": 0.02354038506746292,
      "learning_rate": 1.677943442631316e-05,
      "loss": 0.0622,
      "step": 15780
    },
    {
      "epoch": 0.48342160854789823,
      "grad_norm": 0.016489248722791672,
      "learning_rate": 1.6777393380889694e-05,
      "loss": 0.0436,
      "step": 15790
    },
    {
      "epoch": 0.4837277653614181,
      "grad_norm": 1.6921132802963257,
      "learning_rate": 1.6775352335466227e-05,
      "loss": 0.1318,
      "step": 15800
    },
    {
      "epoch": 0.484033922174938,
      "grad_norm": 0.04323149845004082,
      "learning_rate": 1.677331129004276e-05,
      "loss": 0.0304,
      "step": 15810
    },
    {
      "epoch": 0.4843400789884579,
      "grad_norm": 1.5146102905273438,
      "learning_rate": 1.6771270244619294e-05,
      "loss": 0.0582,
      "step": 15820
    },
    {
      "epoch": 0.4846462358019778,
      "grad_norm": 0.0945398285984993,
      "learning_rate": 1.6769229199195828e-05,
      "loss": 0.0047,
      "step": 15830
    },
    {
      "epoch": 0.48495239261549766,
      "grad_norm": 0.11819786578416824,
      "learning_rate": 1.6767188153772365e-05,
      "loss": 0.0036,
      "step": 15840
    },
    {
      "epoch": 0.4852585494290175,
      "grad_norm": 0.0642530620098114,
      "learning_rate": 1.67651471083489e-05,
      "loss": 0.0262,
      "step": 15850
    },
    {
      "epoch": 0.48556470624253745,
      "grad_norm": 0.16260656714439392,
      "learning_rate": 1.6763106062925432e-05,
      "loss": 0.0028,
      "step": 15860
    },
    {
      "epoch": 0.4858708630560573,
      "grad_norm": 0.04906291887164116,
      "learning_rate": 1.6761065017501966e-05,
      "loss": 0.0027,
      "step": 15870
    },
    {
      "epoch": 0.4861770198695772,
      "grad_norm": 0.04261540248990059,
      "learning_rate": 1.67590239720785e-05,
      "loss": 0.0024,
      "step": 15880
    },
    {
      "epoch": 0.4864831766830971,
      "grad_norm": 0.008113395422697067,
      "learning_rate": 1.6756982926655033e-05,
      "loss": 0.002,
      "step": 15890
    },
    {
      "epoch": 0.48678933349661696,
      "grad_norm": 0.02410784922540188,
      "learning_rate": 1.6754941881231567e-05,
      "loss": 0.0408,
      "step": 15900
    },
    {
      "epoch": 0.4870954903101368,
      "grad_norm": 0.07522326707839966,
      "learning_rate": 1.67529008358081e-05,
      "loss": 0.0019,
      "step": 15910
    },
    {
      "epoch": 0.48740164712365674,
      "grad_norm": 0.05101842060685158,
      "learning_rate": 1.6750859790384638e-05,
      "loss": 0.0824,
      "step": 15920
    },
    {
      "epoch": 0.4877078039371766,
      "grad_norm": 0.07182684540748596,
      "learning_rate": 1.674881874496117e-05,
      "loss": 0.0022,
      "step": 15930
    },
    {
      "epoch": 0.48801396075069653,
      "grad_norm": 0.019159480929374695,
      "learning_rate": 1.6746777699537705e-05,
      "loss": 0.0011,
      "step": 15940
    },
    {
      "epoch": 0.4883201175642164,
      "grad_norm": 0.04581031948328018,
      "learning_rate": 1.674473665411424e-05,
      "loss": 0.0011,
      "step": 15950
    },
    {
      "epoch": 0.48862627437773626,
      "grad_norm": 0.016280028969049454,
      "learning_rate": 1.6742695608690772e-05,
      "loss": 0.0317,
      "step": 15960
    },
    {
      "epoch": 0.4889324311912562,
      "grad_norm": 0.005843177903443575,
      "learning_rate": 1.6740654563267306e-05,
      "loss": 0.0011,
      "step": 15970
    },
    {
      "epoch": 0.48923858800477604,
      "grad_norm": 0.012989268638193607,
      "learning_rate": 1.673861351784384e-05,
      "loss": 0.0015,
      "step": 15980
    },
    {
      "epoch": 0.4895447448182959,
      "grad_norm": 0.02991541661322117,
      "learning_rate": 1.6736572472420377e-05,
      "loss": 0.0019,
      "step": 15990
    },
    {
      "epoch": 0.4898509016318158,
      "grad_norm": 0.029118362814188004,
      "learning_rate": 1.673453142699691e-05,
      "loss": 0.0016,
      "step": 16000
    },
    {
      "epoch": 0.4901570584453357,
      "grad_norm": 0.019153952598571777,
      "learning_rate": 1.6732490381573444e-05,
      "loss": 0.0012,
      "step": 16010
    },
    {
      "epoch": 0.4904632152588556,
      "grad_norm": 0.024374444037675858,
      "learning_rate": 1.6730449336149978e-05,
      "loss": 0.0437,
      "step": 16020
    },
    {
      "epoch": 0.4907693720723755,
      "grad_norm": 0.0032764419447630644,
      "learning_rate": 1.672840829072651e-05,
      "loss": 0.0076,
      "step": 16030
    },
    {
      "epoch": 0.49107552888589534,
      "grad_norm": 0.03519267216324806,
      "learning_rate": 1.6726367245303045e-05,
      "loss": 0.0432,
      "step": 16040
    },
    {
      "epoch": 0.49138168569941526,
      "grad_norm": 0.039993781596422195,
      "learning_rate": 1.672432619987958e-05,
      "loss": 0.0011,
      "step": 16050
    },
    {
      "epoch": 0.4916878425129351,
      "grad_norm": 0.04215393587946892,
      "learning_rate": 1.6722285154456115e-05,
      "loss": 0.0014,
      "step": 16060
    },
    {
      "epoch": 0.491993999326455,
      "grad_norm": 0.7257235050201416,
      "learning_rate": 1.672024410903265e-05,
      "loss": 0.0026,
      "step": 16070
    },
    {
      "epoch": 0.4923001561399749,
      "grad_norm": 0.03599073737859726,
      "learning_rate": 1.6718203063609183e-05,
      "loss": 0.0369,
      "step": 16080
    },
    {
      "epoch": 0.4926063129534948,
      "grad_norm": 0.025609329342842102,
      "learning_rate": 1.6716162018185716e-05,
      "loss": 0.034,
      "step": 16090
    },
    {
      "epoch": 0.49291246976701464,
      "grad_norm": 0.19271115958690643,
      "learning_rate": 1.671412097276225e-05,
      "loss": 0.0015,
      "step": 16100
    },
    {
      "epoch": 0.49321862658053456,
      "grad_norm": 0.04940760135650635,
      "learning_rate": 1.6712079927338784e-05,
      "loss": 0.0015,
      "step": 16110
    },
    {
      "epoch": 0.4935247833940544,
      "grad_norm": 1.7428089380264282,
      "learning_rate": 1.6710038881915317e-05,
      "loss": 0.0373,
      "step": 16120
    },
    {
      "epoch": 0.49383094020757434,
      "grad_norm": 0.025140399113297462,
      "learning_rate": 1.670799783649185e-05,
      "loss": 0.0701,
      "step": 16130
    },
    {
      "epoch": 0.4941370970210942,
      "grad_norm": 0.27025794982910156,
      "learning_rate": 1.6705956791068388e-05,
      "loss": 0.031,
      "step": 16140
    },
    {
      "epoch": 0.49444325383461407,
      "grad_norm": 0.00859465915709734,
      "learning_rate": 1.670391574564492e-05,
      "loss": 0.0026,
      "step": 16150
    },
    {
      "epoch": 0.494749410648134,
      "grad_norm": 0.09637712687253952,
      "learning_rate": 1.6701874700221455e-05,
      "loss": 0.0027,
      "step": 16160
    },
    {
      "epoch": 0.49505556746165386,
      "grad_norm": 0.05293964594602585,
      "learning_rate": 1.669983365479799e-05,
      "loss": 0.0023,
      "step": 16170
    },
    {
      "epoch": 0.4953617242751737,
      "grad_norm": 0.05521400645375252,
      "learning_rate": 1.6697792609374523e-05,
      "loss": 0.0847,
      "step": 16180
    },
    {
      "epoch": 0.49566788108869364,
      "grad_norm": 0.015771513804793358,
      "learning_rate": 1.6695751563951056e-05,
      "loss": 0.0382,
      "step": 16190
    },
    {
      "epoch": 0.4959740379022135,
      "grad_norm": 0.021694453433156013,
      "learning_rate": 1.669371051852759e-05,
      "loss": 0.0017,
      "step": 16200
    },
    {
      "epoch": 0.4962801947157334,
      "grad_norm": 0.030893685296177864,
      "learning_rate": 1.6691669473104127e-05,
      "loss": 0.0057,
      "step": 16210
    },
    {
      "epoch": 0.4965863515292533,
      "grad_norm": 0.05782706290483475,
      "learning_rate": 1.668962842768066e-05,
      "loss": 0.0302,
      "step": 16220
    },
    {
      "epoch": 0.49689250834277315,
      "grad_norm": 0.05536564439535141,
      "learning_rate": 1.6687587382257194e-05,
      "loss": 0.0046,
      "step": 16230
    },
    {
      "epoch": 0.4971986651562931,
      "grad_norm": 0.03824659436941147,
      "learning_rate": 1.6685546336833728e-05,
      "loss": 0.0296,
      "step": 16240
    },
    {
      "epoch": 0.49750482196981294,
      "grad_norm": 0.054744064807891846,
      "learning_rate": 1.668350529141026e-05,
      "loss": 0.0064,
      "step": 16250
    },
    {
      "epoch": 0.4978109787833328,
      "grad_norm": 0.046218547970056534,
      "learning_rate": 1.6681464245986795e-05,
      "loss": 0.0019,
      "step": 16260
    },
    {
      "epoch": 0.4981171355968527,
      "grad_norm": 0.02139321155846119,
      "learning_rate": 1.667942320056333e-05,
      "loss": 0.0019,
      "step": 16270
    },
    {
      "epoch": 0.4984232924103726,
      "grad_norm": 0.03447642922401428,
      "learning_rate": 1.6677382155139862e-05,
      "loss": 0.0012,
      "step": 16280
    },
    {
      "epoch": 0.49872944922389245,
      "grad_norm": 0.021523132920265198,
      "learning_rate": 1.66753411097164e-05,
      "loss": 0.0015,
      "step": 16290
    },
    {
      "epoch": 0.49903560603741237,
      "grad_norm": 0.03812052682042122,
      "learning_rate": 1.6673300064292933e-05,
      "loss": 0.0012,
      "step": 16300
    },
    {
      "epoch": 0.49934176285093224,
      "grad_norm": 0.011928625404834747,
      "learning_rate": 1.6671259018869467e-05,
      "loss": 0.0361,
      "step": 16310
    },
    {
      "epoch": 0.49964791966445216,
      "grad_norm": 0.023537302389740944,
      "learning_rate": 1.6669217973446e-05,
      "loss": 0.0009,
      "step": 16320
    },
    {
      "epoch": 0.499954076477972,
      "grad_norm": 0.03526238352060318,
      "learning_rate": 1.6667176928022534e-05,
      "loss": 0.001,
      "step": 16330
    },
    {
      "epoch": 0.5002602332914919,
      "grad_norm": 0.021469684317708015,
      "learning_rate": 1.6665135882599068e-05,
      "loss": 0.0012,
      "step": 16340
    },
    {
      "epoch": 0.5005663901050118,
      "grad_norm": 0.004519851412624121,
      "learning_rate": 1.66630948371756e-05,
      "loss": 0.0015,
      "step": 16350
    },
    {
      "epoch": 0.5008725469185317,
      "grad_norm": 0.025210225954651833,
      "learning_rate": 1.666105379175214e-05,
      "loss": 0.0008,
      "step": 16360
    },
    {
      "epoch": 0.5011787037320515,
      "grad_norm": 1.908094882965088,
      "learning_rate": 1.6659012746328672e-05,
      "loss": 0.0373,
      "step": 16370
    },
    {
      "epoch": 0.5014848605455714,
      "grad_norm": 0.013718935661017895,
      "learning_rate": 1.6656971700905206e-05,
      "loss": 0.0012,
      "step": 16380
    },
    {
      "epoch": 0.5017910173590914,
      "grad_norm": 0.023117734119296074,
      "learning_rate": 1.665493065548174e-05,
      "loss": 0.0011,
      "step": 16390
    },
    {
      "epoch": 0.5020971741726112,
      "grad_norm": 0.03428678959608078,
      "learning_rate": 1.6652889610058273e-05,
      "loss": 0.0359,
      "step": 16400
    },
    {
      "epoch": 0.5024033309861311,
      "grad_norm": 0.025056229904294014,
      "learning_rate": 1.6650848564634807e-05,
      "loss": 0.0088,
      "step": 16410
    },
    {
      "epoch": 0.502709487799651,
      "grad_norm": 0.10894183814525604,
      "learning_rate": 1.664880751921134e-05,
      "loss": 0.0014,
      "step": 16420
    },
    {
      "epoch": 0.5030156446131708,
      "grad_norm": 2.0879101753234863,
      "learning_rate": 1.6646766473787877e-05,
      "loss": 0.0727,
      "step": 16430
    },
    {
      "epoch": 0.5033218014266907,
      "grad_norm": 0.03085145354270935,
      "learning_rate": 1.664472542836441e-05,
      "loss": 0.0445,
      "step": 16440
    },
    {
      "epoch": 0.5036279582402107,
      "grad_norm": 0.034909315407276154,
      "learning_rate": 1.6642684382940945e-05,
      "loss": 0.032,
      "step": 16450
    },
    {
      "epoch": 0.5039341150537305,
      "grad_norm": 0.07139638811349869,
      "learning_rate": 1.6640643337517478e-05,
      "loss": 0.0021,
      "step": 16460
    },
    {
      "epoch": 0.5042402718672504,
      "grad_norm": 0.05565915256738663,
      "learning_rate": 1.6638602292094012e-05,
      "loss": 0.0019,
      "step": 16470
    },
    {
      "epoch": 0.5045464286807703,
      "grad_norm": 0.06707247346639633,
      "learning_rate": 1.6636561246670545e-05,
      "loss": 0.037,
      "step": 16480
    },
    {
      "epoch": 0.5048525854942901,
      "grad_norm": 0.030606955289840698,
      "learning_rate": 1.663452020124708e-05,
      "loss": 0.0724,
      "step": 16490
    },
    {
      "epoch": 0.5051587423078101,
      "grad_norm": 1.74756920337677,
      "learning_rate": 1.6632479155823613e-05,
      "loss": 0.0518,
      "step": 16500
    },
    {
      "epoch": 0.50546489912133,
      "grad_norm": 0.058748383074998856,
      "learning_rate": 1.663043811040015e-05,
      "loss": 0.0211,
      "step": 16510
    },
    {
      "epoch": 0.5057710559348498,
      "grad_norm": 0.03573144972324371,
      "learning_rate": 1.6628397064976683e-05,
      "loss": 0.0269,
      "step": 16520
    },
    {
      "epoch": 0.5060772127483697,
      "grad_norm": 0.0738101601600647,
      "learning_rate": 1.6626356019553217e-05,
      "loss": 0.0589,
      "step": 16530
    },
    {
      "epoch": 0.5063833695618896,
      "grad_norm": 0.04102109745144844,
      "learning_rate": 1.662431497412975e-05,
      "loss": 0.0032,
      "step": 16540
    },
    {
      "epoch": 0.5066895263754095,
      "grad_norm": 0.050929561257362366,
      "learning_rate": 1.6622273928706284e-05,
      "loss": 0.0313,
      "step": 16550
    },
    {
      "epoch": 0.5069956831889294,
      "grad_norm": 0.13514424860477448,
      "learning_rate": 1.6620232883282818e-05,
      "loss": 0.0058,
      "step": 16560
    },
    {
      "epoch": 0.5073018400024493,
      "grad_norm": 1.3987035751342773,
      "learning_rate": 1.661819183785935e-05,
      "loss": 0.0077,
      "step": 16570
    },
    {
      "epoch": 0.5076079968159691,
      "grad_norm": 0.060436755418777466,
      "learning_rate": 1.661615079243589e-05,
      "loss": 0.0248,
      "step": 16580
    },
    {
      "epoch": 0.507914153629489,
      "grad_norm": 0.05029550939798355,
      "learning_rate": 1.6614109747012422e-05,
      "loss": 0.002,
      "step": 16590
    },
    {
      "epoch": 0.5082203104430089,
      "grad_norm": 0.04158443585038185,
      "learning_rate": 1.6612068701588956e-05,
      "loss": 0.003,
      "step": 16600
    },
    {
      "epoch": 0.5085264672565288,
      "grad_norm": 0.08062448352575302,
      "learning_rate": 1.661002765616549e-05,
      "loss": 0.003,
      "step": 16610
    },
    {
      "epoch": 0.5088326240700487,
      "grad_norm": 0.10435229539871216,
      "learning_rate": 1.6607986610742023e-05,
      "loss": 0.0157,
      "step": 16620
    },
    {
      "epoch": 0.5091387808835686,
      "grad_norm": 0.014095488935709,
      "learning_rate": 1.6605945565318557e-05,
      "loss": 0.0013,
      "step": 16630
    },
    {
      "epoch": 0.5094449376970884,
      "grad_norm": 0.044816792011260986,
      "learning_rate": 1.660390451989509e-05,
      "loss": 0.0357,
      "step": 16640
    },
    {
      "epoch": 0.5097510945106083,
      "grad_norm": 0.04016939550638199,
      "learning_rate": 1.6601863474471628e-05,
      "loss": 0.0017,
      "step": 16650
    },
    {
      "epoch": 0.5100572513241283,
      "grad_norm": 0.007629978470504284,
      "learning_rate": 1.659982242904816e-05,
      "loss": 0.0013,
      "step": 16660
    },
    {
      "epoch": 0.5103634081376481,
      "grad_norm": 0.026605525985360146,
      "learning_rate": 1.6597781383624695e-05,
      "loss": 0.0706,
      "step": 16670
    },
    {
      "epoch": 0.510669564951168,
      "grad_norm": 0.02703867293894291,
      "learning_rate": 1.659574033820123e-05,
      "loss": 0.0014,
      "step": 16680
    },
    {
      "epoch": 0.5109757217646879,
      "grad_norm": 0.03841005265712738,
      "learning_rate": 1.6593699292777762e-05,
      "loss": 0.0432,
      "step": 16690
    },
    {
      "epoch": 0.5112818785782077,
      "grad_norm": 0.10497347265481949,
      "learning_rate": 1.6591658247354296e-05,
      "loss": 0.0458,
      "step": 16700
    },
    {
      "epoch": 0.5115880353917276,
      "grad_norm": 0.07072240114212036,
      "learning_rate": 1.658961720193083e-05,
      "loss": 0.0045,
      "step": 16710
    },
    {
      "epoch": 0.5118941922052476,
      "grad_norm": 0.023181024938821793,
      "learning_rate": 1.6587576156507363e-05,
      "loss": 0.0016,
      "step": 16720
    },
    {
      "epoch": 0.5122003490187674,
      "grad_norm": 0.01792813651263714,
      "learning_rate": 1.65855351110839e-05,
      "loss": 0.0019,
      "step": 16730
    },
    {
      "epoch": 0.5125065058322873,
      "grad_norm": 0.019987735897302628,
      "learning_rate": 1.6583494065660434e-05,
      "loss": 0.0014,
      "step": 16740
    },
    {
      "epoch": 0.5128126626458072,
      "grad_norm": 0.02781057544052601,
      "learning_rate": 1.6581453020236967e-05,
      "loss": 0.0013,
      "step": 16750
    },
    {
      "epoch": 0.513118819459327,
      "grad_norm": 0.008113838732242584,
      "learning_rate": 1.65794119748135e-05,
      "loss": 0.001,
      "step": 16760
    },
    {
      "epoch": 0.513424976272847,
      "grad_norm": 0.027066079899668694,
      "learning_rate": 1.6577370929390035e-05,
      "loss": 0.0065,
      "step": 16770
    },
    {
      "epoch": 0.5137311330863669,
      "grad_norm": 0.06300260126590729,
      "learning_rate": 1.657532988396657e-05,
      "loss": 0.033,
      "step": 16780
    },
    {
      "epoch": 0.5140372898998867,
      "grad_norm": 0.011744222603738308,
      "learning_rate": 1.6573288838543102e-05,
      "loss": 0.0009,
      "step": 16790
    },
    {
      "epoch": 0.5143434467134066,
      "grad_norm": 1.333254098892212,
      "learning_rate": 1.657124779311964e-05,
      "loss": 0.0213,
      "step": 16800
    },
    {
      "epoch": 0.5146496035269265,
      "grad_norm": 0.040958862751722336,
      "learning_rate": 1.6569206747696173e-05,
      "loss": 0.001,
      "step": 16810
    },
    {
      "epoch": 0.5149557603404463,
      "grad_norm": 0.01621023751795292,
      "learning_rate": 1.6567165702272706e-05,
      "loss": 0.0014,
      "step": 16820
    },
    {
      "epoch": 0.5152619171539663,
      "grad_norm": 0.024603433907032013,
      "learning_rate": 1.656512465684924e-05,
      "loss": 0.0007,
      "step": 16830
    },
    {
      "epoch": 0.5155680739674862,
      "grad_norm": 0.035371147096157074,
      "learning_rate": 1.6563083611425774e-05,
      "loss": 0.0012,
      "step": 16840
    },
    {
      "epoch": 0.515874230781006,
      "grad_norm": 1.8368226289749146,
      "learning_rate": 1.6561042566002307e-05,
      "loss": 0.0383,
      "step": 16850
    },
    {
      "epoch": 0.5161803875945259,
      "grad_norm": 0.01978195458650589,
      "learning_rate": 1.655900152057884e-05,
      "loss": 0.001,
      "step": 16860
    },
    {
      "epoch": 0.5164865444080458,
      "grad_norm": 0.004599427804350853,
      "learning_rate": 1.6556960475155378e-05,
      "loss": 0.0009,
      "step": 16870
    },
    {
      "epoch": 0.5167927012215657,
      "grad_norm": 0.020025892183184624,
      "learning_rate": 1.655491942973191e-05,
      "loss": 0.0176,
      "step": 16880
    },
    {
      "epoch": 0.5170988580350856,
      "grad_norm": 0.013939079828560352,
      "learning_rate": 1.6552878384308445e-05,
      "loss": 0.001,
      "step": 16890
    },
    {
      "epoch": 0.5174050148486055,
      "grad_norm": 0.023067224770784378,
      "learning_rate": 1.655083733888498e-05,
      "loss": 0.001,
      "step": 16900
    },
    {
      "epoch": 0.5177111716621253,
      "grad_norm": 0.05304434150457382,
      "learning_rate": 1.6548796293461513e-05,
      "loss": 0.0325,
      "step": 16910
    },
    {
      "epoch": 0.5180173284756452,
      "grad_norm": 0.0912894606590271,
      "learning_rate": 1.6546755248038046e-05,
      "loss": 0.0402,
      "step": 16920
    },
    {
      "epoch": 0.5183234852891652,
      "grad_norm": 0.04821021854877472,
      "learning_rate": 1.654471420261458e-05,
      "loss": 0.0014,
      "step": 16930
    },
    {
      "epoch": 0.518629642102685,
      "grad_norm": 0.022273050621151924,
      "learning_rate": 1.6542673157191113e-05,
      "loss": 0.0012,
      "step": 16940
    },
    {
      "epoch": 0.5189357989162049,
      "grad_norm": 0.017597664147615433,
      "learning_rate": 1.654063211176765e-05,
      "loss": 0.0339,
      "step": 16950
    },
    {
      "epoch": 0.5192419557297248,
      "grad_norm": 0.014150051400065422,
      "learning_rate": 1.6538591066344184e-05,
      "loss": 0.0013,
      "step": 16960
    },
    {
      "epoch": 0.5195481125432446,
      "grad_norm": 0.012925826944410801,
      "learning_rate": 1.6536550020920718e-05,
      "loss": 0.0014,
      "step": 16970
    },
    {
      "epoch": 0.5198542693567645,
      "grad_norm": 0.006182510871440172,
      "learning_rate": 1.653450897549725e-05,
      "loss": 0.0011,
      "step": 16980
    },
    {
      "epoch": 0.5201604261702845,
      "grad_norm": 0.004860129207372665,
      "learning_rate": 1.6532467930073785e-05,
      "loss": 0.0268,
      "step": 16990
    },
    {
      "epoch": 0.5204665829838043,
      "grad_norm": 0.018451331183314323,
      "learning_rate": 1.653042688465032e-05,
      "loss": 0.0038,
      "step": 17000
    },
    {
      "epoch": 0.5207727397973242,
      "grad_norm": 0.044342756271362305,
      "learning_rate": 1.6528385839226852e-05,
      "loss": 0.0017,
      "step": 17010
    },
    {
      "epoch": 0.5210788966108441,
      "grad_norm": 0.0506894551217556,
      "learning_rate": 1.652634479380339e-05,
      "loss": 0.0113,
      "step": 17020
    },
    {
      "epoch": 0.5213850534243639,
      "grad_norm": 0.023562556132674217,
      "learning_rate": 1.6524303748379923e-05,
      "loss": 0.0009,
      "step": 17030
    },
    {
      "epoch": 0.5216912102378839,
      "grad_norm": 0.025000646710395813,
      "learning_rate": 1.6522262702956457e-05,
      "loss": 0.0445,
      "step": 17040
    },
    {
      "epoch": 0.5219973670514038,
      "grad_norm": 0.01237867958843708,
      "learning_rate": 1.652022165753299e-05,
      "loss": 0.0615,
      "step": 17050
    },
    {
      "epoch": 0.5223035238649236,
      "grad_norm": 0.013150379993021488,
      "learning_rate": 1.6518180612109524e-05,
      "loss": 0.073,
      "step": 17060
    },
    {
      "epoch": 0.5226096806784435,
      "grad_norm": 0.07993731647729874,
      "learning_rate": 1.6516139566686058e-05,
      "loss": 0.023,
      "step": 17070
    },
    {
      "epoch": 0.5229158374919634,
      "grad_norm": 0.07269664108753204,
      "learning_rate": 1.651409852126259e-05,
      "loss": 0.0151,
      "step": 17080
    },
    {
      "epoch": 0.5232219943054832,
      "grad_norm": 0.060519956052303314,
      "learning_rate": 1.6512057475839128e-05,
      "loss": 0.0176,
      "step": 17090
    },
    {
      "epoch": 0.5235281511190032,
      "grad_norm": 0.0572262741625309,
      "learning_rate": 1.6510016430415662e-05,
      "loss": 0.0025,
      "step": 17100
    },
    {
      "epoch": 0.5238343079325231,
      "grad_norm": 3.1175644397735596,
      "learning_rate": 1.6507975384992196e-05,
      "loss": 0.0104,
      "step": 17110
    },
    {
      "epoch": 0.5241404647460429,
      "grad_norm": 0.03821433708071709,
      "learning_rate": 1.650593433956873e-05,
      "loss": 0.0021,
      "step": 17120
    },
    {
      "epoch": 0.5244466215595628,
      "grad_norm": 1.795288324356079,
      "learning_rate": 1.6503893294145263e-05,
      "loss": 0.0368,
      "step": 17130
    },
    {
      "epoch": 0.5247527783730827,
      "grad_norm": 0.03273487463593483,
      "learning_rate": 1.6501852248721797e-05,
      "loss": 0.0398,
      "step": 17140
    },
    {
      "epoch": 0.5250589351866026,
      "grad_norm": 0.02110968343913555,
      "learning_rate": 1.649981120329833e-05,
      "loss": 0.001,
      "step": 17150
    },
    {
      "epoch": 0.5253650920001225,
      "grad_norm": 0.03305762633681297,
      "learning_rate": 1.6497770157874864e-05,
      "loss": 0.0315,
      "step": 17160
    },
    {
      "epoch": 0.5256712488136424,
      "grad_norm": 0.07800909131765366,
      "learning_rate": 1.64957291124514e-05,
      "loss": 0.0374,
      "step": 17170
    },
    {
      "epoch": 0.5259774056271622,
      "grad_norm": 0.06680372357368469,
      "learning_rate": 1.6493688067027934e-05,
      "loss": 0.0326,
      "step": 17180
    },
    {
      "epoch": 0.5262835624406821,
      "grad_norm": 0.07900522649288177,
      "learning_rate": 1.6491647021604468e-05,
      "loss": 0.0032,
      "step": 17190
    },
    {
      "epoch": 0.526589719254202,
      "grad_norm": 0.15055787563323975,
      "learning_rate": 1.6489605976181002e-05,
      "loss": 0.0362,
      "step": 17200
    },
    {
      "epoch": 0.5268958760677219,
      "grad_norm": 0.05299738049507141,
      "learning_rate": 1.6487564930757535e-05,
      "loss": 0.0032,
      "step": 17210
    },
    {
      "epoch": 0.5272020328812418,
      "grad_norm": 0.023163579404354095,
      "learning_rate": 1.648552388533407e-05,
      "loss": 0.0019,
      "step": 17220
    },
    {
      "epoch": 0.5275081896947617,
      "grad_norm": 0.03544104844331741,
      "learning_rate": 1.6483482839910603e-05,
      "loss": 0.0202,
      "step": 17230
    },
    {
      "epoch": 0.5278143465082815,
      "grad_norm": 0.09816358238458633,
      "learning_rate": 1.648144179448714e-05,
      "loss": 0.0019,
      "step": 17240
    },
    {
      "epoch": 0.5281205033218014,
      "grad_norm": 0.05185175687074661,
      "learning_rate": 1.6479400749063673e-05,
      "loss": 0.0017,
      "step": 17250
    },
    {
      "epoch": 0.5284266601353214,
      "grad_norm": 0.024396611377596855,
      "learning_rate": 1.6477359703640207e-05,
      "loss": 0.0191,
      "step": 17260
    },
    {
      "epoch": 0.5287328169488412,
      "grad_norm": 0.014095290564000607,
      "learning_rate": 1.647531865821674e-05,
      "loss": 0.0015,
      "step": 17270
    },
    {
      "epoch": 0.5290389737623611,
      "grad_norm": 0.0964067205786705,
      "learning_rate": 1.6473277612793274e-05,
      "loss": 0.0343,
      "step": 17280
    },
    {
      "epoch": 0.529345130575881,
      "grad_norm": 0.03804824501276016,
      "learning_rate": 1.6471236567369808e-05,
      "loss": 0.0015,
      "step": 17290
    },
    {
      "epoch": 0.5296512873894008,
      "grad_norm": 0.02773095667362213,
      "learning_rate": 1.646919552194634e-05,
      "loss": 0.0346,
      "step": 17300
    },
    {
      "epoch": 0.5299574442029208,
      "grad_norm": 0.09141997992992401,
      "learning_rate": 1.646715447652288e-05,
      "loss": 0.0017,
      "step": 17310
    },
    {
      "epoch": 0.5302636010164407,
      "grad_norm": 0.03980967774987221,
      "learning_rate": 1.6465113431099412e-05,
      "loss": 0.041,
      "step": 17320
    },
    {
      "epoch": 0.5305697578299605,
      "grad_norm": 0.044228289276361465,
      "learning_rate": 1.6463072385675946e-05,
      "loss": 0.0268,
      "step": 17330
    },
    {
      "epoch": 0.5308759146434804,
      "grad_norm": 0.06565989553928375,
      "learning_rate": 1.646103134025248e-05,
      "loss": 0.0388,
      "step": 17340
    },
    {
      "epoch": 0.5311820714570002,
      "grad_norm": 0.03285519778728485,
      "learning_rate": 1.6458990294829013e-05,
      "loss": 0.0013,
      "step": 17350
    },
    {
      "epoch": 0.5314882282705201,
      "grad_norm": 0.022246170789003372,
      "learning_rate": 1.6456949249405547e-05,
      "loss": 0.0012,
      "step": 17360
    },
    {
      "epoch": 0.5317943850840401,
      "grad_norm": 0.01197630912065506,
      "learning_rate": 1.645490820398208e-05,
      "loss": 0.0728,
      "step": 17370
    },
    {
      "epoch": 0.53210054189756,
      "grad_norm": 0.06816897541284561,
      "learning_rate": 1.6452867158558614e-05,
      "loss": 0.002,
      "step": 17380
    },
    {
      "epoch": 0.5324066987110798,
      "grad_norm": 0.04867076873779297,
      "learning_rate": 1.645082611313515e-05,
      "loss": 0.0031,
      "step": 17390
    },
    {
      "epoch": 0.5327128555245997,
      "grad_norm": 0.04517285153269768,
      "learning_rate": 1.6448785067711685e-05,
      "loss": 0.0019,
      "step": 17400
    },
    {
      "epoch": 0.5330190123381195,
      "grad_norm": 0.0661557987332344,
      "learning_rate": 1.644674402228822e-05,
      "loss": 0.0018,
      "step": 17410
    },
    {
      "epoch": 0.5333251691516395,
      "grad_norm": 0.02131563052535057,
      "learning_rate": 1.644470297686475e-05,
      "loss": 0.0012,
      "step": 17420
    },
    {
      "epoch": 0.5336313259651594,
      "grad_norm": 0.021357625722885132,
      "learning_rate": 1.6442661931441286e-05,
      "loss": 0.0016,
      "step": 17430
    },
    {
      "epoch": 0.5339374827786793,
      "grad_norm": 0.037324972450733185,
      "learning_rate": 1.644062088601782e-05,
      "loss": 0.0274,
      "step": 17440
    },
    {
      "epoch": 0.5342436395921991,
      "grad_norm": 0.03957406431436539,
      "learning_rate": 1.6438579840594353e-05,
      "loss": 0.0013,
      "step": 17450
    },
    {
      "epoch": 0.534549796405719,
      "grad_norm": 0.025531219318509102,
      "learning_rate": 1.643653879517089e-05,
      "loss": 0.0448,
      "step": 17460
    },
    {
      "epoch": 0.5348559532192388,
      "grad_norm": 0.0395304299890995,
      "learning_rate": 1.6434497749747424e-05,
      "loss": 0.0012,
      "step": 17470
    },
    {
      "epoch": 0.5351621100327588,
      "grad_norm": 0.04857146367430687,
      "learning_rate": 1.6432456704323957e-05,
      "loss": 0.0323,
      "step": 17480
    },
    {
      "epoch": 0.5354682668462787,
      "grad_norm": 0.05811380594968796,
      "learning_rate": 1.6430415658900488e-05,
      "loss": 0.0015,
      "step": 17490
    },
    {
      "epoch": 0.5357744236597985,
      "grad_norm": 0.05035849288105965,
      "learning_rate": 1.6428374613477025e-05,
      "loss": 0.0014,
      "step": 17500
    },
    {
      "epoch": 0.5360805804733184,
      "grad_norm": 0.04247783496975899,
      "learning_rate": 1.6426333568053558e-05,
      "loss": 0.0204,
      "step": 17510
    },
    {
      "epoch": 0.5363867372868383,
      "grad_norm": 0.042619120329618454,
      "learning_rate": 1.6424292522630092e-05,
      "loss": 0.0015,
      "step": 17520
    },
    {
      "epoch": 0.5366928941003583,
      "grad_norm": 0.026724372059106827,
      "learning_rate": 1.6422251477206626e-05,
      "loss": 0.0569,
      "step": 17530
    },
    {
      "epoch": 0.5369990509138781,
      "grad_norm": 0.07065948098897934,
      "learning_rate": 1.6420210431783163e-05,
      "loss": 0.0013,
      "step": 17540
    },
    {
      "epoch": 0.537305207727398,
      "grad_norm": 0.3026691973209381,
      "learning_rate": 1.6418169386359696e-05,
      "loss": 0.0018,
      "step": 17550
    },
    {
      "epoch": 0.5376113645409178,
      "grad_norm": 0.04276187717914581,
      "learning_rate": 1.641612834093623e-05,
      "loss": 0.0354,
      "step": 17560
    },
    {
      "epoch": 0.5379175213544377,
      "grad_norm": 0.020780904218554497,
      "learning_rate": 1.6414087295512764e-05,
      "loss": 0.0012,
      "step": 17570
    },
    {
      "epoch": 0.5382236781679576,
      "grad_norm": 0.030640169978141785,
      "learning_rate": 1.6412046250089297e-05,
      "loss": 0.0012,
      "step": 17580
    },
    {
      "epoch": 0.5385298349814776,
      "grad_norm": 0.18549777567386627,
      "learning_rate": 1.641000520466583e-05,
      "loss": 0.0128,
      "step": 17590
    },
    {
      "epoch": 0.5388359917949974,
      "grad_norm": 0.024075370281934738,
      "learning_rate": 1.6407964159242364e-05,
      "loss": 0.0252,
      "step": 17600
    },
    {
      "epoch": 0.5391421486085173,
      "grad_norm": 0.06353453546762466,
      "learning_rate": 1.64059231138189e-05,
      "loss": 0.0018,
      "step": 17610
    },
    {
      "epoch": 0.5394483054220371,
      "grad_norm": 0.0396769642829895,
      "learning_rate": 1.6403882068395435e-05,
      "loss": 0.0114,
      "step": 17620
    },
    {
      "epoch": 0.539754462235557,
      "grad_norm": 0.03546707704663277,
      "learning_rate": 1.640184102297197e-05,
      "loss": 0.0101,
      "step": 17630
    },
    {
      "epoch": 0.540060619049077,
      "grad_norm": 0.036509331315755844,
      "learning_rate": 1.63997999775485e-05,
      "loss": 0.0359,
      "step": 17640
    },
    {
      "epoch": 0.5403667758625968,
      "grad_norm": 0.20802642405033112,
      "learning_rate": 1.6397758932125036e-05,
      "loss": 0.0022,
      "step": 17650
    },
    {
      "epoch": 0.5406729326761167,
      "grad_norm": 0.02195325493812561,
      "learning_rate": 1.639571788670157e-05,
      "loss": 0.0011,
      "step": 17660
    },
    {
      "epoch": 0.5409790894896366,
      "grad_norm": 0.027076683938503265,
      "learning_rate": 1.6393676841278103e-05,
      "loss": 0.0013,
      "step": 17670
    },
    {
      "epoch": 0.5412852463031564,
      "grad_norm": 0.02356819249689579,
      "learning_rate": 1.639163579585464e-05,
      "loss": 0.001,
      "step": 17680
    },
    {
      "epoch": 0.5415914031166763,
      "grad_norm": 0.03961893543601036,
      "learning_rate": 1.6389594750431174e-05,
      "loss": 0.0401,
      "step": 17690
    },
    {
      "epoch": 0.5418975599301963,
      "grad_norm": 0.00835137628018856,
      "learning_rate": 1.6387553705007708e-05,
      "loss": 0.0008,
      "step": 17700
    },
    {
      "epoch": 0.5422037167437161,
      "grad_norm": 1.968047022819519,
      "learning_rate": 1.6385512659584238e-05,
      "loss": 0.0752,
      "step": 17710
    },
    {
      "epoch": 0.542509873557236,
      "grad_norm": 0.06407403945922852,
      "learning_rate": 1.6383471614160775e-05,
      "loss": 0.0291,
      "step": 17720
    },
    {
      "epoch": 0.5428160303707559,
      "grad_norm": 0.024512534961104393,
      "learning_rate": 1.638143056873731e-05,
      "loss": 0.0015,
      "step": 17730
    },
    {
      "epoch": 0.5431221871842757,
      "grad_norm": 0.04934084042906761,
      "learning_rate": 1.6379389523313842e-05,
      "loss": 0.034,
      "step": 17740
    },
    {
      "epoch": 0.5434283439977957,
      "grad_norm": 0.050950150936841965,
      "learning_rate": 1.6377348477890376e-05,
      "loss": 0.0027,
      "step": 17750
    },
    {
      "epoch": 0.5437345008113156,
      "grad_norm": 0.02033846266567707,
      "learning_rate": 1.6375307432466913e-05,
      "loss": 0.0018,
      "step": 17760
    },
    {
      "epoch": 0.5440406576248354,
      "grad_norm": 0.0649678111076355,
      "learning_rate": 1.6373266387043447e-05,
      "loss": 0.0015,
      "step": 17770
    },
    {
      "epoch": 0.5443468144383553,
      "grad_norm": 0.022345086559653282,
      "learning_rate": 1.6371225341619977e-05,
      "loss": 0.0352,
      "step": 17780
    },
    {
      "epoch": 0.5446529712518752,
      "grad_norm": 1.8173717260360718,
      "learning_rate": 1.6369184296196514e-05,
      "loss": 0.0383,
      "step": 17790
    },
    {
      "epoch": 0.5449591280653951,
      "grad_norm": 0.014938019216060638,
      "learning_rate": 1.6367143250773048e-05,
      "loss": 0.0017,
      "step": 17800
    },
    {
      "epoch": 0.545265284878915,
      "grad_norm": 0.0156011413782835,
      "learning_rate": 1.636510220534958e-05,
      "loss": 0.0707,
      "step": 17810
    },
    {
      "epoch": 0.5455714416924349,
      "grad_norm": 0.017185376957058907,
      "learning_rate": 1.6363061159926115e-05,
      "loss": 0.0014,
      "step": 17820
    },
    {
      "epoch": 0.5458775985059547,
      "grad_norm": 0.026435496285557747,
      "learning_rate": 1.6361020114502652e-05,
      "loss": 0.0018,
      "step": 17830
    },
    {
      "epoch": 0.5461837553194746,
      "grad_norm": 0.03759821131825447,
      "learning_rate": 1.6358979069079185e-05,
      "loss": 0.0064,
      "step": 17840
    },
    {
      "epoch": 0.5464899121329945,
      "grad_norm": 0.059338733553886414,
      "learning_rate": 1.6356938023655716e-05,
      "loss": 0.0018,
      "step": 17850
    },
    {
      "epoch": 0.5467960689465144,
      "grad_norm": 0.6831011772155762,
      "learning_rate": 1.635489697823225e-05,
      "loss": 0.0032,
      "step": 17860
    },
    {
      "epoch": 0.5471022257600343,
      "grad_norm": 0.023306116461753845,
      "learning_rate": 1.6352855932808786e-05,
      "loss": 0.0015,
      "step": 17870
    },
    {
      "epoch": 0.5474083825735542,
      "grad_norm": 0.03049333021044731,
      "learning_rate": 1.635081488738532e-05,
      "loss": 0.0009,
      "step": 17880
    },
    {
      "epoch": 0.547714539387074,
      "grad_norm": 0.02894159033894539,
      "learning_rate": 1.6348773841961854e-05,
      "loss": 0.0011,
      "step": 17890
    },
    {
      "epoch": 0.5480206962005939,
      "grad_norm": 0.017394239082932472,
      "learning_rate": 1.634673279653839e-05,
      "loss": 0.0008,
      "step": 17900
    },
    {
      "epoch": 0.5483268530141139,
      "grad_norm": 0.02814468927681446,
      "learning_rate": 1.6344691751114924e-05,
      "loss": 0.001,
      "step": 17910
    },
    {
      "epoch": 0.5486330098276337,
      "grad_norm": 0.02134901098906994,
      "learning_rate": 1.6342650705691455e-05,
      "loss": 0.001,
      "step": 17920
    },
    {
      "epoch": 0.5489391666411536,
      "grad_norm": 0.027576075866818428,
      "learning_rate": 1.6340609660267988e-05,
      "loss": 0.0429,
      "step": 17930
    },
    {
      "epoch": 0.5492453234546735,
      "grad_norm": 0.016551269218325615,
      "learning_rate": 1.6338568614844525e-05,
      "loss": 0.0006,
      "step": 17940
    },
    {
      "epoch": 0.5495514802681933,
      "grad_norm": 0.02451252192258835,
      "learning_rate": 1.633652756942106e-05,
      "loss": 0.001,
      "step": 17950
    },
    {
      "epoch": 0.5498576370817132,
      "grad_norm": 0.013679685071110725,
      "learning_rate": 1.6334486523997593e-05,
      "loss": 0.0007,
      "step": 17960
    },
    {
      "epoch": 0.5501637938952332,
      "grad_norm": 1.8446168899536133,
      "learning_rate": 1.6332445478574126e-05,
      "loss": 0.0759,
      "step": 17970
    },
    {
      "epoch": 0.550469950708753,
      "grad_norm": 0.06422638148069382,
      "learning_rate": 1.6330404433150663e-05,
      "loss": 0.0387,
      "step": 17980
    },
    {
      "epoch": 0.5507761075222729,
      "grad_norm": 0.059898145496845245,
      "learning_rate": 1.6328363387727194e-05,
      "loss": 0.0021,
      "step": 17990
    },
    {
      "epoch": 0.5510822643357928,
      "grad_norm": 0.06330728530883789,
      "learning_rate": 1.6326322342303727e-05,
      "loss": 0.0019,
      "step": 18000
    },
    {
      "epoch": 0.5513884211493126,
      "grad_norm": 0.0350441113114357,
      "learning_rate": 1.6324281296880264e-05,
      "loss": 0.0013,
      "step": 18010
    },
    {
      "epoch": 0.5516945779628326,
      "grad_norm": 0.04261304438114166,
      "learning_rate": 1.6322240251456798e-05,
      "loss": 0.0385,
      "step": 18020
    },
    {
      "epoch": 0.5520007347763525,
      "grad_norm": 0.07535535842180252,
      "learning_rate": 1.632019920603333e-05,
      "loss": 0.0417,
      "step": 18030
    },
    {
      "epoch": 0.5523068915898723,
      "grad_norm": 0.01817689649760723,
      "learning_rate": 1.6318158160609865e-05,
      "loss": 0.0015,
      "step": 18040
    },
    {
      "epoch": 0.5526130484033922,
      "grad_norm": 0.02661370113492012,
      "learning_rate": 1.6316117115186402e-05,
      "loss": 0.0012,
      "step": 18050
    },
    {
      "epoch": 0.5529192052169121,
      "grad_norm": 0.03132155165076256,
      "learning_rate": 1.6314076069762932e-05,
      "loss": 0.0039,
      "step": 18060
    },
    {
      "epoch": 0.5532253620304319,
      "grad_norm": 1.8809131383895874,
      "learning_rate": 1.6312035024339466e-05,
      "loss": 0.0714,
      "step": 18070
    },
    {
      "epoch": 0.5535315188439519,
      "grad_norm": 0.020691823214292526,
      "learning_rate": 1.6309993978916e-05,
      "loss": 0.0011,
      "step": 18080
    },
    {
      "epoch": 0.5538376756574718,
      "grad_norm": 0.04030425101518631,
      "learning_rate": 1.6307952933492537e-05,
      "loss": 0.0332,
      "step": 18090
    },
    {
      "epoch": 0.5541438324709916,
      "grad_norm": 0.01761339232325554,
      "learning_rate": 1.630591188806907e-05,
      "loss": 0.0379,
      "step": 18100
    },
    {
      "epoch": 0.5544499892845115,
      "grad_norm": 1.8251219987869263,
      "learning_rate": 1.6303870842645604e-05,
      "loss": 0.0339,
      "step": 18110
    },
    {
      "epoch": 0.5547561460980314,
      "grad_norm": 0.02406422607600689,
      "learning_rate": 1.630182979722214e-05,
      "loss": 0.0017,
      "step": 18120
    },
    {
      "epoch": 0.5550623029115513,
      "grad_norm": 0.031182125210762024,
      "learning_rate": 1.6299788751798675e-05,
      "loss": 0.0053,
      "step": 18130
    },
    {
      "epoch": 0.5553684597250712,
      "grad_norm": 0.06699267774820328,
      "learning_rate": 1.6297747706375205e-05,
      "loss": 0.0351,
      "step": 18140
    },
    {
      "epoch": 0.5556746165385911,
      "grad_norm": 0.0372689813375473,
      "learning_rate": 1.629570666095174e-05,
      "loss": 0.055,
      "step": 18150
    },
    {
      "epoch": 0.5559807733521109,
      "grad_norm": 0.015313073061406612,
      "learning_rate": 1.6293665615528276e-05,
      "loss": 0.038,
      "step": 18160
    },
    {
      "epoch": 0.5562869301656308,
      "grad_norm": 0.024157332256436348,
      "learning_rate": 1.629162457010481e-05,
      "loss": 0.0169,
      "step": 18170
    },
    {
      "epoch": 0.5565930869791508,
      "grad_norm": 0.03458033874630928,
      "learning_rate": 1.6289583524681343e-05,
      "loss": 0.0017,
      "step": 18180
    },
    {
      "epoch": 0.5568992437926706,
      "grad_norm": 0.02489929273724556,
      "learning_rate": 1.6287542479257877e-05,
      "loss": 0.0023,
      "step": 18190
    },
    {
      "epoch": 0.5572054006061905,
      "grad_norm": 0.020929837599396706,
      "learning_rate": 1.6285501433834414e-05,
      "loss": 0.0013,
      "step": 18200
    },
    {
      "epoch": 0.5575115574197104,
      "grad_norm": 0.01926756650209427,
      "learning_rate": 1.6283460388410944e-05,
      "loss": 0.0358,
      "step": 18210
    },
    {
      "epoch": 0.5578177142332302,
      "grad_norm": 0.023218020796775818,
      "learning_rate": 1.6281419342987478e-05,
      "loss": 0.0016,
      "step": 18220
    },
    {
      "epoch": 0.5581238710467501,
      "grad_norm": 0.019575176760554314,
      "learning_rate": 1.6279378297564015e-05,
      "loss": 0.0016,
      "step": 18230
    },
    {
      "epoch": 0.5584300278602701,
      "grad_norm": 0.021022243425250053,
      "learning_rate": 1.6277337252140548e-05,
      "loss": 0.0007,
      "step": 18240
    },
    {
      "epoch": 0.5587361846737899,
      "grad_norm": 0.027203300967812538,
      "learning_rate": 1.6275296206717082e-05,
      "loss": 0.0013,
      "step": 18250
    },
    {
      "epoch": 0.5590423414873098,
      "grad_norm": 0.012015380896627903,
      "learning_rate": 1.6273255161293615e-05,
      "loss": 0.0012,
      "step": 18260
    },
    {
      "epoch": 0.5593484983008297,
      "grad_norm": 0.01992063596844673,
      "learning_rate": 1.6271214115870153e-05,
      "loss": 0.0018,
      "step": 18270
    },
    {
      "epoch": 0.5596546551143495,
      "grad_norm": 0.00837779138237238,
      "learning_rate": 1.6269173070446683e-05,
      "loss": 0.0007,
      "step": 18280
    },
    {
      "epoch": 0.5599608119278695,
      "grad_norm": 0.010440921410918236,
      "learning_rate": 1.6267132025023216e-05,
      "loss": 0.0012,
      "step": 18290
    },
    {
      "epoch": 0.5602669687413894,
      "grad_norm": 0.025118770077824593,
      "learning_rate": 1.626509097959975e-05,
      "loss": 0.0007,
      "step": 18300
    },
    {
      "epoch": 0.5605731255549092,
      "grad_norm": 0.014980142936110497,
      "learning_rate": 1.6263049934176287e-05,
      "loss": 0.0449,
      "step": 18310
    },
    {
      "epoch": 0.5608792823684291,
      "grad_norm": 0.01792086288332939,
      "learning_rate": 1.626100888875282e-05,
      "loss": 0.0034,
      "step": 18320
    },
    {
      "epoch": 0.561185439181949,
      "grad_norm": 1.7804182767868042,
      "learning_rate": 1.6258967843329354e-05,
      "loss": 0.0329,
      "step": 18330
    },
    {
      "epoch": 0.5614915959954688,
      "grad_norm": 0.054696083068847656,
      "learning_rate": 1.625692679790589e-05,
      "loss": 0.0012,
      "step": 18340
    },
    {
      "epoch": 0.5617977528089888,
      "grad_norm": 0.01219611894339323,
      "learning_rate": 1.625488575248242e-05,
      "loss": 0.0074,
      "step": 18350
    },
    {
      "epoch": 0.5621039096225087,
      "grad_norm": 0.027516404166817665,
      "learning_rate": 1.6252844707058955e-05,
      "loss": 0.0014,
      "step": 18360
    },
    {
      "epoch": 0.5624100664360285,
      "grad_norm": 0.022120507434010506,
      "learning_rate": 1.625080366163549e-05,
      "loss": 0.0011,
      "step": 18370
    },
    {
      "epoch": 0.5627162232495484,
      "grad_norm": 0.00506949657574296,
      "learning_rate": 1.6248762616212026e-05,
      "loss": 0.0009,
      "step": 18380
    },
    {
      "epoch": 0.5630223800630683,
      "grad_norm": 0.006759962532669306,
      "learning_rate": 1.624672157078856e-05,
      "loss": 0.0007,
      "step": 18390
    },
    {
      "epoch": 0.5633285368765882,
      "grad_norm": 0.028356388211250305,
      "learning_rate": 1.6244680525365093e-05,
      "loss": 0.113,
      "step": 18400
    },
    {
      "epoch": 0.5636346936901081,
      "grad_norm": 0.033863868564367294,
      "learning_rate": 1.6242639479941627e-05,
      "loss": 0.044,
      "step": 18410
    },
    {
      "epoch": 0.563940850503628,
      "grad_norm": 0.03447888791561127,
      "learning_rate": 1.624059843451816e-05,
      "loss": 0.0533,
      "step": 18420
    },
    {
      "epoch": 0.5642470073171478,
      "grad_norm": 0.037088342010974884,
      "learning_rate": 1.6238557389094694e-05,
      "loss": 0.0024,
      "step": 18430
    },
    {
      "epoch": 0.5645531641306677,
      "grad_norm": 0.610444962978363,
      "learning_rate": 1.6236516343671228e-05,
      "loss": 0.0034,
      "step": 18440
    },
    {
      "epoch": 0.5648593209441876,
      "grad_norm": 0.03816274553537369,
      "learning_rate": 1.6234475298247765e-05,
      "loss": 0.0017,
      "step": 18450
    },
    {
      "epoch": 0.5651654777577075,
      "grad_norm": 0.014915620908141136,
      "learning_rate": 1.62324342528243e-05,
      "loss": 0.001,
      "step": 18460
    },
    {
      "epoch": 0.5654716345712274,
      "grad_norm": 0.02796606719493866,
      "learning_rate": 1.6230393207400832e-05,
      "loss": 0.0426,
      "step": 18470
    },
    {
      "epoch": 0.5657777913847473,
      "grad_norm": 0.021216105669736862,
      "learning_rate": 1.6228352161977366e-05,
      "loss": 0.0017,
      "step": 18480
    },
    {
      "epoch": 0.5660839481982671,
      "grad_norm": 0.03209735453128815,
      "learning_rate": 1.62263111165539e-05,
      "loss": 0.0012,
      "step": 18490
    },
    {
      "epoch": 0.566390105011787,
      "grad_norm": 0.019487278535962105,
      "learning_rate": 1.6224270071130433e-05,
      "loss": 0.001,
      "step": 18500
    },
    {
      "epoch": 0.566696261825307,
      "grad_norm": 0.017872149124741554,
      "learning_rate": 1.6222229025706967e-05,
      "loss": 0.0017,
      "step": 18510
    },
    {
      "epoch": 0.5670024186388268,
      "grad_norm": 0.01692640781402588,
      "learning_rate": 1.62201879802835e-05,
      "loss": 0.0299,
      "step": 18520
    },
    {
      "epoch": 0.5673085754523467,
      "grad_norm": 0.015111073851585388,
      "learning_rate": 1.6218146934860037e-05,
      "loss": 0.0008,
      "step": 18530
    },
    {
      "epoch": 0.5676147322658666,
      "grad_norm": 0.06648910790681839,
      "learning_rate": 1.621610588943657e-05,
      "loss": 0.0343,
      "step": 18540
    },
    {
      "epoch": 0.5679208890793864,
      "grad_norm": 2.0491738319396973,
      "learning_rate": 1.6214064844013105e-05,
      "loss": 0.0969,
      "step": 18550
    },
    {
      "epoch": 0.5682270458929064,
      "grad_norm": 0.016929922625422478,
      "learning_rate": 1.621202379858964e-05,
      "loss": 0.0017,
      "step": 18560
    },
    {
      "epoch": 0.5685332027064263,
      "grad_norm": 0.020818782970309258,
      "learning_rate": 1.6209982753166172e-05,
      "loss": 0.0016,
      "step": 18570
    },
    {
      "epoch": 0.5688393595199461,
      "grad_norm": 0.005484182387590408,
      "learning_rate": 1.6207941707742706e-05,
      "loss": 0.0013,
      "step": 18580
    },
    {
      "epoch": 0.569145516333466,
      "grad_norm": 0.017377838492393494,
      "learning_rate": 1.620590066231924e-05,
      "loss": 0.0014,
      "step": 18590
    },
    {
      "epoch": 0.5694516731469859,
      "grad_norm": 0.2907578945159912,
      "learning_rate": 1.6203859616895776e-05,
      "loss": 0.0023,
      "step": 18600
    },
    {
      "epoch": 0.5697578299605057,
      "grad_norm": 0.02973254583775997,
      "learning_rate": 1.620181857147231e-05,
      "loss": 0.0128,
      "step": 18610
    },
    {
      "epoch": 0.5700639867740257,
      "grad_norm": 3.6212551593780518,
      "learning_rate": 1.6199777526048844e-05,
      "loss": 0.0537,
      "step": 18620
    },
    {
      "epoch": 0.5703701435875456,
      "grad_norm": 0.02670462615787983,
      "learning_rate": 1.6197736480625377e-05,
      "loss": 0.0335,
      "step": 18630
    },
    {
      "epoch": 0.5706763004010654,
      "grad_norm": 0.020814958959817886,
      "learning_rate": 1.619569543520191e-05,
      "loss": 0.0382,
      "step": 18640
    },
    {
      "epoch": 0.5709824572145853,
      "grad_norm": 0.01641007699072361,
      "learning_rate": 1.6193654389778445e-05,
      "loss": 0.0846,
      "step": 18650
    },
    {
      "epoch": 0.5712886140281052,
      "grad_norm": 0.4244064688682556,
      "learning_rate": 1.6191613344354978e-05,
      "loss": 0.002,
      "step": 18660
    },
    {
      "epoch": 0.5715947708416251,
      "grad_norm": 0.22627386450767517,
      "learning_rate": 1.6189572298931512e-05,
      "loss": 0.0403,
      "step": 18670
    },
    {
      "epoch": 0.571900927655145,
      "grad_norm": 0.7422277927398682,
      "learning_rate": 1.618753125350805e-05,
      "loss": 0.0757,
      "step": 18680
    },
    {
      "epoch": 0.5722070844686649,
      "grad_norm": 0.13229727745056152,
      "learning_rate": 1.6185490208084583e-05,
      "loss": 0.0076,
      "step": 18690
    },
    {
      "epoch": 0.5725132412821847,
      "grad_norm": 0.053491514176130295,
      "learning_rate": 1.6183449162661116e-05,
      "loss": 0.0022,
      "step": 18700
    },
    {
      "epoch": 0.5728193980957046,
      "grad_norm": 0.016499897465109825,
      "learning_rate": 1.618140811723765e-05,
      "loss": 0.0028,
      "step": 18710
    },
    {
      "epoch": 0.5731255549092245,
      "grad_norm": 0.03030303120613098,
      "learning_rate": 1.6179367071814183e-05,
      "loss": 0.0063,
      "step": 18720
    },
    {
      "epoch": 0.5734317117227444,
      "grad_norm": 0.08756222575902939,
      "learning_rate": 1.6177326026390717e-05,
      "loss": 0.0635,
      "step": 18730
    },
    {
      "epoch": 0.5737378685362643,
      "grad_norm": 0.03313787281513214,
      "learning_rate": 1.617528498096725e-05,
      "loss": 0.0342,
      "step": 18740
    },
    {
      "epoch": 0.5740440253497842,
      "grad_norm": 0.1484677791595459,
      "learning_rate": 1.6173243935543788e-05,
      "loss": 0.0033,
      "step": 18750
    },
    {
      "epoch": 0.574350182163304,
      "grad_norm": 0.06719069182872772,
      "learning_rate": 1.617120289012032e-05,
      "loss": 0.0031,
      "step": 18760
    },
    {
      "epoch": 0.5746563389768239,
      "grad_norm": 0.029378602281212807,
      "learning_rate": 1.6169161844696855e-05,
      "loss": 0.0022,
      "step": 18770
    },
    {
      "epoch": 0.5749624957903439,
      "grad_norm": 0.05431760847568512,
      "learning_rate": 1.616712079927339e-05,
      "loss": 0.0106,
      "step": 18780
    },
    {
      "epoch": 0.5752686526038637,
      "grad_norm": 0.027414223179221153,
      "learning_rate": 1.6165079753849922e-05,
      "loss": 0.035,
      "step": 18790
    },
    {
      "epoch": 0.5755748094173836,
      "grad_norm": 0.04973655566573143,
      "learning_rate": 1.6163038708426456e-05,
      "loss": 0.0022,
      "step": 18800
    },
    {
      "epoch": 0.5758809662309035,
      "grad_norm": 0.05007046461105347,
      "learning_rate": 1.616099766300299e-05,
      "loss": 0.0022,
      "step": 18810
    },
    {
      "epoch": 0.5761871230444233,
      "grad_norm": 0.02208671346306801,
      "learning_rate": 1.6158956617579527e-05,
      "loss": 0.0014,
      "step": 18820
    },
    {
      "epoch": 0.5764932798579432,
      "grad_norm": 0.054720714688301086,
      "learning_rate": 1.615691557215606e-05,
      "loss": 0.0177,
      "step": 18830
    },
    {
      "epoch": 0.5767994366714632,
      "grad_norm": 0.05192385986447334,
      "learning_rate": 1.6154874526732594e-05,
      "loss": 0.0013,
      "step": 18840
    },
    {
      "epoch": 0.577105593484983,
      "grad_norm": 0.025610890239477158,
      "learning_rate": 1.6152833481309128e-05,
      "loss": 0.0013,
      "step": 18850
    },
    {
      "epoch": 0.5774117502985029,
      "grad_norm": 0.025021761655807495,
      "learning_rate": 1.615079243588566e-05,
      "loss": 0.0015,
      "step": 18860
    },
    {
      "epoch": 0.5777179071120228,
      "grad_norm": 0.02158878929913044,
      "learning_rate": 1.6148751390462195e-05,
      "loss": 0.007,
      "step": 18870
    },
    {
      "epoch": 0.5780240639255426,
      "grad_norm": 0.04749052971601486,
      "learning_rate": 1.614671034503873e-05,
      "loss": 0.0343,
      "step": 18880
    },
    {
      "epoch": 0.5783302207390626,
      "grad_norm": 0.04423171654343605,
      "learning_rate": 1.6144669299615262e-05,
      "loss": 0.0014,
      "step": 18890
    },
    {
      "epoch": 0.5786363775525825,
      "grad_norm": 0.030546437948942184,
      "learning_rate": 1.61426282541918e-05,
      "loss": 0.0035,
      "step": 18900
    },
    {
      "epoch": 0.5789425343661023,
      "grad_norm": 0.030510837212204933,
      "learning_rate": 1.6140587208768333e-05,
      "loss": 0.0346,
      "step": 18910
    },
    {
      "epoch": 0.5792486911796222,
      "grad_norm": 0.13909141719341278,
      "learning_rate": 1.6138546163344867e-05,
      "loss": 0.0383,
      "step": 18920
    },
    {
      "epoch": 0.579554847993142,
      "grad_norm": 0.031034456565976143,
      "learning_rate": 1.61365051179214e-05,
      "loss": 0.0013,
      "step": 18930
    },
    {
      "epoch": 0.5798610048066619,
      "grad_norm": 0.5667552351951599,
      "learning_rate": 1.6134464072497934e-05,
      "loss": 0.0355,
      "step": 18940
    },
    {
      "epoch": 0.5801671616201819,
      "grad_norm": 0.022585144266486168,
      "learning_rate": 1.6132423027074467e-05,
      "loss": 0.0022,
      "step": 18950
    },
    {
      "epoch": 0.5804733184337018,
      "grad_norm": 0.06596000492572784,
      "learning_rate": 1.6130381981651e-05,
      "loss": 0.0019,
      "step": 18960
    },
    {
      "epoch": 0.5807794752472216,
      "grad_norm": 0.019914763048291206,
      "learning_rate": 1.6128340936227538e-05,
      "loss": 0.0011,
      "step": 18970
    },
    {
      "epoch": 0.5810856320607415,
      "grad_norm": 0.012777380645275116,
      "learning_rate": 1.6126299890804072e-05,
      "loss": 0.0013,
      "step": 18980
    },
    {
      "epoch": 0.5813917888742614,
      "grad_norm": 1.7168093919754028,
      "learning_rate": 1.6124258845380605e-05,
      "loss": 0.0692,
      "step": 18990
    },
    {
      "epoch": 0.5816979456877813,
      "grad_norm": 0.03934361785650253,
      "learning_rate": 1.612221779995714e-05,
      "loss": 0.0304,
      "step": 19000
    },
    {
      "epoch": 0.5820041025013012,
      "grad_norm": 0.04514537379145622,
      "learning_rate": 1.6120176754533673e-05,
      "loss": 0.0407,
      "step": 19010
    },
    {
      "epoch": 0.582310259314821,
      "grad_norm": 0.035792671144008636,
      "learning_rate": 1.6118135709110206e-05,
      "loss": 0.0028,
      "step": 19020
    },
    {
      "epoch": 0.5826164161283409,
      "grad_norm": 0.061814822256565094,
      "learning_rate": 1.611609466368674e-05,
      "loss": 0.0019,
      "step": 19030
    },
    {
      "epoch": 0.5829225729418608,
      "grad_norm": 0.020648570731282234,
      "learning_rate": 1.6114053618263277e-05,
      "loss": 0.0022,
      "step": 19040
    },
    {
      "epoch": 0.5832287297553808,
      "grad_norm": 0.0007736498373560607,
      "learning_rate": 1.611201257283981e-05,
      "loss": 0.0221,
      "step": 19050
    },
    {
      "epoch": 0.5835348865689006,
      "grad_norm": 0.12942713499069214,
      "learning_rate": 1.6109971527416344e-05,
      "loss": 0.0019,
      "step": 19060
    },
    {
      "epoch": 0.5838410433824205,
      "grad_norm": 0.09523936361074448,
      "learning_rate": 1.6107930481992878e-05,
      "loss": 0.0262,
      "step": 19070
    },
    {
      "epoch": 0.5841472001959404,
      "grad_norm": 0.10270179063081741,
      "learning_rate": 1.610588943656941e-05,
      "loss": 0.0437,
      "step": 19080
    },
    {
      "epoch": 0.5844533570094602,
      "grad_norm": 0.06207727640867233,
      "learning_rate": 1.6103848391145945e-05,
      "loss": 0.0021,
      "step": 19090
    },
    {
      "epoch": 0.5847595138229801,
      "grad_norm": 2.8393912315368652,
      "learning_rate": 1.610180734572248e-05,
      "loss": 0.0422,
      "step": 19100
    },
    {
      "epoch": 0.5850656706365001,
      "grad_norm": 0.052871812134981155,
      "learning_rate": 1.6099766300299013e-05,
      "loss": 0.0339,
      "step": 19110
    },
    {
      "epoch": 0.5853718274500199,
      "grad_norm": 0.013405821286141872,
      "learning_rate": 1.609772525487555e-05,
      "loss": 0.0041,
      "step": 19120
    },
    {
      "epoch": 0.5856779842635398,
      "grad_norm": 0.04234300181269646,
      "learning_rate": 1.6095684209452083e-05,
      "loss": 0.0017,
      "step": 19130
    },
    {
      "epoch": 0.5859841410770597,
      "grad_norm": 0.018714487552642822,
      "learning_rate": 1.6093643164028617e-05,
      "loss": 0.0026,
      "step": 19140
    },
    {
      "epoch": 0.5862902978905795,
      "grad_norm": 0.031242862343788147,
      "learning_rate": 1.609160211860515e-05,
      "loss": 0.0372,
      "step": 19150
    },
    {
      "epoch": 0.5865964547040995,
      "grad_norm": 0.009661119431257248,
      "learning_rate": 1.6089561073181684e-05,
      "loss": 0.0012,
      "step": 19160
    },
    {
      "epoch": 0.5869026115176194,
      "grad_norm": 0.05599113926291466,
      "learning_rate": 1.6087520027758218e-05,
      "loss": 0.0013,
      "step": 19170
    },
    {
      "epoch": 0.5872087683311392,
      "grad_norm": 0.02062991075217724,
      "learning_rate": 1.608547898233475e-05,
      "loss": 0.0016,
      "step": 19180
    },
    {
      "epoch": 0.5875149251446591,
      "grad_norm": 0.007055206224322319,
      "learning_rate": 1.608343793691129e-05,
      "loss": 0.0038,
      "step": 19190
    },
    {
      "epoch": 0.587821081958179,
      "grad_norm": 0.0628637745976448,
      "learning_rate": 1.6081396891487822e-05,
      "loss": 0.0619,
      "step": 19200
    },
    {
      "epoch": 0.5881272387716988,
      "grad_norm": 0.032328251749277115,
      "learning_rate": 1.6079355846064356e-05,
      "loss": 0.0376,
      "step": 19210
    },
    {
      "epoch": 0.5884333955852188,
      "grad_norm": 4.2011284828186035,
      "learning_rate": 1.607731480064089e-05,
      "loss": 0.0659,
      "step": 19220
    },
    {
      "epoch": 0.5887395523987387,
      "grad_norm": 0.02096378616988659,
      "learning_rate": 1.6075273755217423e-05,
      "loss": 0.0021,
      "step": 19230
    },
    {
      "epoch": 0.5890457092122585,
      "grad_norm": 0.025969287380576134,
      "learning_rate": 1.6073232709793957e-05,
      "loss": 0.0009,
      "step": 19240
    },
    {
      "epoch": 0.5893518660257784,
      "grad_norm": 0.013745751231908798,
      "learning_rate": 1.607119166437049e-05,
      "loss": 0.0009,
      "step": 19250
    },
    {
      "epoch": 0.5896580228392982,
      "grad_norm": 0.026112500578165054,
      "learning_rate": 1.6069150618947027e-05,
      "loss": 0.0431,
      "step": 19260
    },
    {
      "epoch": 0.5899641796528182,
      "grad_norm": 0.018008170649409294,
      "learning_rate": 1.606710957352356e-05,
      "loss": 0.0013,
      "step": 19270
    },
    {
      "epoch": 0.5902703364663381,
      "grad_norm": 0.041191600263118744,
      "learning_rate": 1.6065068528100095e-05,
      "loss": 0.0114,
      "step": 19280
    },
    {
      "epoch": 0.590576493279858,
      "grad_norm": 0.02317855693399906,
      "learning_rate": 1.6063027482676628e-05,
      "loss": 0.0307,
      "step": 19290
    },
    {
      "epoch": 0.5908826500933778,
      "grad_norm": 0.04818989709019661,
      "learning_rate": 1.6060986437253162e-05,
      "loss": 0.0023,
      "step": 19300
    },
    {
      "epoch": 0.5911888069068977,
      "grad_norm": 0.02779252827167511,
      "learning_rate": 1.6058945391829696e-05,
      "loss": 0.0016,
      "step": 19310
    },
    {
      "epoch": 0.5914949637204175,
      "grad_norm": 0.4612744152545929,
      "learning_rate": 1.605690434640623e-05,
      "loss": 0.0266,
      "step": 19320
    },
    {
      "epoch": 0.5918011205339375,
      "grad_norm": 0.05727830156683922,
      "learning_rate": 1.6054863300982763e-05,
      "loss": 0.0487,
      "step": 19330
    },
    {
      "epoch": 0.5921072773474574,
      "grad_norm": 0.036332614719867706,
      "learning_rate": 1.60528222555593e-05,
      "loss": 0.032,
      "step": 19340
    },
    {
      "epoch": 0.5924134341609772,
      "grad_norm": 0.07067768275737762,
      "learning_rate": 1.6050781210135834e-05,
      "loss": 0.0016,
      "step": 19350
    },
    {
      "epoch": 0.5927195909744971,
      "grad_norm": 0.05467131361365318,
      "learning_rate": 1.6048740164712367e-05,
      "loss": 0.0016,
      "step": 19360
    },
    {
      "epoch": 0.593025747788017,
      "grad_norm": 0.04820861667394638,
      "learning_rate": 1.60466991192889e-05,
      "loss": 0.0596,
      "step": 19370
    },
    {
      "epoch": 0.593331904601537,
      "grad_norm": 0.036934882402420044,
      "learning_rate": 1.6044658073865434e-05,
      "loss": 0.0339,
      "step": 19380
    },
    {
      "epoch": 0.5936380614150568,
      "grad_norm": 0.016545049846172333,
      "learning_rate": 1.6042617028441968e-05,
      "loss": 0.0023,
      "step": 19390
    },
    {
      "epoch": 0.5939442182285767,
      "grad_norm": 0.03144002705812454,
      "learning_rate": 1.6040575983018502e-05,
      "loss": 0.0012,
      "step": 19400
    },
    {
      "epoch": 0.5942503750420965,
      "grad_norm": 0.01582280918955803,
      "learning_rate": 1.603853493759504e-05,
      "loss": 0.001,
      "step": 19410
    },
    {
      "epoch": 0.5945565318556164,
      "grad_norm": 0.034335870295763016,
      "learning_rate": 1.6036493892171572e-05,
      "loss": 0.0014,
      "step": 19420
    },
    {
      "epoch": 0.5948626886691364,
      "grad_norm": 0.028181301429867744,
      "learning_rate": 1.6034452846748106e-05,
      "loss": 0.0011,
      "step": 19430
    },
    {
      "epoch": 0.5951688454826563,
      "grad_norm": 0.030923323705792427,
      "learning_rate": 1.603241180132464e-05,
      "loss": 0.0011,
      "step": 19440
    },
    {
      "epoch": 0.5954750022961761,
      "grad_norm": 0.03099321387708187,
      "learning_rate": 1.6030370755901173e-05,
      "loss": 0.0015,
      "step": 19450
    },
    {
      "epoch": 0.595781159109696,
      "grad_norm": 2.687354326248169,
      "learning_rate": 1.6028329710477707e-05,
      "loss": 0.0251,
      "step": 19460
    },
    {
      "epoch": 0.5960873159232158,
      "grad_norm": 0.017337284982204437,
      "learning_rate": 1.602628866505424e-05,
      "loss": 0.0007,
      "step": 19470
    },
    {
      "epoch": 0.5963934727367357,
      "grad_norm": 0.02186567708849907,
      "learning_rate": 1.6024247619630778e-05,
      "loss": 0.0341,
      "step": 19480
    },
    {
      "epoch": 0.5966996295502557,
      "grad_norm": 0.03384419158101082,
      "learning_rate": 1.602220657420731e-05,
      "loss": 0.053,
      "step": 19490
    },
    {
      "epoch": 0.5970057863637755,
      "grad_norm": 0.035313572734594345,
      "learning_rate": 1.6020165528783845e-05,
      "loss": 0.0015,
      "step": 19500
    },
    {
      "epoch": 0.5973119431772954,
      "grad_norm": 0.03325770050287247,
      "learning_rate": 1.601812448336038e-05,
      "loss": 0.037,
      "step": 19510
    },
    {
      "epoch": 0.5976180999908153,
      "grad_norm": 0.031477898359298706,
      "learning_rate": 1.6016083437936912e-05,
      "loss": 0.0017,
      "step": 19520
    },
    {
      "epoch": 0.5979242568043351,
      "grad_norm": 0.029087333008646965,
      "learning_rate": 1.6014042392513446e-05,
      "loss": 0.0357,
      "step": 19530
    },
    {
      "epoch": 0.5982304136178551,
      "grad_norm": 0.01515842042863369,
      "learning_rate": 1.601200134708998e-05,
      "loss": 0.0022,
      "step": 19540
    },
    {
      "epoch": 0.598536570431375,
      "grad_norm": 0.03599165752530098,
      "learning_rate": 1.6009960301666513e-05,
      "loss": 0.0016,
      "step": 19550
    },
    {
      "epoch": 0.5988427272448948,
      "grad_norm": 0.01672235131263733,
      "learning_rate": 1.600791925624305e-05,
      "loss": 0.0011,
      "step": 19560
    },
    {
      "epoch": 0.5991488840584147,
      "grad_norm": 0.023012960329651833,
      "learning_rate": 1.6005878210819584e-05,
      "loss": 0.0015,
      "step": 19570
    },
    {
      "epoch": 0.5994550408719346,
      "grad_norm": 1.8052421808242798,
      "learning_rate": 1.6003837165396118e-05,
      "loss": 0.0668,
      "step": 19580
    },
    {
      "epoch": 0.5997611976854544,
      "grad_norm": 0.01923263445496559,
      "learning_rate": 1.600179611997265e-05,
      "loss": 0.0015,
      "step": 19590
    },
    {
      "epoch": 0.6000673544989744,
      "grad_norm": 0.05872943624854088,
      "learning_rate": 1.5999755074549185e-05,
      "loss": 0.0017,
      "step": 19600
    },
    {
      "epoch": 0.6003735113124943,
      "grad_norm": 1.8494378328323364,
      "learning_rate": 1.599771402912572e-05,
      "loss": 0.0653,
      "step": 19610
    },
    {
      "epoch": 0.6006796681260141,
      "grad_norm": 0.05633631721138954,
      "learning_rate": 1.5995672983702252e-05,
      "loss": 0.0021,
      "step": 19620
    },
    {
      "epoch": 0.600985824939534,
      "grad_norm": 0.08012095093727112,
      "learning_rate": 1.599363193827879e-05,
      "loss": 0.0012,
      "step": 19630
    },
    {
      "epoch": 0.6012919817530539,
      "grad_norm": 0.03813105449080467,
      "learning_rate": 1.5991590892855323e-05,
      "loss": 0.0019,
      "step": 19640
    },
    {
      "epoch": 0.6015981385665738,
      "grad_norm": 0.044402699917554855,
      "learning_rate": 1.5989549847431856e-05,
      "loss": 0.0319,
      "step": 19650
    },
    {
      "epoch": 0.6019042953800937,
      "grad_norm": 0.01862061209976673,
      "learning_rate": 1.598750880200839e-05,
      "loss": 0.0011,
      "step": 19660
    },
    {
      "epoch": 0.6022104521936136,
      "grad_norm": 0.010755776427686214,
      "learning_rate": 1.5985467756584924e-05,
      "loss": 0.0014,
      "step": 19670
    },
    {
      "epoch": 0.6025166090071334,
      "grad_norm": 0.056552235037088394,
      "learning_rate": 1.5983426711161457e-05,
      "loss": 0.0384,
      "step": 19680
    },
    {
      "epoch": 0.6028227658206533,
      "grad_norm": 0.022724123671650887,
      "learning_rate": 1.598138566573799e-05,
      "loss": 0.0015,
      "step": 19690
    },
    {
      "epoch": 0.6031289226341732,
      "grad_norm": 0.04332580044865608,
      "learning_rate": 1.5979344620314528e-05,
      "loss": 0.049,
      "step": 19700
    },
    {
      "epoch": 0.6034350794476931,
      "grad_norm": 0.03325840085744858,
      "learning_rate": 1.597730357489106e-05,
      "loss": 0.0013,
      "step": 19710
    },
    {
      "epoch": 0.603741236261213,
      "grad_norm": 0.027025366201996803,
      "learning_rate": 1.5975262529467595e-05,
      "loss": 0.0015,
      "step": 19720
    },
    {
      "epoch": 0.6040473930747329,
      "grad_norm": 1.5977604389190674,
      "learning_rate": 1.597322148404413e-05,
      "loss": 0.0347,
      "step": 19730
    },
    {
      "epoch": 0.6043535498882527,
      "grad_norm": 0.041164081543684006,
      "learning_rate": 1.5971180438620663e-05,
      "loss": 0.0011,
      "step": 19740
    },
    {
      "epoch": 0.6046597067017726,
      "grad_norm": 0.016139987856149673,
      "learning_rate": 1.5969139393197196e-05,
      "loss": 0.0699,
      "step": 19750
    },
    {
      "epoch": 0.6049658635152926,
      "grad_norm": 0.019185049459338188,
      "learning_rate": 1.596709834777373e-05,
      "loss": 0.0012,
      "step": 19760
    },
    {
      "epoch": 0.6052720203288124,
      "grad_norm": 0.020504478365182877,
      "learning_rate": 1.5965057302350264e-05,
      "loss": 0.0017,
      "step": 19770
    },
    {
      "epoch": 0.6055781771423323,
      "grad_norm": 0.028289563953876495,
      "learning_rate": 1.59630162569268e-05,
      "loss": 0.0016,
      "step": 19780
    },
    {
      "epoch": 0.6058843339558522,
      "grad_norm": 0.03745323792099953,
      "learning_rate": 1.5960975211503334e-05,
      "loss": 0.0389,
      "step": 19790
    },
    {
      "epoch": 0.606190490769372,
      "grad_norm": 0.06527210772037506,
      "learning_rate": 1.5958934166079868e-05,
      "loss": 0.0121,
      "step": 19800
    },
    {
      "epoch": 0.606496647582892,
      "grad_norm": 0.011847356334328651,
      "learning_rate": 1.59568931206564e-05,
      "loss": 0.0015,
      "step": 19810
    },
    {
      "epoch": 0.6068028043964119,
      "grad_norm": 0.03661821410059929,
      "learning_rate": 1.5954852075232935e-05,
      "loss": 0.0011,
      "step": 19820
    },
    {
      "epoch": 0.6071089612099317,
      "grad_norm": 0.0383615680038929,
      "learning_rate": 1.595281102980947e-05,
      "loss": 0.0112,
      "step": 19830
    },
    {
      "epoch": 0.6074151180234516,
      "grad_norm": 0.008297344669699669,
      "learning_rate": 1.5950769984386002e-05,
      "loss": 0.0007,
      "step": 19840
    },
    {
      "epoch": 0.6077212748369715,
      "grad_norm": 0.0777420699596405,
      "learning_rate": 1.594872893896254e-05,
      "loss": 0.001,
      "step": 19850
    },
    {
      "epoch": 0.6080274316504913,
      "grad_norm": 0.05476278066635132,
      "learning_rate": 1.5946687893539073e-05,
      "loss": 0.0074,
      "step": 19860
    },
    {
      "epoch": 0.6083335884640113,
      "grad_norm": 0.023792700842022896,
      "learning_rate": 1.5944646848115607e-05,
      "loss": 0.001,
      "step": 19870
    },
    {
      "epoch": 0.6086397452775312,
      "grad_norm": 0.016345717012882233,
      "learning_rate": 1.594260580269214e-05,
      "loss": 0.0009,
      "step": 19880
    },
    {
      "epoch": 0.608945902091051,
      "grad_norm": 0.030344555154442787,
      "learning_rate": 1.5940564757268674e-05,
      "loss": 0.0015,
      "step": 19890
    },
    {
      "epoch": 0.6092520589045709,
      "grad_norm": 0.016936374828219414,
      "learning_rate": 1.5938523711845208e-05,
      "loss": 0.0007,
      "step": 19900
    },
    {
      "epoch": 0.6095582157180908,
      "grad_norm": 0.011673767119646072,
      "learning_rate": 1.593648266642174e-05,
      "loss": 0.0008,
      "step": 19910
    },
    {
      "epoch": 0.6098643725316107,
      "grad_norm": 1.5612263679504395,
      "learning_rate": 1.5934441620998275e-05,
      "loss": 0.0412,
      "step": 19920
    },
    {
      "epoch": 0.6101705293451306,
      "grad_norm": 0.018414797261357307,
      "learning_rate": 1.5932400575574812e-05,
      "loss": 0.0006,
      "step": 19930
    },
    {
      "epoch": 0.6104766861586505,
      "grad_norm": 0.02781151421368122,
      "learning_rate": 1.5930359530151346e-05,
      "loss": 0.0518,
      "step": 19940
    },
    {
      "epoch": 0.6107828429721703,
      "grad_norm": 0.05841853469610214,
      "learning_rate": 1.592831848472788e-05,
      "loss": 0.0009,
      "step": 19950
    },
    {
      "epoch": 0.6110889997856902,
      "grad_norm": 0.013669404201209545,
      "learning_rate": 1.5926277439304413e-05,
      "loss": 0.0011,
      "step": 19960
    },
    {
      "epoch": 0.6113951565992101,
      "grad_norm": 0.04231785237789154,
      "learning_rate": 1.5924236393880947e-05,
      "loss": 0.0009,
      "step": 19970
    },
    {
      "epoch": 0.61170131341273,
      "grad_norm": 0.011111888103187084,
      "learning_rate": 1.592219534845748e-05,
      "loss": 0.0007,
      "step": 19980
    },
    {
      "epoch": 0.6120074702262499,
      "grad_norm": 0.01735452562570572,
      "learning_rate": 1.5920154303034014e-05,
      "loss": 0.0008,
      "step": 19990
    },
    {
      "epoch": 0.6123136270397698,
      "grad_norm": 0.03174804896116257,
      "learning_rate": 1.591811325761055e-05,
      "loss": 0.0431,
      "step": 20000
    },
    {
      "epoch": 0.6126197838532896,
      "grad_norm": 0.029008785262703896,
      "learning_rate": 1.5916072212187085e-05,
      "loss": 0.001,
      "step": 20010
    },
    {
      "epoch": 0.6129259406668095,
      "grad_norm": 0.0071700140833854675,
      "learning_rate": 1.5914031166763618e-05,
      "loss": 0.0007,
      "step": 20020
    },
    {
      "epoch": 0.6132320974803295,
      "grad_norm": 0.013900060206651688,
      "learning_rate": 1.5911990121340152e-05,
      "loss": 0.0006,
      "step": 20030
    },
    {
      "epoch": 0.6135382542938493,
      "grad_norm": 0.01814502291381359,
      "learning_rate": 1.5909949075916685e-05,
      "loss": 0.037,
      "step": 20040
    },
    {
      "epoch": 0.6138444111073692,
      "grad_norm": 0.011564947664737701,
      "learning_rate": 1.590790803049322e-05,
      "loss": 0.0008,
      "step": 20050
    },
    {
      "epoch": 0.6141505679208891,
      "grad_norm": 0.021623533219099045,
      "learning_rate": 1.5905866985069753e-05,
      "loss": 0.0081,
      "step": 20060
    },
    {
      "epoch": 0.6144567247344089,
      "grad_norm": 0.010251174680888653,
      "learning_rate": 1.590382593964629e-05,
      "loss": 0.0031,
      "step": 20070
    },
    {
      "epoch": 0.6147628815479288,
      "grad_norm": 0.017834359779953957,
      "learning_rate": 1.5901784894222823e-05,
      "loss": 0.0008,
      "step": 20080
    },
    {
      "epoch": 0.6150690383614488,
      "grad_norm": 0.022316455841064453,
      "learning_rate": 1.5899743848799357e-05,
      "loss": 0.0006,
      "step": 20090
    },
    {
      "epoch": 0.6153751951749686,
      "grad_norm": 0.02837059274315834,
      "learning_rate": 1.589770280337589e-05,
      "loss": 0.0012,
      "step": 20100
    },
    {
      "epoch": 0.6156813519884885,
      "grad_norm": 0.007145109586417675,
      "learning_rate": 1.5895661757952424e-05,
      "loss": 0.0342,
      "step": 20110
    },
    {
      "epoch": 0.6159875088020084,
      "grad_norm": 0.020970037207007408,
      "learning_rate": 1.5893620712528958e-05,
      "loss": 0.0005,
      "step": 20120
    },
    {
      "epoch": 0.6162936656155282,
      "grad_norm": 0.03074328601360321,
      "learning_rate": 1.589157966710549e-05,
      "loss": 0.0008,
      "step": 20130
    },
    {
      "epoch": 0.6165998224290482,
      "grad_norm": 0.009659482166171074,
      "learning_rate": 1.5889538621682025e-05,
      "loss": 0.0795,
      "step": 20140
    },
    {
      "epoch": 0.6169059792425681,
      "grad_norm": 0.014864972792565823,
      "learning_rate": 1.5887497576258562e-05,
      "loss": 0.0009,
      "step": 20150
    },
    {
      "epoch": 0.6172121360560879,
      "grad_norm": 0.038292720913887024,
      "learning_rate": 1.5885456530835096e-05,
      "loss": 0.0012,
      "step": 20160
    },
    {
      "epoch": 0.6175182928696078,
      "grad_norm": 0.020298540592193604,
      "learning_rate": 1.588341548541163e-05,
      "loss": 0.0011,
      "step": 20170
    },
    {
      "epoch": 0.6178244496831277,
      "grad_norm": 1.9992573261260986,
      "learning_rate": 1.5881374439988163e-05,
      "loss": 0.1012,
      "step": 20180
    },
    {
      "epoch": 0.6181306064966475,
      "grad_norm": 0.0750517025589943,
      "learning_rate": 1.5879333394564697e-05,
      "loss": 0.0012,
      "step": 20190
    },
    {
      "epoch": 0.6184367633101675,
      "grad_norm": 0.04278961569070816,
      "learning_rate": 1.587729234914123e-05,
      "loss": 0.0018,
      "step": 20200
    },
    {
      "epoch": 0.6187429201236874,
      "grad_norm": 0.02803626097738743,
      "learning_rate": 1.5875251303717764e-05,
      "loss": 0.033,
      "step": 20210
    },
    {
      "epoch": 0.6190490769372072,
      "grad_norm": 0.0325014591217041,
      "learning_rate": 1.58732102582943e-05,
      "loss": 0.0023,
      "step": 20220
    },
    {
      "epoch": 0.6193552337507271,
      "grad_norm": 0.08614779263734818,
      "learning_rate": 1.5871169212870835e-05,
      "loss": 0.0339,
      "step": 20230
    },
    {
      "epoch": 0.619661390564247,
      "grad_norm": 0.08596831560134888,
      "learning_rate": 1.586912816744737e-05,
      "loss": 0.0306,
      "step": 20240
    },
    {
      "epoch": 0.6199675473777669,
      "grad_norm": 0.07367812097072601,
      "learning_rate": 1.5867087122023902e-05,
      "loss": 0.0023,
      "step": 20250
    },
    {
      "epoch": 0.6202737041912868,
      "grad_norm": 0.023695286363363266,
      "learning_rate": 1.5865046076600436e-05,
      "loss": 0.0312,
      "step": 20260
    },
    {
      "epoch": 0.6205798610048067,
      "grad_norm": 0.0756857693195343,
      "learning_rate": 1.586300503117697e-05,
      "loss": 0.0028,
      "step": 20270
    },
    {
      "epoch": 0.6208860178183265,
      "grad_norm": 1.3810609579086304,
      "learning_rate": 1.5860963985753503e-05,
      "loss": 0.0243,
      "step": 20280
    },
    {
      "epoch": 0.6211921746318464,
      "grad_norm": 0.02035611681640148,
      "learning_rate": 1.585892294033004e-05,
      "loss": 0.0018,
      "step": 20290
    },
    {
      "epoch": 0.6214983314453664,
      "grad_norm": 0.03373365476727486,
      "learning_rate": 1.5856881894906574e-05,
      "loss": 0.0362,
      "step": 20300
    },
    {
      "epoch": 0.6218044882588862,
      "grad_norm": 0.05842394009232521,
      "learning_rate": 1.5854840849483107e-05,
      "loss": 0.0031,
      "step": 20310
    },
    {
      "epoch": 0.6221106450724061,
      "grad_norm": 0.039925482124090195,
      "learning_rate": 1.585279980405964e-05,
      "loss": 0.061,
      "step": 20320
    },
    {
      "epoch": 0.622416801885926,
      "grad_norm": 0.09143278002738953,
      "learning_rate": 1.5850758758636175e-05,
      "loss": 0.0023,
      "step": 20330
    },
    {
      "epoch": 0.6227229586994458,
      "grad_norm": 0.05178726091980934,
      "learning_rate": 1.584871771321271e-05,
      "loss": 0.0328,
      "step": 20340
    },
    {
      "epoch": 0.6230291155129657,
      "grad_norm": 0.08639975637197495,
      "learning_rate": 1.5846676667789242e-05,
      "loss": 0.0338,
      "step": 20350
    },
    {
      "epoch": 0.6233352723264857,
      "grad_norm": 0.06928039342164993,
      "learning_rate": 1.5844635622365776e-05,
      "loss": 0.0417,
      "step": 20360
    },
    {
      "epoch": 0.6236414291400055,
      "grad_norm": 0.04825438931584358,
      "learning_rate": 1.5842594576942313e-05,
      "loss": 0.0029,
      "step": 20370
    },
    {
      "epoch": 0.6239475859535254,
      "grad_norm": 0.051265615969896317,
      "learning_rate": 1.5840553531518846e-05,
      "loss": 0.0329,
      "step": 20380
    },
    {
      "epoch": 0.6242537427670453,
      "grad_norm": 0.02892274409532547,
      "learning_rate": 1.583851248609538e-05,
      "loss": 0.0055,
      "step": 20390
    },
    {
      "epoch": 0.6245598995805651,
      "grad_norm": 0.023711349815130234,
      "learning_rate": 1.5836471440671914e-05,
      "loss": 0.0346,
      "step": 20400
    },
    {
      "epoch": 0.6248660563940851,
      "grad_norm": 0.0410052053630352,
      "learning_rate": 1.5834430395248447e-05,
      "loss": 0.0435,
      "step": 20410
    },
    {
      "epoch": 0.625172213207605,
      "grad_norm": 0.10625369101762772,
      "learning_rate": 1.583238934982498e-05,
      "loss": 0.0343,
      "step": 20420
    },
    {
      "epoch": 0.6254783700211248,
      "grad_norm": 0.06485123932361603,
      "learning_rate": 1.5830348304401515e-05,
      "loss": 0.0301,
      "step": 20430
    },
    {
      "epoch": 0.6257845268346447,
      "grad_norm": 0.09882748872041702,
      "learning_rate": 1.582830725897805e-05,
      "loss": 0.0378,
      "step": 20440
    },
    {
      "epoch": 0.6260906836481646,
      "grad_norm": 0.055449485778808594,
      "learning_rate": 1.5826266213554585e-05,
      "loss": 0.0018,
      "step": 20450
    },
    {
      "epoch": 0.6263968404616844,
      "grad_norm": 0.036082569509744644,
      "learning_rate": 1.582422516813112e-05,
      "loss": 0.0665,
      "step": 20460
    },
    {
      "epoch": 0.6267029972752044,
      "grad_norm": 0.0024883951991796494,
      "learning_rate": 1.5822184122707653e-05,
      "loss": 0.0034,
      "step": 20470
    },
    {
      "epoch": 0.6270091540887243,
      "grad_norm": 0.08834129571914673,
      "learning_rate": 1.5820143077284186e-05,
      "loss": 0.0306,
      "step": 20480
    },
    {
      "epoch": 0.6273153109022441,
      "grad_norm": 0.04369062930345535,
      "learning_rate": 1.581810203186072e-05,
      "loss": 0.0037,
      "step": 20490
    },
    {
      "epoch": 0.627621467715764,
      "grad_norm": 0.07104761898517609,
      "learning_rate": 1.5816060986437253e-05,
      "loss": 0.0034,
      "step": 20500
    },
    {
      "epoch": 0.6279276245292839,
      "grad_norm": 0.08347572386264801,
      "learning_rate": 1.581401994101379e-05,
      "loss": 0.0029,
      "step": 20510
    },
    {
      "epoch": 0.6282337813428038,
      "grad_norm": 0.07625401020050049,
      "learning_rate": 1.5811978895590324e-05,
      "loss": 0.0268,
      "step": 20520
    },
    {
      "epoch": 0.6285399381563237,
      "grad_norm": 0.05720462650060654,
      "learning_rate": 1.5809937850166858e-05,
      "loss": 0.0031,
      "step": 20530
    },
    {
      "epoch": 0.6288460949698436,
      "grad_norm": 0.03129405155777931,
      "learning_rate": 1.580789680474339e-05,
      "loss": 0.0017,
      "step": 20540
    },
    {
      "epoch": 0.6291522517833634,
      "grad_norm": 0.01405303180217743,
      "learning_rate": 1.5805855759319925e-05,
      "loss": 0.0011,
      "step": 20550
    },
    {
      "epoch": 0.6294584085968833,
      "grad_norm": 0.007970300503075123,
      "learning_rate": 1.580381471389646e-05,
      "loss": 0.0305,
      "step": 20560
    },
    {
      "epoch": 0.6297645654104032,
      "grad_norm": 0.04395722597837448,
      "learning_rate": 1.5801773668472992e-05,
      "loss": 0.0274,
      "step": 20570
    },
    {
      "epoch": 0.6300707222239231,
      "grad_norm": 0.15325038135051727,
      "learning_rate": 1.5799732623049526e-05,
      "loss": 0.0017,
      "step": 20580
    },
    {
      "epoch": 0.630376879037443,
      "grad_norm": 1.745748519897461,
      "learning_rate": 1.5797691577626063e-05,
      "loss": 0.0335,
      "step": 20590
    },
    {
      "epoch": 0.6306830358509629,
      "grad_norm": 0.05718977004289627,
      "learning_rate": 1.5795650532202597e-05,
      "loss": 0.0015,
      "step": 20600
    },
    {
      "epoch": 0.6309891926644827,
      "grad_norm": 0.0478116013109684,
      "learning_rate": 1.579360948677913e-05,
      "loss": 0.0323,
      "step": 20610
    },
    {
      "epoch": 0.6312953494780026,
      "grad_norm": 0.03958877548575401,
      "learning_rate": 1.5791568441355664e-05,
      "loss": 0.0024,
      "step": 20620
    },
    {
      "epoch": 0.6316015062915226,
      "grad_norm": 1.7055693864822388,
      "learning_rate": 1.5789527395932198e-05,
      "loss": 0.0359,
      "step": 20630
    },
    {
      "epoch": 0.6319076631050424,
      "grad_norm": 0.04194796085357666,
      "learning_rate": 1.578748635050873e-05,
      "loss": 0.0013,
      "step": 20640
    },
    {
      "epoch": 0.6322138199185623,
      "grad_norm": 1.7966147661209106,
      "learning_rate": 1.5785445305085265e-05,
      "loss": 0.0261,
      "step": 20650
    },
    {
      "epoch": 0.6325199767320822,
      "grad_norm": 0.025679081678390503,
      "learning_rate": 1.5783404259661802e-05,
      "loss": 0.0066,
      "step": 20660
    },
    {
      "epoch": 0.632826133545602,
      "grad_norm": 0.07113614678382874,
      "learning_rate": 1.5781363214238336e-05,
      "loss": 0.06,
      "step": 20670
    },
    {
      "epoch": 0.633132290359122,
      "grad_norm": 0.04303516820073128,
      "learning_rate": 1.577932216881487e-05,
      "loss": 0.0037,
      "step": 20680
    },
    {
      "epoch": 0.6334384471726419,
      "grad_norm": 0.03401002660393715,
      "learning_rate": 1.5777281123391403e-05,
      "loss": 0.0023,
      "step": 20690
    },
    {
      "epoch": 0.6337446039861617,
      "grad_norm": 1.5338504314422607,
      "learning_rate": 1.5775240077967936e-05,
      "loss": 0.027,
      "step": 20700
    },
    {
      "epoch": 0.6340507607996816,
      "grad_norm": 0.04901054874062538,
      "learning_rate": 1.577319903254447e-05,
      "loss": 0.0023,
      "step": 20710
    },
    {
      "epoch": 0.6343569176132015,
      "grad_norm": 1.887028455734253,
      "learning_rate": 1.5771157987121004e-05,
      "loss": 0.0398,
      "step": 20720
    },
    {
      "epoch": 0.6346630744267213,
      "grad_norm": 0.027160201221704483,
      "learning_rate": 1.576911694169754e-05,
      "loss": 0.0015,
      "step": 20730
    },
    {
      "epoch": 0.6349692312402413,
      "grad_norm": 0.0627753958106041,
      "learning_rate": 1.5767075896274074e-05,
      "loss": 0.0019,
      "step": 20740
    },
    {
      "epoch": 0.6352753880537612,
      "grad_norm": 0.04979771375656128,
      "learning_rate": 1.5765034850850608e-05,
      "loss": 0.002,
      "step": 20750
    },
    {
      "epoch": 0.635581544867281,
      "grad_norm": 0.06226302683353424,
      "learning_rate": 1.5762993805427142e-05,
      "loss": 0.0366,
      "step": 20760
    },
    {
      "epoch": 0.6358877016808009,
      "grad_norm": 0.02471093460917473,
      "learning_rate": 1.5760952760003675e-05,
      "loss": 0.0011,
      "step": 20770
    },
    {
      "epoch": 0.6361938584943208,
      "grad_norm": 0.021456610411405563,
      "learning_rate": 1.575891171458021e-05,
      "loss": 0.0135,
      "step": 20780
    },
    {
      "epoch": 0.6365000153078407,
      "grad_norm": 0.027576396241784096,
      "learning_rate": 1.5756870669156743e-05,
      "loss": 0.0013,
      "step": 20790
    },
    {
      "epoch": 0.6368061721213606,
      "grad_norm": 0.006311898585408926,
      "learning_rate": 1.5754829623733276e-05,
      "loss": 0.0012,
      "step": 20800
    },
    {
      "epoch": 0.6371123289348805,
      "grad_norm": 0.019712403416633606,
      "learning_rate": 1.5752788578309813e-05,
      "loss": 0.0018,
      "step": 20810
    },
    {
      "epoch": 0.6374184857484003,
      "grad_norm": 0.041146427392959595,
      "learning_rate": 1.5750747532886347e-05,
      "loss": 0.0017,
      "step": 20820
    },
    {
      "epoch": 0.6377246425619202,
      "grad_norm": 0.00789028313010931,
      "learning_rate": 1.574870648746288e-05,
      "loss": 0.0008,
      "step": 20830
    },
    {
      "epoch": 0.63803079937544,
      "grad_norm": 0.012136105448007584,
      "learning_rate": 1.5746665442039414e-05,
      "loss": 0.0005,
      "step": 20840
    },
    {
      "epoch": 0.63833695618896,
      "grad_norm": 0.06308401376008987,
      "learning_rate": 1.5744624396615948e-05,
      "loss": 0.0182,
      "step": 20850
    },
    {
      "epoch": 0.6386431130024799,
      "grad_norm": 0.025147030130028725,
      "learning_rate": 1.574258335119248e-05,
      "loss": 0.0393,
      "step": 20860
    },
    {
      "epoch": 0.6389492698159998,
      "grad_norm": 0.03459220752120018,
      "learning_rate": 1.5740542305769015e-05,
      "loss": 0.0008,
      "step": 20870
    },
    {
      "epoch": 0.6392554266295196,
      "grad_norm": 0.04661930352449417,
      "learning_rate": 1.5738501260345552e-05,
      "loss": 0.0057,
      "step": 20880
    },
    {
      "epoch": 0.6395615834430395,
      "grad_norm": 0.025713425129652023,
      "learning_rate": 1.5736460214922086e-05,
      "loss": 0.0009,
      "step": 20890
    },
    {
      "epoch": 0.6398677402565595,
      "grad_norm": 0.01927969418466091,
      "learning_rate": 1.573441916949862e-05,
      "loss": 0.0383,
      "step": 20900
    },
    {
      "epoch": 0.6401738970700793,
      "grad_norm": 0.021796423941850662,
      "learning_rate": 1.5732378124075153e-05,
      "loss": 0.0417,
      "step": 20910
    },
    {
      "epoch": 0.6404800538835992,
      "grad_norm": 0.40968430042266846,
      "learning_rate": 1.5730337078651687e-05,
      "loss": 0.0382,
      "step": 20920
    },
    {
      "epoch": 0.640786210697119,
      "grad_norm": 0.07592547684907913,
      "learning_rate": 1.572829603322822e-05,
      "loss": 0.0017,
      "step": 20930
    },
    {
      "epoch": 0.6410923675106389,
      "grad_norm": 0.017003418877720833,
      "learning_rate": 1.5726254987804754e-05,
      "loss": 0.0045,
      "step": 20940
    },
    {
      "epoch": 0.6413985243241588,
      "grad_norm": 0.0518043227493763,
      "learning_rate": 1.572421394238129e-05,
      "loss": 0.0013,
      "step": 20950
    },
    {
      "epoch": 0.6417046811376788,
      "grad_norm": 0.03421451151371002,
      "learning_rate": 1.5722172896957825e-05,
      "loss": 0.0013,
      "step": 20960
    },
    {
      "epoch": 0.6420108379511986,
      "grad_norm": 0.01853933185338974,
      "learning_rate": 1.572013185153436e-05,
      "loss": 0.0306,
      "step": 20970
    },
    {
      "epoch": 0.6423169947647185,
      "grad_norm": 0.03458147868514061,
      "learning_rate": 1.5718090806110892e-05,
      "loss": 0.0259,
      "step": 20980
    },
    {
      "epoch": 0.6426231515782383,
      "grad_norm": 0.016613515093922615,
      "learning_rate": 1.5716049760687426e-05,
      "loss": 0.0021,
      "step": 20990
    },
    {
      "epoch": 0.6429293083917582,
      "grad_norm": 0.012572885490953922,
      "learning_rate": 1.571400871526396e-05,
      "loss": 0.0362,
      "step": 21000
    },
    {
      "epoch": 0.6432354652052782,
      "grad_norm": 0.04304511472582817,
      "learning_rate": 1.5711967669840493e-05,
      "loss": 0.0012,
      "step": 21010
    },
    {
      "epoch": 0.643541622018798,
      "grad_norm": 0.04012569412589073,
      "learning_rate": 1.5709926624417027e-05,
      "loss": 0.001,
      "step": 21020
    },
    {
      "epoch": 0.6438477788323179,
      "grad_norm": 0.000825573573820293,
      "learning_rate": 1.5707885578993564e-05,
      "loss": 0.0013,
      "step": 21030
    },
    {
      "epoch": 0.6441539356458378,
      "grad_norm": 0.031092677265405655,
      "learning_rate": 1.5705844533570097e-05,
      "loss": 0.0009,
      "step": 21040
    },
    {
      "epoch": 0.6444600924593576,
      "grad_norm": 5.166196346282959,
      "learning_rate": 1.570380348814663e-05,
      "loss": 0.0155,
      "step": 21050
    },
    {
      "epoch": 0.6447662492728776,
      "grad_norm": 0.03635361045598984,
      "learning_rate": 1.5701762442723165e-05,
      "loss": 0.0945,
      "step": 21060
    },
    {
      "epoch": 0.6450724060863975,
      "grad_norm": 0.023461034521460533,
      "learning_rate": 1.5699721397299698e-05,
      "loss": 0.0013,
      "step": 21070
    },
    {
      "epoch": 0.6453785628999174,
      "grad_norm": 0.024179674685001373,
      "learning_rate": 1.5697680351876232e-05,
      "loss": 0.0013,
      "step": 21080
    },
    {
      "epoch": 0.6456847197134372,
      "grad_norm": 0.015094862319529057,
      "learning_rate": 1.5695639306452766e-05,
      "loss": 0.0008,
      "step": 21090
    },
    {
      "epoch": 0.6459908765269571,
      "grad_norm": 0.020274529233574867,
      "learning_rate": 1.5693598261029303e-05,
      "loss": 0.009,
      "step": 21100
    },
    {
      "epoch": 0.646297033340477,
      "grad_norm": 0.019037984311580658,
      "learning_rate": 1.5691557215605836e-05,
      "loss": 0.0099,
      "step": 21110
    },
    {
      "epoch": 0.6466031901539969,
      "grad_norm": 0.015731293708086014,
      "learning_rate": 1.568951617018237e-05,
      "loss": 0.0009,
      "step": 21120
    },
    {
      "epoch": 0.6469093469675168,
      "grad_norm": 0.021194027736783028,
      "learning_rate": 1.5687475124758904e-05,
      "loss": 0.0228,
      "step": 21130
    },
    {
      "epoch": 0.6472155037810366,
      "grad_norm": 0.008136505261063576,
      "learning_rate": 1.5685434079335437e-05,
      "loss": 0.0009,
      "step": 21140
    },
    {
      "epoch": 0.6475216605945565,
      "grad_norm": 1.850285291671753,
      "learning_rate": 1.568339303391197e-05,
      "loss": 0.041,
      "step": 21150
    },
    {
      "epoch": 0.6478278174080764,
      "grad_norm": 3.5305864810943604,
      "learning_rate": 1.5681351988488504e-05,
      "loss": 0.0945,
      "step": 21160
    },
    {
      "epoch": 0.6481339742215964,
      "grad_norm": 0.027329115197062492,
      "learning_rate": 1.5679310943065038e-05,
      "loss": 0.0297,
      "step": 21170
    },
    {
      "epoch": 0.6484401310351162,
      "grad_norm": 0.2410973161458969,
      "learning_rate": 1.5677269897641575e-05,
      "loss": 0.0033,
      "step": 21180
    },
    {
      "epoch": 0.6487462878486361,
      "grad_norm": 0.06366675347089767,
      "learning_rate": 1.567522885221811e-05,
      "loss": 0.036,
      "step": 21190
    },
    {
      "epoch": 0.649052444662156,
      "grad_norm": 0.006711434107273817,
      "learning_rate": 1.5673187806794642e-05,
      "loss": 0.0021,
      "step": 21200
    },
    {
      "epoch": 0.6493586014756758,
      "grad_norm": 0.0549803264439106,
      "learning_rate": 1.5671146761371176e-05,
      "loss": 0.037,
      "step": 21210
    },
    {
      "epoch": 0.6496647582891957,
      "grad_norm": 0.042954545468091965,
      "learning_rate": 1.566910571594771e-05,
      "loss": 0.0325,
      "step": 21220
    },
    {
      "epoch": 0.6499709151027157,
      "grad_norm": 0.03970609977841377,
      "learning_rate": 1.5667064670524243e-05,
      "loss": 0.0025,
      "step": 21230
    },
    {
      "epoch": 0.6502770719162355,
      "grad_norm": 0.03865182399749756,
      "learning_rate": 1.5665023625100777e-05,
      "loss": 0.0018,
      "step": 21240
    },
    {
      "epoch": 0.6505832287297554,
      "grad_norm": 0.06592690944671631,
      "learning_rate": 1.5662982579677314e-05,
      "loss": 0.0568,
      "step": 21250
    },
    {
      "epoch": 0.6508893855432752,
      "grad_norm": 0.021027615293860435,
      "learning_rate": 1.5660941534253848e-05,
      "loss": 0.0098,
      "step": 21260
    },
    {
      "epoch": 0.6511955423567951,
      "grad_norm": 0.046386368572711945,
      "learning_rate": 1.565890048883038e-05,
      "loss": 0.0022,
      "step": 21270
    },
    {
      "epoch": 0.6515016991703151,
      "grad_norm": 0.037988606840372086,
      "learning_rate": 1.565685944340691e-05,
      "loss": 0.0411,
      "step": 21280
    },
    {
      "epoch": 0.651807855983835,
      "grad_norm": 0.05295078456401825,
      "learning_rate": 1.565481839798345e-05,
      "loss": 0.0023,
      "step": 21290
    },
    {
      "epoch": 0.6521140127973548,
      "grad_norm": 0.07560474425554276,
      "learning_rate": 1.5652777352559982e-05,
      "loss": 0.0017,
      "step": 21300
    },
    {
      "epoch": 0.6524201696108747,
      "grad_norm": 0.011402622796595097,
      "learning_rate": 1.5650736307136516e-05,
      "loss": 0.0016,
      "step": 21310
    },
    {
      "epoch": 0.6527263264243945,
      "grad_norm": 0.019655415788292885,
      "learning_rate": 1.5648695261713053e-05,
      "loss": 0.0296,
      "step": 21320
    },
    {
      "epoch": 0.6530324832379144,
      "grad_norm": 0.0485699400305748,
      "learning_rate": 1.5646654216289587e-05,
      "loss": 0.0505,
      "step": 21330
    },
    {
      "epoch": 0.6533386400514344,
      "grad_norm": 0.0701136514544487,
      "learning_rate": 1.564461317086612e-05,
      "loss": 0.0537,
      "step": 21340
    },
    {
      "epoch": 0.6536447968649542,
      "grad_norm": 0.06450988352298737,
      "learning_rate": 1.564257212544265e-05,
      "loss": 0.002,
      "step": 21350
    },
    {
      "epoch": 0.6539509536784741,
      "grad_norm": 0.03104872815310955,
      "learning_rate": 1.5640531080019188e-05,
      "loss": 0.0426,
      "step": 21360
    },
    {
      "epoch": 0.654257110491994,
      "grad_norm": 0.05532843619585037,
      "learning_rate": 1.563849003459572e-05,
      "loss": 0.0024,
      "step": 21370
    },
    {
      "epoch": 0.6545632673055138,
      "grad_norm": 0.012739898636937141,
      "learning_rate": 1.5636448989172255e-05,
      "loss": 0.0098,
      "step": 21380
    },
    {
      "epoch": 0.6548694241190338,
      "grad_norm": 0.039788514375686646,
      "learning_rate": 1.563440794374879e-05,
      "loss": 0.0016,
      "step": 21390
    },
    {
      "epoch": 0.6551755809325537,
      "grad_norm": 0.03360959142446518,
      "learning_rate": 1.5632366898325325e-05,
      "loss": 0.0337,
      "step": 21400
    },
    {
      "epoch": 0.6554817377460735,
      "grad_norm": 0.022047752514481544,
      "learning_rate": 1.563032585290186e-05,
      "loss": 0.0018,
      "step": 21410
    },
    {
      "epoch": 0.6557878945595934,
      "grad_norm": 0.058546893298625946,
      "learning_rate": 1.562828480747839e-05,
      "loss": 0.0018,
      "step": 21420
    },
    {
      "epoch": 0.6560940513731133,
      "grad_norm": 0.046584926545619965,
      "learning_rate": 1.5626243762054926e-05,
      "loss": 0.0015,
      "step": 21430
    },
    {
      "epoch": 0.6564002081866331,
      "grad_norm": 0.019868994131684303,
      "learning_rate": 1.562420271663146e-05,
      "loss": 0.0631,
      "step": 21440
    },
    {
      "epoch": 0.6567063650001531,
      "grad_norm": 0.07005579769611359,
      "learning_rate": 1.5622161671207994e-05,
      "loss": 0.0015,
      "step": 21450
    },
    {
      "epoch": 0.657012521813673,
      "grad_norm": 0.04120391607284546,
      "learning_rate": 1.5620120625784527e-05,
      "loss": 0.0021,
      "step": 21460
    },
    {
      "epoch": 0.6573186786271928,
      "grad_norm": 0.08684249222278595,
      "learning_rate": 1.5618079580361064e-05,
      "loss": 0.064,
      "step": 21470
    },
    {
      "epoch": 0.6576248354407127,
      "grad_norm": 0.04964596405625343,
      "learning_rate": 1.5616038534937598e-05,
      "loss": 0.0021,
      "step": 21480
    },
    {
      "epoch": 0.6579309922542326,
      "grad_norm": 0.08995562046766281,
      "learning_rate": 1.561399748951413e-05,
      "loss": 0.0023,
      "step": 21490
    },
    {
      "epoch": 0.6582371490677525,
      "grad_norm": 0.021537035703659058,
      "learning_rate": 1.5611956444090662e-05,
      "loss": 0.047,
      "step": 21500
    },
    {
      "epoch": 0.6585433058812724,
      "grad_norm": 0.07794570922851562,
      "learning_rate": 1.56099153986672e-05,
      "loss": 0.0021,
      "step": 21510
    },
    {
      "epoch": 0.6588494626947923,
      "grad_norm": 0.03866969794034958,
      "learning_rate": 1.5607874353243733e-05,
      "loss": 0.0018,
      "step": 21520
    },
    {
      "epoch": 0.6591556195083121,
      "grad_norm": 0.03075406141579151,
      "learning_rate": 1.5605833307820266e-05,
      "loss": 0.0027,
      "step": 21530
    },
    {
      "epoch": 0.659461776321832,
      "grad_norm": 0.03809608146548271,
      "learning_rate": 1.5603792262396803e-05,
      "loss": 0.0374,
      "step": 21540
    },
    {
      "epoch": 0.659767933135352,
      "grad_norm": 0.03301303833723068,
      "learning_rate": 1.5601751216973337e-05,
      "loss": 0.0118,
      "step": 21550
    },
    {
      "epoch": 0.6600740899488718,
      "grad_norm": 0.03751889988780022,
      "learning_rate": 1.559971017154987e-05,
      "loss": 0.0143,
      "step": 21560
    },
    {
      "epoch": 0.6603802467623917,
      "grad_norm": 1.6490434408187866,
      "learning_rate": 1.55976691261264e-05,
      "loss": 0.0301,
      "step": 21570
    },
    {
      "epoch": 0.6606864035759116,
      "grad_norm": 0.038807462900877,
      "learning_rate": 1.5595628080702938e-05,
      "loss": 0.0018,
      "step": 21580
    },
    {
      "epoch": 0.6609925603894314,
      "grad_norm": 0.027631307020783424,
      "learning_rate": 1.559358703527947e-05,
      "loss": 0.0016,
      "step": 21590
    },
    {
      "epoch": 0.6612987172029513,
      "grad_norm": 0.05600445345044136,
      "learning_rate": 1.5591545989856005e-05,
      "loss": 0.0015,
      "step": 21600
    },
    {
      "epoch": 0.6616048740164713,
      "grad_norm": 0.03404533863067627,
      "learning_rate": 1.558950494443254e-05,
      "loss": 0.0357,
      "step": 21610
    },
    {
      "epoch": 0.6619110308299911,
      "grad_norm": 1.634791612625122,
      "learning_rate": 1.5587463899009076e-05,
      "loss": 0.0268,
      "step": 21620
    },
    {
      "epoch": 0.662217187643511,
      "grad_norm": 0.036928627640008926,
      "learning_rate": 1.558542285358561e-05,
      "loss": 0.0012,
      "step": 21630
    },
    {
      "epoch": 0.6625233444570309,
      "grad_norm": 0.03568706661462784,
      "learning_rate": 1.558338180816214e-05,
      "loss": 0.0011,
      "step": 21640
    },
    {
      "epoch": 0.6628295012705507,
      "grad_norm": 0.04690532758831978,
      "learning_rate": 1.5581340762738677e-05,
      "loss": 0.0014,
      "step": 21650
    },
    {
      "epoch": 0.6631356580840707,
      "grad_norm": 0.012810921296477318,
      "learning_rate": 1.557929971731521e-05,
      "loss": 0.0025,
      "step": 21660
    },
    {
      "epoch": 0.6634418148975906,
      "grad_norm": 0.05105821043252945,
      "learning_rate": 1.5577258671891744e-05,
      "loss": 0.0067,
      "step": 21670
    },
    {
      "epoch": 0.6637479717111104,
      "grad_norm": 0.025158289819955826,
      "learning_rate": 1.5575217626468278e-05,
      "loss": 0.001,
      "step": 21680
    },
    {
      "epoch": 0.6640541285246303,
      "grad_norm": 0.021668627858161926,
      "learning_rate": 1.5573176581044815e-05,
      "loss": 0.0657,
      "step": 21690
    },
    {
      "epoch": 0.6643602853381502,
      "grad_norm": 0.03954124078154564,
      "learning_rate": 1.557113553562135e-05,
      "loss": 0.0017,
      "step": 21700
    },
    {
      "epoch": 0.66466644215167,
      "grad_norm": 0.06067958474159241,
      "learning_rate": 1.556909449019788e-05,
      "loss": 0.0393,
      "step": 21710
    },
    {
      "epoch": 0.66497259896519,
      "grad_norm": 1.8157238960266113,
      "learning_rate": 1.5567053444774412e-05,
      "loss": 0.0381,
      "step": 21720
    },
    {
      "epoch": 0.6652787557787099,
      "grad_norm": 0.09085926413536072,
      "learning_rate": 1.556501239935095e-05,
      "loss": 0.0365,
      "step": 21730
    },
    {
      "epoch": 0.6655849125922297,
      "grad_norm": 0.1273314505815506,
      "learning_rate": 1.5562971353927483e-05,
      "loss": 0.003,
      "step": 21740
    },
    {
      "epoch": 0.6658910694057496,
      "grad_norm": 0.006702267099171877,
      "learning_rate": 1.5560930308504017e-05,
      "loss": 0.0017,
      "step": 21750
    },
    {
      "epoch": 0.6661972262192695,
      "grad_norm": 0.027395404875278473,
      "learning_rate": 1.5558889263080554e-05,
      "loss": 0.0032,
      "step": 21760
    },
    {
      "epoch": 0.6665033830327894,
      "grad_norm": 0.03318692743778229,
      "learning_rate": 1.5556848217657087e-05,
      "loss": 0.0017,
      "step": 21770
    },
    {
      "epoch": 0.6668095398463093,
      "grad_norm": 0.036354199051856995,
      "learning_rate": 1.5554807172233618e-05,
      "loss": 0.0302,
      "step": 21780
    },
    {
      "epoch": 0.6671156966598292,
      "grad_norm": 0.041090816259384155,
      "learning_rate": 1.555276612681015e-05,
      "loss": 0.0016,
      "step": 21790
    },
    {
      "epoch": 0.667421853473349,
      "grad_norm": 0.030733622610569,
      "learning_rate": 1.5550725081386688e-05,
      "loss": 0.0326,
      "step": 21800
    },
    {
      "epoch": 0.6677280102868689,
      "grad_norm": 0.03605959936976433,
      "learning_rate": 1.5548684035963222e-05,
      "loss": 0.0022,
      "step": 21810
    },
    {
      "epoch": 0.6680341671003888,
      "grad_norm": 0.026553630828857422,
      "learning_rate": 1.5546642990539755e-05,
      "loss": 0.0019,
      "step": 21820
    },
    {
      "epoch": 0.6683403239139087,
      "grad_norm": 0.04512147977948189,
      "learning_rate": 1.554460194511629e-05,
      "loss": 0.0012,
      "step": 21830
    },
    {
      "epoch": 0.6686464807274286,
      "grad_norm": 0.052016306668519974,
      "learning_rate": 1.5542560899692826e-05,
      "loss": 0.041,
      "step": 21840
    },
    {
      "epoch": 0.6689526375409485,
      "grad_norm": 1.8274521827697754,
      "learning_rate": 1.5540519854269356e-05,
      "loss": 0.0375,
      "step": 21850
    },
    {
      "epoch": 0.6692587943544683,
      "grad_norm": 0.04175638407468796,
      "learning_rate": 1.553847880884589e-05,
      "loss": 0.0016,
      "step": 21860
    },
    {
      "epoch": 0.6695649511679882,
      "grad_norm": 0.04031708464026451,
      "learning_rate": 1.5536437763422427e-05,
      "loss": 0.0019,
      "step": 21870
    },
    {
      "epoch": 0.6698711079815082,
      "grad_norm": 0.03583095222711563,
      "learning_rate": 1.553439671799896e-05,
      "loss": 0.0381,
      "step": 21880
    },
    {
      "epoch": 0.670177264795028,
      "grad_norm": 0.06042243540287018,
      "learning_rate": 1.5532355672575494e-05,
      "loss": 0.0017,
      "step": 21890
    },
    {
      "epoch": 0.6704834216085479,
      "grad_norm": 0.05064180865883827,
      "learning_rate": 1.5530314627152028e-05,
      "loss": 0.0017,
      "step": 21900
    },
    {
      "epoch": 0.6707895784220678,
      "grad_norm": 0.021172866225242615,
      "learning_rate": 1.5528273581728565e-05,
      "loss": 0.1008,
      "step": 21910
    },
    {
      "epoch": 0.6710957352355876,
      "grad_norm": 0.06699972599744797,
      "learning_rate": 1.5526232536305095e-05,
      "loss": 0.0322,
      "step": 21920
    },
    {
      "epoch": 0.6714018920491076,
      "grad_norm": 0.019853470847010612,
      "learning_rate": 1.552419149088163e-05,
      "loss": 0.0458,
      "step": 21930
    },
    {
      "epoch": 0.6717080488626275,
      "grad_norm": 0.09400896728038788,
      "learning_rate": 1.5522150445458163e-05,
      "loss": 0.032,
      "step": 21940
    },
    {
      "epoch": 0.6720142056761473,
      "grad_norm": 0.042573340237140656,
      "learning_rate": 1.55201094000347e-05,
      "loss": 0.0235,
      "step": 21950
    },
    {
      "epoch": 0.6723203624896672,
      "grad_norm": 0.16563820838928223,
      "learning_rate": 1.5518068354611233e-05,
      "loss": 0.0028,
      "step": 21960
    },
    {
      "epoch": 0.6726265193031871,
      "grad_norm": 0.05613255873322487,
      "learning_rate": 1.5516027309187767e-05,
      "loss": 0.0283,
      "step": 21970
    },
    {
      "epoch": 0.6729326761167069,
      "grad_norm": 0.018149467185139656,
      "learning_rate": 1.5513986263764304e-05,
      "loss": 0.0022,
      "step": 21980
    },
    {
      "epoch": 0.6732388329302269,
      "grad_norm": 0.061771195381879807,
      "learning_rate": 1.5511945218340834e-05,
      "loss": 0.0529,
      "step": 21990
    },
    {
      "epoch": 0.6735449897437468,
      "grad_norm": 1.6775007247924805,
      "learning_rate": 1.5509904172917368e-05,
      "loss": 0.0323,
      "step": 22000
    },
    {
      "epoch": 0.6738511465572666,
      "grad_norm": 1.5608649253845215,
      "learning_rate": 1.55078631274939e-05,
      "loss": 0.0454,
      "step": 22010
    },
    {
      "epoch": 0.6741573033707865,
      "grad_norm": 0.08458437770605087,
      "learning_rate": 1.550582208207044e-05,
      "loss": 0.0037,
      "step": 22020
    },
    {
      "epoch": 0.6744634601843064,
      "grad_norm": 0.06084777042269707,
      "learning_rate": 1.5503781036646972e-05,
      "loss": 0.0033,
      "step": 22030
    },
    {
      "epoch": 0.6747696169978263,
      "grad_norm": 0.07166426628828049,
      "learning_rate": 1.5501739991223506e-05,
      "loss": 0.0029,
      "step": 22040
    },
    {
      "epoch": 0.6750757738113462,
      "grad_norm": 0.09022704511880875,
      "learning_rate": 1.549969894580004e-05,
      "loss": 0.0465,
      "step": 22050
    },
    {
      "epoch": 0.6753819306248661,
      "grad_norm": 0.057667382061481476,
      "learning_rate": 1.5497657900376576e-05,
      "loss": 0.0028,
      "step": 22060
    },
    {
      "epoch": 0.6756880874383859,
      "grad_norm": 0.0428394079208374,
      "learning_rate": 1.5495616854953107e-05,
      "loss": 0.0022,
      "step": 22070
    },
    {
      "epoch": 0.6759942442519058,
      "grad_norm": 0.016836676746606827,
      "learning_rate": 1.549357580952964e-05,
      "loss": 0.002,
      "step": 22080
    },
    {
      "epoch": 0.6763004010654257,
      "grad_norm": 0.02895358018577099,
      "learning_rate": 1.5491534764106177e-05,
      "loss": 0.0016,
      "step": 22090
    },
    {
      "epoch": 0.6766065578789456,
      "grad_norm": 0.03320721164345741,
      "learning_rate": 1.548949371868271e-05,
      "loss": 0.0014,
      "step": 22100
    },
    {
      "epoch": 0.6769127146924655,
      "grad_norm": 1.7555961608886719,
      "learning_rate": 1.5487452673259245e-05,
      "loss": 0.03,
      "step": 22110
    },
    {
      "epoch": 0.6772188715059854,
      "grad_norm": 0.052481137216091156,
      "learning_rate": 1.548541162783578e-05,
      "loss": 0.0399,
      "step": 22120
    },
    {
      "epoch": 0.6775250283195052,
      "grad_norm": 0.03549852967262268,
      "learning_rate": 1.5483370582412315e-05,
      "loss": 0.0299,
      "step": 22130
    },
    {
      "epoch": 0.6778311851330251,
      "grad_norm": 0.06990212947130203,
      "learning_rate": 1.5481329536988846e-05,
      "loss": 0.0339,
      "step": 22140
    },
    {
      "epoch": 0.6781373419465451,
      "grad_norm": 0.030322356149554253,
      "learning_rate": 1.547928849156538e-05,
      "loss": 0.0036,
      "step": 22150
    },
    {
      "epoch": 0.6784434987600649,
      "grad_norm": 0.06350961327552795,
      "learning_rate": 1.5477247446141913e-05,
      "loss": 0.0022,
      "step": 22160
    },
    {
      "epoch": 0.6787496555735848,
      "grad_norm": 0.06087850034236908,
      "learning_rate": 1.547520640071845e-05,
      "loss": 0.0302,
      "step": 22170
    },
    {
      "epoch": 0.6790558123871047,
      "grad_norm": 0.06011810526251793,
      "learning_rate": 1.5473165355294984e-05,
      "loss": 0.0021,
      "step": 22180
    },
    {
      "epoch": 0.6793619692006245,
      "grad_norm": 0.013355420902371407,
      "learning_rate": 1.5471124309871517e-05,
      "loss": 0.0453,
      "step": 22190
    },
    {
      "epoch": 0.6796681260141444,
      "grad_norm": 0.03547872230410576,
      "learning_rate": 1.5469083264448054e-05,
      "loss": 0.0561,
      "step": 22200
    },
    {
      "epoch": 0.6799742828276644,
      "grad_norm": 0.03775088116526604,
      "learning_rate": 1.5467042219024585e-05,
      "loss": 0.0024,
      "step": 22210
    },
    {
      "epoch": 0.6802804396411842,
      "grad_norm": 0.044882651418447495,
      "learning_rate": 1.5465001173601118e-05,
      "loss": 0.0025,
      "step": 22220
    },
    {
      "epoch": 0.6805865964547041,
      "grad_norm": 0.02676064893603325,
      "learning_rate": 1.5462960128177652e-05,
      "loss": 0.002,
      "step": 22230
    },
    {
      "epoch": 0.680892753268224,
      "grad_norm": 0.021793948486447334,
      "learning_rate": 1.546091908275419e-05,
      "loss": 0.0022,
      "step": 22240
    },
    {
      "epoch": 0.6811989100817438,
      "grad_norm": 0.03315053880214691,
      "learning_rate": 1.5458878037330723e-05,
      "loss": 0.0014,
      "step": 22250
    },
    {
      "epoch": 0.6815050668952638,
      "grad_norm": 0.016859348863363266,
      "learning_rate": 1.5456836991907256e-05,
      "loss": 0.0015,
      "step": 22260
    },
    {
      "epoch": 0.6818112237087837,
      "grad_norm": 0.06721638143062592,
      "learning_rate": 1.545479594648379e-05,
      "loss": 0.0014,
      "step": 22270
    },
    {
      "epoch": 0.6821173805223035,
      "grad_norm": 0.019840266555547714,
      "learning_rate": 1.5452754901060323e-05,
      "loss": 0.0329,
      "step": 22280
    },
    {
      "epoch": 0.6824235373358234,
      "grad_norm": 0.03456396982073784,
      "learning_rate": 1.5450713855636857e-05,
      "loss": 0.0019,
      "step": 22290
    },
    {
      "epoch": 0.6827296941493433,
      "grad_norm": 0.023267444223165512,
      "learning_rate": 1.544867281021339e-05,
      "loss": 0.001,
      "step": 22300
    },
    {
      "epoch": 0.6830358509628632,
      "grad_norm": 0.020623570308089256,
      "learning_rate": 1.5446631764789928e-05,
      "loss": 0.0013,
      "step": 22310
    },
    {
      "epoch": 0.6833420077763831,
      "grad_norm": 0.051623620092868805,
      "learning_rate": 1.544459071936646e-05,
      "loss": 0.0009,
      "step": 22320
    },
    {
      "epoch": 0.683648164589903,
      "grad_norm": 2.9338037967681885,
      "learning_rate": 1.5442549673942995e-05,
      "loss": 0.0066,
      "step": 22330
    },
    {
      "epoch": 0.6839543214034228,
      "grad_norm": 0.0419430285692215,
      "learning_rate": 1.544050862851953e-05,
      "loss": 0.0321,
      "step": 22340
    },
    {
      "epoch": 0.6842604782169427,
      "grad_norm": 1.8745741844177246,
      "learning_rate": 1.5438467583096062e-05,
      "loss": 0.079,
      "step": 22350
    },
    {
      "epoch": 0.6845666350304626,
      "grad_norm": 0.03787558898329735,
      "learning_rate": 1.5436426537672596e-05,
      "loss": 0.0254,
      "step": 22360
    },
    {
      "epoch": 0.6848727918439825,
      "grad_norm": 0.07768649607896805,
      "learning_rate": 1.543438549224913e-05,
      "loss": 0.0864,
      "step": 22370
    },
    {
      "epoch": 0.6851789486575024,
      "grad_norm": 1.1628859043121338,
      "learning_rate": 1.5432344446825663e-05,
      "loss": 0.0046,
      "step": 22380
    },
    {
      "epoch": 0.6854851054710223,
      "grad_norm": 0.0294747706502676,
      "learning_rate": 1.54303034014022e-05,
      "loss": 0.0033,
      "step": 22390
    },
    {
      "epoch": 0.6857912622845421,
      "grad_norm": 0.043302375823259354,
      "learning_rate": 1.5428262355978734e-05,
      "loss": 0.0607,
      "step": 22400
    },
    {
      "epoch": 0.686097419098062,
      "grad_norm": 0.03215838223695755,
      "learning_rate": 1.5426221310555268e-05,
      "loss": 0.0341,
      "step": 22410
    },
    {
      "epoch": 0.686403575911582,
      "grad_norm": 0.11377860605716705,
      "learning_rate": 1.54241802651318e-05,
      "loss": 0.0026,
      "step": 22420
    },
    {
      "epoch": 0.6867097327251018,
      "grad_norm": 0.024329781532287598,
      "learning_rate": 1.5422139219708335e-05,
      "loss": 0.0016,
      "step": 22430
    },
    {
      "epoch": 0.6870158895386217,
      "grad_norm": 0.020259547978639603,
      "learning_rate": 1.542009817428487e-05,
      "loss": 0.0019,
      "step": 22440
    },
    {
      "epoch": 0.6873220463521416,
      "grad_norm": 0.030710728839039803,
      "learning_rate": 1.5418057128861402e-05,
      "loss": 0.0018,
      "step": 22450
    },
    {
      "epoch": 0.6876282031656614,
      "grad_norm": 0.023390237241983414,
      "learning_rate": 1.541601608343794e-05,
      "loss": 0.0009,
      "step": 22460
    },
    {
      "epoch": 0.6879343599791813,
      "grad_norm": 0.05782843381166458,
      "learning_rate": 1.5413975038014473e-05,
      "loss": 0.0012,
      "step": 22470
    },
    {
      "epoch": 0.6882405167927013,
      "grad_norm": 0.01867852918803692,
      "learning_rate": 1.5411933992591006e-05,
      "loss": 0.0012,
      "step": 22480
    },
    {
      "epoch": 0.6885466736062211,
      "grad_norm": 0.02076752297580242,
      "learning_rate": 1.540989294716754e-05,
      "loss": 0.0012,
      "step": 22490
    },
    {
      "epoch": 0.688852830419741,
      "grad_norm": 0.008219999261200428,
      "learning_rate": 1.5407851901744074e-05,
      "loss": 0.0017,
      "step": 22500
    },
    {
      "epoch": 0.6891589872332609,
      "grad_norm": 0.016625486314296722,
      "learning_rate": 1.5405810856320607e-05,
      "loss": 0.0008,
      "step": 22510
    },
    {
      "epoch": 0.6894651440467807,
      "grad_norm": 0.01737101562321186,
      "learning_rate": 1.540376981089714e-05,
      "loss": 0.0012,
      "step": 22520
    },
    {
      "epoch": 0.6897713008603007,
      "grad_norm": 0.009723820723593235,
      "learning_rate": 1.5401728765473675e-05,
      "loss": 0.0012,
      "step": 22530
    },
    {
      "epoch": 0.6900774576738206,
      "grad_norm": 0.24518638849258423,
      "learning_rate": 1.5399687720050212e-05,
      "loss": 0.0009,
      "step": 22540
    },
    {
      "epoch": 0.6903836144873404,
      "grad_norm": 0.015835480764508247,
      "learning_rate": 1.5397646674626745e-05,
      "loss": 0.0006,
      "step": 22550
    },
    {
      "epoch": 0.6906897713008603,
      "grad_norm": 0.011693969368934631,
      "learning_rate": 1.539560562920328e-05,
      "loss": 0.0006,
      "step": 22560
    },
    {
      "epoch": 0.6909959281143802,
      "grad_norm": 0.024161865934729576,
      "learning_rate": 1.5393564583779813e-05,
      "loss": 0.0125,
      "step": 22570
    },
    {
      "epoch": 0.6913020849279,
      "grad_norm": 0.009952738881111145,
      "learning_rate": 1.5391523538356346e-05,
      "loss": 0.0008,
      "step": 22580
    },
    {
      "epoch": 0.69160824174142,
      "grad_norm": 0.009427313692867756,
      "learning_rate": 1.538948249293288e-05,
      "loss": 0.039,
      "step": 22590
    },
    {
      "epoch": 0.6919143985549399,
      "grad_norm": 0.009497660212218761,
      "learning_rate": 1.5387441447509414e-05,
      "loss": 0.0011,
      "step": 22600
    },
    {
      "epoch": 0.6922205553684597,
      "grad_norm": 0.0020679987501353025,
      "learning_rate": 1.538540040208595e-05,
      "loss": 0.0006,
      "step": 22610
    },
    {
      "epoch": 0.6925267121819796,
      "grad_norm": 0.07788179814815521,
      "learning_rate": 1.5383359356662484e-05,
      "loss": 0.0008,
      "step": 22620
    },
    {
      "epoch": 0.6928328689954995,
      "grad_norm": 0.014510544016957283,
      "learning_rate": 1.5381318311239018e-05,
      "loss": 0.0065,
      "step": 22630
    },
    {
      "epoch": 0.6931390258090194,
      "grad_norm": 0.015682609751820564,
      "learning_rate": 1.537927726581555e-05,
      "loss": 0.0024,
      "step": 22640
    },
    {
      "epoch": 0.6934451826225393,
      "grad_norm": 0.0106655927374959,
      "learning_rate": 1.5377236220392085e-05,
      "loss": 0.0005,
      "step": 22650
    },
    {
      "epoch": 0.6937513394360592,
      "grad_norm": 0.024573853239417076,
      "learning_rate": 1.537519517496862e-05,
      "loss": 0.0005,
      "step": 22660
    },
    {
      "epoch": 0.694057496249579,
      "grad_norm": 0.007642583455890417,
      "learning_rate": 1.5373154129545153e-05,
      "loss": 0.0767,
      "step": 22670
    },
    {
      "epoch": 0.6943636530630989,
      "grad_norm": 0.01090782880783081,
      "learning_rate": 1.537111308412169e-05,
      "loss": 0.0367,
      "step": 22680
    },
    {
      "epoch": 0.6946698098766187,
      "grad_norm": 3.441366672515869,
      "learning_rate": 1.5369072038698223e-05,
      "loss": 0.0732,
      "step": 22690
    },
    {
      "epoch": 0.6949759666901387,
      "grad_norm": 0.08121518045663834,
      "learning_rate": 1.5367030993274757e-05,
      "loss": 0.0015,
      "step": 22700
    },
    {
      "epoch": 0.6952821235036586,
      "grad_norm": 0.0275085661560297,
      "learning_rate": 1.536498994785129e-05,
      "loss": 0.0416,
      "step": 22710
    },
    {
      "epoch": 0.6955882803171785,
      "grad_norm": 0.06225059553980827,
      "learning_rate": 1.5362948902427824e-05,
      "loss": 0.1055,
      "step": 22720
    },
    {
      "epoch": 0.6958944371306983,
      "grad_norm": 0.13609270751476288,
      "learning_rate": 1.5360907857004358e-05,
      "loss": 0.0115,
      "step": 22730
    },
    {
      "epoch": 0.6962005939442182,
      "grad_norm": 0.03621109947562218,
      "learning_rate": 1.535886681158089e-05,
      "loss": 0.0015,
      "step": 22740
    },
    {
      "epoch": 0.6965067507577382,
      "grad_norm": 0.027629142627120018,
      "learning_rate": 1.5356825766157425e-05,
      "loss": 0.004,
      "step": 22750
    },
    {
      "epoch": 0.696812907571258,
      "grad_norm": 0.03397651016712189,
      "learning_rate": 1.5354784720733962e-05,
      "loss": 0.0566,
      "step": 22760
    },
    {
      "epoch": 0.6971190643847779,
      "grad_norm": 0.06818508356809616,
      "learning_rate": 1.5352743675310496e-05,
      "loss": 0.0019,
      "step": 22770
    },
    {
      "epoch": 0.6974252211982978,
      "grad_norm": 0.047468364238739014,
      "learning_rate": 1.535070262988703e-05,
      "loss": 0.0025,
      "step": 22780
    },
    {
      "epoch": 0.6977313780118176,
      "grad_norm": 0.06002627685666084,
      "learning_rate": 1.5348661584463563e-05,
      "loss": 0.0396,
      "step": 22790
    },
    {
      "epoch": 0.6980375348253376,
      "grad_norm": 0.03906664252281189,
      "learning_rate": 1.5346620539040097e-05,
      "loss": 0.0019,
      "step": 22800
    },
    {
      "epoch": 0.6983436916388575,
      "grad_norm": 1.254101276397705,
      "learning_rate": 1.534457949361663e-05,
      "loss": 0.0051,
      "step": 22810
    },
    {
      "epoch": 0.6986498484523773,
      "grad_norm": 0.05698180943727493,
      "learning_rate": 1.5342538448193164e-05,
      "loss": 0.0014,
      "step": 22820
    },
    {
      "epoch": 0.6989560052658972,
      "grad_norm": 0.06500883400440216,
      "learning_rate": 1.53404974027697e-05,
      "loss": 0.0015,
      "step": 22830
    },
    {
      "epoch": 0.699262162079417,
      "grad_norm": 0.04912271350622177,
      "learning_rate": 1.5338456357346235e-05,
      "loss": 0.0111,
      "step": 22840
    },
    {
      "epoch": 0.6995683188929369,
      "grad_norm": 0.04719088226556778,
      "learning_rate": 1.5336415311922768e-05,
      "loss": 0.0016,
      "step": 22850
    },
    {
      "epoch": 0.6998744757064569,
      "grad_norm": 0.02302238717675209,
      "learning_rate": 1.5334374266499302e-05,
      "loss": 0.0352,
      "step": 22860
    },
    {
      "epoch": 0.7001806325199768,
      "grad_norm": 0.008181782439351082,
      "learning_rate": 1.5332333221075836e-05,
      "loss": 0.0011,
      "step": 22870
    },
    {
      "epoch": 0.7004867893334966,
      "grad_norm": 0.022426264360547066,
      "learning_rate": 1.533029217565237e-05,
      "loss": 0.0016,
      "step": 22880
    },
    {
      "epoch": 0.7007929461470165,
      "grad_norm": 0.02155936323106289,
      "learning_rate": 1.5328251130228903e-05,
      "loss": 0.0375,
      "step": 22890
    },
    {
      "epoch": 0.7010991029605363,
      "grad_norm": 0.03747233375906944,
      "learning_rate": 1.532621008480544e-05,
      "loss": 0.0013,
      "step": 22900
    },
    {
      "epoch": 0.7014052597740563,
      "grad_norm": 0.026852263137698174,
      "learning_rate": 1.5324169039381974e-05,
      "loss": 0.0013,
      "step": 22910
    },
    {
      "epoch": 0.7017114165875762,
      "grad_norm": 0.00629063043743372,
      "learning_rate": 1.5322127993958507e-05,
      "loss": 0.0016,
      "step": 22920
    },
    {
      "epoch": 0.702017573401096,
      "grad_norm": 0.014334284700453281,
      "learning_rate": 1.532008694853504e-05,
      "loss": 0.0009,
      "step": 22930
    },
    {
      "epoch": 0.7023237302146159,
      "grad_norm": 0.019481193274259567,
      "learning_rate": 1.5318045903111574e-05,
      "loss": 0.0288,
      "step": 22940
    },
    {
      "epoch": 0.7026298870281358,
      "grad_norm": 0.028749482706189156,
      "learning_rate": 1.5316004857688108e-05,
      "loss": 0.0009,
      "step": 22950
    },
    {
      "epoch": 0.7029360438416556,
      "grad_norm": 0.027139021083712578,
      "learning_rate": 1.5313963812264642e-05,
      "loss": 0.0357,
      "step": 22960
    },
    {
      "epoch": 0.7032422006551756,
      "grad_norm": 0.026004891842603683,
      "learning_rate": 1.5311922766841175e-05,
      "loss": 0.0014,
      "step": 22970
    },
    {
      "epoch": 0.7035483574686955,
      "grad_norm": 0.022440163418650627,
      "learning_rate": 1.5309881721417712e-05,
      "loss": 0.0009,
      "step": 22980
    },
    {
      "epoch": 0.7038545142822153,
      "grad_norm": 0.026259932667016983,
      "learning_rate": 1.5307840675994246e-05,
      "loss": 0.0007,
      "step": 22990
    },
    {
      "epoch": 0.7041606710957352,
      "grad_norm": 0.01649344153702259,
      "learning_rate": 1.530579963057078e-05,
      "loss": 0.0006,
      "step": 23000
    },
    {
      "epoch": 0.7044668279092551,
      "grad_norm": 0.013716370798647404,
      "learning_rate": 1.5303758585147313e-05,
      "loss": 0.002,
      "step": 23010
    },
    {
      "epoch": 0.704772984722775,
      "grad_norm": 0.007097848691046238,
      "learning_rate": 1.5301717539723847e-05,
      "loss": 0.0006,
      "step": 23020
    },
    {
      "epoch": 0.7050791415362949,
      "grad_norm": 0.01797759346663952,
      "learning_rate": 1.529967649430038e-05,
      "loss": 0.0006,
      "step": 23030
    },
    {
      "epoch": 0.7053852983498148,
      "grad_norm": 0.06932157278060913,
      "learning_rate": 1.5297635448876914e-05,
      "loss": 0.0008,
      "step": 23040
    },
    {
      "epoch": 0.7056914551633346,
      "grad_norm": 0.029897132888436317,
      "learning_rate": 1.529559440345345e-05,
      "loss": 0.0332,
      "step": 23050
    },
    {
      "epoch": 0.7059976119768545,
      "grad_norm": 0.02561754733324051,
      "learning_rate": 1.5293553358029985e-05,
      "loss": 0.001,
      "step": 23060
    },
    {
      "epoch": 0.7063037687903744,
      "grad_norm": 1.931118130683899,
      "learning_rate": 1.529151231260652e-05,
      "loss": 0.0372,
      "step": 23070
    },
    {
      "epoch": 0.7066099256038944,
      "grad_norm": 0.045364633202552795,
      "learning_rate": 1.5289471267183052e-05,
      "loss": 0.0009,
      "step": 23080
    },
    {
      "epoch": 0.7069160824174142,
      "grad_norm": 0.011662050150334835,
      "learning_rate": 1.5287430221759586e-05,
      "loss": 0.0016,
      "step": 23090
    },
    {
      "epoch": 0.7072222392309341,
      "grad_norm": 0.027472427114844322,
      "learning_rate": 1.528538917633612e-05,
      "loss": 0.0051,
      "step": 23100
    },
    {
      "epoch": 0.7075283960444539,
      "grad_norm": 0.02242802456021309,
      "learning_rate": 1.5283348130912653e-05,
      "loss": 0.0315,
      "step": 23110
    },
    {
      "epoch": 0.7078345528579738,
      "grad_norm": 0.01758449710905552,
      "learning_rate": 1.528130708548919e-05,
      "loss": 0.039,
      "step": 23120
    },
    {
      "epoch": 0.7081407096714938,
      "grad_norm": 0.06792114675045013,
      "learning_rate": 1.5279266040065724e-05,
      "loss": 0.0012,
      "step": 23130
    },
    {
      "epoch": 0.7084468664850136,
      "grad_norm": 0.04558359831571579,
      "learning_rate": 1.5277224994642258e-05,
      "loss": 0.0414,
      "step": 23140
    },
    {
      "epoch": 0.7087530232985335,
      "grad_norm": 0.05436156690120697,
      "learning_rate": 1.527518394921879e-05,
      "loss": 0.001,
      "step": 23150
    },
    {
      "epoch": 0.7090591801120534,
      "grad_norm": 0.10021961480379105,
      "learning_rate": 1.5273142903795325e-05,
      "loss": 0.0379,
      "step": 23160
    },
    {
      "epoch": 0.7093653369255732,
      "grad_norm": 0.04827972128987312,
      "learning_rate": 1.527110185837186e-05,
      "loss": 0.0028,
      "step": 23170
    },
    {
      "epoch": 0.7096714937390932,
      "grad_norm": 0.029427537694573402,
      "learning_rate": 1.5269060812948392e-05,
      "loss": 0.001,
      "step": 23180
    },
    {
      "epoch": 0.7099776505526131,
      "grad_norm": 0.017935100942850113,
      "learning_rate": 1.5267019767524926e-05,
      "loss": 0.0012,
      "step": 23190
    },
    {
      "epoch": 0.710283807366133,
      "grad_norm": 0.0054587735794484615,
      "learning_rate": 1.5264978722101463e-05,
      "loss": 0.001,
      "step": 23200
    },
    {
      "epoch": 0.7105899641796528,
      "grad_norm": 0.01367469597607851,
      "learning_rate": 1.5262937676677996e-05,
      "loss": 0.0007,
      "step": 23210
    },
    {
      "epoch": 0.7108961209931727,
      "grad_norm": 0.045278679579496384,
      "learning_rate": 1.526089663125453e-05,
      "loss": 0.0279,
      "step": 23220
    },
    {
      "epoch": 0.7112022778066925,
      "grad_norm": 0.009929592721164227,
      "learning_rate": 1.5258855585831064e-05,
      "loss": 0.0005,
      "step": 23230
    },
    {
      "epoch": 0.7115084346202125,
      "grad_norm": 0.013797945342957973,
      "learning_rate": 1.5256814540407599e-05,
      "loss": 0.0007,
      "step": 23240
    },
    {
      "epoch": 0.7118145914337324,
      "grad_norm": 0.017203688621520996,
      "learning_rate": 1.5254773494984133e-05,
      "loss": 0.0007,
      "step": 23250
    },
    {
      "epoch": 0.7121207482472522,
      "grad_norm": 0.0063996571116149426,
      "learning_rate": 1.5252732449560665e-05,
      "loss": 0.0007,
      "step": 23260
    },
    {
      "epoch": 0.7124269050607721,
      "grad_norm": 0.09688641130924225,
      "learning_rate": 1.5250691404137202e-05,
      "loss": 0.0006,
      "step": 23270
    },
    {
      "epoch": 0.712733061874292,
      "grad_norm": 0.05856001749634743,
      "learning_rate": 1.5248650358713735e-05,
      "loss": 0.0421,
      "step": 23280
    },
    {
      "epoch": 0.713039218687812,
      "grad_norm": 0.022543057799339294,
      "learning_rate": 1.5246609313290269e-05,
      "loss": 0.0399,
      "step": 23290
    },
    {
      "epoch": 0.7133453755013318,
      "grad_norm": 0.01798088103532791,
      "learning_rate": 1.5244568267866801e-05,
      "loss": 0.0138,
      "step": 23300
    },
    {
      "epoch": 0.7136515323148517,
      "grad_norm": 0.012819341383874416,
      "learning_rate": 1.5242527222443338e-05,
      "loss": 0.0007,
      "step": 23310
    },
    {
      "epoch": 0.7139576891283715,
      "grad_norm": 0.016047382727265358,
      "learning_rate": 1.5240486177019872e-05,
      "loss": 0.0402,
      "step": 23320
    },
    {
      "epoch": 0.7142638459418914,
      "grad_norm": 0.05394594743847847,
      "learning_rate": 1.5238445131596405e-05,
      "loss": 0.0011,
      "step": 23330
    },
    {
      "epoch": 0.7145700027554113,
      "grad_norm": 0.0277100820094347,
      "learning_rate": 1.523640408617294e-05,
      "loss": 0.0007,
      "step": 23340
    },
    {
      "epoch": 0.7148761595689312,
      "grad_norm": 0.015995046123862267,
      "learning_rate": 1.5234363040749474e-05,
      "loss": 0.0363,
      "step": 23350
    },
    {
      "epoch": 0.7151823163824511,
      "grad_norm": 0.0056211925111711025,
      "learning_rate": 1.5232321995326008e-05,
      "loss": 0.0007,
      "step": 23360
    },
    {
      "epoch": 0.715488473195971,
      "grad_norm": 0.018812472000718117,
      "learning_rate": 1.523028094990254e-05,
      "loss": 0.0087,
      "step": 23370
    },
    {
      "epoch": 0.7157946300094908,
      "grad_norm": 0.11089584976434708,
      "learning_rate": 1.5228239904479077e-05,
      "loss": 0.0032,
      "step": 23380
    },
    {
      "epoch": 0.7161007868230107,
      "grad_norm": 0.014161272905766964,
      "learning_rate": 1.522619885905561e-05,
      "loss": 0.0012,
      "step": 23390
    },
    {
      "epoch": 0.7164069436365307,
      "grad_norm": 0.01664900779724121,
      "learning_rate": 1.5224157813632144e-05,
      "loss": 0.0354,
      "step": 23400
    },
    {
      "epoch": 0.7167131004500505,
      "grad_norm": 0.04084259644150734,
      "learning_rate": 1.5222116768208676e-05,
      "loss": 0.0301,
      "step": 23410
    },
    {
      "epoch": 0.7170192572635704,
      "grad_norm": 0.020250054076313972,
      "learning_rate": 1.5220075722785213e-05,
      "loss": 0.0009,
      "step": 23420
    },
    {
      "epoch": 0.7173254140770903,
      "grad_norm": 0.010645083151757717,
      "learning_rate": 1.5218034677361747e-05,
      "loss": 0.0359,
      "step": 23430
    },
    {
      "epoch": 0.7176315708906101,
      "grad_norm": 0.01781027764081955,
      "learning_rate": 1.5215993631938279e-05,
      "loss": 0.0348,
      "step": 23440
    },
    {
      "epoch": 0.71793772770413,
      "grad_norm": 0.05623224377632141,
      "learning_rate": 1.5213952586514816e-05,
      "loss": 0.0249,
      "step": 23450
    },
    {
      "epoch": 0.71824388451765,
      "grad_norm": 0.05772410333156586,
      "learning_rate": 1.521191154109135e-05,
      "loss": 0.0018,
      "step": 23460
    },
    {
      "epoch": 0.7185500413311698,
      "grad_norm": 0.039980366826057434,
      "learning_rate": 1.5209870495667883e-05,
      "loss": 0.0013,
      "step": 23470
    },
    {
      "epoch": 0.7188561981446897,
      "grad_norm": 0.031019767746329308,
      "learning_rate": 1.5207829450244415e-05,
      "loss": 0.0016,
      "step": 23480
    },
    {
      "epoch": 0.7191623549582096,
      "grad_norm": 0.03360998257994652,
      "learning_rate": 1.5205788404820952e-05,
      "loss": 0.036,
      "step": 23490
    },
    {
      "epoch": 0.7194685117717294,
      "grad_norm": 0.04449566826224327,
      "learning_rate": 1.5203747359397486e-05,
      "loss": 0.0014,
      "step": 23500
    },
    {
      "epoch": 0.7197746685852494,
      "grad_norm": 0.06437569856643677,
      "learning_rate": 1.5201706313974018e-05,
      "loss": 0.0015,
      "step": 23510
    },
    {
      "epoch": 0.7200808253987693,
      "grad_norm": 0.01746620237827301,
      "learning_rate": 1.5199665268550551e-05,
      "loss": 0.0724,
      "step": 23520
    },
    {
      "epoch": 0.7203869822122891,
      "grad_norm": 0.08354280143976212,
      "learning_rate": 1.5197624223127088e-05,
      "loss": 0.0056,
      "step": 23530
    },
    {
      "epoch": 0.720693139025809,
      "grad_norm": 0.034019630402326584,
      "learning_rate": 1.5195583177703622e-05,
      "loss": 0.0007,
      "step": 23540
    },
    {
      "epoch": 0.7209992958393289,
      "grad_norm": 0.022169101983308792,
      "learning_rate": 1.5193542132280154e-05,
      "loss": 0.0022,
      "step": 23550
    },
    {
      "epoch": 0.7213054526528488,
      "grad_norm": 0.024222368374466896,
      "learning_rate": 1.5191501086856691e-05,
      "loss": 0.0009,
      "step": 23560
    },
    {
      "epoch": 0.7216116094663687,
      "grad_norm": 1.5570536851882935,
      "learning_rate": 1.5189460041433225e-05,
      "loss": 0.0654,
      "step": 23570
    },
    {
      "epoch": 0.7219177662798886,
      "grad_norm": 0.011932086199522018,
      "learning_rate": 1.5187418996009758e-05,
      "loss": 0.0011,
      "step": 23580
    },
    {
      "epoch": 0.7222239230934084,
      "grad_norm": 0.0503295436501503,
      "learning_rate": 1.518537795058629e-05,
      "loss": 0.0012,
      "step": 23590
    },
    {
      "epoch": 0.7225300799069283,
      "grad_norm": 0.007774682249873877,
      "learning_rate": 1.5183336905162827e-05,
      "loss": 0.0016,
      "step": 23600
    },
    {
      "epoch": 0.7228362367204482,
      "grad_norm": 0.028211237862706184,
      "learning_rate": 1.518129585973936e-05,
      "loss": 0.0015,
      "step": 23610
    },
    {
      "epoch": 0.7231423935339681,
      "grad_norm": 0.009977355599403381,
      "learning_rate": 1.5179254814315893e-05,
      "loss": 0.0014,
      "step": 23620
    },
    {
      "epoch": 0.723448550347488,
      "grad_norm": 0.007245739456266165,
      "learning_rate": 1.5177213768892426e-05,
      "loss": 0.001,
      "step": 23630
    },
    {
      "epoch": 0.7237547071610079,
      "grad_norm": 0.029093461111187935,
      "learning_rate": 1.5175172723468963e-05,
      "loss": 0.0599,
      "step": 23640
    },
    {
      "epoch": 0.7240608639745277,
      "grad_norm": 0.011272396892309189,
      "learning_rate": 1.5173131678045497e-05,
      "loss": 0.0008,
      "step": 23650
    },
    {
      "epoch": 0.7243670207880476,
      "grad_norm": 0.02251594327390194,
      "learning_rate": 1.5171090632622029e-05,
      "loss": 0.0007,
      "step": 23660
    },
    {
      "epoch": 0.7246731776015676,
      "grad_norm": 0.028717853128910065,
      "learning_rate": 1.5169049587198563e-05,
      "loss": 0.0008,
      "step": 23670
    },
    {
      "epoch": 0.7249793344150874,
      "grad_norm": 1.9215716123580933,
      "learning_rate": 1.51670085417751e-05,
      "loss": 0.0374,
      "step": 23680
    },
    {
      "epoch": 0.7252854912286073,
      "grad_norm": 0.011921397410333157,
      "learning_rate": 1.5164967496351632e-05,
      "loss": 0.0008,
      "step": 23690
    },
    {
      "epoch": 0.7255916480421272,
      "grad_norm": 0.005212409887462854,
      "learning_rate": 1.5162926450928165e-05,
      "loss": 0.0011,
      "step": 23700
    },
    {
      "epoch": 0.725897804855647,
      "grad_norm": 0.008053799159824848,
      "learning_rate": 1.5160885405504702e-05,
      "loss": 0.0436,
      "step": 23710
    },
    {
      "epoch": 0.7262039616691669,
      "grad_norm": 0.04439155012369156,
      "learning_rate": 1.5158844360081236e-05,
      "loss": 0.0009,
      "step": 23720
    },
    {
      "epoch": 0.7265101184826869,
      "grad_norm": 0.04319975525140762,
      "learning_rate": 1.5156803314657768e-05,
      "loss": 0.0009,
      "step": 23730
    },
    {
      "epoch": 0.7268162752962067,
      "grad_norm": 0.02771192416548729,
      "learning_rate": 1.5154762269234302e-05,
      "loss": 0.0819,
      "step": 23740
    },
    {
      "epoch": 0.7271224321097266,
      "grad_norm": 0.0008373128366656601,
      "learning_rate": 1.5152721223810839e-05,
      "loss": 0.0464,
      "step": 23750
    },
    {
      "epoch": 0.7274285889232465,
      "grad_norm": 2.2985360622406006,
      "learning_rate": 1.515068017838737e-05,
      "loss": 0.0065,
      "step": 23760
    },
    {
      "epoch": 0.7277347457367663,
      "grad_norm": 0.041157495230436325,
      "learning_rate": 1.5148639132963904e-05,
      "loss": 0.0013,
      "step": 23770
    },
    {
      "epoch": 0.7280409025502863,
      "grad_norm": 0.03519156947731972,
      "learning_rate": 1.5146598087540438e-05,
      "loss": 0.0037,
      "step": 23780
    },
    {
      "epoch": 0.7283470593638062,
      "grad_norm": 0.016507573425769806,
      "learning_rate": 1.5144557042116975e-05,
      "loss": 0.0011,
      "step": 23790
    },
    {
      "epoch": 0.728653216177326,
      "grad_norm": 0.025524243712425232,
      "learning_rate": 1.5142515996693507e-05,
      "loss": 0.0047,
      "step": 23800
    },
    {
      "epoch": 0.7289593729908459,
      "grad_norm": 0.020531978458166122,
      "learning_rate": 1.514047495127004e-05,
      "loss": 0.0007,
      "step": 23810
    },
    {
      "epoch": 0.7292655298043658,
      "grad_norm": 0.019653376191854477,
      "learning_rate": 1.5138433905846577e-05,
      "loss": 0.0009,
      "step": 23820
    },
    {
      "epoch": 0.7295716866178856,
      "grad_norm": 0.041158176958560944,
      "learning_rate": 1.513639286042311e-05,
      "loss": 0.0013,
      "step": 23830
    },
    {
      "epoch": 0.7298778434314056,
      "grad_norm": 0.02964717335999012,
      "learning_rate": 1.5134351814999643e-05,
      "loss": 0.0008,
      "step": 23840
    },
    {
      "epoch": 0.7301840002449255,
      "grad_norm": 0.029409799724817276,
      "learning_rate": 1.5132310769576177e-05,
      "loss": 0.034,
      "step": 23850
    },
    {
      "epoch": 0.7304901570584453,
      "grad_norm": 0.024972200393676758,
      "learning_rate": 1.5130269724152714e-05,
      "loss": 0.0888,
      "step": 23860
    },
    {
      "epoch": 0.7307963138719652,
      "grad_norm": 0.03601584956049919,
      "learning_rate": 1.5128228678729246e-05,
      "loss": 0.0016,
      "step": 23870
    },
    {
      "epoch": 0.7311024706854851,
      "grad_norm": 0.05610334873199463,
      "learning_rate": 1.512618763330578e-05,
      "loss": 0.059,
      "step": 23880
    },
    {
      "epoch": 0.731408627499005,
      "grad_norm": 0.0577489472925663,
      "learning_rate": 1.5124146587882313e-05,
      "loss": 0.0019,
      "step": 23890
    },
    {
      "epoch": 0.7317147843125249,
      "grad_norm": 0.029231678694486618,
      "learning_rate": 1.512210554245885e-05,
      "loss": 0.0018,
      "step": 23900
    },
    {
      "epoch": 0.7320209411260448,
      "grad_norm": 0.0625414028763771,
      "learning_rate": 1.5120064497035382e-05,
      "loss": 0.0209,
      "step": 23910
    },
    {
      "epoch": 0.7323270979395646,
      "grad_norm": 0.03160499781370163,
      "learning_rate": 1.5118023451611916e-05,
      "loss": 0.0015,
      "step": 23920
    },
    {
      "epoch": 0.7326332547530845,
      "grad_norm": 0.040127016603946686,
      "learning_rate": 1.5115982406188453e-05,
      "loss": 0.0016,
      "step": 23930
    },
    {
      "epoch": 0.7329394115666044,
      "grad_norm": 0.03826452046632767,
      "learning_rate": 1.5113941360764985e-05,
      "loss": 0.0011,
      "step": 23940
    },
    {
      "epoch": 0.7332455683801243,
      "grad_norm": 0.029929842799901962,
      "learning_rate": 1.5111900315341518e-05,
      "loss": 0.019,
      "step": 23950
    },
    {
      "epoch": 0.7335517251936442,
      "grad_norm": 0.05969288572669029,
      "learning_rate": 1.5109859269918052e-05,
      "loss": 0.0317,
      "step": 23960
    },
    {
      "epoch": 0.7338578820071641,
      "grad_norm": 0.034530870616436005,
      "learning_rate": 1.5107818224494589e-05,
      "loss": 0.0627,
      "step": 23970
    },
    {
      "epoch": 0.7341640388206839,
      "grad_norm": 0.09281695634126663,
      "learning_rate": 1.5105777179071121e-05,
      "loss": 0.0023,
      "step": 23980
    },
    {
      "epoch": 0.7344701956342038,
      "grad_norm": 0.060655105859041214,
      "learning_rate": 1.5103736133647655e-05,
      "loss": 0.0344,
      "step": 23990
    },
    {
      "epoch": 0.7347763524477238,
      "grad_norm": 0.17094318568706512,
      "learning_rate": 1.5101695088224188e-05,
      "loss": 0.0145,
      "step": 24000
    },
    {
      "epoch": 0.7350825092612436,
      "grad_norm": 0.07246974110603333,
      "learning_rate": 1.5099654042800724e-05,
      "loss": 0.0338,
      "step": 24010
    },
    {
      "epoch": 0.7353886660747635,
      "grad_norm": 0.03464102745056152,
      "learning_rate": 1.5097612997377257e-05,
      "loss": 0.003,
      "step": 24020
    },
    {
      "epoch": 0.7356948228882834,
      "grad_norm": 0.18835259974002838,
      "learning_rate": 1.509557195195379e-05,
      "loss": 0.003,
      "step": 24030
    },
    {
      "epoch": 0.7360009797018032,
      "grad_norm": 0.02079526148736477,
      "learning_rate": 1.5093530906530328e-05,
      "loss": 0.0014,
      "step": 24040
    },
    {
      "epoch": 0.7363071365153232,
      "grad_norm": 0.032690130174160004,
      "learning_rate": 1.509148986110686e-05,
      "loss": 0.0315,
      "step": 24050
    },
    {
      "epoch": 0.7366132933288431,
      "grad_norm": 0.04555646330118179,
      "learning_rate": 1.5089448815683393e-05,
      "loss": 0.0022,
      "step": 24060
    },
    {
      "epoch": 0.7369194501423629,
      "grad_norm": 0.02395700290799141,
      "learning_rate": 1.5087407770259927e-05,
      "loss": 0.0016,
      "step": 24070
    },
    {
      "epoch": 0.7372256069558828,
      "grad_norm": 0.06095818430185318,
      "learning_rate": 1.5085366724836462e-05,
      "loss": 0.0046,
      "step": 24080
    },
    {
      "epoch": 0.7375317637694027,
      "grad_norm": 0.02489289827644825,
      "learning_rate": 1.5083325679412996e-05,
      "loss": 0.0012,
      "step": 24090
    },
    {
      "epoch": 0.7378379205829225,
      "grad_norm": 0.021785663440823555,
      "learning_rate": 1.508128463398953e-05,
      "loss": 0.0012,
      "step": 24100
    },
    {
      "epoch": 0.7381440773964425,
      "grad_norm": 0.020796140655875206,
      "learning_rate": 1.5079243588566063e-05,
      "loss": 0.001,
      "step": 24110
    },
    {
      "epoch": 0.7384502342099624,
      "grad_norm": 0.024541933089494705,
      "learning_rate": 1.5077202543142599e-05,
      "loss": 0.0019,
      "step": 24120
    },
    {
      "epoch": 0.7387563910234822,
      "grad_norm": 0.007295168470591307,
      "learning_rate": 1.5075161497719132e-05,
      "loss": 0.0009,
      "step": 24130
    },
    {
      "epoch": 0.7390625478370021,
      "grad_norm": 0.02089909464120865,
      "learning_rate": 1.5073120452295666e-05,
      "loss": 0.0057,
      "step": 24140
    },
    {
      "epoch": 0.739368704650522,
      "grad_norm": 1.8897004127502441,
      "learning_rate": 1.5071079406872203e-05,
      "loss": 0.0919,
      "step": 24150
    },
    {
      "epoch": 0.7396748614640419,
      "grad_norm": 0.0589510053396225,
      "learning_rate": 1.5069038361448735e-05,
      "loss": 0.0619,
      "step": 24160
    },
    {
      "epoch": 0.7399810182775618,
      "grad_norm": 0.021026715636253357,
      "learning_rate": 1.5066997316025269e-05,
      "loss": 0.0326,
      "step": 24170
    },
    {
      "epoch": 0.7402871750910817,
      "grad_norm": 0.03533332422375679,
      "learning_rate": 1.5064956270601802e-05,
      "loss": 0.0156,
      "step": 24180
    },
    {
      "epoch": 0.7405933319046015,
      "grad_norm": 0.0009210565476678312,
      "learning_rate": 1.5062915225178338e-05,
      "loss": 0.0377,
      "step": 24190
    },
    {
      "epoch": 0.7408994887181214,
      "grad_norm": 0.03933870419859886,
      "learning_rate": 1.5060874179754871e-05,
      "loss": 0.0312,
      "step": 24200
    },
    {
      "epoch": 0.7412056455316413,
      "grad_norm": 0.06162634491920471,
      "learning_rate": 1.5058833134331405e-05,
      "loss": 0.0358,
      "step": 24210
    },
    {
      "epoch": 0.7415118023451612,
      "grad_norm": 0.028795182704925537,
      "learning_rate": 1.5056792088907939e-05,
      "loss": 0.0108,
      "step": 24220
    },
    {
      "epoch": 0.7418179591586811,
      "grad_norm": 0.056868672370910645,
      "learning_rate": 1.5054751043484474e-05,
      "loss": 0.0284,
      "step": 24230
    },
    {
      "epoch": 0.742124115972201,
      "grad_norm": 0.04297591373324394,
      "learning_rate": 1.5052709998061007e-05,
      "loss": 0.0327,
      "step": 24240
    },
    {
      "epoch": 0.7424302727857208,
      "grad_norm": 0.006021183915436268,
      "learning_rate": 1.5050668952637541e-05,
      "loss": 0.0353,
      "step": 24250
    },
    {
      "epoch": 0.7427364295992407,
      "grad_norm": 0.05735745280981064,
      "learning_rate": 1.5048627907214076e-05,
      "loss": 0.0037,
      "step": 24260
    },
    {
      "epoch": 0.7430425864127607,
      "grad_norm": 0.07023876160383224,
      "learning_rate": 1.504658686179061e-05,
      "loss": 0.0022,
      "step": 24270
    },
    {
      "epoch": 0.7433487432262805,
      "grad_norm": 0.06282424181699753,
      "learning_rate": 1.5044545816367144e-05,
      "loss": 0.0048,
      "step": 24280
    },
    {
      "epoch": 0.7436549000398004,
      "grad_norm": 0.0508006252348423,
      "learning_rate": 1.5042504770943677e-05,
      "loss": 0.0022,
      "step": 24290
    },
    {
      "epoch": 0.7439610568533203,
      "grad_norm": 0.04622945189476013,
      "learning_rate": 1.5040463725520213e-05,
      "loss": 0.0266,
      "step": 24300
    },
    {
      "epoch": 0.7442672136668401,
      "grad_norm": 0.016522573307156563,
      "learning_rate": 1.5038422680096746e-05,
      "loss": 0.0012,
      "step": 24310
    },
    {
      "epoch": 0.74457337048036,
      "grad_norm": 0.07256129384040833,
      "learning_rate": 1.503638163467328e-05,
      "loss": 0.0408,
      "step": 24320
    },
    {
      "epoch": 0.74487952729388,
      "grad_norm": 0.0808010995388031,
      "learning_rate": 1.5034340589249814e-05,
      "loss": 0.0322,
      "step": 24330
    },
    {
      "epoch": 0.7451856841073998,
      "grad_norm": 0.06061328575015068,
      "learning_rate": 1.5032299543826349e-05,
      "loss": 0.0033,
      "step": 24340
    },
    {
      "epoch": 0.7454918409209197,
      "grad_norm": 0.0577891506254673,
      "learning_rate": 1.5030258498402883e-05,
      "loss": 0.0018,
      "step": 24350
    },
    {
      "epoch": 0.7457979977344396,
      "grad_norm": 0.030036412179470062,
      "learning_rate": 1.5028217452979416e-05,
      "loss": 0.0015,
      "step": 24360
    },
    {
      "epoch": 0.7461041545479594,
      "grad_norm": 0.023897873237729073,
      "learning_rate": 1.5026176407555952e-05,
      "loss": 0.0017,
      "step": 24370
    },
    {
      "epoch": 0.7464103113614794,
      "grad_norm": 0.03678743913769722,
      "learning_rate": 1.5024135362132485e-05,
      "loss": 0.0013,
      "step": 24380
    },
    {
      "epoch": 0.7467164681749993,
      "grad_norm": 0.011760489083826542,
      "learning_rate": 1.5022094316709019e-05,
      "loss": 0.0013,
      "step": 24390
    },
    {
      "epoch": 0.7470226249885191,
      "grad_norm": 0.028396598994731903,
      "learning_rate": 1.5020053271285553e-05,
      "loss": 0.0013,
      "step": 24400
    },
    {
      "epoch": 0.747328781802039,
      "grad_norm": 0.011387833394110203,
      "learning_rate": 1.5018012225862088e-05,
      "loss": 0.022,
      "step": 24410
    },
    {
      "epoch": 0.7476349386155589,
      "grad_norm": 0.010560461319983006,
      "learning_rate": 1.5015971180438622e-05,
      "loss": 0.0428,
      "step": 24420
    },
    {
      "epoch": 0.7479410954290788,
      "grad_norm": 0.0029039804358035326,
      "learning_rate": 1.5013930135015155e-05,
      "loss": 0.001,
      "step": 24430
    },
    {
      "epoch": 0.7482472522425987,
      "grad_norm": 0.02986292727291584,
      "learning_rate": 1.5011889089591689e-05,
      "loss": 0.0008,
      "step": 24440
    },
    {
      "epoch": 0.7485534090561186,
      "grad_norm": 0.023998143151402473,
      "learning_rate": 1.5009848044168224e-05,
      "loss": 0.001,
      "step": 24450
    },
    {
      "epoch": 0.7488595658696384,
      "grad_norm": 0.025831209495663643,
      "learning_rate": 1.5007806998744758e-05,
      "loss": 0.028,
      "step": 24460
    },
    {
      "epoch": 0.7491657226831583,
      "grad_norm": 0.025739632546901703,
      "learning_rate": 1.5005765953321291e-05,
      "loss": 0.0271,
      "step": 24470
    },
    {
      "epoch": 0.7494718794966782,
      "grad_norm": 0.02885132096707821,
      "learning_rate": 1.5003724907897827e-05,
      "loss": 0.0631,
      "step": 24480
    },
    {
      "epoch": 0.7497780363101981,
      "grad_norm": 0.01733568124473095,
      "learning_rate": 1.500168386247436e-05,
      "loss": 0.0018,
      "step": 24490
    },
    {
      "epoch": 0.750084193123718,
      "grad_norm": 0.0496784932911396,
      "learning_rate": 1.4999642817050894e-05,
      "loss": 0.0361,
      "step": 24500
    },
    {
      "epoch": 0.7503903499372379,
      "grad_norm": 0.05148554593324661,
      "learning_rate": 1.4997601771627428e-05,
      "loss": 0.0026,
      "step": 24510
    },
    {
      "epoch": 0.7506965067507577,
      "grad_norm": 0.03444554656744003,
      "learning_rate": 1.4995560726203963e-05,
      "loss": 0.0019,
      "step": 24520
    },
    {
      "epoch": 0.7510026635642776,
      "grad_norm": 0.01986653171479702,
      "learning_rate": 1.4993519680780497e-05,
      "loss": 0.0017,
      "step": 24530
    },
    {
      "epoch": 0.7513088203777976,
      "grad_norm": 0.030585724860429764,
      "learning_rate": 1.499147863535703e-05,
      "loss": 0.0016,
      "step": 24540
    },
    {
      "epoch": 0.7516149771913174,
      "grad_norm": 0.03615201264619827,
      "learning_rate": 1.4989437589933564e-05,
      "loss": 0.0011,
      "step": 24550
    },
    {
      "epoch": 0.7519211340048373,
      "grad_norm": 0.03943151980638504,
      "learning_rate": 1.49873965445101e-05,
      "loss": 0.0015,
      "step": 24560
    },
    {
      "epoch": 0.7522272908183572,
      "grad_norm": 0.07025215774774551,
      "learning_rate": 1.4985355499086633e-05,
      "loss": 0.0039,
      "step": 24570
    },
    {
      "epoch": 0.752533447631877,
      "grad_norm": 0.03677015006542206,
      "learning_rate": 1.4983314453663167e-05,
      "loss": 0.001,
      "step": 24580
    },
    {
      "epoch": 0.7528396044453969,
      "grad_norm": 0.01605292595922947,
      "learning_rate": 1.4981273408239702e-05,
      "loss": 0.0012,
      "step": 24590
    },
    {
      "epoch": 0.7531457612589169,
      "grad_norm": 1.5063154697418213,
      "learning_rate": 1.4979232362816236e-05,
      "loss": 0.0194,
      "step": 24600
    },
    {
      "epoch": 0.7534519180724367,
      "grad_norm": 0.05180460587143898,
      "learning_rate": 1.497719131739277e-05,
      "loss": 0.0013,
      "step": 24610
    },
    {
      "epoch": 0.7537580748859566,
      "grad_norm": 0.024653421714901924,
      "learning_rate": 1.4975150271969303e-05,
      "loss": 0.0563,
      "step": 24620
    },
    {
      "epoch": 0.7540642316994765,
      "grad_norm": 0.7149409055709839,
      "learning_rate": 1.4973109226545838e-05,
      "loss": 0.0251,
      "step": 24630
    },
    {
      "epoch": 0.7543703885129963,
      "grad_norm": 0.08705238252878189,
      "learning_rate": 1.4971068181122372e-05,
      "loss": 0.0016,
      "step": 24640
    },
    {
      "epoch": 0.7546765453265163,
      "grad_norm": 0.07021055370569229,
      "learning_rate": 1.4969027135698906e-05,
      "loss": 0.0014,
      "step": 24650
    },
    {
      "epoch": 0.7549827021400362,
      "grad_norm": 0.03869977220892906,
      "learning_rate": 1.496698609027544e-05,
      "loss": 0.003,
      "step": 24660
    },
    {
      "epoch": 0.755288858953556,
      "grad_norm": 0.02940278686583042,
      "learning_rate": 1.4964945044851975e-05,
      "loss": 0.0354,
      "step": 24670
    },
    {
      "epoch": 0.7555950157670759,
      "grad_norm": 0.03689492866396904,
      "learning_rate": 1.4962903999428508e-05,
      "loss": 0.0015,
      "step": 24680
    },
    {
      "epoch": 0.7559011725805957,
      "grad_norm": 0.14989891648292542,
      "learning_rate": 1.4960862954005042e-05,
      "loss": 0.0025,
      "step": 24690
    },
    {
      "epoch": 0.7562073293941156,
      "grad_norm": 0.05247121676802635,
      "learning_rate": 1.4958821908581577e-05,
      "loss": 0.0013,
      "step": 24700
    },
    {
      "epoch": 0.7565134862076356,
      "grad_norm": 0.024234352633357048,
      "learning_rate": 1.495678086315811e-05,
      "loss": 0.0012,
      "step": 24710
    },
    {
      "epoch": 0.7568196430211555,
      "grad_norm": 0.02579084224998951,
      "learning_rate": 1.4954739817734644e-05,
      "loss": 0.0037,
      "step": 24720
    },
    {
      "epoch": 0.7571257998346753,
      "grad_norm": 0.03625013679265976,
      "learning_rate": 1.4952698772311178e-05,
      "loss": 0.0011,
      "step": 24730
    },
    {
      "epoch": 0.7574319566481952,
      "grad_norm": 0.023075345903635025,
      "learning_rate": 1.4950657726887713e-05,
      "loss": 0.0009,
      "step": 24740
    },
    {
      "epoch": 0.757738113461715,
      "grad_norm": 0.03171232342720032,
      "learning_rate": 1.4948616681464247e-05,
      "loss": 0.0384,
      "step": 24750
    },
    {
      "epoch": 0.758044270275235,
      "grad_norm": 0.01460567768663168,
      "learning_rate": 1.494657563604078e-05,
      "loss": 0.0009,
      "step": 24760
    },
    {
      "epoch": 0.7583504270887549,
      "grad_norm": 1.5783659219741821,
      "learning_rate": 1.4944534590617314e-05,
      "loss": 0.1198,
      "step": 24770
    },
    {
      "epoch": 0.7586565839022748,
      "grad_norm": 0.009197955951094627,
      "learning_rate": 1.494249354519385e-05,
      "loss": 0.0333,
      "step": 24780
    },
    {
      "epoch": 0.7589627407157946,
      "grad_norm": 0.039977122098207474,
      "learning_rate": 1.4940452499770383e-05,
      "loss": 0.0045,
      "step": 24790
    },
    {
      "epoch": 0.7592688975293145,
      "grad_norm": 0.029534071683883667,
      "learning_rate": 1.4938411454346917e-05,
      "loss": 0.0008,
      "step": 24800
    },
    {
      "epoch": 0.7595750543428345,
      "grad_norm": 0.04790337383747101,
      "learning_rate": 1.4936370408923452e-05,
      "loss": 0.0012,
      "step": 24810
    },
    {
      "epoch": 0.7598812111563543,
      "grad_norm": 0.018288666382431984,
      "learning_rate": 1.4934329363499986e-05,
      "loss": 0.0006,
      "step": 24820
    },
    {
      "epoch": 0.7601873679698742,
      "grad_norm": 0.027452800422906876,
      "learning_rate": 1.493228831807652e-05,
      "loss": 0.0008,
      "step": 24830
    },
    {
      "epoch": 0.760493524783394,
      "grad_norm": 0.01788971945643425,
      "learning_rate": 1.4930247272653053e-05,
      "loss": 0.043,
      "step": 24840
    },
    {
      "epoch": 0.7607996815969139,
      "grad_norm": 2.0421836376190186,
      "learning_rate": 1.4928206227229589e-05,
      "loss": 0.045,
      "step": 24850
    },
    {
      "epoch": 0.7611058384104338,
      "grad_norm": 0.027703432366251945,
      "learning_rate": 1.4926165181806122e-05,
      "loss": 0.0008,
      "step": 24860
    },
    {
      "epoch": 0.7614119952239538,
      "grad_norm": 0.025599651038646698,
      "learning_rate": 1.4924124136382656e-05,
      "loss": 0.0719,
      "step": 24870
    },
    {
      "epoch": 0.7617181520374736,
      "grad_norm": 0.04644801467657089,
      "learning_rate": 1.492208309095919e-05,
      "loss": 0.0016,
      "step": 24880
    },
    {
      "epoch": 0.7620243088509935,
      "grad_norm": 0.04291483759880066,
      "learning_rate": 1.4920042045535725e-05,
      "loss": 0.0012,
      "step": 24890
    },
    {
      "epoch": 0.7623304656645133,
      "grad_norm": 0.020768476650118828,
      "learning_rate": 1.4918001000112259e-05,
      "loss": 0.0014,
      "step": 24900
    },
    {
      "epoch": 0.7626366224780332,
      "grad_norm": 0.03530682995915413,
      "learning_rate": 1.4915959954688792e-05,
      "loss": 0.0016,
      "step": 24910
    },
    {
      "epoch": 0.7629427792915532,
      "grad_norm": 0.027637211605906487,
      "learning_rate": 1.4913918909265326e-05,
      "loss": 0.0015,
      "step": 24920
    },
    {
      "epoch": 0.763248936105073,
      "grad_norm": 0.015292276628315449,
      "learning_rate": 1.4911877863841861e-05,
      "loss": 0.0011,
      "step": 24930
    },
    {
      "epoch": 0.7635550929185929,
      "grad_norm": 0.031817369163036346,
      "learning_rate": 1.4909836818418395e-05,
      "loss": 0.001,
      "step": 24940
    },
    {
      "epoch": 0.7638612497321128,
      "grad_norm": 0.0265491995960474,
      "learning_rate": 1.4907795772994928e-05,
      "loss": 0.0243,
      "step": 24950
    },
    {
      "epoch": 0.7641674065456326,
      "grad_norm": 0.010874638333916664,
      "learning_rate": 1.4905754727571464e-05,
      "loss": 0.0009,
      "step": 24960
    },
    {
      "epoch": 0.7644735633591525,
      "grad_norm": 0.03634268417954445,
      "learning_rate": 1.4903713682147997e-05,
      "loss": 0.0007,
      "step": 24970
    },
    {
      "epoch": 0.7647797201726725,
      "grad_norm": 0.030391713604331017,
      "learning_rate": 1.4901672636724531e-05,
      "loss": 0.0487,
      "step": 24980
    },
    {
      "epoch": 0.7650858769861923,
      "grad_norm": 0.02024473249912262,
      "learning_rate": 1.4899631591301065e-05,
      "loss": 0.0008,
      "step": 24990
    },
    {
      "epoch": 0.7653920337997122,
      "grad_norm": 0.012048831209540367,
      "learning_rate": 1.48975905458776e-05,
      "loss": 0.0496,
      "step": 25000
    },
    {
      "epoch": 0.7656981906132321,
      "grad_norm": 0.032329004257917404,
      "learning_rate": 1.4895549500454134e-05,
      "loss": 0.001,
      "step": 25010
    },
    {
      "epoch": 0.7660043474267519,
      "grad_norm": 0.013149078004062176,
      "learning_rate": 1.4893508455030667e-05,
      "loss": 0.0348,
      "step": 25020
    },
    {
      "epoch": 0.7663105042402719,
      "grad_norm": 0.005415802355855703,
      "learning_rate": 1.4891467409607201e-05,
      "loss": 0.0304,
      "step": 25030
    },
    {
      "epoch": 0.7666166610537918,
      "grad_norm": 0.025466663762927055,
      "learning_rate": 1.4889426364183736e-05,
      "loss": 0.0396,
      "step": 25040
    },
    {
      "epoch": 0.7669228178673116,
      "grad_norm": 0.04459374397993088,
      "learning_rate": 1.488738531876027e-05,
      "loss": 0.0293,
      "step": 25050
    },
    {
      "epoch": 0.7672289746808315,
      "grad_norm": 0.038871899247169495,
      "learning_rate": 1.4885344273336804e-05,
      "loss": 0.0019,
      "step": 25060
    },
    {
      "epoch": 0.7675351314943514,
      "grad_norm": 0.05790211260318756,
      "learning_rate": 1.4883303227913339e-05,
      "loss": 0.0501,
      "step": 25070
    },
    {
      "epoch": 0.7678412883078712,
      "grad_norm": 0.011204316280782223,
      "learning_rate": 1.4881262182489873e-05,
      "loss": 0.0053,
      "step": 25080
    },
    {
      "epoch": 0.7681474451213912,
      "grad_norm": 0.017586002126336098,
      "learning_rate": 1.4879221137066406e-05,
      "loss": 0.0018,
      "step": 25090
    },
    {
      "epoch": 0.7684536019349111,
      "grad_norm": 0.038999564945697784,
      "learning_rate": 1.487718009164294e-05,
      "loss": 0.0021,
      "step": 25100
    },
    {
      "epoch": 0.7687597587484309,
      "grad_norm": 0.025891512632369995,
      "learning_rate": 1.4875139046219475e-05,
      "loss": 0.0009,
      "step": 25110
    },
    {
      "epoch": 0.7690659155619508,
      "grad_norm": 0.0561121366918087,
      "learning_rate": 1.4873098000796009e-05,
      "loss": 0.0018,
      "step": 25120
    },
    {
      "epoch": 0.7693720723754707,
      "grad_norm": 0.014567028731107712,
      "learning_rate": 1.4871056955372542e-05,
      "loss": 0.0011,
      "step": 25130
    },
    {
      "epoch": 0.7696782291889906,
      "grad_norm": 0.03135562688112259,
      "learning_rate": 1.4869015909949076e-05,
      "loss": 0.0386,
      "step": 25140
    },
    {
      "epoch": 0.7699843860025105,
      "grad_norm": 0.03354586288332939,
      "learning_rate": 1.4866974864525611e-05,
      "loss": 0.0027,
      "step": 25150
    },
    {
      "epoch": 0.7702905428160304,
      "grad_norm": 0.03274736553430557,
      "learning_rate": 1.4864933819102145e-05,
      "loss": 0.0013,
      "step": 25160
    },
    {
      "epoch": 0.7705966996295502,
      "grad_norm": 0.017365649342536926,
      "learning_rate": 1.4862892773678679e-05,
      "loss": 0.0169,
      "step": 25170
    },
    {
      "epoch": 0.7709028564430701,
      "grad_norm": 0.013294323347508907,
      "learning_rate": 1.4860851728255214e-05,
      "loss": 0.0295,
      "step": 25180
    },
    {
      "epoch": 0.77120901325659,
      "grad_norm": 0.032949697226285934,
      "learning_rate": 1.4858810682831748e-05,
      "loss": 0.0015,
      "step": 25190
    },
    {
      "epoch": 0.77151517007011,
      "grad_norm": 0.012981086038053036,
      "learning_rate": 1.4856769637408281e-05,
      "loss": 0.0014,
      "step": 25200
    },
    {
      "epoch": 0.7718213268836298,
      "grad_norm": 0.02991843968629837,
      "learning_rate": 1.4854728591984815e-05,
      "loss": 0.001,
      "step": 25210
    },
    {
      "epoch": 0.7721274836971497,
      "grad_norm": 0.03310941532254219,
      "learning_rate": 1.485268754656135e-05,
      "loss": 0.0009,
      "step": 25220
    },
    {
      "epoch": 0.7724336405106695,
      "grad_norm": 0.011597184464335442,
      "learning_rate": 1.4850646501137884e-05,
      "loss": 0.0012,
      "step": 25230
    },
    {
      "epoch": 0.7727397973241894,
      "grad_norm": 0.03329915553331375,
      "learning_rate": 1.4848605455714418e-05,
      "loss": 0.0011,
      "step": 25240
    },
    {
      "epoch": 0.7730459541377094,
      "grad_norm": 0.005448362790048122,
      "learning_rate": 1.4846564410290951e-05,
      "loss": 0.0006,
      "step": 25250
    },
    {
      "epoch": 0.7733521109512292,
      "grad_norm": 0.012429337948560715,
      "learning_rate": 1.4844523364867487e-05,
      "loss": 0.0007,
      "step": 25260
    },
    {
      "epoch": 0.7736582677647491,
      "grad_norm": 0.020621052011847496,
      "learning_rate": 1.484248231944402e-05,
      "loss": 0.0732,
      "step": 25270
    },
    {
      "epoch": 0.773964424578269,
      "grad_norm": 2.066824197769165,
      "learning_rate": 1.4840441274020554e-05,
      "loss": 0.0426,
      "step": 25280
    },
    {
      "epoch": 0.7742705813917888,
      "grad_norm": 0.022406067699193954,
      "learning_rate": 1.483840022859709e-05,
      "loss": 0.0014,
      "step": 25290
    },
    {
      "epoch": 0.7745767382053088,
      "grad_norm": 0.015952840447425842,
      "learning_rate": 1.4836359183173623e-05,
      "loss": 0.001,
      "step": 25300
    },
    {
      "epoch": 0.7748828950188287,
      "grad_norm": 0.01404048316180706,
      "learning_rate": 1.4834318137750157e-05,
      "loss": 0.0012,
      "step": 25310
    },
    {
      "epoch": 0.7751890518323485,
      "grad_norm": 0.012334785424172878,
      "learning_rate": 1.483227709232669e-05,
      "loss": 0.0342,
      "step": 25320
    },
    {
      "epoch": 0.7754952086458684,
      "grad_norm": 0.005312916357070208,
      "learning_rate": 1.4830236046903226e-05,
      "loss": 0.0008,
      "step": 25330
    },
    {
      "epoch": 0.7758013654593883,
      "grad_norm": 0.030356500297784805,
      "learning_rate": 1.482819500147976e-05,
      "loss": 0.0013,
      "step": 25340
    },
    {
      "epoch": 0.7761075222729081,
      "grad_norm": 0.041340172290802,
      "learning_rate": 1.4826153956056293e-05,
      "loss": 0.0008,
      "step": 25350
    },
    {
      "epoch": 0.7764136790864281,
      "grad_norm": 1.8800283670425415,
      "learning_rate": 1.4824112910632826e-05,
      "loss": 0.0765,
      "step": 25360
    },
    {
      "epoch": 0.776719835899948,
      "grad_norm": 1.8924821615219116,
      "learning_rate": 1.4822071865209362e-05,
      "loss": 0.0729,
      "step": 25370
    },
    {
      "epoch": 0.7770259927134678,
      "grad_norm": 0.06172897666692734,
      "learning_rate": 1.4820030819785895e-05,
      "loss": 0.0017,
      "step": 25380
    },
    {
      "epoch": 0.7773321495269877,
      "grad_norm": 0.16439029574394226,
      "learning_rate": 1.4817989774362429e-05,
      "loss": 0.0019,
      "step": 25390
    },
    {
      "epoch": 0.7776383063405076,
      "grad_norm": 0.028232427313923836,
      "learning_rate": 1.4815948728938964e-05,
      "loss": 0.0024,
      "step": 25400
    },
    {
      "epoch": 0.7779444631540275,
      "grad_norm": 0.033155523240566254,
      "learning_rate": 1.4813907683515498e-05,
      "loss": 0.0076,
      "step": 25410
    },
    {
      "epoch": 0.7782506199675474,
      "grad_norm": 0.1050749197602272,
      "learning_rate": 1.4811866638092032e-05,
      "loss": 0.0416,
      "step": 25420
    },
    {
      "epoch": 0.7785567767810673,
      "grad_norm": 0.032528314739465714,
      "learning_rate": 1.4809825592668565e-05,
      "loss": 0.0016,
      "step": 25430
    },
    {
      "epoch": 0.7788629335945871,
      "grad_norm": 0.0030696766916662455,
      "learning_rate": 1.48077845472451e-05,
      "loss": 0.0026,
      "step": 25440
    },
    {
      "epoch": 0.779169090408107,
      "grad_norm": 0.06519278138875961,
      "learning_rate": 1.4805743501821634e-05,
      "loss": 0.0015,
      "step": 25450
    },
    {
      "epoch": 0.7794752472216269,
      "grad_norm": 0.05698283016681671,
      "learning_rate": 1.4803702456398168e-05,
      "loss": 0.0012,
      "step": 25460
    },
    {
      "epoch": 0.7797814040351468,
      "grad_norm": 0.029278095811605453,
      "learning_rate": 1.4801661410974702e-05,
      "loss": 0.0012,
      "step": 25470
    },
    {
      "epoch": 0.7800875608486667,
      "grad_norm": 0.042944081127643585,
      "learning_rate": 1.4799620365551237e-05,
      "loss": 0.0619,
      "step": 25480
    },
    {
      "epoch": 0.7803937176621866,
      "grad_norm": 1.8018609285354614,
      "learning_rate": 1.479757932012777e-05,
      "loss": 0.0347,
      "step": 25490
    },
    {
      "epoch": 0.7806998744757064,
      "grad_norm": 0.02871306613087654,
      "learning_rate": 1.4795538274704304e-05,
      "loss": 0.0026,
      "step": 25500
    },
    {
      "epoch": 0.7810060312892263,
      "grad_norm": 0.02387242391705513,
      "learning_rate": 1.479349722928084e-05,
      "loss": 0.0589,
      "step": 25510
    },
    {
      "epoch": 0.7813121881027463,
      "grad_norm": 0.0836525559425354,
      "learning_rate": 1.4791456183857373e-05,
      "loss": 0.0301,
      "step": 25520
    },
    {
      "epoch": 0.7816183449162661,
      "grad_norm": 0.1438843458890915,
      "learning_rate": 1.4789415138433907e-05,
      "loss": 0.0024,
      "step": 25530
    },
    {
      "epoch": 0.781924501729786,
      "grad_norm": 1.7186561822891235,
      "learning_rate": 1.478737409301044e-05,
      "loss": 0.0338,
      "step": 25540
    },
    {
      "epoch": 0.7822306585433059,
      "grad_norm": 0.07697665691375732,
      "learning_rate": 1.4785333047586976e-05,
      "loss": 0.0022,
      "step": 25550
    },
    {
      "epoch": 0.7825368153568257,
      "grad_norm": 0.02447422593832016,
      "learning_rate": 1.478329200216351e-05,
      "loss": 0.0017,
      "step": 25560
    },
    {
      "epoch": 0.7828429721703456,
      "grad_norm": 0.03270666301250458,
      "learning_rate": 1.4781250956740043e-05,
      "loss": 0.002,
      "step": 25570
    },
    {
      "epoch": 0.7831491289838656,
      "grad_norm": 0.03613256290555,
      "learning_rate": 1.4779209911316577e-05,
      "loss": 0.0272,
      "step": 25580
    },
    {
      "epoch": 0.7834552857973854,
      "grad_norm": 0.06274711340665817,
      "learning_rate": 1.4777168865893112e-05,
      "loss": 0.002,
      "step": 25590
    },
    {
      "epoch": 0.7837614426109053,
      "grad_norm": 0.014291915111243725,
      "learning_rate": 1.4775127820469646e-05,
      "loss": 0.0018,
      "step": 25600
    },
    {
      "epoch": 0.7840675994244252,
      "grad_norm": 0.06338146328926086,
      "learning_rate": 1.477308677504618e-05,
      "loss": 0.0017,
      "step": 25610
    },
    {
      "epoch": 0.784373756237945,
      "grad_norm": 0.00484418636187911,
      "learning_rate": 1.4771045729622715e-05,
      "loss": 0.0009,
      "step": 25620
    },
    {
      "epoch": 0.784679913051465,
      "grad_norm": 0.009160700254142284,
      "learning_rate": 1.4769004684199248e-05,
      "loss": 0.0026,
      "step": 25630
    },
    {
      "epoch": 0.7849860698649849,
      "grad_norm": 0.01111324317753315,
      "learning_rate": 1.4766963638775782e-05,
      "loss": 0.0348,
      "step": 25640
    },
    {
      "epoch": 0.7852922266785047,
      "grad_norm": 0.039699651300907135,
      "learning_rate": 1.4764922593352316e-05,
      "loss": 0.0012,
      "step": 25650
    },
    {
      "epoch": 0.7855983834920246,
      "grad_norm": 0.057103294879198074,
      "learning_rate": 1.4762881547928851e-05,
      "loss": 0.001,
      "step": 25660
    },
    {
      "epoch": 0.7859045403055445,
      "grad_norm": 0.027486389502882957,
      "learning_rate": 1.4760840502505385e-05,
      "loss": 0.0283,
      "step": 25670
    },
    {
      "epoch": 0.7862106971190644,
      "grad_norm": 0.03838050737977028,
      "learning_rate": 1.4758799457081918e-05,
      "loss": 0.0014,
      "step": 25680
    },
    {
      "epoch": 0.7865168539325843,
      "grad_norm": 0.028336577117443085,
      "learning_rate": 1.4756758411658452e-05,
      "loss": 0.0449,
      "step": 25690
    },
    {
      "epoch": 0.7868230107461042,
      "grad_norm": 0.09943809360265732,
      "learning_rate": 1.4754717366234987e-05,
      "loss": 0.0014,
      "step": 25700
    },
    {
      "epoch": 0.787129167559624,
      "grad_norm": 0.04568430408835411,
      "learning_rate": 1.4752676320811521e-05,
      "loss": 0.0012,
      "step": 25710
    },
    {
      "epoch": 0.7874353243731439,
      "grad_norm": 0.023130347952246666,
      "learning_rate": 1.4750635275388055e-05,
      "loss": 0.044,
      "step": 25720
    },
    {
      "epoch": 0.7877414811866638,
      "grad_norm": 0.05748254060745239,
      "learning_rate": 1.474859422996459e-05,
      "loss": 0.036,
      "step": 25730
    },
    {
      "epoch": 0.7880476380001837,
      "grad_norm": 0.004446953535079956,
      "learning_rate": 1.4746553184541124e-05,
      "loss": 0.0256,
      "step": 25740
    },
    {
      "epoch": 0.7883537948137036,
      "grad_norm": 0.05244055017828941,
      "learning_rate": 1.4744512139117657e-05,
      "loss": 0.031,
      "step": 25750
    },
    {
      "epoch": 0.7886599516272235,
      "grad_norm": 0.025867152959108353,
      "learning_rate": 1.4742471093694191e-05,
      "loss": 0.0059,
      "step": 25760
    },
    {
      "epoch": 0.7889661084407433,
      "grad_norm": 0.035761889070272446,
      "learning_rate": 1.4740430048270726e-05,
      "loss": 0.0017,
      "step": 25770
    },
    {
      "epoch": 0.7892722652542632,
      "grad_norm": 0.05789479240775108,
      "learning_rate": 1.473838900284726e-05,
      "loss": 0.0302,
      "step": 25780
    },
    {
      "epoch": 0.7895784220677832,
      "grad_norm": 0.052553966641426086,
      "learning_rate": 1.4736347957423794e-05,
      "loss": 0.0013,
      "step": 25790
    },
    {
      "epoch": 0.789884578881303,
      "grad_norm": 0.04081326350569725,
      "learning_rate": 1.4734306912000327e-05,
      "loss": 0.0018,
      "step": 25800
    },
    {
      "epoch": 0.7901907356948229,
      "grad_norm": 0.03148159384727478,
      "learning_rate": 1.4732265866576862e-05,
      "loss": 0.0012,
      "step": 25810
    },
    {
      "epoch": 0.7904968925083428,
      "grad_norm": 0.060873646289110184,
      "learning_rate": 1.4730224821153396e-05,
      "loss": 0.0011,
      "step": 25820
    },
    {
      "epoch": 0.7908030493218626,
      "grad_norm": 0.016439126804471016,
      "learning_rate": 1.472818377572993e-05,
      "loss": 0.002,
      "step": 25830
    },
    {
      "epoch": 0.7911092061353825,
      "grad_norm": 0.010630890727043152,
      "learning_rate": 1.4726142730306465e-05,
      "loss": 0.001,
      "step": 25840
    },
    {
      "epoch": 0.7914153629489025,
      "grad_norm": 0.03409386798739433,
      "learning_rate": 1.4724101684882999e-05,
      "loss": 0.0007,
      "step": 25850
    },
    {
      "epoch": 0.7917215197624223,
      "grad_norm": 0.0687602087855339,
      "learning_rate": 1.4722060639459532e-05,
      "loss": 0.0402,
      "step": 25860
    },
    {
      "epoch": 0.7920276765759422,
      "grad_norm": 0.036357585340738297,
      "learning_rate": 1.4720019594036066e-05,
      "loss": 0.0012,
      "step": 25870
    },
    {
      "epoch": 0.7923338333894621,
      "grad_norm": 0.0265944954007864,
      "learning_rate": 1.4717978548612601e-05,
      "loss": 0.0423,
      "step": 25880
    },
    {
      "epoch": 0.7926399902029819,
      "grad_norm": 0.00787280686199665,
      "learning_rate": 1.4715937503189135e-05,
      "loss": 0.0013,
      "step": 25890
    },
    {
      "epoch": 0.7929461470165019,
      "grad_norm": 0.02077990025281906,
      "learning_rate": 1.4713896457765669e-05,
      "loss": 0.0008,
      "step": 25900
    },
    {
      "epoch": 0.7932523038300218,
      "grad_norm": 1.7154247760772705,
      "learning_rate": 1.4711855412342202e-05,
      "loss": 0.0322,
      "step": 25910
    },
    {
      "epoch": 0.7935584606435416,
      "grad_norm": 1.5455470085144043,
      "learning_rate": 1.4709814366918738e-05,
      "loss": 0.0529,
      "step": 25920
    },
    {
      "epoch": 0.7938646174570615,
      "grad_norm": 0.053272876888513565,
      "learning_rate": 1.4707773321495271e-05,
      "loss": 0.0319,
      "step": 25930
    },
    {
      "epoch": 0.7941707742705814,
      "grad_norm": 0.045320771634578705,
      "learning_rate": 1.4705732276071805e-05,
      "loss": 0.0178,
      "step": 25940
    },
    {
      "epoch": 0.7944769310841012,
      "grad_norm": 0.02789006382226944,
      "learning_rate": 1.470369123064834e-05,
      "loss": 0.003,
      "step": 25950
    },
    {
      "epoch": 0.7947830878976212,
      "grad_norm": 0.04041777551174164,
      "learning_rate": 1.4701650185224874e-05,
      "loss": 0.004,
      "step": 25960
    },
    {
      "epoch": 0.7950892447111411,
      "grad_norm": 0.039851415902376175,
      "learning_rate": 1.4699609139801408e-05,
      "loss": 0.0011,
      "step": 25970
    },
    {
      "epoch": 0.7953954015246609,
      "grad_norm": 0.04792667180299759,
      "learning_rate": 1.4697568094377941e-05,
      "loss": 0.003,
      "step": 25980
    },
    {
      "epoch": 0.7957015583381808,
      "grad_norm": 0.01751204952597618,
      "learning_rate": 1.4695527048954477e-05,
      "loss": 0.0398,
      "step": 25990
    },
    {
      "epoch": 0.7960077151517007,
      "grad_norm": 0.045893896371126175,
      "learning_rate": 1.469348600353101e-05,
      "loss": 0.0015,
      "step": 26000
    },
    {
      "epoch": 0.7963138719652206,
      "grad_norm": 0.02171909064054489,
      "learning_rate": 1.4691444958107544e-05,
      "loss": 0.0325,
      "step": 26010
    },
    {
      "epoch": 0.7966200287787405,
      "grad_norm": 0.039658330380916595,
      "learning_rate": 1.4689403912684077e-05,
      "loss": 0.004,
      "step": 26020
    },
    {
      "epoch": 0.7969261855922604,
      "grad_norm": 0.017026765272021294,
      "learning_rate": 1.4687362867260613e-05,
      "loss": 0.0014,
      "step": 26030
    },
    {
      "epoch": 0.7972323424057802,
      "grad_norm": 1.7122868299484253,
      "learning_rate": 1.4685321821837146e-05,
      "loss": 0.0676,
      "step": 26040
    },
    {
      "epoch": 0.7975384992193001,
      "grad_norm": 0.06710344552993774,
      "learning_rate": 1.468328077641368e-05,
      "loss": 0.0011,
      "step": 26050
    },
    {
      "epoch": 0.7978446560328201,
      "grad_norm": 0.02390255592763424,
      "learning_rate": 1.4681239730990215e-05,
      "loss": 0.0023,
      "step": 26060
    },
    {
      "epoch": 0.7981508128463399,
      "grad_norm": 1.8454406261444092,
      "learning_rate": 1.4679198685566749e-05,
      "loss": 0.0364,
      "step": 26070
    },
    {
      "epoch": 0.7984569696598598,
      "grad_norm": 0.04251391068100929,
      "learning_rate": 1.4677157640143283e-05,
      "loss": 0.0017,
      "step": 26080
    },
    {
      "epoch": 0.7987631264733797,
      "grad_norm": 0.02750322036445141,
      "learning_rate": 1.4675116594719816e-05,
      "loss": 0.0053,
      "step": 26090
    },
    {
      "epoch": 0.7990692832868995,
      "grad_norm": 0.01810428313910961,
      "learning_rate": 1.4673075549296352e-05,
      "loss": 0.0015,
      "step": 26100
    },
    {
      "epoch": 0.7993754401004194,
      "grad_norm": 0.03211258724331856,
      "learning_rate": 1.4671034503872885e-05,
      "loss": 0.0011,
      "step": 26110
    },
    {
      "epoch": 0.7996815969139394,
      "grad_norm": 0.015102174133062363,
      "learning_rate": 1.4668993458449419e-05,
      "loss": 0.0009,
      "step": 26120
    },
    {
      "epoch": 0.7999877537274592,
      "grad_norm": 0.02132267877459526,
      "learning_rate": 1.4666952413025953e-05,
      "loss": 0.0011,
      "step": 26130
    },
    {
      "epoch": 0.8002939105409791,
      "grad_norm": 0.07227738946676254,
      "learning_rate": 1.4664911367602488e-05,
      "loss": 0.0011,
      "step": 26140
    },
    {
      "epoch": 0.800600067354499,
      "grad_norm": 0.019935788586735725,
      "learning_rate": 1.4662870322179022e-05,
      "loss": 0.001,
      "step": 26150
    },
    {
      "epoch": 0.8009062241680188,
      "grad_norm": 0.023477891460061073,
      "learning_rate": 1.4660829276755555e-05,
      "loss": 0.0007,
      "step": 26160
    },
    {
      "epoch": 0.8012123809815388,
      "grad_norm": 0.008873062208294868,
      "learning_rate": 1.4658788231332089e-05,
      "loss": 0.0343,
      "step": 26170
    },
    {
      "epoch": 0.8015185377950587,
      "grad_norm": 0.03960057348012924,
      "learning_rate": 1.4656747185908624e-05,
      "loss": 0.0015,
      "step": 26180
    },
    {
      "epoch": 0.8018246946085785,
      "grad_norm": 1.6335619688034058,
      "learning_rate": 1.4654706140485158e-05,
      "loss": 0.0038,
      "step": 26190
    },
    {
      "epoch": 0.8021308514220984,
      "grad_norm": 0.027488620951771736,
      "learning_rate": 1.4652665095061692e-05,
      "loss": 0.0012,
      "step": 26200
    },
    {
      "epoch": 0.8024370082356183,
      "grad_norm": 0.0383538119494915,
      "learning_rate": 1.4650624049638227e-05,
      "loss": 0.001,
      "step": 26210
    },
    {
      "epoch": 0.8027431650491381,
      "grad_norm": 0.013182468712329865,
      "learning_rate": 1.464858300421476e-05,
      "loss": 0.0742,
      "step": 26220
    },
    {
      "epoch": 0.8030493218626581,
      "grad_norm": 0.018062587827444077,
      "learning_rate": 1.4646541958791294e-05,
      "loss": 0.0012,
      "step": 26230
    },
    {
      "epoch": 0.803355478676178,
      "grad_norm": 0.01598188653588295,
      "learning_rate": 1.4644500913367828e-05,
      "loss": 0.001,
      "step": 26240
    },
    {
      "epoch": 0.8036616354896978,
      "grad_norm": 0.03139881044626236,
      "learning_rate": 1.4642459867944363e-05,
      "loss": 0.0319,
      "step": 26250
    },
    {
      "epoch": 0.8039677923032177,
      "grad_norm": 0.026374436914920807,
      "learning_rate": 1.4640418822520897e-05,
      "loss": 0.0009,
      "step": 26260
    },
    {
      "epoch": 0.8042739491167376,
      "grad_norm": 0.6215963959693909,
      "learning_rate": 1.463837777709743e-05,
      "loss": 0.0017,
      "step": 26270
    },
    {
      "epoch": 0.8045801059302575,
      "grad_norm": 0.04342545196413994,
      "learning_rate": 1.4636336731673964e-05,
      "loss": 0.0365,
      "step": 26280
    },
    {
      "epoch": 0.8048862627437774,
      "grad_norm": 0.023782437667250633,
      "learning_rate": 1.46342956862505e-05,
      "loss": 0.0135,
      "step": 26290
    },
    {
      "epoch": 0.8051924195572973,
      "grad_norm": 0.007637322414666414,
      "learning_rate": 1.4632254640827033e-05,
      "loss": 0.0015,
      "step": 26300
    },
    {
      "epoch": 0.8054985763708171,
      "grad_norm": 0.04692027345299721,
      "learning_rate": 1.4630213595403567e-05,
      "loss": 0.0013,
      "step": 26310
    },
    {
      "epoch": 0.805804733184337,
      "grad_norm": 0.05009616166353226,
      "learning_rate": 1.4628172549980102e-05,
      "loss": 0.0372,
      "step": 26320
    },
    {
      "epoch": 0.8061108899978568,
      "grad_norm": 0.06455099582672119,
      "learning_rate": 1.4626131504556636e-05,
      "loss": 0.0294,
      "step": 26330
    },
    {
      "epoch": 0.8064170468113768,
      "grad_norm": 0.022419828921556473,
      "learning_rate": 1.462409045913317e-05,
      "loss": 0.0013,
      "step": 26340
    },
    {
      "epoch": 0.8067232036248967,
      "grad_norm": 0.03447224199771881,
      "learning_rate": 1.4622049413709703e-05,
      "loss": 0.0026,
      "step": 26350
    },
    {
      "epoch": 0.8070293604384166,
      "grad_norm": 0.016944393515586853,
      "learning_rate": 1.4620008368286238e-05,
      "loss": 0.0011,
      "step": 26360
    },
    {
      "epoch": 0.8073355172519364,
      "grad_norm": 0.0011304834624752402,
      "learning_rate": 1.4617967322862772e-05,
      "loss": 0.001,
      "step": 26370
    },
    {
      "epoch": 0.8076416740654563,
      "grad_norm": 0.024913785979151726,
      "learning_rate": 1.4615926277439306e-05,
      "loss": 0.0036,
      "step": 26380
    },
    {
      "epoch": 0.8079478308789763,
      "grad_norm": 1.925344467163086,
      "learning_rate": 1.461388523201584e-05,
      "loss": 0.0395,
      "step": 26390
    },
    {
      "epoch": 0.8082539876924961,
      "grad_norm": 0.1681184023618698,
      "learning_rate": 1.4611844186592375e-05,
      "loss": 0.0013,
      "step": 26400
    },
    {
      "epoch": 0.808560144506016,
      "grad_norm": 0.023354969918727875,
      "learning_rate": 1.4609803141168908e-05,
      "loss": 0.0008,
      "step": 26410
    },
    {
      "epoch": 0.8088663013195359,
      "grad_norm": 0.037334371358156204,
      "learning_rate": 1.4607762095745442e-05,
      "loss": 0.001,
      "step": 26420
    },
    {
      "epoch": 0.8091724581330557,
      "grad_norm": 0.029447020962834358,
      "learning_rate": 1.4605721050321977e-05,
      "loss": 0.001,
      "step": 26430
    },
    {
      "epoch": 0.8094786149465756,
      "grad_norm": 0.02137524075806141,
      "learning_rate": 1.4603680004898511e-05,
      "loss": 0.0007,
      "step": 26440
    },
    {
      "epoch": 0.8097847717600956,
      "grad_norm": 0.017656655982136726,
      "learning_rate": 1.4601638959475045e-05,
      "loss": 0.0011,
      "step": 26450
    },
    {
      "epoch": 0.8100909285736154,
      "grad_norm": 0.014638158492743969,
      "learning_rate": 1.4599597914051578e-05,
      "loss": 0.0044,
      "step": 26460
    },
    {
      "epoch": 0.8103970853871353,
      "grad_norm": 0.021061429753899574,
      "learning_rate": 1.4597556868628114e-05,
      "loss": 0.073,
      "step": 26470
    },
    {
      "epoch": 0.8107032422006551,
      "grad_norm": 0.02191920019686222,
      "learning_rate": 1.4595515823204647e-05,
      "loss": 0.001,
      "step": 26480
    },
    {
      "epoch": 0.811009399014175,
      "grad_norm": 0.03456394746899605,
      "learning_rate": 1.459347477778118e-05,
      "loss": 0.0022,
      "step": 26490
    },
    {
      "epoch": 0.811315555827695,
      "grad_norm": 0.039414484053850174,
      "learning_rate": 1.4591433732357714e-05,
      "loss": 0.0326,
      "step": 26500
    },
    {
      "epoch": 0.8116217126412149,
      "grad_norm": 0.042949311435222626,
      "learning_rate": 1.458939268693425e-05,
      "loss": 0.0323,
      "step": 26510
    },
    {
      "epoch": 0.8119278694547347,
      "grad_norm": 0.019952131435275078,
      "learning_rate": 1.4587351641510783e-05,
      "loss": 0.0014,
      "step": 26520
    },
    {
      "epoch": 0.8122340262682546,
      "grad_norm": 0.0011834377655759454,
      "learning_rate": 1.4585310596087317e-05,
      "loss": 0.0012,
      "step": 26530
    },
    {
      "epoch": 0.8125401830817744,
      "grad_norm": 0.07330551743507385,
      "learning_rate": 1.4583269550663852e-05,
      "loss": 0.0009,
      "step": 26540
    },
    {
      "epoch": 0.8128463398952944,
      "grad_norm": 0.01961347460746765,
      "learning_rate": 1.4581228505240386e-05,
      "loss": 0.0014,
      "step": 26550
    },
    {
      "epoch": 0.8131524967088143,
      "grad_norm": 0.008071037009358406,
      "learning_rate": 1.457918745981692e-05,
      "loss": 0.001,
      "step": 26560
    },
    {
      "epoch": 0.8134586535223342,
      "grad_norm": 0.021637991070747375,
      "learning_rate": 1.4577146414393453e-05,
      "loss": 0.0338,
      "step": 26570
    },
    {
      "epoch": 0.813764810335854,
      "grad_norm": 0.04163218289613724,
      "learning_rate": 1.4575105368969989e-05,
      "loss": 0.0011,
      "step": 26580
    },
    {
      "epoch": 0.8140709671493739,
      "grad_norm": 0.011893551796674728,
      "learning_rate": 1.4573064323546522e-05,
      "loss": 0.0008,
      "step": 26590
    },
    {
      "epoch": 0.8143771239628937,
      "grad_norm": 0.0452423058450222,
      "learning_rate": 1.4571023278123056e-05,
      "loss": 0.0009,
      "step": 26600
    },
    {
      "epoch": 0.8146832807764137,
      "grad_norm": 0.01940959505736828,
      "learning_rate": 1.456898223269959e-05,
      "loss": 0.0009,
      "step": 26610
    },
    {
      "epoch": 0.8149894375899336,
      "grad_norm": 0.02541026845574379,
      "learning_rate": 1.4566941187276125e-05,
      "loss": 0.0014,
      "step": 26620
    },
    {
      "epoch": 0.8152955944034534,
      "grad_norm": 0.013473372906446457,
      "learning_rate": 1.4564900141852659e-05,
      "loss": 0.0197,
      "step": 26630
    },
    {
      "epoch": 0.8156017512169733,
      "grad_norm": 0.0026830045972019434,
      "learning_rate": 1.4562859096429192e-05,
      "loss": 0.0405,
      "step": 26640
    },
    {
      "epoch": 0.8159079080304932,
      "grad_norm": 0.011507906951010227,
      "learning_rate": 1.4560818051005728e-05,
      "loss": 0.0008,
      "step": 26650
    },
    {
      "epoch": 0.8162140648440132,
      "grad_norm": 0.5675345659255981,
      "learning_rate": 1.4558777005582261e-05,
      "loss": 0.0483,
      "step": 26660
    },
    {
      "epoch": 0.816520221657533,
      "grad_norm": 0.02447371557354927,
      "learning_rate": 1.4556735960158795e-05,
      "loss": 0.0007,
      "step": 26670
    },
    {
      "epoch": 0.8168263784710529,
      "grad_norm": 0.014882931485772133,
      "learning_rate": 1.4554694914735329e-05,
      "loss": 0.0008,
      "step": 26680
    },
    {
      "epoch": 0.8171325352845727,
      "grad_norm": 0.013704085722565651,
      "learning_rate": 1.4552653869311864e-05,
      "loss": 0.0004,
      "step": 26690
    },
    {
      "epoch": 0.8174386920980926,
      "grad_norm": 0.012224537320435047,
      "learning_rate": 1.4550612823888397e-05,
      "loss": 0.0008,
      "step": 26700
    },
    {
      "epoch": 0.8177448489116125,
      "grad_norm": 0.01774287410080433,
      "learning_rate": 1.4548571778464931e-05,
      "loss": 0.0703,
      "step": 26710
    },
    {
      "epoch": 0.8180510057251325,
      "grad_norm": 0.00946167204529047,
      "learning_rate": 1.4546530733041465e-05,
      "loss": 0.0007,
      "step": 26720
    },
    {
      "epoch": 0.8183571625386523,
      "grad_norm": 0.055383116006851196,
      "learning_rate": 1.4544489687618e-05,
      "loss": 0.0009,
      "step": 26730
    },
    {
      "epoch": 0.8186633193521722,
      "grad_norm": 0.018493594601750374,
      "learning_rate": 1.4542448642194534e-05,
      "loss": 0.0011,
      "step": 26740
    },
    {
      "epoch": 0.818969476165692,
      "grad_norm": 0.022845759987831116,
      "learning_rate": 1.4540407596771067e-05,
      "loss": 0.0006,
      "step": 26750
    },
    {
      "epoch": 0.8192756329792119,
      "grad_norm": 0.03262537717819214,
      "learning_rate": 1.4538366551347603e-05,
      "loss": 0.0296,
      "step": 26760
    },
    {
      "epoch": 0.8195817897927319,
      "grad_norm": 0.015648379921913147,
      "learning_rate": 1.4536325505924136e-05,
      "loss": 0.0005,
      "step": 26770
    },
    {
      "epoch": 0.8198879466062517,
      "grad_norm": 0.018991131335496902,
      "learning_rate": 1.453428446050067e-05,
      "loss": 0.0008,
      "step": 26780
    },
    {
      "epoch": 0.8201941034197716,
      "grad_norm": 0.011402043513953686,
      "learning_rate": 1.4532243415077204e-05,
      "loss": 0.0273,
      "step": 26790
    },
    {
      "epoch": 0.8205002602332915,
      "grad_norm": 0.029707783833146095,
      "learning_rate": 1.4530202369653739e-05,
      "loss": 0.0457,
      "step": 26800
    },
    {
      "epoch": 0.8208064170468113,
      "grad_norm": 0.02382826805114746,
      "learning_rate": 1.4528161324230273e-05,
      "loss": 0.0009,
      "step": 26810
    },
    {
      "epoch": 0.8211125738603312,
      "grad_norm": 0.02732880786061287,
      "learning_rate": 1.4526120278806806e-05,
      "loss": 0.0011,
      "step": 26820
    },
    {
      "epoch": 0.8214187306738512,
      "grad_norm": 0.017185481265187263,
      "learning_rate": 1.452407923338334e-05,
      "loss": 0.0015,
      "step": 26830
    },
    {
      "epoch": 0.821724887487371,
      "grad_norm": 0.02919820509850979,
      "learning_rate": 1.4522038187959875e-05,
      "loss": 0.0008,
      "step": 26840
    },
    {
      "epoch": 0.8220310443008909,
      "grad_norm": 0.02592378295958042,
      "learning_rate": 1.4519997142536409e-05,
      "loss": 0.0014,
      "step": 26850
    },
    {
      "epoch": 0.8223372011144108,
      "grad_norm": 0.014496362768113613,
      "learning_rate": 1.4517956097112943e-05,
      "loss": 0.0309,
      "step": 26860
    },
    {
      "epoch": 0.8226433579279306,
      "grad_norm": 0.04014335572719574,
      "learning_rate": 1.4515915051689478e-05,
      "loss": 0.001,
      "step": 26870
    },
    {
      "epoch": 0.8229495147414506,
      "grad_norm": 0.007182672154158354,
      "learning_rate": 1.4513874006266012e-05,
      "loss": 0.0011,
      "step": 26880
    },
    {
      "epoch": 0.8232556715549705,
      "grad_norm": 0.023326540365815163,
      "learning_rate": 1.4511832960842545e-05,
      "loss": 0.0258,
      "step": 26890
    },
    {
      "epoch": 0.8235618283684903,
      "grad_norm": 0.013924838043749332,
      "learning_rate": 1.4509791915419079e-05,
      "loss": 0.0359,
      "step": 26900
    },
    {
      "epoch": 0.8238679851820102,
      "grad_norm": 0.03671234846115112,
      "learning_rate": 1.4507750869995614e-05,
      "loss": 0.0254,
      "step": 26910
    },
    {
      "epoch": 0.8241741419955301,
      "grad_norm": 0.031216081231832504,
      "learning_rate": 1.4505709824572148e-05,
      "loss": 0.0011,
      "step": 26920
    },
    {
      "epoch": 0.82448029880905,
      "grad_norm": 0.02194468304514885,
      "learning_rate": 1.4503668779148681e-05,
      "loss": 0.0014,
      "step": 26930
    },
    {
      "epoch": 0.8247864556225699,
      "grad_norm": 0.02916444092988968,
      "learning_rate": 1.4501627733725213e-05,
      "loss": 0.0011,
      "step": 26940
    },
    {
      "epoch": 0.8250926124360898,
      "grad_norm": 0.02987721562385559,
      "learning_rate": 1.449958668830175e-05,
      "loss": 0.0139,
      "step": 26950
    },
    {
      "epoch": 0.8253987692496096,
      "grad_norm": 0.03467504307627678,
      "learning_rate": 1.4497545642878284e-05,
      "loss": 0.0352,
      "step": 26960
    },
    {
      "epoch": 0.8257049260631295,
      "grad_norm": 0.02453789673745632,
      "learning_rate": 1.4495504597454818e-05,
      "loss": 0.0011,
      "step": 26970
    },
    {
      "epoch": 0.8260110828766494,
      "grad_norm": 0.024603044614195824,
      "learning_rate": 1.4493463552031353e-05,
      "loss": 0.0008,
      "step": 26980
    },
    {
      "epoch": 0.8263172396901693,
      "grad_norm": 0.000514378072693944,
      "learning_rate": 1.4491422506607887e-05,
      "loss": 0.0016,
      "step": 26990
    },
    {
      "epoch": 0.8266233965036892,
      "grad_norm": 1.6262489557266235,
      "learning_rate": 1.448938146118442e-05,
      "loss": 0.0036,
      "step": 27000
    },
    {
      "epoch": 0.8269295533172091,
      "grad_norm": 0.013258191756904125,
      "learning_rate": 1.4487340415760954e-05,
      "loss": 0.0006,
      "step": 27010
    },
    {
      "epoch": 0.8272357101307289,
      "grad_norm": 1.867578387260437,
      "learning_rate": 1.448529937033749e-05,
      "loss": 0.0364,
      "step": 27020
    },
    {
      "epoch": 0.8275418669442488,
      "grad_norm": 0.010885649360716343,
      "learning_rate": 1.4483258324914023e-05,
      "loss": 0.0359,
      "step": 27030
    },
    {
      "epoch": 0.8278480237577688,
      "grad_norm": 0.02805299684405327,
      "learning_rate": 1.4481217279490557e-05,
      "loss": 0.0017,
      "step": 27040
    },
    {
      "epoch": 0.8281541805712886,
      "grad_norm": 0.0383327454328537,
      "learning_rate": 1.4479176234067089e-05,
      "loss": 0.0011,
      "step": 27050
    },
    {
      "epoch": 0.8284603373848085,
      "grad_norm": 0.0025555207394063473,
      "learning_rate": 1.4477135188643626e-05,
      "loss": 0.0015,
      "step": 27060
    },
    {
      "epoch": 0.8287664941983284,
      "grad_norm": 0.010183574631810188,
      "learning_rate": 1.447509414322016e-05,
      "loss": 0.0008,
      "step": 27070
    },
    {
      "epoch": 0.8290726510118482,
      "grad_norm": 0.003851682646200061,
      "learning_rate": 1.4473053097796693e-05,
      "loss": 0.0398,
      "step": 27080
    },
    {
      "epoch": 0.8293788078253681,
      "grad_norm": 0.02688775397837162,
      "learning_rate": 1.4471012052373228e-05,
      "loss": 0.001,
      "step": 27090
    },
    {
      "epoch": 0.8296849646388881,
      "grad_norm": 0.015663113445043564,
      "learning_rate": 1.4468971006949762e-05,
      "loss": 0.0008,
      "step": 27100
    },
    {
      "epoch": 0.8299911214524079,
      "grad_norm": 0.023782510310411453,
      "learning_rate": 1.4466929961526296e-05,
      "loss": 0.0006,
      "step": 27110
    },
    {
      "epoch": 0.8302972782659278,
      "grad_norm": 0.01720830611884594,
      "learning_rate": 1.4464888916102827e-05,
      "loss": 0.0566,
      "step": 27120
    },
    {
      "epoch": 0.8306034350794477,
      "grad_norm": 1.740703821182251,
      "learning_rate": 1.4462847870679365e-05,
      "loss": 0.0041,
      "step": 27130
    },
    {
      "epoch": 0.8309095918929675,
      "grad_norm": 0.02951619401574135,
      "learning_rate": 1.4460806825255898e-05,
      "loss": 0.0011,
      "step": 27140
    },
    {
      "epoch": 0.8312157487064875,
      "grad_norm": 0.02204325795173645,
      "learning_rate": 1.4458765779832432e-05,
      "loss": 0.0361,
      "step": 27150
    },
    {
      "epoch": 0.8315219055200074,
      "grad_norm": 0.074535071849823,
      "learning_rate": 1.4456724734408964e-05,
      "loss": 0.0087,
      "step": 27160
    },
    {
      "epoch": 0.8318280623335272,
      "grad_norm": 0.036812879145145416,
      "learning_rate": 1.44546836889855e-05,
      "loss": 0.0285,
      "step": 27170
    },
    {
      "epoch": 0.8321342191470471,
      "grad_norm": 0.01034099142998457,
      "learning_rate": 1.4452642643562034e-05,
      "loss": 0.0339,
      "step": 27180
    },
    {
      "epoch": 0.832440375960567,
      "grad_norm": 1.2857401371002197,
      "learning_rate": 1.4450601598138566e-05,
      "loss": 0.0037,
      "step": 27190
    },
    {
      "epoch": 0.8327465327740868,
      "grad_norm": 0.02260034717619419,
      "learning_rate": 1.4448560552715103e-05,
      "loss": 0.0195,
      "step": 27200
    },
    {
      "epoch": 0.8330526895876068,
      "grad_norm": 0.03083236701786518,
      "learning_rate": 1.4446519507291637e-05,
      "loss": 0.001,
      "step": 27210
    },
    {
      "epoch": 0.8333588464011267,
      "grad_norm": 0.01185520552098751,
      "learning_rate": 1.444447846186817e-05,
      "loss": 0.0029,
      "step": 27220
    },
    {
      "epoch": 0.8336650032146465,
      "grad_norm": 0.008065619505941868,
      "learning_rate": 1.4442437416444703e-05,
      "loss": 0.0962,
      "step": 27230
    },
    {
      "epoch": 0.8339711600281664,
      "grad_norm": 0.03169158473610878,
      "learning_rate": 1.444039637102124e-05,
      "loss": 0.0011,
      "step": 27240
    },
    {
      "epoch": 0.8342773168416863,
      "grad_norm": 4.550971984863281,
      "learning_rate": 1.4438355325597773e-05,
      "loss": 0.0337,
      "step": 27250
    },
    {
      "epoch": 0.8345834736552062,
      "grad_norm": 0.06394846737384796,
      "learning_rate": 1.4436314280174307e-05,
      "loss": 0.0409,
      "step": 27260
    },
    {
      "epoch": 0.8348896304687261,
      "grad_norm": 0.011401791125535965,
      "learning_rate": 1.4434273234750839e-05,
      "loss": 0.0234,
      "step": 27270
    },
    {
      "epoch": 0.835195787282246,
      "grad_norm": 0.03013007901608944,
      "learning_rate": 1.4432232189327376e-05,
      "loss": 0.0227,
      "step": 27280
    },
    {
      "epoch": 0.8355019440957658,
      "grad_norm": 0.01901155523955822,
      "learning_rate": 1.443019114390391e-05,
      "loss": 0.0044,
      "step": 27290
    },
    {
      "epoch": 0.8358081009092857,
      "grad_norm": 0.05625744163990021,
      "learning_rate": 1.4428150098480442e-05,
      "loss": 0.01,
      "step": 27300
    },
    {
      "epoch": 0.8361142577228057,
      "grad_norm": 0.04723883792757988,
      "learning_rate": 1.4426109053056979e-05,
      "loss": 0.0395,
      "step": 27310
    },
    {
      "epoch": 0.8364204145363255,
      "grad_norm": 0.03606384992599487,
      "learning_rate": 1.4424068007633512e-05,
      "loss": 0.0364,
      "step": 27320
    },
    {
      "epoch": 0.8367265713498454,
      "grad_norm": 0.06082526594400406,
      "learning_rate": 1.4422026962210046e-05,
      "loss": 0.0233,
      "step": 27330
    },
    {
      "epoch": 0.8370327281633653,
      "grad_norm": 0.06147681921720505,
      "learning_rate": 1.4419985916786578e-05,
      "loss": 0.002,
      "step": 27340
    },
    {
      "epoch": 0.8373388849768851,
      "grad_norm": 0.03366963192820549,
      "learning_rate": 1.4417944871363115e-05,
      "loss": 0.0019,
      "step": 27350
    },
    {
      "epoch": 0.837645041790405,
      "grad_norm": 0.054269939661026,
      "learning_rate": 1.4415903825939649e-05,
      "loss": 0.0011,
      "step": 27360
    },
    {
      "epoch": 0.837951198603925,
      "grad_norm": 0.05114191025495529,
      "learning_rate": 1.441386278051618e-05,
      "loss": 0.0351,
      "step": 27370
    },
    {
      "epoch": 0.8382573554174448,
      "grad_norm": 0.04573563486337662,
      "learning_rate": 1.4411821735092714e-05,
      "loss": 0.0023,
      "step": 27380
    },
    {
      "epoch": 0.8385635122309647,
      "grad_norm": 0.003943232819437981,
      "learning_rate": 1.4409780689669251e-05,
      "loss": 0.0043,
      "step": 27390
    },
    {
      "epoch": 0.8388696690444846,
      "grad_norm": 0.05284811183810234,
      "learning_rate": 1.4407739644245785e-05,
      "loss": 0.0012,
      "step": 27400
    },
    {
      "epoch": 0.8391758258580044,
      "grad_norm": 0.01380491815507412,
      "learning_rate": 1.4405698598822317e-05,
      "loss": 0.0358,
      "step": 27410
    },
    {
      "epoch": 0.8394819826715244,
      "grad_norm": 0.04156328737735748,
      "learning_rate": 1.440365755339885e-05,
      "loss": 0.0013,
      "step": 27420
    },
    {
      "epoch": 0.8397881394850443,
      "grad_norm": 0.06513597816228867,
      "learning_rate": 1.4401616507975387e-05,
      "loss": 0.0013,
      "step": 27430
    },
    {
      "epoch": 0.8400942962985641,
      "grad_norm": 0.04557391256093979,
      "learning_rate": 1.439957546255192e-05,
      "loss": 0.0608,
      "step": 27440
    },
    {
      "epoch": 0.840400453112084,
      "grad_norm": 0.028991784900426865,
      "learning_rate": 1.4397534417128453e-05,
      "loss": 0.0015,
      "step": 27450
    },
    {
      "epoch": 0.8407066099256039,
      "grad_norm": 0.06398863345384598,
      "learning_rate": 1.439549337170499e-05,
      "loss": 0.0014,
      "step": 27460
    },
    {
      "epoch": 0.8410127667391237,
      "grad_norm": 0.038027845323085785,
      "learning_rate": 1.4393452326281524e-05,
      "loss": 0.001,
      "step": 27470
    },
    {
      "epoch": 0.8413189235526437,
      "grad_norm": 0.00814275722950697,
      "learning_rate": 1.4391411280858056e-05,
      "loss": 0.0011,
      "step": 27480
    },
    {
      "epoch": 0.8416250803661636,
      "grad_norm": 0.044008076190948486,
      "learning_rate": 1.438937023543459e-05,
      "loss": 0.0014,
      "step": 27490
    },
    {
      "epoch": 0.8419312371796834,
      "grad_norm": 0.010415548458695412,
      "learning_rate": 1.4387329190011126e-05,
      "loss": 0.0361,
      "step": 27500
    },
    {
      "epoch": 0.8422373939932033,
      "grad_norm": 0.07846266031265259,
      "learning_rate": 1.438528814458766e-05,
      "loss": 0.005,
      "step": 27510
    },
    {
      "epoch": 0.8425435508067232,
      "grad_norm": 0.038390591740608215,
      "learning_rate": 1.4383247099164192e-05,
      "loss": 0.0017,
      "step": 27520
    },
    {
      "epoch": 0.8428497076202431,
      "grad_norm": 0.06601545959711075,
      "learning_rate": 1.4381206053740726e-05,
      "loss": 0.0606,
      "step": 27530
    },
    {
      "epoch": 0.843155864433763,
      "grad_norm": 0.058772094547748566,
      "learning_rate": 1.4379165008317263e-05,
      "loss": 0.0018,
      "step": 27540
    },
    {
      "epoch": 0.8434620212472829,
      "grad_norm": 0.03600841388106346,
      "learning_rate": 1.4377123962893795e-05,
      "loss": 0.0009,
      "step": 27550
    },
    {
      "epoch": 0.8437681780608027,
      "grad_norm": 0.04599558562040329,
      "learning_rate": 1.4375082917470328e-05,
      "loss": 0.0015,
      "step": 27560
    },
    {
      "epoch": 0.8440743348743226,
      "grad_norm": 0.015150312334299088,
      "learning_rate": 1.4373041872046865e-05,
      "loss": 0.0014,
      "step": 27570
    },
    {
      "epoch": 0.8443804916878425,
      "grad_norm": 0.050212617963552475,
      "learning_rate": 1.4371000826623399e-05,
      "loss": 0.0044,
      "step": 27580
    },
    {
      "epoch": 0.8446866485013624,
      "grad_norm": 0.07576067000627518,
      "learning_rate": 1.436895978119993e-05,
      "loss": 0.0012,
      "step": 27590
    },
    {
      "epoch": 0.8449928053148823,
      "grad_norm": 0.013469593599438667,
      "learning_rate": 1.4366918735776464e-05,
      "loss": 0.028,
      "step": 27600
    },
    {
      "epoch": 0.8452989621284022,
      "grad_norm": 0.03483840450644493,
      "learning_rate": 1.4364877690353001e-05,
      "loss": 0.0371,
      "step": 27610
    },
    {
      "epoch": 0.845605118941922,
      "grad_norm": 0.023171883076429367,
      "learning_rate": 1.4362836644929533e-05,
      "loss": 0.001,
      "step": 27620
    },
    {
      "epoch": 0.8459112757554419,
      "grad_norm": 0.0744689479470253,
      "learning_rate": 1.4360795599506067e-05,
      "loss": 0.0013,
      "step": 27630
    },
    {
      "epoch": 0.8462174325689619,
      "grad_norm": 0.03635682910680771,
      "learning_rate": 1.43587545540826e-05,
      "loss": 0.0012,
      "step": 27640
    },
    {
      "epoch": 0.8465235893824817,
      "grad_norm": 0.02993004396557808,
      "learning_rate": 1.4356713508659138e-05,
      "loss": 0.0013,
      "step": 27650
    },
    {
      "epoch": 0.8468297461960016,
      "grad_norm": 0.02844957634806633,
      "learning_rate": 1.435467246323567e-05,
      "loss": 0.0008,
      "step": 27660
    },
    {
      "epoch": 0.8471359030095215,
      "grad_norm": 0.010932562872767448,
      "learning_rate": 1.4352631417812203e-05,
      "loss": 0.0018,
      "step": 27670
    },
    {
      "epoch": 0.8474420598230413,
      "grad_norm": 0.0161177609115839,
      "learning_rate": 1.435059037238874e-05,
      "loss": 0.0442,
      "step": 27680
    },
    {
      "epoch": 0.8477482166365612,
      "grad_norm": 0.009719730354845524,
      "learning_rate": 1.4348549326965272e-05,
      "loss": 0.0005,
      "step": 27690
    },
    {
      "epoch": 0.8480543734500812,
      "grad_norm": 0.08918611705303192,
      "learning_rate": 1.4346508281541806e-05,
      "loss": 0.0013,
      "step": 27700
    },
    {
      "epoch": 0.848360530263601,
      "grad_norm": 0.02508567087352276,
      "learning_rate": 1.434446723611834e-05,
      "loss": 0.0405,
      "step": 27710
    },
    {
      "epoch": 0.8486666870771209,
      "grad_norm": 0.025529377162456512,
      "learning_rate": 1.4342426190694877e-05,
      "loss": 0.0011,
      "step": 27720
    },
    {
      "epoch": 0.8489728438906408,
      "grad_norm": 0.00941704586148262,
      "learning_rate": 1.4340385145271409e-05,
      "loss": 0.0009,
      "step": 27730
    },
    {
      "epoch": 0.8492790007041606,
      "grad_norm": 0.020060528069734573,
      "learning_rate": 1.4338344099847942e-05,
      "loss": 0.0413,
      "step": 27740
    },
    {
      "epoch": 0.8495851575176806,
      "grad_norm": 0.03083118051290512,
      "learning_rate": 1.4336303054424476e-05,
      "loss": 0.0339,
      "step": 27750
    },
    {
      "epoch": 0.8498913143312005,
      "grad_norm": 0.025434907525777817,
      "learning_rate": 1.4334262009001011e-05,
      "loss": 0.0008,
      "step": 27760
    },
    {
      "epoch": 0.8501974711447203,
      "grad_norm": 0.045917171984910965,
      "learning_rate": 1.4332220963577545e-05,
      "loss": 0.0025,
      "step": 27770
    },
    {
      "epoch": 0.8505036279582402,
      "grad_norm": 0.03440631926059723,
      "learning_rate": 1.4330179918154079e-05,
      "loss": 0.063,
      "step": 27780
    },
    {
      "epoch": 0.8508097847717601,
      "grad_norm": 0.03864016383886337,
      "learning_rate": 1.4328138872730616e-05,
      "loss": 0.0497,
      "step": 27790
    },
    {
      "epoch": 0.85111594158528,
      "grad_norm": 0.07955019176006317,
      "learning_rate": 1.4326097827307147e-05,
      "loss": 0.0361,
      "step": 27800
    },
    {
      "epoch": 0.8514220983987999,
      "grad_norm": 0.05585338920354843,
      "learning_rate": 1.4324056781883681e-05,
      "loss": 0.0315,
      "step": 27810
    },
    {
      "epoch": 0.8517282552123198,
      "grad_norm": 0.031549423933029175,
      "learning_rate": 1.4322015736460215e-05,
      "loss": 0.0027,
      "step": 27820
    },
    {
      "epoch": 0.8520344120258396,
      "grad_norm": 0.1111966073513031,
      "learning_rate": 1.4319974691036752e-05,
      "loss": 0.0662,
      "step": 27830
    },
    {
      "epoch": 0.8523405688393595,
      "grad_norm": 0.08613599836826324,
      "learning_rate": 1.4317933645613284e-05,
      "loss": 0.0027,
      "step": 27840
    },
    {
      "epoch": 0.8526467256528794,
      "grad_norm": 0.0016095290193334222,
      "learning_rate": 1.4315892600189817e-05,
      "loss": 0.0046,
      "step": 27850
    },
    {
      "epoch": 0.8529528824663993,
      "grad_norm": 0.03524510934948921,
      "learning_rate": 1.4313851554766351e-05,
      "loss": 0.0028,
      "step": 27860
    },
    {
      "epoch": 0.8532590392799192,
      "grad_norm": 0.0316336527466774,
      "learning_rate": 1.4311810509342886e-05,
      "loss": 0.0018,
      "step": 27870
    },
    {
      "epoch": 0.8535651960934391,
      "grad_norm": 0.0373566709458828,
      "learning_rate": 1.430976946391942e-05,
      "loss": 0.0027,
      "step": 27880
    },
    {
      "epoch": 0.8538713529069589,
      "grad_norm": 0.03378099575638771,
      "learning_rate": 1.4307728418495954e-05,
      "loss": 0.0013,
      "step": 27890
    },
    {
      "epoch": 0.8541775097204788,
      "grad_norm": 0.012184938415884972,
      "learning_rate": 1.430568737307249e-05,
      "loss": 0.0098,
      "step": 27900
    },
    {
      "epoch": 0.8544836665339988,
      "grad_norm": 0.026055842638015747,
      "learning_rate": 1.4303646327649023e-05,
      "loss": 0.0361,
      "step": 27910
    },
    {
      "epoch": 0.8547898233475186,
      "grad_norm": 0.03961160033941269,
      "learning_rate": 1.4301605282225556e-05,
      "loss": 0.0013,
      "step": 27920
    },
    {
      "epoch": 0.8550959801610385,
      "grad_norm": 0.02779357135295868,
      "learning_rate": 1.429956423680209e-05,
      "loss": 0.0009,
      "step": 27930
    },
    {
      "epoch": 0.8554021369745584,
      "grad_norm": 0.037380702793598175,
      "learning_rate": 1.4297523191378625e-05,
      "loss": 0.0442,
      "step": 27940
    },
    {
      "epoch": 0.8557082937880782,
      "grad_norm": 0.035030074417591095,
      "learning_rate": 1.4295482145955159e-05,
      "loss": 0.0012,
      "step": 27950
    },
    {
      "epoch": 0.8560144506015981,
      "grad_norm": 0.02369121089577675,
      "learning_rate": 1.4293441100531693e-05,
      "loss": 0.0012,
      "step": 27960
    },
    {
      "epoch": 0.8563206074151181,
      "grad_norm": 0.014006217941641808,
      "learning_rate": 1.4291400055108226e-05,
      "loss": 0.0164,
      "step": 27970
    },
    {
      "epoch": 0.8566267642286379,
      "grad_norm": 0.0038398923352360725,
      "learning_rate": 1.4289359009684762e-05,
      "loss": 0.0011,
      "step": 27980
    },
    {
      "epoch": 0.8569329210421578,
      "grad_norm": 0.012038460932672024,
      "learning_rate": 1.4287317964261295e-05,
      "loss": 0.0378,
      "step": 27990
    },
    {
      "epoch": 0.8572390778556777,
      "grad_norm": 0.010393691249191761,
      "learning_rate": 1.4285276918837829e-05,
      "loss": 0.0006,
      "step": 28000
    },
    {
      "epoch": 0.8575452346691975,
      "grad_norm": 0.00850012619048357,
      "learning_rate": 1.4283235873414364e-05,
      "loss": 0.001,
      "step": 28010
    },
    {
      "epoch": 0.8578513914827175,
      "grad_norm": 1.8473871946334839,
      "learning_rate": 1.4281194827990898e-05,
      "loss": 0.0035,
      "step": 28020
    },
    {
      "epoch": 0.8581575482962374,
      "grad_norm": 0.01752883568406105,
      "learning_rate": 1.4279153782567431e-05,
      "loss": 0.0005,
      "step": 28030
    },
    {
      "epoch": 0.8584637051097572,
      "grad_norm": 0.04438583180308342,
      "learning_rate": 1.4277112737143965e-05,
      "loss": 0.0293,
      "step": 28040
    },
    {
      "epoch": 0.8587698619232771,
      "grad_norm": 0.020099962130188942,
      "learning_rate": 1.42750716917205e-05,
      "loss": 0.0472,
      "step": 28050
    },
    {
      "epoch": 0.859076018736797,
      "grad_norm": 0.16986551880836487,
      "learning_rate": 1.4273030646297034e-05,
      "loss": 0.0584,
      "step": 28060
    },
    {
      "epoch": 0.8593821755503168,
      "grad_norm": 0.045876696705818176,
      "learning_rate": 1.4270989600873568e-05,
      "loss": 0.001,
      "step": 28070
    },
    {
      "epoch": 0.8596883323638368,
      "grad_norm": 0.007834347896277905,
      "learning_rate": 1.4268948555450101e-05,
      "loss": 0.0024,
      "step": 28080
    },
    {
      "epoch": 0.8599944891773567,
      "grad_norm": 0.08068496733903885,
      "learning_rate": 1.4266907510026637e-05,
      "loss": 0.0025,
      "step": 28090
    },
    {
      "epoch": 0.8603006459908765,
      "grad_norm": 0.026385677978396416,
      "learning_rate": 1.426486646460317e-05,
      "loss": 0.0006,
      "step": 28100
    },
    {
      "epoch": 0.8606068028043964,
      "grad_norm": 0.031930722296237946,
      "learning_rate": 1.4262825419179704e-05,
      "loss": 0.0388,
      "step": 28110
    },
    {
      "epoch": 0.8609129596179163,
      "grad_norm": 0.058139652013778687,
      "learning_rate": 1.426078437375624e-05,
      "loss": 0.0011,
      "step": 28120
    },
    {
      "epoch": 0.8612191164314362,
      "grad_norm": 0.001732723438180983,
      "learning_rate": 1.4258743328332773e-05,
      "loss": 0.001,
      "step": 28130
    },
    {
      "epoch": 0.8615252732449561,
      "grad_norm": 0.02731042355298996,
      "learning_rate": 1.4256702282909307e-05,
      "loss": 0.0407,
      "step": 28140
    },
    {
      "epoch": 0.861831430058476,
      "grad_norm": 0.03491945564746857,
      "learning_rate": 1.425466123748584e-05,
      "loss": 0.0011,
      "step": 28150
    },
    {
      "epoch": 0.8621375868719958,
      "grad_norm": 0.010105859488248825,
      "learning_rate": 1.4252620192062376e-05,
      "loss": 0.0013,
      "step": 28160
    },
    {
      "epoch": 0.8624437436855157,
      "grad_norm": 0.018999911844730377,
      "learning_rate": 1.425057914663891e-05,
      "loss": 0.0012,
      "step": 28170
    },
    {
      "epoch": 0.8627499004990357,
      "grad_norm": 0.016475414857268333,
      "learning_rate": 1.4248538101215443e-05,
      "loss": 0.0357,
      "step": 28180
    },
    {
      "epoch": 0.8630560573125555,
      "grad_norm": 0.02083456702530384,
      "learning_rate": 1.4246497055791977e-05,
      "loss": 0.001,
      "step": 28190
    },
    {
      "epoch": 0.8633622141260754,
      "grad_norm": 0.005111859645694494,
      "learning_rate": 1.4244456010368512e-05,
      "loss": 0.0009,
      "step": 28200
    },
    {
      "epoch": 0.8636683709395953,
      "grad_norm": 0.022921446710824966,
      "learning_rate": 1.4242414964945046e-05,
      "loss": 0.0307,
      "step": 28210
    },
    {
      "epoch": 0.8639745277531151,
      "grad_norm": 0.043696265667676926,
      "learning_rate": 1.424037391952158e-05,
      "loss": 0.0368,
      "step": 28220
    },
    {
      "epoch": 0.864280684566635,
      "grad_norm": 0.17317262291908264,
      "learning_rate": 1.4238332874098115e-05,
      "loss": 0.0015,
      "step": 28230
    },
    {
      "epoch": 0.864586841380155,
      "grad_norm": 0.04747443646192551,
      "learning_rate": 1.4236291828674648e-05,
      "loss": 0.0468,
      "step": 28240
    },
    {
      "epoch": 0.8648929981936748,
      "grad_norm": 0.04664504900574684,
      "learning_rate": 1.4234250783251182e-05,
      "loss": 0.0012,
      "step": 28250
    },
    {
      "epoch": 0.8651991550071947,
      "grad_norm": 0.07907342165708542,
      "learning_rate": 1.4232209737827715e-05,
      "loss": 0.0019,
      "step": 28260
    },
    {
      "epoch": 0.8655053118207146,
      "grad_norm": 0.03957168385386467,
      "learning_rate": 1.423016869240425e-05,
      "loss": 0.0018,
      "step": 28270
    },
    {
      "epoch": 0.8658114686342344,
      "grad_norm": 1.5629831552505493,
      "learning_rate": 1.4228127646980784e-05,
      "loss": 0.0281,
      "step": 28280
    },
    {
      "epoch": 0.8661176254477544,
      "grad_norm": 0.016979318112134933,
      "learning_rate": 1.4226086601557318e-05,
      "loss": 0.0014,
      "step": 28290
    },
    {
      "epoch": 0.8664237822612743,
      "grad_norm": 0.027415065094828606,
      "learning_rate": 1.4224045556133852e-05,
      "loss": 0.0405,
      "step": 28300
    },
    {
      "epoch": 0.8667299390747941,
      "grad_norm": 0.03560331091284752,
      "learning_rate": 1.4222004510710387e-05,
      "loss": 0.0008,
      "step": 28310
    },
    {
      "epoch": 0.867036095888314,
      "grad_norm": 0.02534942515194416,
      "learning_rate": 1.421996346528692e-05,
      "loss": 0.0013,
      "step": 28320
    },
    {
      "epoch": 0.8673422527018338,
      "grad_norm": 0.024054545909166336,
      "learning_rate": 1.4217922419863454e-05,
      "loss": 0.0255,
      "step": 28330
    },
    {
      "epoch": 0.8676484095153537,
      "grad_norm": 0.052460089325904846,
      "learning_rate": 1.421588137443999e-05,
      "loss": 0.0017,
      "step": 28340
    },
    {
      "epoch": 0.8679545663288737,
      "grad_norm": 0.02280931919813156,
      "learning_rate": 1.4213840329016523e-05,
      "loss": 0.0017,
      "step": 28350
    },
    {
      "epoch": 0.8682607231423936,
      "grad_norm": 0.025751519948244095,
      "learning_rate": 1.4211799283593057e-05,
      "loss": 0.0012,
      "step": 28360
    },
    {
      "epoch": 0.8685668799559134,
      "grad_norm": 0.018500979989767075,
      "learning_rate": 1.420975823816959e-05,
      "loss": 0.0717,
      "step": 28370
    },
    {
      "epoch": 0.8688730367694333,
      "grad_norm": 0.011649620719254017,
      "learning_rate": 1.4207717192746126e-05,
      "loss": 0.0012,
      "step": 28380
    },
    {
      "epoch": 0.8691791935829531,
      "grad_norm": 0.0538417287170887,
      "learning_rate": 1.420567614732266e-05,
      "loss": 0.0024,
      "step": 28390
    },
    {
      "epoch": 0.8694853503964731,
      "grad_norm": 0.03595287352800369,
      "learning_rate": 1.4203635101899193e-05,
      "loss": 0.0012,
      "step": 28400
    },
    {
      "epoch": 0.869791507209993,
      "grad_norm": 0.04939986765384674,
      "learning_rate": 1.4201594056475727e-05,
      "loss": 0.0367,
      "step": 28410
    },
    {
      "epoch": 0.8700976640235129,
      "grad_norm": 0.03091101162135601,
      "learning_rate": 1.4199553011052262e-05,
      "loss": 0.0217,
      "step": 28420
    },
    {
      "epoch": 0.8704038208370327,
      "grad_norm": 0.027898406609892845,
      "learning_rate": 1.4197511965628796e-05,
      "loss": 0.0011,
      "step": 28430
    },
    {
      "epoch": 0.8707099776505526,
      "grad_norm": 0.0447118803858757,
      "learning_rate": 1.419547092020533e-05,
      "loss": 0.0011,
      "step": 28440
    },
    {
      "epoch": 0.8710161344640724,
      "grad_norm": 0.04526109620928764,
      "learning_rate": 1.4193429874781865e-05,
      "loss": 0.0361,
      "step": 28450
    },
    {
      "epoch": 0.8713222912775924,
      "grad_norm": 0.02002941071987152,
      "learning_rate": 1.4191388829358398e-05,
      "loss": 0.001,
      "step": 28460
    },
    {
      "epoch": 0.8716284480911123,
      "grad_norm": 0.01571383699774742,
      "learning_rate": 1.4189347783934932e-05,
      "loss": 0.0012,
      "step": 28470
    },
    {
      "epoch": 0.8719346049046321,
      "grad_norm": 0.03993958979845047,
      "learning_rate": 1.4187306738511466e-05,
      "loss": 0.0011,
      "step": 28480
    },
    {
      "epoch": 0.872240761718152,
      "grad_norm": 0.03828652203083038,
      "learning_rate": 1.4185265693088001e-05,
      "loss": 0.002,
      "step": 28490
    },
    {
      "epoch": 0.8725469185316719,
      "grad_norm": 0.03332878649234772,
      "learning_rate": 1.4183224647664535e-05,
      "loss": 0.0009,
      "step": 28500
    },
    {
      "epoch": 0.8728530753451919,
      "grad_norm": 0.005680078640580177,
      "learning_rate": 1.4181183602241068e-05,
      "loss": 0.0186,
      "step": 28510
    },
    {
      "epoch": 0.8731592321587117,
      "grad_norm": 0.02974516712129116,
      "learning_rate": 1.4179142556817602e-05,
      "loss": 0.0007,
      "step": 28520
    },
    {
      "epoch": 0.8734653889722316,
      "grad_norm": 0.03756462410092354,
      "learning_rate": 1.4177101511394137e-05,
      "loss": 0.0011,
      "step": 28530
    },
    {
      "epoch": 0.8737715457857514,
      "grad_norm": 0.014254109933972359,
      "learning_rate": 1.4175060465970671e-05,
      "loss": 0.0007,
      "step": 28540
    },
    {
      "epoch": 0.8740777025992713,
      "grad_norm": 0.014343103393912315,
      "learning_rate": 1.4173019420547205e-05,
      "loss": 0.0009,
      "step": 28550
    },
    {
      "epoch": 0.8743838594127913,
      "grad_norm": 0.004549767822027206,
      "learning_rate": 1.417097837512374e-05,
      "loss": 0.0026,
      "step": 28560
    },
    {
      "epoch": 0.8746900162263112,
      "grad_norm": 0.0058750887401402,
      "learning_rate": 1.4168937329700274e-05,
      "loss": 0.0337,
      "step": 28570
    },
    {
      "epoch": 0.874996173039831,
      "grad_norm": 0.05089617520570755,
      "learning_rate": 1.4166896284276807e-05,
      "loss": 0.0009,
      "step": 28580
    },
    {
      "epoch": 0.8753023298533509,
      "grad_norm": 0.013697292655706406,
      "learning_rate": 1.4164855238853341e-05,
      "loss": 0.0004,
      "step": 28590
    },
    {
      "epoch": 0.8756084866668707,
      "grad_norm": 0.02524355612695217,
      "learning_rate": 1.4162814193429876e-05,
      "loss": 0.0005,
      "step": 28600
    },
    {
      "epoch": 0.8759146434803906,
      "grad_norm": 0.002589175011962652,
      "learning_rate": 1.416077314800641e-05,
      "loss": 0.0035,
      "step": 28610
    },
    {
      "epoch": 0.8762208002939106,
      "grad_norm": 0.20641236007213593,
      "learning_rate": 1.4158732102582944e-05,
      "loss": 0.0344,
      "step": 28620
    },
    {
      "epoch": 0.8765269571074304,
      "grad_norm": 0.021782442927360535,
      "learning_rate": 1.4156691057159477e-05,
      "loss": 0.0007,
      "step": 28630
    },
    {
      "epoch": 0.8768331139209503,
      "grad_norm": 0.009330580942332745,
      "learning_rate": 1.4154650011736013e-05,
      "loss": 0.0005,
      "step": 28640
    },
    {
      "epoch": 0.8771392707344702,
      "grad_norm": 0.010148594155907631,
      "learning_rate": 1.4152608966312546e-05,
      "loss": 0.0442,
      "step": 28650
    },
    {
      "epoch": 0.87744542754799,
      "grad_norm": 0.020075293257832527,
      "learning_rate": 1.415056792088908e-05,
      "loss": 0.0008,
      "step": 28660
    },
    {
      "epoch": 0.87775158436151,
      "grad_norm": 0.012182088568806648,
      "learning_rate": 1.4148526875465613e-05,
      "loss": 0.0405,
      "step": 28670
    },
    {
      "epoch": 0.8780577411750299,
      "grad_norm": 0.047053903341293335,
      "learning_rate": 1.4146485830042149e-05,
      "loss": 0.0009,
      "step": 28680
    },
    {
      "epoch": 0.8783638979885497,
      "grad_norm": 0.0197454746812582,
      "learning_rate": 1.4144444784618682e-05,
      "loss": 0.001,
      "step": 28690
    },
    {
      "epoch": 0.8786700548020696,
      "grad_norm": 0.040522973984479904,
      "learning_rate": 1.4142403739195216e-05,
      "loss": 0.0373,
      "step": 28700
    },
    {
      "epoch": 0.8789762116155895,
      "grad_norm": 0.013673271052539349,
      "learning_rate": 1.4140362693771751e-05,
      "loss": 0.0009,
      "step": 28710
    },
    {
      "epoch": 0.8792823684291093,
      "grad_norm": 0.0100999241694808,
      "learning_rate": 1.4138321648348285e-05,
      "loss": 0.0009,
      "step": 28720
    },
    {
      "epoch": 0.8795885252426293,
      "grad_norm": 0.0043217092752456665,
      "learning_rate": 1.4136280602924819e-05,
      "loss": 0.0008,
      "step": 28730
    },
    {
      "epoch": 0.8798946820561492,
      "grad_norm": 0.05709794908761978,
      "learning_rate": 1.4134239557501352e-05,
      "loss": 0.0956,
      "step": 28740
    },
    {
      "epoch": 0.880200838869669,
      "grad_norm": 0.014756049029529095,
      "learning_rate": 1.4132198512077888e-05,
      "loss": 0.0031,
      "step": 28750
    },
    {
      "epoch": 0.8805069956831889,
      "grad_norm": 2.0141212940216064,
      "learning_rate": 1.4130157466654421e-05,
      "loss": 0.0527,
      "step": 28760
    },
    {
      "epoch": 0.8808131524967088,
      "grad_norm": 0.027226855978369713,
      "learning_rate": 1.4128116421230955e-05,
      "loss": 0.0306,
      "step": 28770
    },
    {
      "epoch": 0.8811193093102287,
      "grad_norm": 0.028236273676156998,
      "learning_rate": 1.4126075375807489e-05,
      "loss": 0.0098,
      "step": 28780
    },
    {
      "epoch": 0.8814254661237486,
      "grad_norm": 0.004693666007369757,
      "learning_rate": 1.4124034330384024e-05,
      "loss": 0.0704,
      "step": 28790
    },
    {
      "epoch": 0.8817316229372685,
      "grad_norm": 0.007570137735456228,
      "learning_rate": 1.4121993284960558e-05,
      "loss": 0.0015,
      "step": 28800
    },
    {
      "epoch": 0.8820377797507883,
      "grad_norm": 0.016407344490289688,
      "learning_rate": 1.4119952239537091e-05,
      "loss": 0.0347,
      "step": 28810
    },
    {
      "epoch": 0.8823439365643082,
      "grad_norm": 1.7449440956115723,
      "learning_rate": 1.4117911194113627e-05,
      "loss": 0.075,
      "step": 28820
    },
    {
      "epoch": 0.8826500933778281,
      "grad_norm": 0.08642391115427017,
      "learning_rate": 1.411587014869016e-05,
      "loss": 0.012,
      "step": 28830
    },
    {
      "epoch": 0.882956250191348,
      "grad_norm": 0.11626870930194855,
      "learning_rate": 1.4113829103266694e-05,
      "loss": 0.0322,
      "step": 28840
    },
    {
      "epoch": 0.8832624070048679,
      "grad_norm": 0.03925783187150955,
      "learning_rate": 1.4111788057843228e-05,
      "loss": 0.0613,
      "step": 28850
    },
    {
      "epoch": 0.8835685638183878,
      "grad_norm": 0.031421586871147156,
      "learning_rate": 1.4109747012419763e-05,
      "loss": 0.0374,
      "step": 28860
    },
    {
      "epoch": 0.8838747206319076,
      "grad_norm": 0.040205083787441254,
      "learning_rate": 1.4107705966996297e-05,
      "loss": 0.0018,
      "step": 28870
    },
    {
      "epoch": 0.8841808774454275,
      "grad_norm": 0.06245279684662819,
      "learning_rate": 1.410566492157283e-05,
      "loss": 0.03,
      "step": 28880
    },
    {
      "epoch": 0.8844870342589475,
      "grad_norm": 1.7096095085144043,
      "learning_rate": 1.4103623876149364e-05,
      "loss": 0.0355,
      "step": 28890
    },
    {
      "epoch": 0.8847931910724673,
      "grad_norm": 0.005568372085690498,
      "learning_rate": 1.41015828307259e-05,
      "loss": 0.0017,
      "step": 28900
    },
    {
      "epoch": 0.8850993478859872,
      "grad_norm": 0.03165842592716217,
      "learning_rate": 1.4099541785302433e-05,
      "loss": 0.0027,
      "step": 28910
    },
    {
      "epoch": 0.8854055046995071,
      "grad_norm": 0.029834896326065063,
      "learning_rate": 1.4097500739878966e-05,
      "loss": 0.0016,
      "step": 28920
    },
    {
      "epoch": 0.8857116615130269,
      "grad_norm": 0.05490652099251747,
      "learning_rate": 1.4095459694455502e-05,
      "loss": 0.0017,
      "step": 28930
    },
    {
      "epoch": 0.8860178183265468,
      "grad_norm": 0.02758733369410038,
      "learning_rate": 1.4093418649032035e-05,
      "loss": 0.0017,
      "step": 28940
    },
    {
      "epoch": 0.8863239751400668,
      "grad_norm": 1.7143481969833374,
      "learning_rate": 1.4091377603608569e-05,
      "loss": 0.0319,
      "step": 28950
    },
    {
      "epoch": 0.8866301319535866,
      "grad_norm": 0.037320420145988464,
      "learning_rate": 1.4089336558185103e-05,
      "loss": 0.002,
      "step": 28960
    },
    {
      "epoch": 0.8869362887671065,
      "grad_norm": 0.021897001191973686,
      "learning_rate": 1.4087295512761638e-05,
      "loss": 0.0013,
      "step": 28970
    },
    {
      "epoch": 0.8872424455806264,
      "grad_norm": 0.01626892015337944,
      "learning_rate": 1.4085254467338172e-05,
      "loss": 0.0365,
      "step": 28980
    },
    {
      "epoch": 0.8875486023941462,
      "grad_norm": 0.031187044456601143,
      "learning_rate": 1.4083213421914705e-05,
      "loss": 0.0012,
      "step": 28990
    },
    {
      "epoch": 0.8878547592076662,
      "grad_norm": 0.009845797903835773,
      "learning_rate": 1.4081172376491239e-05,
      "loss": 0.0332,
      "step": 29000
    },
    {
      "epoch": 0.8881609160211861,
      "grad_norm": 0.02409311570227146,
      "learning_rate": 1.4079131331067774e-05,
      "loss": 0.0017,
      "step": 29010
    },
    {
      "epoch": 0.8884670728347059,
      "grad_norm": 0.03719979152083397,
      "learning_rate": 1.4077090285644308e-05,
      "loss": 0.0013,
      "step": 29020
    },
    {
      "epoch": 0.8887732296482258,
      "grad_norm": 0.04767770320177078,
      "learning_rate": 1.4075049240220842e-05,
      "loss": 0.0017,
      "step": 29030
    },
    {
      "epoch": 0.8890793864617457,
      "grad_norm": 0.8363387584686279,
      "learning_rate": 1.4073008194797377e-05,
      "loss": 0.0046,
      "step": 29040
    },
    {
      "epoch": 0.8893855432752656,
      "grad_norm": 0.018132541328668594,
      "learning_rate": 1.407096714937391e-05,
      "loss": 0.0008,
      "step": 29050
    },
    {
      "epoch": 0.8896917000887855,
      "grad_norm": 0.013157456181943417,
      "learning_rate": 1.4068926103950444e-05,
      "loss": 0.001,
      "step": 29060
    },
    {
      "epoch": 0.8899978569023054,
      "grad_norm": 0.06190447881817818,
      "learning_rate": 1.4066885058526978e-05,
      "loss": 0.0359,
      "step": 29070
    },
    {
      "epoch": 0.8903040137158252,
      "grad_norm": 0.0003964796778745949,
      "learning_rate": 1.4064844013103513e-05,
      "loss": 0.0013,
      "step": 29080
    },
    {
      "epoch": 0.8906101705293451,
      "grad_norm": 0.04920579120516777,
      "learning_rate": 1.4062802967680047e-05,
      "loss": 0.0058,
      "step": 29090
    },
    {
      "epoch": 0.890916327342865,
      "grad_norm": 0.007564806845039129,
      "learning_rate": 1.406076192225658e-05,
      "loss": 0.0009,
      "step": 29100
    },
    {
      "epoch": 0.8912224841563849,
      "grad_norm": 1.7064508199691772,
      "learning_rate": 1.4058720876833114e-05,
      "loss": 0.0292,
      "step": 29110
    },
    {
      "epoch": 0.8915286409699048,
      "grad_norm": 0.3180197477340698,
      "learning_rate": 1.405667983140965e-05,
      "loss": 0.0016,
      "step": 29120
    },
    {
      "epoch": 0.8918347977834247,
      "grad_norm": 0.0423441082239151,
      "learning_rate": 1.4054638785986183e-05,
      "loss": 0.0015,
      "step": 29130
    },
    {
      "epoch": 0.8921409545969445,
      "grad_norm": 0.020687291398644447,
      "learning_rate": 1.4052597740562717e-05,
      "loss": 0.0008,
      "step": 29140
    },
    {
      "epoch": 0.8924471114104644,
      "grad_norm": 3.767163038253784,
      "learning_rate": 1.4050556695139252e-05,
      "loss": 0.0133,
      "step": 29150
    },
    {
      "epoch": 0.8927532682239844,
      "grad_norm": 0.016712253913283348,
      "learning_rate": 1.4048515649715786e-05,
      "loss": 0.0007,
      "step": 29160
    },
    {
      "epoch": 0.8930594250375042,
      "grad_norm": 0.03765718266367912,
      "learning_rate": 1.404647460429232e-05,
      "loss": 0.0442,
      "step": 29170
    },
    {
      "epoch": 0.8933655818510241,
      "grad_norm": 0.024943111464381218,
      "learning_rate": 1.4044433558868853e-05,
      "loss": 0.0335,
      "step": 29180
    },
    {
      "epoch": 0.893671738664544,
      "grad_norm": 0.023135516792535782,
      "learning_rate": 1.4042392513445388e-05,
      "loss": 0.001,
      "step": 29190
    },
    {
      "epoch": 0.8939778954780638,
      "grad_norm": 0.04049557447433472,
      "learning_rate": 1.4040351468021922e-05,
      "loss": 0.0013,
      "step": 29200
    },
    {
      "epoch": 0.8942840522915837,
      "grad_norm": 0.9076515436172485,
      "learning_rate": 1.4038310422598456e-05,
      "loss": 0.0455,
      "step": 29210
    },
    {
      "epoch": 0.8945902091051037,
      "grad_norm": 0.03918037191033363,
      "learning_rate": 1.403626937717499e-05,
      "loss": 0.0694,
      "step": 29220
    },
    {
      "epoch": 0.8948963659186235,
      "grad_norm": 0.03361903503537178,
      "learning_rate": 1.4034228331751525e-05,
      "loss": 0.0022,
      "step": 29230
    },
    {
      "epoch": 0.8952025227321434,
      "grad_norm": 0.05417533218860626,
      "learning_rate": 1.4032187286328058e-05,
      "loss": 0.0019,
      "step": 29240
    },
    {
      "epoch": 0.8955086795456633,
      "grad_norm": 0.026974573731422424,
      "learning_rate": 1.4030146240904592e-05,
      "loss": 0.0016,
      "step": 29250
    },
    {
      "epoch": 0.8958148363591831,
      "grad_norm": 0.025072354823350906,
      "learning_rate": 1.4028105195481127e-05,
      "loss": 0.0099,
      "step": 29260
    },
    {
      "epoch": 0.8961209931727031,
      "grad_norm": 0.028868719935417175,
      "learning_rate": 1.4026064150057661e-05,
      "loss": 0.0012,
      "step": 29270
    },
    {
      "epoch": 0.896427149986223,
      "grad_norm": 0.03813370689749718,
      "learning_rate": 1.4024023104634195e-05,
      "loss": 0.0366,
      "step": 29280
    },
    {
      "epoch": 0.8967333067997428,
      "grad_norm": 0.026666011661291122,
      "learning_rate": 1.4021982059210728e-05,
      "loss": 0.0371,
      "step": 29290
    },
    {
      "epoch": 0.8970394636132627,
      "grad_norm": 0.03755432739853859,
      "learning_rate": 1.4019941013787264e-05,
      "loss": 0.0018,
      "step": 29300
    },
    {
      "epoch": 0.8973456204267826,
      "grad_norm": 0.003678961656987667,
      "learning_rate": 1.4017899968363797e-05,
      "loss": 0.0012,
      "step": 29310
    },
    {
      "epoch": 0.8976517772403024,
      "grad_norm": 0.05209055542945862,
      "learning_rate": 1.4015858922940331e-05,
      "loss": 0.0015,
      "step": 29320
    },
    {
      "epoch": 0.8979579340538224,
      "grad_norm": 0.015350256115198135,
      "learning_rate": 1.4013817877516865e-05,
      "loss": 0.002,
      "step": 29330
    },
    {
      "epoch": 0.8982640908673423,
      "grad_norm": 0.03342406824231148,
      "learning_rate": 1.40117768320934e-05,
      "loss": 0.0293,
      "step": 29340
    },
    {
      "epoch": 0.8985702476808621,
      "grad_norm": 0.10864715278148651,
      "learning_rate": 1.4009735786669933e-05,
      "loss": 0.0423,
      "step": 29350
    },
    {
      "epoch": 0.898876404494382,
      "grad_norm": 0.15903425216674805,
      "learning_rate": 1.4007694741246467e-05,
      "loss": 0.0017,
      "step": 29360
    },
    {
      "epoch": 0.8991825613079019,
      "grad_norm": 0.034067850559949875,
      "learning_rate": 1.4005653695823002e-05,
      "loss": 0.0011,
      "step": 29370
    },
    {
      "epoch": 0.8994887181214218,
      "grad_norm": 0.036268021911382675,
      "learning_rate": 1.4003612650399536e-05,
      "loss": 0.0011,
      "step": 29380
    },
    {
      "epoch": 0.8997948749349417,
      "grad_norm": 0.02908492088317871,
      "learning_rate": 1.400157160497607e-05,
      "loss": 0.0011,
      "step": 29390
    },
    {
      "epoch": 0.9001010317484616,
      "grad_norm": 0.02204163558781147,
      "learning_rate": 1.3999530559552603e-05,
      "loss": 0.0328,
      "step": 29400
    },
    {
      "epoch": 0.9004071885619814,
      "grad_norm": 0.5763170719146729,
      "learning_rate": 1.3997489514129139e-05,
      "loss": 0.0316,
      "step": 29410
    },
    {
      "epoch": 0.9007133453755013,
      "grad_norm": 0.035485416650772095,
      "learning_rate": 1.3995448468705672e-05,
      "loss": 0.0419,
      "step": 29420
    },
    {
      "epoch": 0.9010195021890213,
      "grad_norm": 0.053825706243515015,
      "learning_rate": 1.3993407423282206e-05,
      "loss": 0.0379,
      "step": 29430
    },
    {
      "epoch": 0.9013256590025411,
      "grad_norm": 0.03504417464137077,
      "learning_rate": 1.399136637785874e-05,
      "loss": 0.0017,
      "step": 29440
    },
    {
      "epoch": 0.901631815816061,
      "grad_norm": 0.0320454016327858,
      "learning_rate": 1.3989325332435275e-05,
      "loss": 0.0346,
      "step": 29450
    },
    {
      "epoch": 0.9019379726295809,
      "grad_norm": 0.06484030187129974,
      "learning_rate": 1.3987284287011809e-05,
      "loss": 0.0024,
      "step": 29460
    },
    {
      "epoch": 0.9022441294431007,
      "grad_norm": 0.07027138024568558,
      "learning_rate": 1.3985243241588342e-05,
      "loss": 0.0712,
      "step": 29470
    },
    {
      "epoch": 0.9025502862566206,
      "grad_norm": 0.0727820172905922,
      "learning_rate": 1.3983202196164878e-05,
      "loss": 0.0015,
      "step": 29480
    },
    {
      "epoch": 0.9028564430701406,
      "grad_norm": 0.06717158854007721,
      "learning_rate": 1.3981161150741411e-05,
      "loss": 0.0311,
      "step": 29490
    },
    {
      "epoch": 0.9031625998836604,
      "grad_norm": 0.024467051029205322,
      "learning_rate": 1.3979120105317945e-05,
      "loss": 0.0027,
      "step": 29500
    },
    {
      "epoch": 0.9034687566971803,
      "grad_norm": 0.10441984236240387,
      "learning_rate": 1.3977079059894479e-05,
      "loss": 0.0289,
      "step": 29510
    },
    {
      "epoch": 0.9037749135107002,
      "grad_norm": 0.04666063189506531,
      "learning_rate": 1.3975038014471014e-05,
      "loss": 0.0022,
      "step": 29520
    },
    {
      "epoch": 0.90408107032422,
      "grad_norm": 0.0605185367166996,
      "learning_rate": 1.3972996969047548e-05,
      "loss": 0.0019,
      "step": 29530
    },
    {
      "epoch": 0.90438722713774,
      "grad_norm": 0.03446575254201889,
      "learning_rate": 1.3970955923624081e-05,
      "loss": 0.0018,
      "step": 29540
    },
    {
      "epoch": 0.9046933839512599,
      "grad_norm": 0.17503498494625092,
      "learning_rate": 1.3968914878200615e-05,
      "loss": 0.0018,
      "step": 29550
    },
    {
      "epoch": 0.9049995407647797,
      "grad_norm": 0.02164798602461815,
      "learning_rate": 1.396687383277715e-05,
      "loss": 0.0013,
      "step": 29560
    },
    {
      "epoch": 0.9053056975782996,
      "grad_norm": 0.026483742520213127,
      "learning_rate": 1.3964832787353684e-05,
      "loss": 0.0409,
      "step": 29570
    },
    {
      "epoch": 0.9056118543918195,
      "grad_norm": 0.04636218771338463,
      "learning_rate": 1.3962791741930217e-05,
      "loss": 0.0013,
      "step": 29580
    },
    {
      "epoch": 0.9059180112053393,
      "grad_norm": 0.02136867493391037,
      "learning_rate": 1.3960750696506753e-05,
      "loss": 0.0011,
      "step": 29590
    },
    {
      "epoch": 0.9062241680188593,
      "grad_norm": 0.03893125057220459,
      "learning_rate": 1.3958709651083286e-05,
      "loss": 0.0366,
      "step": 29600
    },
    {
      "epoch": 0.9065303248323792,
      "grad_norm": 0.021593371406197548,
      "learning_rate": 1.395666860565982e-05,
      "loss": 0.0356,
      "step": 29610
    },
    {
      "epoch": 0.906836481645899,
      "grad_norm": 0.03080102615058422,
      "learning_rate": 1.3954627560236354e-05,
      "loss": 0.0127,
      "step": 29620
    },
    {
      "epoch": 0.9071426384594189,
      "grad_norm": 0.04699299857020378,
      "learning_rate": 1.3952586514812889e-05,
      "loss": 0.0295,
      "step": 29630
    },
    {
      "epoch": 0.9074487952729388,
      "grad_norm": 0.07094865292310715,
      "learning_rate": 1.3950545469389423e-05,
      "loss": 0.0057,
      "step": 29640
    },
    {
      "epoch": 0.9077549520864587,
      "grad_norm": 0.025280609726905823,
      "learning_rate": 1.3948504423965956e-05,
      "loss": 0.0021,
      "step": 29650
    },
    {
      "epoch": 0.9080611088999786,
      "grad_norm": 0.016829997301101685,
      "learning_rate": 1.394646337854249e-05,
      "loss": 0.0019,
      "step": 29660
    },
    {
      "epoch": 0.9083672657134985,
      "grad_norm": 0.03281020745635033,
      "learning_rate": 1.3944422333119025e-05,
      "loss": 0.0013,
      "step": 29670
    },
    {
      "epoch": 0.9086734225270183,
      "grad_norm": 0.01578476093709469,
      "learning_rate": 1.3942381287695559e-05,
      "loss": 0.0009,
      "step": 29680
    },
    {
      "epoch": 0.9089795793405382,
      "grad_norm": 0.02178332768380642,
      "learning_rate": 1.3940340242272093e-05,
      "loss": 0.0007,
      "step": 29690
    },
    {
      "epoch": 0.909285736154058,
      "grad_norm": 0.03502225503325462,
      "learning_rate": 1.3938299196848628e-05,
      "loss": 0.0013,
      "step": 29700
    },
    {
      "epoch": 0.909591892967578,
      "grad_norm": 0.036259252578020096,
      "learning_rate": 1.3936258151425162e-05,
      "loss": 0.0009,
      "step": 29710
    },
    {
      "epoch": 0.9098980497810979,
      "grad_norm": 0.07639150321483612,
      "learning_rate": 1.3934217106001695e-05,
      "loss": 0.0011,
      "step": 29720
    },
    {
      "epoch": 0.9102042065946178,
      "grad_norm": 0.05836005508899689,
      "learning_rate": 1.3932176060578229e-05,
      "loss": 0.0011,
      "step": 29730
    },
    {
      "epoch": 0.9105103634081376,
      "grad_norm": 0.023426478728652,
      "learning_rate": 1.3930135015154764e-05,
      "loss": 0.0061,
      "step": 29740
    },
    {
      "epoch": 0.9108165202216575,
      "grad_norm": 0.04280593991279602,
      "learning_rate": 1.3928093969731298e-05,
      "loss": 0.0318,
      "step": 29750
    },
    {
      "epoch": 0.9111226770351775,
      "grad_norm": 0.025519372895359993,
      "learning_rate": 1.3926052924307832e-05,
      "loss": 0.0012,
      "step": 29760
    },
    {
      "epoch": 0.9114288338486973,
      "grad_norm": 0.01428283378481865,
      "learning_rate": 1.3924011878884365e-05,
      "loss": 0.0202,
      "step": 29770
    },
    {
      "epoch": 0.9117349906622172,
      "grad_norm": 0.046821948140859604,
      "learning_rate": 1.39219708334609e-05,
      "loss": 0.0841,
      "step": 29780
    },
    {
      "epoch": 0.9120411474757371,
      "grad_norm": 0.0005195256089791656,
      "learning_rate": 1.3919929788037434e-05,
      "loss": 0.0298,
      "step": 29790
    },
    {
      "epoch": 0.9123473042892569,
      "grad_norm": 0.05330771580338478,
      "learning_rate": 1.3917888742613968e-05,
      "loss": 0.0318,
      "step": 29800
    },
    {
      "epoch": 0.9126534611027769,
      "grad_norm": 1.9212167263031006,
      "learning_rate": 1.3915847697190503e-05,
      "loss": 0.0634,
      "step": 29810
    },
    {
      "epoch": 0.9129596179162968,
      "grad_norm": 0.06937349587678909,
      "learning_rate": 1.3913806651767037e-05,
      "loss": 0.0015,
      "step": 29820
    },
    {
      "epoch": 0.9132657747298166,
      "grad_norm": 0.035123344510793686,
      "learning_rate": 1.391176560634357e-05,
      "loss": 0.0355,
      "step": 29830
    },
    {
      "epoch": 0.9135719315433365,
      "grad_norm": 0.055635157972574234,
      "learning_rate": 1.3909724560920104e-05,
      "loss": 0.0115,
      "step": 29840
    },
    {
      "epoch": 0.9138780883568564,
      "grad_norm": 0.0473766066133976,
      "learning_rate": 1.390768351549664e-05,
      "loss": 0.0018,
      "step": 29850
    },
    {
      "epoch": 0.9141842451703762,
      "grad_norm": 1.4762494564056396,
      "learning_rate": 1.3905642470073173e-05,
      "loss": 0.0168,
      "step": 29860
    },
    {
      "epoch": 0.9144904019838962,
      "grad_norm": 0.02733047865331173,
      "learning_rate": 1.3903601424649707e-05,
      "loss": 0.0011,
      "step": 29870
    },
    {
      "epoch": 0.9147965587974161,
      "grad_norm": 0.03646879643201828,
      "learning_rate": 1.390156037922624e-05,
      "loss": 0.0017,
      "step": 29880
    },
    {
      "epoch": 0.9151027156109359,
      "grad_norm": 0.021198540925979614,
      "learning_rate": 1.3899519333802776e-05,
      "loss": 0.0521,
      "step": 29890
    },
    {
      "epoch": 0.9154088724244558,
      "grad_norm": 0.07125930488109589,
      "learning_rate": 1.389747828837931e-05,
      "loss": 0.0016,
      "step": 29900
    },
    {
      "epoch": 0.9157150292379757,
      "grad_norm": 0.021774474531412125,
      "learning_rate": 1.3895437242955843e-05,
      "loss": 0.0014,
      "step": 29910
    },
    {
      "epoch": 0.9160211860514956,
      "grad_norm": 0.039728835225105286,
      "learning_rate": 1.3893396197532377e-05,
      "loss": 0.0019,
      "step": 29920
    },
    {
      "epoch": 0.9163273428650155,
      "grad_norm": 0.05577888339757919,
      "learning_rate": 1.3891355152108912e-05,
      "loss": 0.0015,
      "step": 29930
    },
    {
      "epoch": 0.9166334996785354,
      "grad_norm": 0.017459705471992493,
      "learning_rate": 1.3889314106685446e-05,
      "loss": 0.0009,
      "step": 29940
    },
    {
      "epoch": 0.9169396564920552,
      "grad_norm": 0.043889664113521576,
      "learning_rate": 1.388727306126198e-05,
      "loss": 0.0013,
      "step": 29950
    },
    {
      "epoch": 0.9172458133055751,
      "grad_norm": 0.04042047634720802,
      "learning_rate": 1.3885232015838515e-05,
      "loss": 0.0318,
      "step": 29960
    },
    {
      "epoch": 0.917551970119095,
      "grad_norm": 0.01880505681037903,
      "learning_rate": 1.3883190970415048e-05,
      "loss": 0.0012,
      "step": 29970
    },
    {
      "epoch": 0.9178581269326149,
      "grad_norm": 0.04352472722530365,
      "learning_rate": 1.3881149924991582e-05,
      "loss": 0.0014,
      "step": 29980
    },
    {
      "epoch": 0.9181642837461348,
      "grad_norm": 0.02108857035636902,
      "learning_rate": 1.3879108879568116e-05,
      "loss": 0.0007,
      "step": 29990
    },
    {
      "epoch": 0.9184704405596547,
      "grad_norm": 2.452664852142334,
      "learning_rate": 1.3877067834144651e-05,
      "loss": 0.005,
      "step": 30000
    },
    {
      "epoch": 0.9187765973731745,
      "grad_norm": 0.028031131252646446,
      "learning_rate": 1.3875026788721185e-05,
      "loss": 0.0012,
      "step": 30010
    },
    {
      "epoch": 0.9190827541866944,
      "grad_norm": 0.0008779263589531183,
      "learning_rate": 1.3872985743297718e-05,
      "loss": 0.0018,
      "step": 30020
    },
    {
      "epoch": 0.9193889110002144,
      "grad_norm": 0.016218475997447968,
      "learning_rate": 1.3870944697874252e-05,
      "loss": 0.0005,
      "step": 30030
    },
    {
      "epoch": 0.9196950678137342,
      "grad_norm": 5.236911773681641,
      "learning_rate": 1.3868903652450787e-05,
      "loss": 0.0864,
      "step": 30040
    },
    {
      "epoch": 0.9200012246272541,
      "grad_norm": 0.0167219378054142,
      "learning_rate": 1.386686260702732e-05,
      "loss": 0.0041,
      "step": 30050
    },
    {
      "epoch": 0.920307381440774,
      "grad_norm": 0.24166791141033173,
      "learning_rate": 1.3864821561603854e-05,
      "loss": 0.0009,
      "step": 30060
    },
    {
      "epoch": 0.9206135382542938,
      "grad_norm": 0.021898142993450165,
      "learning_rate": 1.386278051618039e-05,
      "loss": 0.0008,
      "step": 30070
    },
    {
      "epoch": 0.9209196950678137,
      "grad_norm": 0.033119261264801025,
      "learning_rate": 1.3860739470756923e-05,
      "loss": 0.0146,
      "step": 30080
    },
    {
      "epoch": 0.9212258518813337,
      "grad_norm": 0.006656093988567591,
      "learning_rate": 1.3858698425333457e-05,
      "loss": 0.0366,
      "step": 30090
    },
    {
      "epoch": 0.9215320086948535,
      "grad_norm": 0.009921396151185036,
      "learning_rate": 1.385665737990999e-05,
      "loss": 0.0038,
      "step": 30100
    },
    {
      "epoch": 0.9218381655083734,
      "grad_norm": 0.019464783370494843,
      "learning_rate": 1.3854616334486526e-05,
      "loss": 0.0724,
      "step": 30110
    },
    {
      "epoch": 0.9221443223218933,
      "grad_norm": 0.026351580396294594,
      "learning_rate": 1.385257528906306e-05,
      "loss": 0.0012,
      "step": 30120
    },
    {
      "epoch": 0.9224504791354131,
      "grad_norm": 0.015794049948453903,
      "learning_rate": 1.3850534243639593e-05,
      "loss": 0.001,
      "step": 30130
    },
    {
      "epoch": 0.9227566359489331,
      "grad_norm": 0.04961685836315155,
      "learning_rate": 1.3848493198216127e-05,
      "loss": 0.0173,
      "step": 30140
    },
    {
      "epoch": 0.923062792762453,
      "grad_norm": 0.026465050876140594,
      "learning_rate": 1.3846452152792662e-05,
      "loss": 0.0318,
      "step": 30150
    },
    {
      "epoch": 0.9233689495759728,
      "grad_norm": 0.04981514438986778,
      "learning_rate": 1.3844411107369196e-05,
      "loss": 0.0017,
      "step": 30160
    },
    {
      "epoch": 0.9236751063894927,
      "grad_norm": 0.021149134263396263,
      "learning_rate": 1.384237006194573e-05,
      "loss": 0.002,
      "step": 30170
    },
    {
      "epoch": 0.9239812632030125,
      "grad_norm": 0.004527201410382986,
      "learning_rate": 1.3840329016522265e-05,
      "loss": 0.0014,
      "step": 30180
    },
    {
      "epoch": 0.9242874200165324,
      "grad_norm": 0.028498735278844833,
      "learning_rate": 1.3838287971098799e-05,
      "loss": 0.0067,
      "step": 30190
    },
    {
      "epoch": 0.9245935768300524,
      "grad_norm": 0.028183558955788612,
      "learning_rate": 1.3836246925675332e-05,
      "loss": 0.001,
      "step": 30200
    },
    {
      "epoch": 0.9248997336435723,
      "grad_norm": 0.010307143442332745,
      "learning_rate": 1.3834205880251866e-05,
      "loss": 0.0762,
      "step": 30210
    },
    {
      "epoch": 0.9252058904570921,
      "grad_norm": 0.049824442714452744,
      "learning_rate": 1.3832164834828401e-05,
      "loss": 0.0011,
      "step": 30220
    },
    {
      "epoch": 0.925512047270612,
      "grad_norm": 0.03900531306862831,
      "learning_rate": 1.3830123789404935e-05,
      "loss": 0.0372,
      "step": 30230
    },
    {
      "epoch": 0.9258182040841318,
      "grad_norm": 1.6478221416473389,
      "learning_rate": 1.3828082743981468e-05,
      "loss": 0.0585,
      "step": 30240
    },
    {
      "epoch": 0.9261243608976518,
      "grad_norm": 0.06252006441354752,
      "learning_rate": 1.3826041698558002e-05,
      "loss": 0.0022,
      "step": 30250
    },
    {
      "epoch": 0.9264305177111717,
      "grad_norm": 0.01702122576534748,
      "learning_rate": 1.3824000653134537e-05,
      "loss": 0.0358,
      "step": 30260
    },
    {
      "epoch": 0.9267366745246916,
      "grad_norm": 0.011574866250157356,
      "learning_rate": 1.3821959607711071e-05,
      "loss": 0.0014,
      "step": 30270
    },
    {
      "epoch": 0.9270428313382114,
      "grad_norm": 0.02312690019607544,
      "learning_rate": 1.3819918562287605e-05,
      "loss": 0.0016,
      "step": 30280
    },
    {
      "epoch": 0.9273489881517313,
      "grad_norm": 0.03561931848526001,
      "learning_rate": 1.381787751686414e-05,
      "loss": 0.0431,
      "step": 30290
    },
    {
      "epoch": 0.9276551449652513,
      "grad_norm": 0.03352074325084686,
      "learning_rate": 1.3815836471440674e-05,
      "loss": 0.0512,
      "step": 30300
    },
    {
      "epoch": 0.9279613017787711,
      "grad_norm": 0.05967281386256218,
      "learning_rate": 1.3813795426017207e-05,
      "loss": 0.03,
      "step": 30310
    },
    {
      "epoch": 0.928267458592291,
      "grad_norm": 0.06640757620334625,
      "learning_rate": 1.3811754380593741e-05,
      "loss": 0.0011,
      "step": 30320
    },
    {
      "epoch": 0.9285736154058108,
      "grad_norm": 0.09034764766693115,
      "learning_rate": 1.3809713335170276e-05,
      "loss": 0.0356,
      "step": 30330
    },
    {
      "epoch": 0.9288797722193307,
      "grad_norm": 0.07869768142700195,
      "learning_rate": 1.380767228974681e-05,
      "loss": 0.0025,
      "step": 30340
    },
    {
      "epoch": 0.9291859290328506,
      "grad_norm": 0.006771703716367483,
      "learning_rate": 1.3805631244323344e-05,
      "loss": 0.0021,
      "step": 30350
    },
    {
      "epoch": 0.9294920858463706,
      "grad_norm": 0.013488427735865116,
      "learning_rate": 1.3803590198899877e-05,
      "loss": 0.002,
      "step": 30360
    },
    {
      "epoch": 0.9297982426598904,
      "grad_norm": 0.034734077751636505,
      "learning_rate": 1.3801549153476413e-05,
      "loss": 0.0017,
      "step": 30370
    },
    {
      "epoch": 0.9301043994734103,
      "grad_norm": 0.02954168990254402,
      "learning_rate": 1.3799508108052946e-05,
      "loss": 0.0406,
      "step": 30380
    },
    {
      "epoch": 0.9304105562869301,
      "grad_norm": 1.8112703561782837,
      "learning_rate": 1.379746706262948e-05,
      "loss": 0.0665,
      "step": 30390
    },
    {
      "epoch": 0.93071671310045,
      "grad_norm": 0.05181994289159775,
      "learning_rate": 1.3795426017206015e-05,
      "loss": 0.0017,
      "step": 30400
    },
    {
      "epoch": 0.93102286991397,
      "grad_norm": 0.04456504434347153,
      "learning_rate": 1.3793384971782549e-05,
      "loss": 0.0013,
      "step": 30410
    },
    {
      "epoch": 0.9313290267274899,
      "grad_norm": 0.04598189890384674,
      "learning_rate": 1.3791343926359083e-05,
      "loss": 0.0022,
      "step": 30420
    },
    {
      "epoch": 0.9316351835410097,
      "grad_norm": 0.8142741918563843,
      "learning_rate": 1.3789302880935616e-05,
      "loss": 0.0031,
      "step": 30430
    },
    {
      "epoch": 0.9319413403545296,
      "grad_norm": 0.053166504949331284,
      "learning_rate": 1.3787261835512152e-05,
      "loss": 0.001,
      "step": 30440
    },
    {
      "epoch": 0.9322474971680494,
      "grad_norm": 0.02255118079483509,
      "learning_rate": 1.3785220790088685e-05,
      "loss": 0.0339,
      "step": 30450
    },
    {
      "epoch": 0.9325536539815693,
      "grad_norm": 0.035977356135845184,
      "learning_rate": 1.3783179744665219e-05,
      "loss": 0.0014,
      "step": 30460
    },
    {
      "epoch": 0.9328598107950893,
      "grad_norm": 0.06535674631595612,
      "learning_rate": 1.3781138699241752e-05,
      "loss": 0.0635,
      "step": 30470
    },
    {
      "epoch": 0.9331659676086091,
      "grad_norm": 0.12179119884967804,
      "learning_rate": 1.3779097653818288e-05,
      "loss": 0.0026,
      "step": 30480
    },
    {
      "epoch": 0.933472124422129,
      "grad_norm": 0.04312751814723015,
      "learning_rate": 1.3777056608394821e-05,
      "loss": 0.0018,
      "step": 30490
    },
    {
      "epoch": 0.9337782812356489,
      "grad_norm": 0.051463671028614044,
      "learning_rate": 1.3775015562971355e-05,
      "loss": 0.0386,
      "step": 30500
    },
    {
      "epoch": 0.9340844380491687,
      "grad_norm": 0.06693438440561295,
      "learning_rate": 1.377297451754789e-05,
      "loss": 0.0014,
      "step": 30510
    },
    {
      "epoch": 0.9343905948626887,
      "grad_norm": 0.026920489966869354,
      "learning_rate": 1.3770933472124424e-05,
      "loss": 0.0021,
      "step": 30520
    },
    {
      "epoch": 0.9346967516762086,
      "grad_norm": 0.011553642340004444,
      "learning_rate": 1.3768892426700958e-05,
      "loss": 0.0012,
      "step": 30530
    },
    {
      "epoch": 0.9350029084897284,
      "grad_norm": 0.060410261154174805,
      "learning_rate": 1.3766851381277491e-05,
      "loss": 0.0015,
      "step": 30540
    },
    {
      "epoch": 0.9353090653032483,
      "grad_norm": 0.015339180827140808,
      "learning_rate": 1.3764810335854027e-05,
      "loss": 0.0031,
      "step": 30550
    },
    {
      "epoch": 0.9356152221167682,
      "grad_norm": 0.005336367059499025,
      "learning_rate": 1.376276929043056e-05,
      "loss": 0.0008,
      "step": 30560
    },
    {
      "epoch": 0.935921378930288,
      "grad_norm": 0.02242097817361355,
      "learning_rate": 1.3760728245007094e-05,
      "loss": 0.0304,
      "step": 30570
    },
    {
      "epoch": 0.936227535743808,
      "grad_norm": 0.021999012678861618,
      "learning_rate": 1.3758687199583628e-05,
      "loss": 0.0172,
      "step": 30580
    },
    {
      "epoch": 0.9365336925573279,
      "grad_norm": 0.011401940137147903,
      "learning_rate": 1.3756646154160163e-05,
      "loss": 0.0524,
      "step": 30590
    },
    {
      "epoch": 0.9368398493708477,
      "grad_norm": 0.01771184802055359,
      "learning_rate": 1.3754605108736697e-05,
      "loss": 0.0407,
      "step": 30600
    },
    {
      "epoch": 0.9371460061843676,
      "grad_norm": 0.0418957844376564,
      "learning_rate": 1.375256406331323e-05,
      "loss": 0.0014,
      "step": 30610
    },
    {
      "epoch": 0.9374521629978875,
      "grad_norm": 0.04287934675812721,
      "learning_rate": 1.3750523017889766e-05,
      "loss": 0.0015,
      "step": 30620
    },
    {
      "epoch": 0.9377583198114074,
      "grad_norm": 0.018286287784576416,
      "learning_rate": 1.37484819724663e-05,
      "loss": 0.0013,
      "step": 30630
    },
    {
      "epoch": 0.9380644766249273,
      "grad_norm": 0.011577914468944073,
      "learning_rate": 1.3746440927042833e-05,
      "loss": 0.0009,
      "step": 30640
    },
    {
      "epoch": 0.9383706334384472,
      "grad_norm": 0.025212692096829414,
      "learning_rate": 1.3744399881619367e-05,
      "loss": 0.0343,
      "step": 30650
    },
    {
      "epoch": 0.938676790251967,
      "grad_norm": 0.03875511512160301,
      "learning_rate": 1.3742358836195902e-05,
      "loss": 0.0438,
      "step": 30660
    },
    {
      "epoch": 0.9389829470654869,
      "grad_norm": 0.039744701236486435,
      "learning_rate": 1.3740317790772436e-05,
      "loss": 0.0012,
      "step": 30670
    },
    {
      "epoch": 0.9392891038790069,
      "grad_norm": 0.01261917408555746,
      "learning_rate": 1.373827674534897e-05,
      "loss": 0.0033,
      "step": 30680
    },
    {
      "epoch": 0.9395952606925267,
      "grad_norm": 0.0012511834502220154,
      "learning_rate": 1.3736235699925503e-05,
      "loss": 0.0013,
      "step": 30690
    },
    {
      "epoch": 0.9399014175060466,
      "grad_norm": 0.040465325117111206,
      "learning_rate": 1.3734194654502038e-05,
      "loss": 0.0027,
      "step": 30700
    },
    {
      "epoch": 0.9402075743195665,
      "grad_norm": 0.02861206978559494,
      "learning_rate": 1.3732153609078572e-05,
      "loss": 0.0436,
      "step": 30710
    },
    {
      "epoch": 0.9405137311330863,
      "grad_norm": 0.01646886020898819,
      "learning_rate": 1.3730112563655105e-05,
      "loss": 0.0013,
      "step": 30720
    },
    {
      "epoch": 0.9408198879466062,
      "grad_norm": 0.01447648648172617,
      "learning_rate": 1.372807151823164e-05,
      "loss": 0.001,
      "step": 30730
    },
    {
      "epoch": 0.9411260447601262,
      "grad_norm": 0.04459711164236069,
      "learning_rate": 1.3726030472808174e-05,
      "loss": 0.001,
      "step": 30740
    },
    {
      "epoch": 0.941432201573646,
      "grad_norm": 0.020094942301511765,
      "learning_rate": 1.3723989427384708e-05,
      "loss": 0.0325,
      "step": 30750
    },
    {
      "epoch": 0.9417383583871659,
      "grad_norm": 0.00915276724845171,
      "learning_rate": 1.3721948381961242e-05,
      "loss": 0.0024,
      "step": 30760
    },
    {
      "epoch": 0.9420445152006858,
      "grad_norm": 0.025515681132674217,
      "learning_rate": 1.3719907336537777e-05,
      "loss": 0.0014,
      "step": 30770
    },
    {
      "epoch": 0.9423506720142056,
      "grad_norm": 0.01676705665886402,
      "learning_rate": 1.371786629111431e-05,
      "loss": 0.0009,
      "step": 30780
    },
    {
      "epoch": 0.9426568288277256,
      "grad_norm": 0.03945818915963173,
      "learning_rate": 1.3715825245690844e-05,
      "loss": 0.0683,
      "step": 30790
    },
    {
      "epoch": 0.9429629856412455,
      "grad_norm": 0.05589231848716736,
      "learning_rate": 1.3713784200267376e-05,
      "loss": 0.0313,
      "step": 30800
    },
    {
      "epoch": 0.9432691424547653,
      "grad_norm": 0.013515684753656387,
      "learning_rate": 1.3711743154843913e-05,
      "loss": 0.0885,
      "step": 30810
    },
    {
      "epoch": 0.9435752992682852,
      "grad_norm": 0.05989928916096687,
      "learning_rate": 1.3709702109420447e-05,
      "loss": 0.0023,
      "step": 30820
    },
    {
      "epoch": 0.9438814560818051,
      "grad_norm": 0.02635621838271618,
      "learning_rate": 1.370766106399698e-05,
      "loss": 0.0332,
      "step": 30830
    },
    {
      "epoch": 0.9441876128953249,
      "grad_norm": 0.06056220084428787,
      "learning_rate": 1.3705620018573516e-05,
      "loss": 0.003,
      "step": 30840
    },
    {
      "epoch": 0.9444937697088449,
      "grad_norm": 0.07449804991483688,
      "learning_rate": 1.370357897315005e-05,
      "loss": 0.0028,
      "step": 30850
    },
    {
      "epoch": 0.9447999265223648,
      "grad_norm": 0.0007764227339066565,
      "learning_rate": 1.3701537927726583e-05,
      "loss": 0.0025,
      "step": 30860
    },
    {
      "epoch": 0.9451060833358846,
      "grad_norm": 0.032405443489551544,
      "learning_rate": 1.3699496882303115e-05,
      "loss": 0.0018,
      "step": 30870
    },
    {
      "epoch": 0.9454122401494045,
      "grad_norm": 0.06423061341047287,
      "learning_rate": 1.3697455836879652e-05,
      "loss": 0.0014,
      "step": 30880
    },
    {
      "epoch": 0.9457183969629244,
      "grad_norm": 0.020077098160982132,
      "learning_rate": 1.3695414791456186e-05,
      "loss": 0.0341,
      "step": 30890
    },
    {
      "epoch": 0.9460245537764443,
      "grad_norm": 0.0337204709649086,
      "learning_rate": 1.369337374603272e-05,
      "loss": 0.0014,
      "step": 30900
    },
    {
      "epoch": 0.9463307105899642,
      "grad_norm": 0.019060257822275162,
      "learning_rate": 1.3691332700609251e-05,
      "loss": 0.0008,
      "step": 30910
    },
    {
      "epoch": 0.9466368674034841,
      "grad_norm": 0.03548359125852585,
      "learning_rate": 1.3689291655185788e-05,
      "loss": 0.0061,
      "step": 30920
    },
    {
      "epoch": 0.9469430242170039,
      "grad_norm": 0.05395544320344925,
      "learning_rate": 1.3687250609762322e-05,
      "loss": 0.0013,
      "step": 30930
    },
    {
      "epoch": 0.9472491810305238,
      "grad_norm": 0.022663665935397148,
      "learning_rate": 1.3685209564338856e-05,
      "loss": 0.001,
      "step": 30940
    },
    {
      "epoch": 0.9475553378440437,
      "grad_norm": 0.028665900230407715,
      "learning_rate": 1.3683168518915391e-05,
      "loss": 0.0008,
      "step": 30950
    },
    {
      "epoch": 0.9478614946575636,
      "grad_norm": 0.023753592744469643,
      "learning_rate": 1.3681127473491925e-05,
      "loss": 0.0012,
      "step": 30960
    },
    {
      "epoch": 0.9481676514710835,
      "grad_norm": 0.01468479074537754,
      "learning_rate": 1.3679086428068458e-05,
      "loss": 0.0367,
      "step": 30970
    },
    {
      "epoch": 0.9484738082846034,
      "grad_norm": 0.02526797726750374,
      "learning_rate": 1.367704538264499e-05,
      "loss": 0.0762,
      "step": 30980
    },
    {
      "epoch": 0.9487799650981232,
      "grad_norm": 0.013390789739787579,
      "learning_rate": 1.3675004337221527e-05,
      "loss": 0.0357,
      "step": 30990
    },
    {
      "epoch": 0.9490861219116431,
      "grad_norm": 0.05819636955857277,
      "learning_rate": 1.3672963291798061e-05,
      "loss": 0.0017,
      "step": 31000
    },
    {
      "epoch": 0.9493922787251631,
      "grad_norm": 0.031248291954398155,
      "learning_rate": 1.3670922246374595e-05,
      "loss": 0.039,
      "step": 31010
    },
    {
      "epoch": 0.9496984355386829,
      "grad_norm": 0.04092780500650406,
      "learning_rate": 1.3668881200951127e-05,
      "loss": 0.002,
      "step": 31020
    },
    {
      "epoch": 0.9500045923522028,
      "grad_norm": 0.07317174971103668,
      "learning_rate": 1.3666840155527664e-05,
      "loss": 0.0373,
      "step": 31030
    },
    {
      "epoch": 0.9503107491657227,
      "grad_norm": 0.05989978834986687,
      "learning_rate": 1.3664799110104197e-05,
      "loss": 0.0323,
      "step": 31040
    },
    {
      "epoch": 0.9506169059792425,
      "grad_norm": 0.07452847808599472,
      "learning_rate": 1.366275806468073e-05,
      "loss": 0.0021,
      "step": 31050
    },
    {
      "epoch": 0.9509230627927625,
      "grad_norm": 1.683256983757019,
      "learning_rate": 1.3660717019257266e-05,
      "loss": 0.0344,
      "step": 31060
    },
    {
      "epoch": 0.9512292196062824,
      "grad_norm": 0.038237880915403366,
      "learning_rate": 1.36586759738338e-05,
      "loss": 0.0131,
      "step": 31070
    },
    {
      "epoch": 0.9515353764198022,
      "grad_norm": 0.05851771682500839,
      "learning_rate": 1.3656634928410334e-05,
      "loss": 0.0021,
      "step": 31080
    },
    {
      "epoch": 0.9518415332333221,
      "grad_norm": 1.8328254222869873,
      "learning_rate": 1.3654593882986866e-05,
      "loss": 0.0434,
      "step": 31090
    },
    {
      "epoch": 0.952147690046842,
      "grad_norm": 0.03247743472456932,
      "learning_rate": 1.3652552837563403e-05,
      "loss": 0.0017,
      "step": 31100
    },
    {
      "epoch": 0.9524538468603618,
      "grad_norm": 0.05061008408665657,
      "learning_rate": 1.3650511792139936e-05,
      "loss": 0.0341,
      "step": 31110
    },
    {
      "epoch": 0.9527600036738818,
      "grad_norm": 0.07162609696388245,
      "learning_rate": 1.3648470746716468e-05,
      "loss": 0.0021,
      "step": 31120
    },
    {
      "epoch": 0.9530661604874017,
      "grad_norm": 0.031579986214637756,
      "learning_rate": 1.3646429701293002e-05,
      "loss": 0.0016,
      "step": 31130
    },
    {
      "epoch": 0.9533723173009215,
      "grad_norm": 0.0341469906270504,
      "learning_rate": 1.3644388655869539e-05,
      "loss": 0.0015,
      "step": 31140
    },
    {
      "epoch": 0.9536784741144414,
      "grad_norm": 0.04886256903409958,
      "learning_rate": 1.3642347610446072e-05,
      "loss": 0.0016,
      "step": 31150
    },
    {
      "epoch": 0.9539846309279613,
      "grad_norm": 0.03871864825487137,
      "learning_rate": 1.3640306565022604e-05,
      "loss": 0.0015,
      "step": 31160
    },
    {
      "epoch": 0.9542907877414812,
      "grad_norm": 0.010624092072248459,
      "learning_rate": 1.3638265519599138e-05,
      "loss": 0.0011,
      "step": 31170
    },
    {
      "epoch": 0.9545969445550011,
      "grad_norm": 0.048309050500392914,
      "learning_rate": 1.3636224474175675e-05,
      "loss": 0.0723,
      "step": 31180
    },
    {
      "epoch": 0.954903101368521,
      "grad_norm": 0.08763513714075089,
      "learning_rate": 1.3634183428752209e-05,
      "loss": 0.0344,
      "step": 31190
    },
    {
      "epoch": 0.9552092581820408,
      "grad_norm": 0.023121055215597153,
      "learning_rate": 1.363214238332874e-05,
      "loss": 0.0311,
      "step": 31200
    },
    {
      "epoch": 0.9555154149955607,
      "grad_norm": 0.03869643434882164,
      "learning_rate": 1.3630101337905278e-05,
      "loss": 0.0018,
      "step": 31210
    },
    {
      "epoch": 0.9558215718090806,
      "grad_norm": 0.05768907815217972,
      "learning_rate": 1.3628060292481811e-05,
      "loss": 0.0025,
      "step": 31220
    },
    {
      "epoch": 0.9561277286226005,
      "grad_norm": 0.037180572748184204,
      "learning_rate": 1.3626019247058343e-05,
      "loss": 0.0026,
      "step": 31230
    },
    {
      "epoch": 0.9564338854361204,
      "grad_norm": 0.03264421969652176,
      "learning_rate": 1.3623978201634877e-05,
      "loss": 0.0431,
      "step": 31240
    },
    {
      "epoch": 0.9567400422496403,
      "grad_norm": 0.03762068226933479,
      "learning_rate": 1.3621937156211414e-05,
      "loss": 0.0313,
      "step": 31250
    },
    {
      "epoch": 0.9570461990631601,
      "grad_norm": 0.02645246498286724,
      "learning_rate": 1.3619896110787948e-05,
      "loss": 0.0009,
      "step": 31260
    },
    {
      "epoch": 0.95735235587668,
      "grad_norm": 0.008651148527860641,
      "learning_rate": 1.361785506536448e-05,
      "loss": 0.0013,
      "step": 31270
    },
    {
      "epoch": 0.9576585126902,
      "grad_norm": 0.020487744361162186,
      "learning_rate": 1.3615814019941013e-05,
      "loss": 0.0033,
      "step": 31280
    },
    {
      "epoch": 0.9579646695037198,
      "grad_norm": 0.025291262194514275,
      "learning_rate": 1.361377297451755e-05,
      "loss": 0.0017,
      "step": 31290
    },
    {
      "epoch": 0.9582708263172397,
      "grad_norm": 0.029737303033471107,
      "learning_rate": 1.3611731929094082e-05,
      "loss": 0.0019,
      "step": 31300
    },
    {
      "epoch": 0.9585769831307596,
      "grad_norm": 0.013034628704190254,
      "learning_rate": 1.3609690883670616e-05,
      "loss": 0.0011,
      "step": 31310
    },
    {
      "epoch": 0.9588831399442794,
      "grad_norm": 0.011872957460582256,
      "learning_rate": 1.3607649838247153e-05,
      "loss": 0.0009,
      "step": 31320
    },
    {
      "epoch": 0.9591892967577993,
      "grad_norm": 0.032232463359832764,
      "learning_rate": 1.3605608792823687e-05,
      "loss": 0.0009,
      "step": 31330
    },
    {
      "epoch": 0.9594954535713193,
      "grad_norm": 0.025053009390830994,
      "learning_rate": 1.3603567747400218e-05,
      "loss": 0.0467,
      "step": 31340
    },
    {
      "epoch": 0.9598016103848391,
      "grad_norm": 0.013222959823906422,
      "learning_rate": 1.3601526701976752e-05,
      "loss": 0.0013,
      "step": 31350
    },
    {
      "epoch": 0.960107767198359,
      "grad_norm": 0.03961087018251419,
      "learning_rate": 1.359948565655329e-05,
      "loss": 0.0336,
      "step": 31360
    },
    {
      "epoch": 0.9604139240118789,
      "grad_norm": 0.015539215877652168,
      "learning_rate": 1.3597444611129821e-05,
      "loss": 0.0012,
      "step": 31370
    },
    {
      "epoch": 0.9607200808253987,
      "grad_norm": 0.01430539321154356,
      "learning_rate": 1.3595403565706355e-05,
      "loss": 0.0007,
      "step": 31380
    },
    {
      "epoch": 0.9610262376389187,
      "grad_norm": 0.04225920885801315,
      "learning_rate": 1.3593362520282888e-05,
      "loss": 0.0009,
      "step": 31390
    },
    {
      "epoch": 0.9613323944524386,
      "grad_norm": 0.029111770913004875,
      "learning_rate": 1.3591321474859425e-05,
      "loss": 0.001,
      "step": 31400
    },
    {
      "epoch": 0.9616385512659584,
      "grad_norm": 0.01524117961525917,
      "learning_rate": 1.3589280429435957e-05,
      "loss": 0.0099,
      "step": 31410
    },
    {
      "epoch": 0.9619447080794783,
      "grad_norm": 0.012963440269231796,
      "learning_rate": 1.3587239384012491e-05,
      "loss": 0.074,
      "step": 31420
    },
    {
      "epoch": 0.9622508648929982,
      "grad_norm": 0.015507289208471775,
      "learning_rate": 1.3585198338589028e-05,
      "loss": 0.0645,
      "step": 31430
    },
    {
      "epoch": 0.962557021706518,
      "grad_norm": 0.02493748627603054,
      "learning_rate": 1.3583157293165562e-05,
      "loss": 0.001,
      "step": 31440
    },
    {
      "epoch": 0.962863178520038,
      "grad_norm": 0.0350818894803524,
      "learning_rate": 1.3581116247742094e-05,
      "loss": 0.0012,
      "step": 31450
    },
    {
      "epoch": 0.9631693353335579,
      "grad_norm": 0.019866589456796646,
      "learning_rate": 1.3579075202318627e-05,
      "loss": 0.0012,
      "step": 31460
    },
    {
      "epoch": 0.9634754921470777,
      "grad_norm": 0.05097188428044319,
      "learning_rate": 1.3577034156895164e-05,
      "loss": 0.0014,
      "step": 31470
    },
    {
      "epoch": 0.9637816489605976,
      "grad_norm": 0.04240667074918747,
      "learning_rate": 1.3574993111471696e-05,
      "loss": 0.0751,
      "step": 31480
    },
    {
      "epoch": 0.9640878057741175,
      "grad_norm": 0.025523101910948753,
      "learning_rate": 1.357295206604823e-05,
      "loss": 0.0415,
      "step": 31490
    },
    {
      "epoch": 0.9643939625876374,
      "grad_norm": 0.25350216031074524,
      "learning_rate": 1.3570911020624764e-05,
      "loss": 0.0034,
      "step": 31500
    },
    {
      "epoch": 0.9647001194011573,
      "grad_norm": 0.05468318983912468,
      "learning_rate": 1.35688699752013e-05,
      "loss": 0.0013,
      "step": 31510
    },
    {
      "epoch": 0.9650062762146772,
      "grad_norm": 0.0876026526093483,
      "learning_rate": 1.3566828929777833e-05,
      "loss": 0.0531,
      "step": 31520
    },
    {
      "epoch": 0.965312433028197,
      "grad_norm": 0.04318324103951454,
      "learning_rate": 1.3564787884354366e-05,
      "loss": 0.0017,
      "step": 31530
    },
    {
      "epoch": 0.9656185898417169,
      "grad_norm": 0.054964467883110046,
      "learning_rate": 1.3562746838930903e-05,
      "loss": 0.0026,
      "step": 31540
    },
    {
      "epoch": 0.9659247466552369,
      "grad_norm": 0.04963652044534683,
      "learning_rate": 1.3560705793507435e-05,
      "loss": 0.0342,
      "step": 31550
    },
    {
      "epoch": 0.9662309034687567,
      "grad_norm": 0.053411342203617096,
      "learning_rate": 1.3558664748083969e-05,
      "loss": 0.0597,
      "step": 31560
    },
    {
      "epoch": 0.9665370602822766,
      "grad_norm": 0.048690877854824066,
      "learning_rate": 1.3556623702660502e-05,
      "loss": 0.0324,
      "step": 31570
    },
    {
      "epoch": 0.9668432170957965,
      "grad_norm": 0.08318522572517395,
      "learning_rate": 1.355458265723704e-05,
      "loss": 0.0036,
      "step": 31580
    },
    {
      "epoch": 0.9671493739093163,
      "grad_norm": 0.03234948217868805,
      "learning_rate": 1.3552541611813571e-05,
      "loss": 0.0347,
      "step": 31590
    },
    {
      "epoch": 0.9674555307228362,
      "grad_norm": 0.0625775158405304,
      "learning_rate": 1.3550500566390105e-05,
      "loss": 0.0023,
      "step": 31600
    },
    {
      "epoch": 0.9677616875363562,
      "grad_norm": 0.02085515484213829,
      "learning_rate": 1.3548459520966639e-05,
      "loss": 0.0024,
      "step": 31610
    },
    {
      "epoch": 0.968067844349876,
      "grad_norm": 0.030359191820025444,
      "learning_rate": 1.3546418475543174e-05,
      "loss": 0.0213,
      "step": 31620
    },
    {
      "epoch": 0.9683740011633959,
      "grad_norm": 0.048508644104003906,
      "learning_rate": 1.3544377430119708e-05,
      "loss": 0.002,
      "step": 31630
    },
    {
      "epoch": 0.9686801579769158,
      "grad_norm": 0.011099150404334068,
      "learning_rate": 1.3542336384696241e-05,
      "loss": 0.0014,
      "step": 31640
    },
    {
      "epoch": 0.9689863147904356,
      "grad_norm": 0.05561438202857971,
      "learning_rate": 1.3540295339272778e-05,
      "loss": 0.0019,
      "step": 31650
    },
    {
      "epoch": 0.9692924716039556,
      "grad_norm": 0.03981922194361687,
      "learning_rate": 1.353825429384931e-05,
      "loss": 0.0367,
      "step": 31660
    },
    {
      "epoch": 0.9695986284174755,
      "grad_norm": 0.019863909110426903,
      "learning_rate": 1.3536213248425844e-05,
      "loss": 0.0014,
      "step": 31670
    },
    {
      "epoch": 0.9699047852309953,
      "grad_norm": 0.08933400362730026,
      "learning_rate": 1.3534172203002378e-05,
      "loss": 0.0021,
      "step": 31680
    },
    {
      "epoch": 0.9702109420445152,
      "grad_norm": 0.04002738371491432,
      "learning_rate": 1.3532131157578915e-05,
      "loss": 0.0015,
      "step": 31690
    },
    {
      "epoch": 0.970517098858035,
      "grad_norm": 0.02252775803208351,
      "learning_rate": 1.3530090112155447e-05,
      "loss": 0.0011,
      "step": 31700
    },
    {
      "epoch": 0.9708232556715549,
      "grad_norm": 0.017073187977075577,
      "learning_rate": 1.352804906673198e-05,
      "loss": 0.0368,
      "step": 31710
    },
    {
      "epoch": 0.9711294124850749,
      "grad_norm": 0.029943922534585,
      "learning_rate": 1.3526008021308514e-05,
      "loss": 0.0012,
      "step": 31720
    },
    {
      "epoch": 0.9714355692985948,
      "grad_norm": 0.025188714265823364,
      "learning_rate": 1.352396697588505e-05,
      "loss": 0.001,
      "step": 31730
    },
    {
      "epoch": 0.9717417261121146,
      "grad_norm": 0.029214397072792053,
      "learning_rate": 1.3521925930461583e-05,
      "loss": 0.0009,
      "step": 31740
    },
    {
      "epoch": 0.9720478829256345,
      "grad_norm": 0.023652944713830948,
      "learning_rate": 1.3519884885038117e-05,
      "loss": 0.0007,
      "step": 31750
    },
    {
      "epoch": 0.9723540397391544,
      "grad_norm": 0.005557640455663204,
      "learning_rate": 1.3517843839614654e-05,
      "loss": 0.001,
      "step": 31760
    },
    {
      "epoch": 0.9726601965526743,
      "grad_norm": 0.022294720634818077,
      "learning_rate": 1.3515802794191186e-05,
      "loss": 0.0007,
      "step": 31770
    },
    {
      "epoch": 0.9729663533661942,
      "grad_norm": 0.007967113517224789,
      "learning_rate": 1.351376174876772e-05,
      "loss": 0.0361,
      "step": 31780
    },
    {
      "epoch": 0.9732725101797141,
      "grad_norm": 0.028127219527959824,
      "learning_rate": 1.3511720703344253e-05,
      "loss": 0.0008,
      "step": 31790
    },
    {
      "epoch": 0.9735786669932339,
      "grad_norm": 0.021673349663615227,
      "learning_rate": 1.3509679657920788e-05,
      "loss": 0.0013,
      "step": 31800
    },
    {
      "epoch": 0.9738848238067538,
      "grad_norm": 0.008524290286004543,
      "learning_rate": 1.3507638612497322e-05,
      "loss": 0.0009,
      "step": 31810
    },
    {
      "epoch": 0.9741909806202736,
      "grad_norm": 0.007736502680927515,
      "learning_rate": 1.3505597567073855e-05,
      "loss": 0.0009,
      "step": 31820
    },
    {
      "epoch": 0.9744971374337936,
      "grad_norm": 0.02253740094602108,
      "learning_rate": 1.3503556521650389e-05,
      "loss": 0.0009,
      "step": 31830
    },
    {
      "epoch": 0.9748032942473135,
      "grad_norm": 0.02137180231511593,
      "learning_rate": 1.3501515476226924e-05,
      "loss": 0.0009,
      "step": 31840
    },
    {
      "epoch": 0.9751094510608334,
      "grad_norm": 0.012996966950595379,
      "learning_rate": 1.3499474430803458e-05,
      "loss": 0.0006,
      "step": 31850
    },
    {
      "epoch": 0.9754156078743532,
      "grad_norm": 0.034255944192409515,
      "learning_rate": 1.3497433385379992e-05,
      "loss": 0.0441,
      "step": 31860
    },
    {
      "epoch": 0.9757217646878731,
      "grad_norm": 0.02293834090232849,
      "learning_rate": 1.3495392339956527e-05,
      "loss": 0.0008,
      "step": 31870
    },
    {
      "epoch": 0.9760279215013931,
      "grad_norm": 0.009072346612811089,
      "learning_rate": 1.349335129453306e-05,
      "loss": 0.0387,
      "step": 31880
    },
    {
      "epoch": 0.9763340783149129,
      "grad_norm": 0.03913791850209236,
      "learning_rate": 1.3491310249109594e-05,
      "loss": 0.0007,
      "step": 31890
    },
    {
      "epoch": 0.9766402351284328,
      "grad_norm": 0.03422093018889427,
      "learning_rate": 1.3489269203686128e-05,
      "loss": 0.001,
      "step": 31900
    },
    {
      "epoch": 0.9769463919419527,
      "grad_norm": 0.01704106107354164,
      "learning_rate": 1.3487228158262663e-05,
      "loss": 0.0008,
      "step": 31910
    },
    {
      "epoch": 0.9772525487554725,
      "grad_norm": 0.022272538393735886,
      "learning_rate": 1.3485187112839197e-05,
      "loss": 0.0331,
      "step": 31920
    },
    {
      "epoch": 0.9775587055689925,
      "grad_norm": 0.05073888227343559,
      "learning_rate": 1.348314606741573e-05,
      "loss": 0.0429,
      "step": 31930
    },
    {
      "epoch": 0.9778648623825124,
      "grad_norm": 0.03403294086456299,
      "learning_rate": 1.3481105021992264e-05,
      "loss": 0.001,
      "step": 31940
    },
    {
      "epoch": 0.9781710191960322,
      "grad_norm": 0.04313037171959877,
      "learning_rate": 1.34790639765688e-05,
      "loss": 0.0022,
      "step": 31950
    },
    {
      "epoch": 0.9784771760095521,
      "grad_norm": 0.02027573622763157,
      "learning_rate": 1.3477022931145333e-05,
      "loss": 0.0317,
      "step": 31960
    },
    {
      "epoch": 0.978783332823072,
      "grad_norm": 0.02401590719819069,
      "learning_rate": 1.3474981885721867e-05,
      "loss": 0.0408,
      "step": 31970
    },
    {
      "epoch": 0.9790894896365918,
      "grad_norm": 1.901190996170044,
      "learning_rate": 1.3472940840298402e-05,
      "loss": 0.0712,
      "step": 31980
    },
    {
      "epoch": 0.9793956464501118,
      "grad_norm": 0.02703551948070526,
      "learning_rate": 1.3470899794874936e-05,
      "loss": 0.0018,
      "step": 31990
    },
    {
      "epoch": 0.9797018032636317,
      "grad_norm": 0.07156748324632645,
      "learning_rate": 1.346885874945147e-05,
      "loss": 0.002,
      "step": 32000
    },
    {
      "epoch": 0.9800079600771515,
      "grad_norm": 1.7925474643707275,
      "learning_rate": 1.3466817704028003e-05,
      "loss": 0.0045,
      "step": 32010
    },
    {
      "epoch": 0.9803141168906714,
      "grad_norm": 0.03207477182149887,
      "learning_rate": 1.3464776658604538e-05,
      "loss": 0.0037,
      "step": 32020
    },
    {
      "epoch": 0.9806202737041912,
      "grad_norm": 0.022659266367554665,
      "learning_rate": 1.3462735613181072e-05,
      "loss": 0.0015,
      "step": 32030
    },
    {
      "epoch": 0.9809264305177112,
      "grad_norm": 0.01960495486855507,
      "learning_rate": 1.3460694567757606e-05,
      "loss": 0.0012,
      "step": 32040
    },
    {
      "epoch": 0.9812325873312311,
      "grad_norm": 0.008942312560975552,
      "learning_rate": 1.345865352233414e-05,
      "loss": 0.0378,
      "step": 32050
    },
    {
      "epoch": 0.981538744144751,
      "grad_norm": 0.03701549023389816,
      "learning_rate": 1.3456612476910675e-05,
      "loss": 0.0016,
      "step": 32060
    },
    {
      "epoch": 0.9818449009582708,
      "grad_norm": 0.015356089919805527,
      "learning_rate": 1.3454571431487208e-05,
      "loss": 0.0225,
      "step": 32070
    },
    {
      "epoch": 0.9821510577717907,
      "grad_norm": 0.021712729707360268,
      "learning_rate": 1.3452530386063742e-05,
      "loss": 0.0335,
      "step": 32080
    },
    {
      "epoch": 0.9824572145853105,
      "grad_norm": 0.01131400279700756,
      "learning_rate": 1.3450489340640277e-05,
      "loss": 0.0016,
      "step": 32090
    },
    {
      "epoch": 0.9827633713988305,
      "grad_norm": 0.014868132770061493,
      "learning_rate": 1.3448448295216811e-05,
      "loss": 0.0312,
      "step": 32100
    },
    {
      "epoch": 0.9830695282123504,
      "grad_norm": 0.005044965073466301,
      "learning_rate": 1.3446407249793345e-05,
      "loss": 0.0054,
      "step": 32110
    },
    {
      "epoch": 0.9833756850258702,
      "grad_norm": 0.04131061211228371,
      "learning_rate": 1.3444366204369878e-05,
      "loss": 0.0289,
      "step": 32120
    },
    {
      "epoch": 0.9836818418393901,
      "grad_norm": 0.03413930907845497,
      "learning_rate": 1.3442325158946414e-05,
      "loss": 0.0315,
      "step": 32130
    },
    {
      "epoch": 0.98398799865291,
      "grad_norm": 0.043117135763168335,
      "learning_rate": 1.3440284113522947e-05,
      "loss": 0.026,
      "step": 32140
    },
    {
      "epoch": 0.98429415546643,
      "grad_norm": 0.058430273085832596,
      "learning_rate": 1.3438243068099481e-05,
      "loss": 0.0282,
      "step": 32150
    },
    {
      "epoch": 0.9846003122799498,
      "grad_norm": 0.03975842893123627,
      "learning_rate": 1.3436202022676015e-05,
      "loss": 0.0015,
      "step": 32160
    },
    {
      "epoch": 0.9849064690934697,
      "grad_norm": 0.06901807337999344,
      "learning_rate": 1.343416097725255e-05,
      "loss": 0.0017,
      "step": 32170
    },
    {
      "epoch": 0.9852126259069895,
      "grad_norm": 0.042979441583156586,
      "learning_rate": 1.3432119931829084e-05,
      "loss": 0.0022,
      "step": 32180
    },
    {
      "epoch": 0.9855187827205094,
      "grad_norm": 0.046653591096401215,
      "learning_rate": 1.3430078886405617e-05,
      "loss": 0.0014,
      "step": 32190
    },
    {
      "epoch": 0.9858249395340293,
      "grad_norm": 0.041315555572509766,
      "learning_rate": 1.3428037840982153e-05,
      "loss": 0.0015,
      "step": 32200
    },
    {
      "epoch": 0.9861310963475493,
      "grad_norm": 0.042942918837070465,
      "learning_rate": 1.3425996795558686e-05,
      "loss": 0.0012,
      "step": 32210
    },
    {
      "epoch": 0.9864372531610691,
      "grad_norm": 0.025544704869389534,
      "learning_rate": 1.342395575013522e-05,
      "loss": 0.0011,
      "step": 32220
    },
    {
      "epoch": 0.986743409974589,
      "grad_norm": 0.023425819352269173,
      "learning_rate": 1.3421914704711753e-05,
      "loss": 0.0402,
      "step": 32230
    },
    {
      "epoch": 0.9870495667881088,
      "grad_norm": 0.03238486498594284,
      "learning_rate": 1.3419873659288289e-05,
      "loss": 0.0009,
      "step": 32240
    },
    {
      "epoch": 0.9873557236016287,
      "grad_norm": 0.007901012897491455,
      "learning_rate": 1.3417832613864822e-05,
      "loss": 0.0009,
      "step": 32250
    },
    {
      "epoch": 0.9876618804151487,
      "grad_norm": 0.03635750338435173,
      "learning_rate": 1.3415791568441356e-05,
      "loss": 0.001,
      "step": 32260
    },
    {
      "epoch": 0.9879680372286685,
      "grad_norm": 1.734671950340271,
      "learning_rate": 1.341375052301789e-05,
      "loss": 0.017,
      "step": 32270
    },
    {
      "epoch": 0.9882741940421884,
      "grad_norm": 0.0034880265593528748,
      "learning_rate": 1.3411709477594425e-05,
      "loss": 0.0008,
      "step": 32280
    },
    {
      "epoch": 0.9885803508557083,
      "grad_norm": 0.03376474976539612,
      "learning_rate": 1.3409668432170959e-05,
      "loss": 0.0116,
      "step": 32290
    },
    {
      "epoch": 0.9888865076692281,
      "grad_norm": 0.04584003984928131,
      "learning_rate": 1.3407627386747492e-05,
      "loss": 0.0013,
      "step": 32300
    },
    {
      "epoch": 0.9891926644827481,
      "grad_norm": 0.013265436515212059,
      "learning_rate": 1.3405586341324028e-05,
      "loss": 0.0334,
      "step": 32310
    },
    {
      "epoch": 0.989498821296268,
      "grad_norm": 0.03372945636510849,
      "learning_rate": 1.3403545295900561e-05,
      "loss": 0.0128,
      "step": 32320
    },
    {
      "epoch": 0.9898049781097878,
      "grad_norm": 0.020169654861092567,
      "learning_rate": 1.3401504250477095e-05,
      "loss": 0.0316,
      "step": 32330
    },
    {
      "epoch": 0.9901111349233077,
      "grad_norm": 0.013662370853126049,
      "learning_rate": 1.3399463205053629e-05,
      "loss": 0.0702,
      "step": 32340
    },
    {
      "epoch": 0.9904172917368276,
      "grad_norm": 0.07738527655601501,
      "learning_rate": 1.3397422159630164e-05,
      "loss": 0.0187,
      "step": 32350
    },
    {
      "epoch": 0.9907234485503474,
      "grad_norm": 0.0591144785284996,
      "learning_rate": 1.3395381114206698e-05,
      "loss": 0.002,
      "step": 32360
    },
    {
      "epoch": 0.9910296053638674,
      "grad_norm": 0.042680226266384125,
      "learning_rate": 1.3393340068783231e-05,
      "loss": 0.0014,
      "step": 32370
    },
    {
      "epoch": 0.9913357621773873,
      "grad_norm": 0.029815346002578735,
      "learning_rate": 1.3391299023359765e-05,
      "loss": 0.0017,
      "step": 32380
    },
    {
      "epoch": 0.9916419189909071,
      "grad_norm": 0.09022187441587448,
      "learning_rate": 1.33892579779363e-05,
      "loss": 0.0026,
      "step": 32390
    },
    {
      "epoch": 0.991948075804427,
      "grad_norm": 0.016008242964744568,
      "learning_rate": 1.3387216932512834e-05,
      "loss": 0.0014,
      "step": 32400
    },
    {
      "epoch": 0.9922542326179469,
      "grad_norm": 0.022037124261260033,
      "learning_rate": 1.3385175887089368e-05,
      "loss": 0.0317,
      "step": 32410
    },
    {
      "epoch": 0.9925603894314668,
      "grad_norm": 0.027912097051739693,
      "learning_rate": 1.3383134841665901e-05,
      "loss": 0.0009,
      "step": 32420
    },
    {
      "epoch": 0.9928665462449867,
      "grad_norm": 0.0664585679769516,
      "learning_rate": 1.3381093796242437e-05,
      "loss": 0.0012,
      "step": 32430
    },
    {
      "epoch": 0.9931727030585066,
      "grad_norm": 0.057803697884082794,
      "learning_rate": 1.337905275081897e-05,
      "loss": 0.0012,
      "step": 32440
    },
    {
      "epoch": 0.9934788598720264,
      "grad_norm": 0.02343204990029335,
      "learning_rate": 1.3377011705395504e-05,
      "loss": 0.0011,
      "step": 32450
    },
    {
      "epoch": 0.9937850166855463,
      "grad_norm": 0.03768683969974518,
      "learning_rate": 1.337497065997204e-05,
      "loss": 0.0013,
      "step": 32460
    },
    {
      "epoch": 0.9940911734990662,
      "grad_norm": 0.009941102005541325,
      "learning_rate": 1.3372929614548573e-05,
      "loss": 0.0009,
      "step": 32470
    },
    {
      "epoch": 0.9943973303125861,
      "grad_norm": 0.10239473730325699,
      "learning_rate": 1.3370888569125106e-05,
      "loss": 0.001,
      "step": 32480
    },
    {
      "epoch": 0.994703487126106,
      "grad_norm": 0.022754564881324768,
      "learning_rate": 1.336884752370164e-05,
      "loss": 0.0011,
      "step": 32490
    },
    {
      "epoch": 0.9950096439396259,
      "grad_norm": 1.3223216533660889,
      "learning_rate": 1.3366806478278175e-05,
      "loss": 0.0497,
      "step": 32500
    },
    {
      "epoch": 0.9953158007531457,
      "grad_norm": 0.01074657030403614,
      "learning_rate": 1.3364765432854709e-05,
      "loss": 0.0008,
      "step": 32510
    },
    {
      "epoch": 0.9956219575666656,
      "grad_norm": 0.03190135583281517,
      "learning_rate": 1.3362724387431243e-05,
      "loss": 0.0017,
      "step": 32520
    },
    {
      "epoch": 0.9959281143801856,
      "grad_norm": 0.02071104571223259,
      "learning_rate": 1.3360683342007776e-05,
      "loss": 0.0012,
      "step": 32530
    },
    {
      "epoch": 0.9962342711937054,
      "grad_norm": 0.009832584299147129,
      "learning_rate": 1.3358642296584312e-05,
      "loss": 0.0007,
      "step": 32540
    },
    {
      "epoch": 0.9965404280072253,
      "grad_norm": 0.04831237345933914,
      "learning_rate": 1.3356601251160845e-05,
      "loss": 0.0009,
      "step": 32550
    },
    {
      "epoch": 0.9968465848207452,
      "grad_norm": 0.01645953767001629,
      "learning_rate": 1.3354560205737379e-05,
      "loss": 0.0006,
      "step": 32560
    },
    {
      "epoch": 0.997152741634265,
      "grad_norm": 0.02158573642373085,
      "learning_rate": 1.3352519160313914e-05,
      "loss": 0.0441,
      "step": 32570
    },
    {
      "epoch": 0.9974588984477849,
      "grad_norm": 0.13215503096580505,
      "learning_rate": 1.3350478114890448e-05,
      "loss": 0.0009,
      "step": 32580
    },
    {
      "epoch": 0.9977650552613049,
      "grad_norm": 0.01524084061384201,
      "learning_rate": 1.3348437069466982e-05,
      "loss": 0.001,
      "step": 32590
    },
    {
      "epoch": 0.9980712120748247,
      "grad_norm": 1.7426728010177612,
      "learning_rate": 1.3346396024043515e-05,
      "loss": 0.0097,
      "step": 32600
    },
    {
      "epoch": 0.9983773688883446,
      "grad_norm": 0.014204748906195164,
      "learning_rate": 1.334435497862005e-05,
      "loss": 0.0005,
      "step": 32610
    },
    {
      "epoch": 0.9986835257018645,
      "grad_norm": 0.019144024699926376,
      "learning_rate": 1.3342313933196584e-05,
      "loss": 0.0008,
      "step": 32620
    },
    {
      "epoch": 0.9989896825153843,
      "grad_norm": 0.02688477374613285,
      "learning_rate": 1.3340272887773118e-05,
      "loss": 0.0383,
      "step": 32630
    },
    {
      "epoch": 0.9992958393289043,
      "grad_norm": 0.010177631862461567,
      "learning_rate": 1.3338231842349652e-05,
      "loss": 0.0157,
      "step": 32640
    },
    {
      "epoch": 0.9996019961424242,
      "grad_norm": 0.017077896744012833,
      "learning_rate": 1.3336190796926187e-05,
      "loss": 0.0007,
      "step": 32650
    },
    {
      "epoch": 0.999908152955944,
      "grad_norm": 0.03272604942321777,
      "learning_rate": 1.333414975150272e-05,
      "loss": 0.034,
      "step": 32660
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9971603520857252,
      "eval_f1": 0.9971603398681192,
      "eval_loss": 0.016291532665491104,
      "eval_precision": 0.9971689083404661,
      "eval_recall": 0.9971603520857253,
      "eval_runtime": 1137.5865,
      "eval_samples_per_second": 114.848,
      "eval_steps_per_second": 7.178,
      "step": 32663
    },
    {
      "epoch": 1.000214309769464,
      "grad_norm": 0.009736635722219944,
      "learning_rate": 1.3332108706079254e-05,
      "loss": 0.0125,
      "step": 32670
    },
    {
      "epoch": 1.0005204665829839,
      "grad_norm": 0.03323608636856079,
      "learning_rate": 1.333006766065579e-05,
      "loss": 0.0009,
      "step": 32680
    },
    {
      "epoch": 1.0008266233965037,
      "grad_norm": 0.014850493520498276,
      "learning_rate": 1.3328026615232323e-05,
      "loss": 0.0007,
      "step": 32690
    },
    {
      "epoch": 1.0011327802100236,
      "grad_norm": 0.03292962536215782,
      "learning_rate": 1.3325985569808857e-05,
      "loss": 0.0593,
      "step": 32700
    },
    {
      "epoch": 1.0014389370235435,
      "grad_norm": 0.041904401034116745,
      "learning_rate": 1.332394452438539e-05,
      "loss": 0.001,
      "step": 32710
    },
    {
      "epoch": 1.0017450938370633,
      "grad_norm": 0.021273043006658554,
      "learning_rate": 1.3321903478961926e-05,
      "loss": 0.0006,
      "step": 32720
    },
    {
      "epoch": 1.0020512506505832,
      "grad_norm": 0.02226812019944191,
      "learning_rate": 1.331986243353846e-05,
      "loss": 0.0011,
      "step": 32730
    },
    {
      "epoch": 1.002357407464103,
      "grad_norm": 0.005039264913648367,
      "learning_rate": 1.3317821388114993e-05,
      "loss": 0.001,
      "step": 32740
    },
    {
      "epoch": 1.002663564277623,
      "grad_norm": 0.02596105821430683,
      "learning_rate": 1.3315780342691527e-05,
      "loss": 0.0008,
      "step": 32750
    },
    {
      "epoch": 1.0029697210911428,
      "grad_norm": 0.007312850095331669,
      "learning_rate": 1.3313739297268062e-05,
      "loss": 0.0008,
      "step": 32760
    },
    {
      "epoch": 1.0032758779046627,
      "grad_norm": 0.018620913848280907,
      "learning_rate": 1.3311698251844596e-05,
      "loss": 0.0012,
      "step": 32770
    },
    {
      "epoch": 1.0035820347181827,
      "grad_norm": 0.012627416290342808,
      "learning_rate": 1.330965720642113e-05,
      "loss": 0.0007,
      "step": 32780
    },
    {
      "epoch": 1.0038881915317026,
      "grad_norm": 0.044299669563770294,
      "learning_rate": 1.3307616160997665e-05,
      "loss": 0.0368,
      "step": 32790
    },
    {
      "epoch": 1.0041943483452225,
      "grad_norm": 0.022350911051034927,
      "learning_rate": 1.3305575115574198e-05,
      "loss": 0.001,
      "step": 32800
    },
    {
      "epoch": 1.0045005051587423,
      "grad_norm": 0.036288224160671234,
      "learning_rate": 1.3303534070150732e-05,
      "loss": 0.0348,
      "step": 32810
    },
    {
      "epoch": 1.0048066619722622,
      "grad_norm": 0.00775185925886035,
      "learning_rate": 1.3301493024727266e-05,
      "loss": 0.0371,
      "step": 32820
    },
    {
      "epoch": 1.005112818785782,
      "grad_norm": 0.0462619923055172,
      "learning_rate": 1.3299451979303801e-05,
      "loss": 0.0328,
      "step": 32830
    },
    {
      "epoch": 1.005418975599302,
      "grad_norm": 0.01693604700267315,
      "learning_rate": 1.3297410933880335e-05,
      "loss": 0.0013,
      "step": 32840
    },
    {
      "epoch": 1.0057251324128218,
      "grad_norm": 0.011695641092956066,
      "learning_rate": 1.3295369888456868e-05,
      "loss": 0.0011,
      "step": 32850
    },
    {
      "epoch": 1.0060312892263417,
      "grad_norm": 0.01659657247364521,
      "learning_rate": 1.3293328843033402e-05,
      "loss": 0.0244,
      "step": 32860
    },
    {
      "epoch": 1.0063374460398615,
      "grad_norm": 0.04912686347961426,
      "learning_rate": 1.3291287797609937e-05,
      "loss": 0.0011,
      "step": 32870
    },
    {
      "epoch": 1.0066436028533814,
      "grad_norm": 0.027475519105792046,
      "learning_rate": 1.3289246752186471e-05,
      "loss": 0.0624,
      "step": 32880
    },
    {
      "epoch": 1.0069497596669015,
      "grad_norm": 0.008868526667356491,
      "learning_rate": 1.3287205706763004e-05,
      "loss": 0.0315,
      "step": 32890
    },
    {
      "epoch": 1.0072559164804213,
      "grad_norm": 0.02776714414358139,
      "learning_rate": 1.328516466133954e-05,
      "loss": 0.0035,
      "step": 32900
    },
    {
      "epoch": 1.0075620732939412,
      "grad_norm": 0.03248879313468933,
      "learning_rate": 1.3283123615916073e-05,
      "loss": 0.0039,
      "step": 32910
    },
    {
      "epoch": 1.007868230107461,
      "grad_norm": 0.12570855021476746,
      "learning_rate": 1.3281082570492607e-05,
      "loss": 0.0009,
      "step": 32920
    },
    {
      "epoch": 1.008174386920981,
      "grad_norm": 0.023911599069833755,
      "learning_rate": 1.327904152506914e-05,
      "loss": 0.0008,
      "step": 32930
    },
    {
      "epoch": 1.0084805437345008,
      "grad_norm": 0.010775210335850716,
      "learning_rate": 1.3277000479645676e-05,
      "loss": 0.001,
      "step": 32940
    },
    {
      "epoch": 1.0087867005480207,
      "grad_norm": 0.029713500291109085,
      "learning_rate": 1.327495943422221e-05,
      "loss": 0.0008,
      "step": 32950
    },
    {
      "epoch": 1.0090928573615405,
      "grad_norm": 0.0037527047097682953,
      "learning_rate": 1.3272918388798743e-05,
      "loss": 0.0006,
      "step": 32960
    },
    {
      "epoch": 1.0093990141750604,
      "grad_norm": 0.01387638971209526,
      "learning_rate": 1.3270877343375277e-05,
      "loss": 0.0006,
      "step": 32970
    },
    {
      "epoch": 1.0097051709885803,
      "grad_norm": 0.008672822266817093,
      "learning_rate": 1.3268836297951812e-05,
      "loss": 0.0014,
      "step": 32980
    },
    {
      "epoch": 1.0100113278021003,
      "grad_norm": 0.012257816269993782,
      "learning_rate": 1.3266795252528346e-05,
      "loss": 0.0289,
      "step": 32990
    },
    {
      "epoch": 1.0103174846156202,
      "grad_norm": 0.011781164444983006,
      "learning_rate": 1.326475420710488e-05,
      "loss": 0.0335,
      "step": 33000
    },
    {
      "epoch": 1.01062364142914,
      "grad_norm": 0.037078410387039185,
      "learning_rate": 1.3262713161681415e-05,
      "loss": 0.0413,
      "step": 33010
    },
    {
      "epoch": 1.01092979824266,
      "grad_norm": 0.032009560614824295,
      "learning_rate": 1.3260672116257949e-05,
      "loss": 0.0699,
      "step": 33020
    },
    {
      "epoch": 1.0112359550561798,
      "grad_norm": 0.04227394983172417,
      "learning_rate": 1.3258631070834482e-05,
      "loss": 0.0013,
      "step": 33030
    },
    {
      "epoch": 1.0115421118696997,
      "grad_norm": 0.006706748623400927,
      "learning_rate": 1.3256590025411016e-05,
      "loss": 0.0011,
      "step": 33040
    },
    {
      "epoch": 1.0118482686832195,
      "grad_norm": 0.03700315207242966,
      "learning_rate": 1.3254548979987551e-05,
      "loss": 0.0028,
      "step": 33050
    },
    {
      "epoch": 1.0121544254967394,
      "grad_norm": 0.03299689665436745,
      "learning_rate": 1.3252507934564085e-05,
      "loss": 0.0016,
      "step": 33060
    },
    {
      "epoch": 1.0124605823102593,
      "grad_norm": 0.0497879683971405,
      "learning_rate": 1.3250466889140619e-05,
      "loss": 0.0362,
      "step": 33070
    },
    {
      "epoch": 1.0127667391237791,
      "grad_norm": 0.02119133435189724,
      "learning_rate": 1.3248425843717152e-05,
      "loss": 0.0013,
      "step": 33080
    },
    {
      "epoch": 1.013072895937299,
      "grad_norm": 0.061598557978868484,
      "learning_rate": 1.3246384798293688e-05,
      "loss": 0.0662,
      "step": 33090
    },
    {
      "epoch": 1.013379052750819,
      "grad_norm": 0.06674746423959732,
      "learning_rate": 1.3244343752870221e-05,
      "loss": 0.0014,
      "step": 33100
    },
    {
      "epoch": 1.013685209564339,
      "grad_norm": 0.041944872587919235,
      "learning_rate": 1.3242302707446755e-05,
      "loss": 0.0015,
      "step": 33110
    },
    {
      "epoch": 1.0139913663778588,
      "grad_norm": 0.026569010689854622,
      "learning_rate": 1.324026166202329e-05,
      "loss": 0.0014,
      "step": 33120
    },
    {
      "epoch": 1.0142975231913787,
      "grad_norm": 0.04233933985233307,
      "learning_rate": 1.3238220616599824e-05,
      "loss": 0.0386,
      "step": 33130
    },
    {
      "epoch": 1.0146036800048985,
      "grad_norm": 0.04849424958229065,
      "learning_rate": 1.3236179571176357e-05,
      "loss": 0.0371,
      "step": 33140
    },
    {
      "epoch": 1.0149098368184184,
      "grad_norm": 0.603188693523407,
      "learning_rate": 1.3234138525752891e-05,
      "loss": 0.002,
      "step": 33150
    },
    {
      "epoch": 1.0152159936319383,
      "grad_norm": 0.03323609381914139,
      "learning_rate": 1.3232097480329426e-05,
      "loss": 0.0414,
      "step": 33160
    },
    {
      "epoch": 1.0155221504454581,
      "grad_norm": 0.04234595596790314,
      "learning_rate": 1.323005643490596e-05,
      "loss": 0.0285,
      "step": 33170
    },
    {
      "epoch": 1.015828307258978,
      "grad_norm": 1.8184760808944702,
      "learning_rate": 1.3228015389482494e-05,
      "loss": 0.0854,
      "step": 33180
    },
    {
      "epoch": 1.0161344640724979,
      "grad_norm": 0.07126205414533615,
      "learning_rate": 1.3225974344059027e-05,
      "loss": 0.0021,
      "step": 33190
    },
    {
      "epoch": 1.0164406208860177,
      "grad_norm": 0.10440219193696976,
      "learning_rate": 1.3223933298635563e-05,
      "loss": 0.0018,
      "step": 33200
    },
    {
      "epoch": 1.0167467776995378,
      "grad_norm": 0.07728098332881927,
      "learning_rate": 1.3221892253212096e-05,
      "loss": 0.0018,
      "step": 33210
    },
    {
      "epoch": 1.0170529345130577,
      "grad_norm": 0.08895755559206009,
      "learning_rate": 1.321985120778863e-05,
      "loss": 0.0266,
      "step": 33220
    },
    {
      "epoch": 1.0173590913265775,
      "grad_norm": 0.08050727844238281,
      "learning_rate": 1.3217810162365165e-05,
      "loss": 0.0021,
      "step": 33230
    },
    {
      "epoch": 1.0176652481400974,
      "grad_norm": 0.051491204649209976,
      "learning_rate": 1.3215769116941699e-05,
      "loss": 0.029,
      "step": 33240
    },
    {
      "epoch": 1.0179714049536173,
      "grad_norm": 0.09039949625730515,
      "learning_rate": 1.3213728071518233e-05,
      "loss": 0.0029,
      "step": 33250
    },
    {
      "epoch": 1.0182775617671371,
      "grad_norm": 0.060876086354255676,
      "learning_rate": 1.3211687026094766e-05,
      "loss": 0.002,
      "step": 33260
    },
    {
      "epoch": 1.018583718580657,
      "grad_norm": 0.03598368167877197,
      "learning_rate": 1.3209645980671302e-05,
      "loss": 0.0016,
      "step": 33270
    },
    {
      "epoch": 1.0188898753941769,
      "grad_norm": 0.06737896800041199,
      "learning_rate": 1.3207604935247835e-05,
      "loss": 0.0432,
      "step": 33280
    },
    {
      "epoch": 1.0191960322076967,
      "grad_norm": 2.0733933448791504,
      "learning_rate": 1.3205563889824369e-05,
      "loss": 0.1234,
      "step": 33290
    },
    {
      "epoch": 1.0195021890212166,
      "grad_norm": 0.26219815015792847,
      "learning_rate": 1.3203522844400903e-05,
      "loss": 0.0242,
      "step": 33300
    },
    {
      "epoch": 1.0198083458347365,
      "grad_norm": 0.0702202096581459,
      "learning_rate": 1.3201481798977438e-05,
      "loss": 0.003,
      "step": 33310
    },
    {
      "epoch": 1.0201145026482565,
      "grad_norm": 0.14297017455101013,
      "learning_rate": 1.3199440753553972e-05,
      "loss": 0.0326,
      "step": 33320
    },
    {
      "epoch": 1.0204206594617764,
      "grad_norm": 0.05840935558080673,
      "learning_rate": 1.3197399708130505e-05,
      "loss": 0.0291,
      "step": 33330
    },
    {
      "epoch": 1.0207268162752963,
      "grad_norm": 0.06862006336450577,
      "learning_rate": 1.319535866270704e-05,
      "loss": 0.0028,
      "step": 33340
    },
    {
      "epoch": 1.0210329730888161,
      "grad_norm": 0.04912714287638664,
      "learning_rate": 1.3193317617283574e-05,
      "loss": 0.0033,
      "step": 33350
    },
    {
      "epoch": 1.021339129902336,
      "grad_norm": 0.05613843351602554,
      "learning_rate": 1.3191276571860108e-05,
      "loss": 0.0296,
      "step": 33360
    },
    {
      "epoch": 1.0216452867158559,
      "grad_norm": 0.06210184842348099,
      "learning_rate": 1.3189235526436641e-05,
      "loss": 0.0027,
      "step": 33370
    },
    {
      "epoch": 1.0219514435293757,
      "grad_norm": 0.17282572388648987,
      "learning_rate": 1.3187194481013177e-05,
      "loss": 0.0027,
      "step": 33380
    },
    {
      "epoch": 1.0222576003428956,
      "grad_norm": 0.04412848502397537,
      "learning_rate": 1.318515343558971e-05,
      "loss": 0.0015,
      "step": 33390
    },
    {
      "epoch": 1.0225637571564155,
      "grad_norm": 0.021247623488307,
      "learning_rate": 1.3183112390166244e-05,
      "loss": 0.002,
      "step": 33400
    },
    {
      "epoch": 1.0228699139699353,
      "grad_norm": 0.09100113064050674,
      "learning_rate": 1.3181071344742778e-05,
      "loss": 0.0012,
      "step": 33410
    },
    {
      "epoch": 1.0231760707834552,
      "grad_norm": 0.008779136463999748,
      "learning_rate": 1.3179030299319313e-05,
      "loss": 0.001,
      "step": 33420
    },
    {
      "epoch": 1.0234822275969753,
      "grad_norm": 0.03529338538646698,
      "learning_rate": 1.3176989253895847e-05,
      "loss": 0.0012,
      "step": 33430
    },
    {
      "epoch": 1.0237883844104951,
      "grad_norm": 0.1019580066204071,
      "learning_rate": 1.317494820847238e-05,
      "loss": 0.0012,
      "step": 33440
    },
    {
      "epoch": 1.024094541224015,
      "grad_norm": 0.04989078640937805,
      "learning_rate": 1.3172907163048916e-05,
      "loss": 0.0372,
      "step": 33450
    },
    {
      "epoch": 1.0244006980375349,
      "grad_norm": 0.029669148847460747,
      "learning_rate": 1.317086611762545e-05,
      "loss": 0.0687,
      "step": 33460
    },
    {
      "epoch": 1.0247068548510547,
      "grad_norm": 0.03420776501297951,
      "learning_rate": 1.3168825072201983e-05,
      "loss": 0.003,
      "step": 33470
    },
    {
      "epoch": 1.0250130116645746,
      "grad_norm": 0.02990049310028553,
      "learning_rate": 1.3166784026778517e-05,
      "loss": 0.0017,
      "step": 33480
    },
    {
      "epoch": 1.0253191684780945,
      "grad_norm": 0.037676963955163956,
      "learning_rate": 1.3164742981355052e-05,
      "loss": 0.0044,
      "step": 33490
    },
    {
      "epoch": 1.0256253252916143,
      "grad_norm": 0.025323636829853058,
      "learning_rate": 1.3162701935931586e-05,
      "loss": 0.0011,
      "step": 33500
    },
    {
      "epoch": 1.0259314821051342,
      "grad_norm": 0.02153324894607067,
      "learning_rate": 1.316066089050812e-05,
      "loss": 0.0016,
      "step": 33510
    },
    {
      "epoch": 1.026237638918654,
      "grad_norm": 0.017222631722688675,
      "learning_rate": 1.3158619845084653e-05,
      "loss": 0.0009,
      "step": 33520
    },
    {
      "epoch": 1.026543795732174,
      "grad_norm": 0.03402397409081459,
      "learning_rate": 1.3156578799661188e-05,
      "loss": 0.0399,
      "step": 33530
    },
    {
      "epoch": 1.026849952545694,
      "grad_norm": 1.6956040859222412,
      "learning_rate": 1.3154537754237722e-05,
      "loss": 0.0604,
      "step": 33540
    },
    {
      "epoch": 1.0271561093592139,
      "grad_norm": 0.03708385303616524,
      "learning_rate": 1.3152496708814256e-05,
      "loss": 0.004,
      "step": 33550
    },
    {
      "epoch": 1.0274622661727337,
      "grad_norm": 0.0007489018607884645,
      "learning_rate": 1.3150455663390791e-05,
      "loss": 0.0347,
      "step": 33560
    },
    {
      "epoch": 1.0277684229862536,
      "grad_norm": 0.018876351416110992,
      "learning_rate": 1.3148414617967324e-05,
      "loss": 0.0017,
      "step": 33570
    },
    {
      "epoch": 1.0280745797997735,
      "grad_norm": 0.018353881314396858,
      "learning_rate": 1.3146373572543858e-05,
      "loss": 0.0013,
      "step": 33580
    },
    {
      "epoch": 1.0283807366132933,
      "grad_norm": 0.02139139175415039,
      "learning_rate": 1.3144332527120392e-05,
      "loss": 0.0029,
      "step": 33590
    },
    {
      "epoch": 1.0286868934268132,
      "grad_norm": 0.025510303676128387,
      "learning_rate": 1.3142291481696927e-05,
      "loss": 0.0011,
      "step": 33600
    },
    {
      "epoch": 1.028993050240333,
      "grad_norm": 0.028287801891565323,
      "learning_rate": 1.314025043627346e-05,
      "loss": 0.0009,
      "step": 33610
    },
    {
      "epoch": 1.029299207053853,
      "grad_norm": 0.022932464256882668,
      "learning_rate": 1.3138209390849994e-05,
      "loss": 0.0312,
      "step": 33620
    },
    {
      "epoch": 1.0296053638673728,
      "grad_norm": 0.0196966715157032,
      "learning_rate": 1.3136168345426528e-05,
      "loss": 0.0009,
      "step": 33630
    },
    {
      "epoch": 1.0299115206808926,
      "grad_norm": 0.0532405860722065,
      "learning_rate": 1.3134127300003063e-05,
      "loss": 0.0013,
      "step": 33640
    },
    {
      "epoch": 1.0302176774944127,
      "grad_norm": 0.009061426855623722,
      "learning_rate": 1.3132086254579597e-05,
      "loss": 0.0056,
      "step": 33650
    },
    {
      "epoch": 1.0305238343079326,
      "grad_norm": 0.00848089437931776,
      "learning_rate": 1.313004520915613e-05,
      "loss": 0.0014,
      "step": 33660
    },
    {
      "epoch": 1.0308299911214525,
      "grad_norm": 0.05329947546124458,
      "learning_rate": 1.3128004163732664e-05,
      "loss": 0.001,
      "step": 33670
    },
    {
      "epoch": 1.0311361479349723,
      "grad_norm": 0.0272201094776392,
      "learning_rate": 1.31259631183092e-05,
      "loss": 0.0011,
      "step": 33680
    },
    {
      "epoch": 1.0314423047484922,
      "grad_norm": 0.019199106842279434,
      "learning_rate": 1.3123922072885733e-05,
      "loss": 0.0011,
      "step": 33690
    },
    {
      "epoch": 1.031748461562012,
      "grad_norm": 0.018449164927005768,
      "learning_rate": 1.3121881027462267e-05,
      "loss": 0.0011,
      "step": 33700
    },
    {
      "epoch": 1.032054618375532,
      "grad_norm": 0.04414188116788864,
      "learning_rate": 1.3119839982038802e-05,
      "loss": 0.0766,
      "step": 33710
    },
    {
      "epoch": 1.0323607751890518,
      "grad_norm": 0.03869744390249252,
      "learning_rate": 1.3117798936615336e-05,
      "loss": 0.0115,
      "step": 33720
    },
    {
      "epoch": 1.0326669320025716,
      "grad_norm": 0.04980822280049324,
      "learning_rate": 1.311575789119187e-05,
      "loss": 0.001,
      "step": 33730
    },
    {
      "epoch": 1.0329730888160915,
      "grad_norm": 0.02253788150846958,
      "learning_rate": 1.3113716845768403e-05,
      "loss": 0.0011,
      "step": 33740
    },
    {
      "epoch": 1.0332792456296116,
      "grad_norm": 0.05282595753669739,
      "learning_rate": 1.3111675800344939e-05,
      "loss": 0.0691,
      "step": 33750
    },
    {
      "epoch": 1.0335854024431315,
      "grad_norm": 0.03256310895085335,
      "learning_rate": 1.3109634754921472e-05,
      "loss": 0.0009,
      "step": 33760
    },
    {
      "epoch": 1.0338915592566513,
      "grad_norm": 0.05845917388796806,
      "learning_rate": 1.3107593709498006e-05,
      "loss": 0.0366,
      "step": 33770
    },
    {
      "epoch": 1.0341977160701712,
      "grad_norm": 0.026910450309515,
      "learning_rate": 1.310555266407454e-05,
      "loss": 0.0268,
      "step": 33780
    },
    {
      "epoch": 1.034503872883691,
      "grad_norm": 0.05126591771841049,
      "learning_rate": 1.3103511618651075e-05,
      "loss": 0.0024,
      "step": 33790
    },
    {
      "epoch": 1.034810029697211,
      "grad_norm": 0.0853205993771553,
      "learning_rate": 1.3101470573227608e-05,
      "loss": 0.029,
      "step": 33800
    },
    {
      "epoch": 1.0351161865107308,
      "grad_norm": 0.02234148234128952,
      "learning_rate": 1.3099429527804142e-05,
      "loss": 0.031,
      "step": 33810
    },
    {
      "epoch": 1.0354223433242506,
      "grad_norm": 0.024647079408168793,
      "learning_rate": 1.3097388482380677e-05,
      "loss": 0.0362,
      "step": 33820
    },
    {
      "epoch": 1.0357285001377705,
      "grad_norm": 0.028245802968740463,
      "learning_rate": 1.3095347436957211e-05,
      "loss": 0.0015,
      "step": 33830
    },
    {
      "epoch": 1.0360346569512904,
      "grad_norm": 0.023048238828778267,
      "learning_rate": 1.3093306391533745e-05,
      "loss": 0.0015,
      "step": 33840
    },
    {
      "epoch": 1.0363408137648102,
      "grad_norm": 0.005401611793786287,
      "learning_rate": 1.3091265346110278e-05,
      "loss": 0.0022,
      "step": 33850
    },
    {
      "epoch": 1.0366469705783303,
      "grad_norm": 0.04401297867298126,
      "learning_rate": 1.3089224300686814e-05,
      "loss": 0.0013,
      "step": 33860
    },
    {
      "epoch": 1.0369531273918502,
      "grad_norm": 0.06997378915548325,
      "learning_rate": 1.3087183255263347e-05,
      "loss": 0.006,
      "step": 33870
    },
    {
      "epoch": 1.03725928420537,
      "grad_norm": 0.024899663403630257,
      "learning_rate": 1.3085142209839881e-05,
      "loss": 0.0017,
      "step": 33880
    },
    {
      "epoch": 1.03756544101889,
      "grad_norm": 0.625485360622406,
      "learning_rate": 1.3083101164416415e-05,
      "loss": 0.0323,
      "step": 33890
    },
    {
      "epoch": 1.0378715978324098,
      "grad_norm": 0.03577469661831856,
      "learning_rate": 1.308106011899295e-05,
      "loss": 0.001,
      "step": 33900
    },
    {
      "epoch": 1.0381777546459297,
      "grad_norm": 0.008662690408527851,
      "learning_rate": 1.3079019073569484e-05,
      "loss": 0.0017,
      "step": 33910
    },
    {
      "epoch": 1.0384839114594495,
      "grad_norm": 0.07217277586460114,
      "learning_rate": 1.3076978028146017e-05,
      "loss": 0.0011,
      "step": 33920
    },
    {
      "epoch": 1.0387900682729694,
      "grad_norm": 0.019799550995230675,
      "learning_rate": 1.3074936982722553e-05,
      "loss": 0.0797,
      "step": 33930
    },
    {
      "epoch": 1.0390962250864892,
      "grad_norm": 0.04330550134181976,
      "learning_rate": 1.3072895937299086e-05,
      "loss": 0.0402,
      "step": 33940
    },
    {
      "epoch": 1.039402381900009,
      "grad_norm": 0.019356433302164078,
      "learning_rate": 1.307085489187562e-05,
      "loss": 0.0014,
      "step": 33950
    },
    {
      "epoch": 1.039708538713529,
      "grad_norm": 0.04575742408633232,
      "learning_rate": 1.3068813846452154e-05,
      "loss": 0.0213,
      "step": 33960
    },
    {
      "epoch": 1.040014695527049,
      "grad_norm": 0.043985966593027115,
      "learning_rate": 1.3066772801028689e-05,
      "loss": 0.028,
      "step": 33970
    },
    {
      "epoch": 1.040320852340569,
      "grad_norm": 0.018432173877954483,
      "learning_rate": 1.3064731755605223e-05,
      "loss": 0.0286,
      "step": 33980
    },
    {
      "epoch": 1.0406270091540888,
      "grad_norm": 0.054565638303756714,
      "learning_rate": 1.3062690710181756e-05,
      "loss": 0.0022,
      "step": 33990
    },
    {
      "epoch": 1.0409331659676087,
      "grad_norm": 0.02389298379421234,
      "learning_rate": 1.306064966475829e-05,
      "loss": 0.0028,
      "step": 34000
    },
    {
      "epoch": 1.0412393227811285,
      "grad_norm": 0.060667913407087326,
      "learning_rate": 1.3058608619334825e-05,
      "loss": 0.0215,
      "step": 34010
    },
    {
      "epoch": 1.0415454795946484,
      "grad_norm": 0.04161492735147476,
      "learning_rate": 1.3056567573911359e-05,
      "loss": 0.028,
      "step": 34020
    },
    {
      "epoch": 1.0418516364081682,
      "grad_norm": 0.33278071880340576,
      "learning_rate": 1.3054526528487892e-05,
      "loss": 0.0021,
      "step": 34030
    },
    {
      "epoch": 1.0421577932216881,
      "grad_norm": 0.04497915878891945,
      "learning_rate": 1.3052485483064428e-05,
      "loss": 0.0022,
      "step": 34040
    },
    {
      "epoch": 1.042463950035208,
      "grad_norm": 0.023518593981862068,
      "learning_rate": 1.3050444437640961e-05,
      "loss": 0.0336,
      "step": 34050
    },
    {
      "epoch": 1.0427701068487278,
      "grad_norm": 0.050954822450876236,
      "learning_rate": 1.3048403392217495e-05,
      "loss": 0.0017,
      "step": 34060
    },
    {
      "epoch": 1.0430762636622477,
      "grad_norm": 0.02952161803841591,
      "learning_rate": 1.3046362346794029e-05,
      "loss": 0.0027,
      "step": 34070
    },
    {
      "epoch": 1.0433824204757678,
      "grad_norm": 0.12745526432991028,
      "learning_rate": 1.3044321301370564e-05,
      "loss": 0.0017,
      "step": 34080
    },
    {
      "epoch": 1.0436885772892877,
      "grad_norm": 0.04057220742106438,
      "learning_rate": 1.3042280255947098e-05,
      "loss": 0.0013,
      "step": 34090
    },
    {
      "epoch": 1.0439947341028075,
      "grad_norm": 0.06807763129472733,
      "learning_rate": 1.3040239210523631e-05,
      "loss": 0.0013,
      "step": 34100
    },
    {
      "epoch": 1.0443008909163274,
      "grad_norm": 0.042795367538928986,
      "learning_rate": 1.3038198165100165e-05,
      "loss": 0.0683,
      "step": 34110
    },
    {
      "epoch": 1.0446070477298472,
      "grad_norm": 0.0351506806910038,
      "learning_rate": 1.30361571196767e-05,
      "loss": 0.0018,
      "step": 34120
    },
    {
      "epoch": 1.0449132045433671,
      "grad_norm": 0.054408565163612366,
      "learning_rate": 1.3034116074253234e-05,
      "loss": 0.0015,
      "step": 34130
    },
    {
      "epoch": 1.045219361356887,
      "grad_norm": 0.01345829013735056,
      "learning_rate": 1.3032075028829768e-05,
      "loss": 0.0012,
      "step": 34140
    },
    {
      "epoch": 1.0455255181704068,
      "grad_norm": 0.0055045620538294315,
      "learning_rate": 1.3030033983406303e-05,
      "loss": 0.001,
      "step": 34150
    },
    {
      "epoch": 1.0458316749839267,
      "grad_norm": 0.31246232986450195,
      "learning_rate": 1.3027992937982837e-05,
      "loss": 0.0016,
      "step": 34160
    },
    {
      "epoch": 1.0461378317974466,
      "grad_norm": 0.029093673452734947,
      "learning_rate": 1.302595189255937e-05,
      "loss": 0.001,
      "step": 34170
    },
    {
      "epoch": 1.0464439886109664,
      "grad_norm": 0.027321303263306618,
      "learning_rate": 1.3023910847135904e-05,
      "loss": 0.0011,
      "step": 34180
    },
    {
      "epoch": 1.0467501454244865,
      "grad_norm": 0.04943632334470749,
      "learning_rate": 1.302186980171244e-05,
      "loss": 0.0044,
      "step": 34190
    },
    {
      "epoch": 1.0470563022380064,
      "grad_norm": 1.8244426250457764,
      "learning_rate": 1.3019828756288973e-05,
      "loss": 0.0323,
      "step": 34200
    },
    {
      "epoch": 1.0473624590515263,
      "grad_norm": 0.044033996760845184,
      "learning_rate": 1.3017787710865507e-05,
      "loss": 0.0017,
      "step": 34210
    },
    {
      "epoch": 1.0476686158650461,
      "grad_norm": 0.004640095867216587,
      "learning_rate": 1.301574666544204e-05,
      "loss": 0.0009,
      "step": 34220
    },
    {
      "epoch": 1.047974772678566,
      "grad_norm": 0.023706313222646713,
      "learning_rate": 1.3013705620018576e-05,
      "loss": 0.0008,
      "step": 34230
    },
    {
      "epoch": 1.0482809294920858,
      "grad_norm": 0.020666126161813736,
      "learning_rate": 1.3011664574595109e-05,
      "loss": 0.0008,
      "step": 34240
    },
    {
      "epoch": 1.0485870863056057,
      "grad_norm": 0.018816815689206123,
      "learning_rate": 1.3009623529171643e-05,
      "loss": 0.0079,
      "step": 34250
    },
    {
      "epoch": 1.0488932431191256,
      "grad_norm": 0.005065178032964468,
      "learning_rate": 1.3007582483748178e-05,
      "loss": 0.0131,
      "step": 34260
    },
    {
      "epoch": 1.0491993999326454,
      "grad_norm": 0.018933352082967758,
      "learning_rate": 1.3005541438324712e-05,
      "loss": 0.001,
      "step": 34270
    },
    {
      "epoch": 1.0495055567461653,
      "grad_norm": 0.02954639494419098,
      "learning_rate": 1.3003500392901245e-05,
      "loss": 0.0019,
      "step": 34280
    },
    {
      "epoch": 1.0498117135596852,
      "grad_norm": 2.0465385913848877,
      "learning_rate": 1.3001459347477779e-05,
      "loss": 0.0382,
      "step": 34290
    },
    {
      "epoch": 1.0501178703732053,
      "grad_norm": 0.056761689484119415,
      "learning_rate": 1.2999418302054314e-05,
      "loss": 0.0527,
      "step": 34300
    },
    {
      "epoch": 1.0504240271867251,
      "grad_norm": 0.031149692833423615,
      "learning_rate": 1.2997377256630848e-05,
      "loss": 0.001,
      "step": 34310
    },
    {
      "epoch": 1.050730184000245,
      "grad_norm": 0.025616588070988655,
      "learning_rate": 1.2995336211207382e-05,
      "loss": 0.0009,
      "step": 34320
    },
    {
      "epoch": 1.0510363408137648,
      "grad_norm": 0.08761665970087051,
      "learning_rate": 1.2993295165783915e-05,
      "loss": 0.0347,
      "step": 34330
    },
    {
      "epoch": 1.0513424976272847,
      "grad_norm": 0.026564626023173332,
      "learning_rate": 1.299125412036045e-05,
      "loss": 0.0009,
      "step": 34340
    },
    {
      "epoch": 1.0516486544408046,
      "grad_norm": 0.09933262318372726,
      "learning_rate": 1.2989213074936984e-05,
      "loss": 0.0348,
      "step": 34350
    },
    {
      "epoch": 1.0519548112543244,
      "grad_norm": 0.020850982517004013,
      "learning_rate": 1.2987172029513518e-05,
      "loss": 0.0012,
      "step": 34360
    },
    {
      "epoch": 1.0522609680678443,
      "grad_norm": 0.07331027090549469,
      "learning_rate": 1.2985130984090053e-05,
      "loss": 0.0723,
      "step": 34370
    },
    {
      "epoch": 1.0525671248813642,
      "grad_norm": 0.030907493084669113,
      "learning_rate": 1.2983089938666587e-05,
      "loss": 0.0015,
      "step": 34380
    },
    {
      "epoch": 1.052873281694884,
      "grad_norm": 0.0923914834856987,
      "learning_rate": 1.298104889324312e-05,
      "loss": 0.0279,
      "step": 34390
    },
    {
      "epoch": 1.053179438508404,
      "grad_norm": 0.049129191786050797,
      "learning_rate": 1.2979007847819654e-05,
      "loss": 0.0053,
      "step": 34400
    },
    {
      "epoch": 1.053485595321924,
      "grad_norm": 0.025527343153953552,
      "learning_rate": 1.297696680239619e-05,
      "loss": 0.0017,
      "step": 34410
    },
    {
      "epoch": 1.0537917521354438,
      "grad_norm": 0.029150158166885376,
      "learning_rate": 1.2974925756972723e-05,
      "loss": 0.0014,
      "step": 34420
    },
    {
      "epoch": 1.0540979089489637,
      "grad_norm": 1.8929435014724731,
      "learning_rate": 1.2972884711549257e-05,
      "loss": 0.0705,
      "step": 34430
    },
    {
      "epoch": 1.0544040657624836,
      "grad_norm": 0.013609625399112701,
      "learning_rate": 1.297084366612579e-05,
      "loss": 0.0013,
      "step": 34440
    },
    {
      "epoch": 1.0547102225760034,
      "grad_norm": 0.03780403360724449,
      "learning_rate": 1.2968802620702326e-05,
      "loss": 0.0023,
      "step": 34450
    },
    {
      "epoch": 1.0550163793895233,
      "grad_norm": 0.009338993579149246,
      "learning_rate": 1.296676157527886e-05,
      "loss": 0.0012,
      "step": 34460
    },
    {
      "epoch": 1.0553225362030432,
      "grad_norm": 0.08060331642627716,
      "learning_rate": 1.2964720529855393e-05,
      "loss": 0.0043,
      "step": 34470
    },
    {
      "epoch": 1.055628693016563,
      "grad_norm": 0.03743860498070717,
      "learning_rate": 1.2962679484431928e-05,
      "loss": 0.0016,
      "step": 34480
    },
    {
      "epoch": 1.055934849830083,
      "grad_norm": 0.039816614240407944,
      "learning_rate": 1.2960638439008462e-05,
      "loss": 0.0034,
      "step": 34490
    },
    {
      "epoch": 1.0562410066436028,
      "grad_norm": 0.009629606269299984,
      "learning_rate": 1.2958597393584996e-05,
      "loss": 0.01,
      "step": 34500
    },
    {
      "epoch": 1.0565471634571226,
      "grad_norm": 0.02980908565223217,
      "learning_rate": 1.295655634816153e-05,
      "loss": 0.0008,
      "step": 34510
    },
    {
      "epoch": 1.0568533202706427,
      "grad_norm": 0.017564641311764717,
      "learning_rate": 1.2954515302738065e-05,
      "loss": 0.0008,
      "step": 34520
    },
    {
      "epoch": 1.0571594770841626,
      "grad_norm": 0.00895149540156126,
      "learning_rate": 1.2952474257314598e-05,
      "loss": 0.089,
      "step": 34530
    },
    {
      "epoch": 1.0574656338976824,
      "grad_norm": 0.022360455244779587,
      "learning_rate": 1.2950433211891132e-05,
      "loss": 0.0006,
      "step": 34540
    },
    {
      "epoch": 1.0577717907112023,
      "grad_norm": 0.00254462962038815,
      "learning_rate": 1.2948392166467666e-05,
      "loss": 0.0008,
      "step": 34550
    },
    {
      "epoch": 1.0580779475247222,
      "grad_norm": 0.028688551858067513,
      "learning_rate": 1.2946351121044201e-05,
      "loss": 0.0711,
      "step": 34560
    },
    {
      "epoch": 1.058384104338242,
      "grad_norm": 0.03698692470788956,
      "learning_rate": 1.2944310075620735e-05,
      "loss": 0.0046,
      "step": 34570
    },
    {
      "epoch": 1.058690261151762,
      "grad_norm": 0.029437629505991936,
      "learning_rate": 1.2942269030197268e-05,
      "loss": 0.0014,
      "step": 34580
    },
    {
      "epoch": 1.0589964179652818,
      "grad_norm": 0.060726117342710495,
      "learning_rate": 1.2940227984773804e-05,
      "loss": 0.0021,
      "step": 34590
    },
    {
      "epoch": 1.0593025747788016,
      "grad_norm": 0.05183093249797821,
      "learning_rate": 1.2938186939350337e-05,
      "loss": 0.0384,
      "step": 34600
    },
    {
      "epoch": 1.0596087315923215,
      "grad_norm": 0.05923175439238548,
      "learning_rate": 1.2936145893926871e-05,
      "loss": 0.0012,
      "step": 34610
    },
    {
      "epoch": 1.0599148884058414,
      "grad_norm": 0.019431082531809807,
      "learning_rate": 1.2934104848503405e-05,
      "loss": 0.0014,
      "step": 34620
    },
    {
      "epoch": 1.0602210452193614,
      "grad_norm": 0.02832920104265213,
      "learning_rate": 1.293206380307994e-05,
      "loss": 0.0327,
      "step": 34630
    },
    {
      "epoch": 1.0605272020328813,
      "grad_norm": 0.032875288277864456,
      "learning_rate": 1.2930022757656474e-05,
      "loss": 0.0008,
      "step": 34640
    },
    {
      "epoch": 1.0608333588464012,
      "grad_norm": 0.030982566997408867,
      "learning_rate": 1.2927981712233007e-05,
      "loss": 0.036,
      "step": 34650
    },
    {
      "epoch": 1.061139515659921,
      "grad_norm": 0.049902740865945816,
      "learning_rate": 1.2925940666809539e-05,
      "loss": 0.0016,
      "step": 34660
    },
    {
      "epoch": 1.061445672473441,
      "grad_norm": 0.03455724939703941,
      "learning_rate": 1.2923899621386076e-05,
      "loss": 0.0014,
      "step": 34670
    },
    {
      "epoch": 1.0617518292869608,
      "grad_norm": 0.028453625738620758,
      "learning_rate": 1.292185857596261e-05,
      "loss": 0.0015,
      "step": 34680
    },
    {
      "epoch": 1.0620579861004806,
      "grad_norm": 0.04580315947532654,
      "learning_rate": 1.2919817530539143e-05,
      "loss": 0.001,
      "step": 34690
    },
    {
      "epoch": 1.0623641429140005,
      "grad_norm": 0.0366918221116066,
      "learning_rate": 1.2917776485115679e-05,
      "loss": 0.001,
      "step": 34700
    },
    {
      "epoch": 1.0626702997275204,
      "grad_norm": 0.021345093846321106,
      "learning_rate": 1.2915735439692212e-05,
      "loss": 0.0009,
      "step": 34710
    },
    {
      "epoch": 1.0629764565410402,
      "grad_norm": 0.02035248652100563,
      "learning_rate": 1.2913694394268746e-05,
      "loss": 0.0359,
      "step": 34720
    },
    {
      "epoch": 1.06328261335456,
      "grad_norm": 0.04310542345046997,
      "learning_rate": 1.2911653348845278e-05,
      "loss": 0.018,
      "step": 34730
    },
    {
      "epoch": 1.0635887701680802,
      "grad_norm": 0.015857363119721413,
      "learning_rate": 1.2909612303421815e-05,
      "loss": 0.0509,
      "step": 34740
    },
    {
      "epoch": 1.0638949269816,
      "grad_norm": 0.04104989767074585,
      "learning_rate": 1.2907571257998349e-05,
      "loss": 0.039,
      "step": 34750
    },
    {
      "epoch": 1.06420108379512,
      "grad_norm": 0.03436113893985748,
      "learning_rate": 1.2905530212574882e-05,
      "loss": 0.0014,
      "step": 34760
    },
    {
      "epoch": 1.0645072406086398,
      "grad_norm": 0.015279702842235565,
      "learning_rate": 1.2903489167151414e-05,
      "loss": 0.1156,
      "step": 34770
    },
    {
      "epoch": 1.0648133974221596,
      "grad_norm": 1.9598853588104248,
      "learning_rate": 1.2901448121727951e-05,
      "loss": 0.0341,
      "step": 34780
    },
    {
      "epoch": 1.0651195542356795,
      "grad_norm": 1.9142018556594849,
      "learning_rate": 1.2899407076304485e-05,
      "loss": 0.036,
      "step": 34790
    },
    {
      "epoch": 1.0654257110491994,
      "grad_norm": 0.02322191745042801,
      "learning_rate": 1.2897366030881019e-05,
      "loss": 0.0012,
      "step": 34800
    },
    {
      "epoch": 1.0657318678627192,
      "grad_norm": 0.026281649246811867,
      "learning_rate": 1.2895324985457554e-05,
      "loss": 0.0386,
      "step": 34810
    },
    {
      "epoch": 1.066038024676239,
      "grad_norm": 0.03281238675117493,
      "learning_rate": 1.2893283940034088e-05,
      "loss": 0.0345,
      "step": 34820
    },
    {
      "epoch": 1.066344181489759,
      "grad_norm": 0.09340972453355789,
      "learning_rate": 1.2891242894610621e-05,
      "loss": 0.0029,
      "step": 34830
    },
    {
      "epoch": 1.0666503383032788,
      "grad_norm": 0.018159015104174614,
      "learning_rate": 1.2889201849187153e-05,
      "loss": 0.002,
      "step": 34840
    },
    {
      "epoch": 1.066956495116799,
      "grad_norm": 0.05008445307612419,
      "learning_rate": 1.288716080376369e-05,
      "loss": 0.0524,
      "step": 34850
    },
    {
      "epoch": 1.0672626519303188,
      "grad_norm": 0.031316984444856644,
      "learning_rate": 1.2885119758340224e-05,
      "loss": 0.0025,
      "step": 34860
    },
    {
      "epoch": 1.0675688087438386,
      "grad_norm": 1.6222436428070068,
      "learning_rate": 1.2883078712916758e-05,
      "loss": 0.0622,
      "step": 34870
    },
    {
      "epoch": 1.0678749655573585,
      "grad_norm": 0.020409271121025085,
      "learning_rate": 1.288103766749329e-05,
      "loss": 0.0309,
      "step": 34880
    },
    {
      "epoch": 1.0681811223708784,
      "grad_norm": 1.7358847856521606,
      "learning_rate": 1.2878996622069827e-05,
      "loss": 0.0308,
      "step": 34890
    },
    {
      "epoch": 1.0684872791843982,
      "grad_norm": 0.051242634654045105,
      "learning_rate": 1.287695557664636e-05,
      "loss": 0.002,
      "step": 34900
    },
    {
      "epoch": 1.068793435997918,
      "grad_norm": 0.035595983266830444,
      "learning_rate": 1.2874914531222892e-05,
      "loss": 0.0027,
      "step": 34910
    },
    {
      "epoch": 1.069099592811438,
      "grad_norm": 0.042869050055742264,
      "learning_rate": 1.2872873485799426e-05,
      "loss": 0.0028,
      "step": 34920
    },
    {
      "epoch": 1.0694057496249578,
      "grad_norm": 0.06039911508560181,
      "learning_rate": 1.2870832440375963e-05,
      "loss": 0.0074,
      "step": 34930
    },
    {
      "epoch": 1.0697119064384777,
      "grad_norm": 0.10311783850193024,
      "learning_rate": 1.2868791394952496e-05,
      "loss": 0.0017,
      "step": 34940
    },
    {
      "epoch": 1.0700180632519978,
      "grad_norm": 0.05194095894694328,
      "learning_rate": 1.2866750349529028e-05,
      "loss": 0.0015,
      "step": 34950
    },
    {
      "epoch": 1.0703242200655176,
      "grad_norm": 0.06967749446630478,
      "learning_rate": 1.2864709304105565e-05,
      "loss": 0.0394,
      "step": 34960
    },
    {
      "epoch": 1.0706303768790375,
      "grad_norm": 0.03675956279039383,
      "learning_rate": 1.2862668258682099e-05,
      "loss": 0.0018,
      "step": 34970
    },
    {
      "epoch": 1.0709365336925574,
      "grad_norm": 0.009179548360407352,
      "learning_rate": 1.2860627213258631e-05,
      "loss": 0.0288,
      "step": 34980
    },
    {
      "epoch": 1.0712426905060772,
      "grad_norm": 0.32305461168289185,
      "learning_rate": 1.2858586167835165e-05,
      "loss": 0.0324,
      "step": 34990
    },
    {
      "epoch": 1.071548847319597,
      "grad_norm": 0.04728518798947334,
      "learning_rate": 1.2856545122411702e-05,
      "loss": 0.03,
      "step": 35000
    },
    {
      "epoch": 1.071855004133117,
      "grad_norm": 0.03340162709355354,
      "learning_rate": 1.2854504076988235e-05,
      "loss": 0.0016,
      "step": 35010
    },
    {
      "epoch": 1.0721611609466368,
      "grad_norm": 0.0215894915163517,
      "learning_rate": 1.2852463031564767e-05,
      "loss": 0.0375,
      "step": 35020
    },
    {
      "epoch": 1.0724673177601567,
      "grad_norm": 0.04890548065304756,
      "learning_rate": 1.2850421986141301e-05,
      "loss": 0.0019,
      "step": 35030
    },
    {
      "epoch": 1.0727734745736766,
      "grad_norm": 0.05747554078698158,
      "learning_rate": 1.2848380940717838e-05,
      "loss": 0.0016,
      "step": 35040
    },
    {
      "epoch": 1.0730796313871964,
      "grad_norm": 0.05428095906972885,
      "learning_rate": 1.284633989529437e-05,
      "loss": 0.0011,
      "step": 35050
    },
    {
      "epoch": 1.0733857882007165,
      "grad_norm": 0.02672712877392769,
      "learning_rate": 1.2844298849870904e-05,
      "loss": 0.0017,
      "step": 35060
    },
    {
      "epoch": 1.0736919450142364,
      "grad_norm": 0.027712170034646988,
      "learning_rate": 1.284225780444744e-05,
      "loss": 0.0013,
      "step": 35070
    },
    {
      "epoch": 1.0739981018277562,
      "grad_norm": 0.02726793847978115,
      "learning_rate": 1.2840216759023974e-05,
      "loss": 0.024,
      "step": 35080
    },
    {
      "epoch": 1.074304258641276,
      "grad_norm": 0.020865559577941895,
      "learning_rate": 1.2838175713600506e-05,
      "loss": 0.0372,
      "step": 35090
    },
    {
      "epoch": 1.074610415454796,
      "grad_norm": 1.7374683618545532,
      "learning_rate": 1.283613466817704e-05,
      "loss": 0.0289,
      "step": 35100
    },
    {
      "epoch": 1.0749165722683158,
      "grad_norm": 0.041283320635557175,
      "learning_rate": 1.2834093622753577e-05,
      "loss": 0.0348,
      "step": 35110
    },
    {
      "epoch": 1.0752227290818357,
      "grad_norm": 0.05736339092254639,
      "learning_rate": 1.283205257733011e-05,
      "loss": 0.0327,
      "step": 35120
    },
    {
      "epoch": 1.0755288858953556,
      "grad_norm": 0.02377602830529213,
      "learning_rate": 1.2830011531906642e-05,
      "loss": 0.07,
      "step": 35130
    },
    {
      "epoch": 1.0758350427088754,
      "grad_norm": 0.09467388689517975,
      "learning_rate": 1.2827970486483176e-05,
      "loss": 0.0311,
      "step": 35140
    },
    {
      "epoch": 1.0761411995223953,
      "grad_norm": 0.06582332402467728,
      "learning_rate": 1.2825929441059713e-05,
      "loss": 0.0031,
      "step": 35150
    },
    {
      "epoch": 1.0764473563359154,
      "grad_norm": 0.007501919753849506,
      "learning_rate": 1.2823888395636245e-05,
      "loss": 0.0033,
      "step": 35160
    },
    {
      "epoch": 1.0767535131494352,
      "grad_norm": 0.04438765347003937,
      "learning_rate": 1.2821847350212779e-05,
      "loss": 0.0335,
      "step": 35170
    },
    {
      "epoch": 1.077059669962955,
      "grad_norm": 0.10431099683046341,
      "learning_rate": 1.2819806304789316e-05,
      "loss": 0.0349,
      "step": 35180
    },
    {
      "epoch": 1.077365826776475,
      "grad_norm": 0.09072481095790863,
      "learning_rate": 1.281776525936585e-05,
      "loss": 0.0024,
      "step": 35190
    },
    {
      "epoch": 1.0776719835899948,
      "grad_norm": 0.07960586994886398,
      "learning_rate": 1.2815724213942381e-05,
      "loss": 0.0023,
      "step": 35200
    },
    {
      "epoch": 1.0779781404035147,
      "grad_norm": 0.05256761237978935,
      "learning_rate": 1.2813683168518915e-05,
      "loss": 0.0313,
      "step": 35210
    },
    {
      "epoch": 1.0782842972170346,
      "grad_norm": 0.06283234804868698,
      "learning_rate": 1.2811642123095452e-05,
      "loss": 0.003,
      "step": 35220
    },
    {
      "epoch": 1.0785904540305544,
      "grad_norm": 0.019781384617090225,
      "learning_rate": 1.2809601077671984e-05,
      "loss": 0.0013,
      "step": 35230
    },
    {
      "epoch": 1.0788966108440743,
      "grad_norm": 0.017299743369221687,
      "learning_rate": 1.2807560032248518e-05,
      "loss": 0.0347,
      "step": 35240
    },
    {
      "epoch": 1.0792027676575942,
      "grad_norm": 1.7092761993408203,
      "learning_rate": 1.2805518986825051e-05,
      "loss": 0.0362,
      "step": 35250
    },
    {
      "epoch": 1.079508924471114,
      "grad_norm": 0.06960579752922058,
      "learning_rate": 1.2803477941401588e-05,
      "loss": 0.0021,
      "step": 35260
    },
    {
      "epoch": 1.079815081284634,
      "grad_norm": 0.09180152416229248,
      "learning_rate": 1.280143689597812e-05,
      "loss": 0.0022,
      "step": 35270
    },
    {
      "epoch": 1.080121238098154,
      "grad_norm": 0.026267293840646744,
      "learning_rate": 1.2799395850554654e-05,
      "loss": 0.0282,
      "step": 35280
    },
    {
      "epoch": 1.0804273949116738,
      "grad_norm": 0.01261703297495842,
      "learning_rate": 1.2797354805131191e-05,
      "loss": 0.0016,
      "step": 35290
    },
    {
      "epoch": 1.0807335517251937,
      "grad_norm": 0.048275381326675415,
      "learning_rate": 1.2795313759707723e-05,
      "loss": 0.0023,
      "step": 35300
    },
    {
      "epoch": 1.0810397085387136,
      "grad_norm": 0.012107305228710175,
      "learning_rate": 1.2793272714284257e-05,
      "loss": 0.0036,
      "step": 35310
    },
    {
      "epoch": 1.0813458653522334,
      "grad_norm": 0.09934842586517334,
      "learning_rate": 1.279123166886079e-05,
      "loss": 0.0016,
      "step": 35320
    },
    {
      "epoch": 1.0816520221657533,
      "grad_norm": 0.02964571863412857,
      "learning_rate": 1.2789190623437327e-05,
      "loss": 0.0013,
      "step": 35330
    },
    {
      "epoch": 1.0819581789792732,
      "grad_norm": 0.04161342978477478,
      "learning_rate": 1.2787149578013859e-05,
      "loss": 0.0018,
      "step": 35340
    },
    {
      "epoch": 1.082264335792793,
      "grad_norm": 0.025082776322960854,
      "learning_rate": 1.2785108532590393e-05,
      "loss": 0.0011,
      "step": 35350
    },
    {
      "epoch": 1.0825704926063129,
      "grad_norm": 0.015500819310545921,
      "learning_rate": 1.2783067487166926e-05,
      "loss": 0.0011,
      "step": 35360
    },
    {
      "epoch": 1.0828766494198327,
      "grad_norm": 0.016873331740498543,
      "learning_rate": 1.2781026441743463e-05,
      "loss": 0.0005,
      "step": 35370
    },
    {
      "epoch": 1.0831828062333528,
      "grad_norm": 0.013247374445199966,
      "learning_rate": 1.2778985396319995e-05,
      "loss": 0.0009,
      "step": 35380
    },
    {
      "epoch": 1.0834889630468727,
      "grad_norm": 0.013701562769711018,
      "learning_rate": 1.2776944350896529e-05,
      "loss": 0.0009,
      "step": 35390
    },
    {
      "epoch": 1.0837951198603926,
      "grad_norm": 0.0016322903102263808,
      "learning_rate": 1.2774903305473066e-05,
      "loss": 0.0009,
      "step": 35400
    },
    {
      "epoch": 1.0841012766739124,
      "grad_norm": 0.04481181502342224,
      "learning_rate": 1.2772862260049598e-05,
      "loss": 0.0012,
      "step": 35410
    },
    {
      "epoch": 1.0844074334874323,
      "grad_norm": 0.031154822558164597,
      "learning_rate": 1.2770821214626132e-05,
      "loss": 0.0292,
      "step": 35420
    },
    {
      "epoch": 1.0847135903009522,
      "grad_norm": 2.117809772491455,
      "learning_rate": 1.2768780169202665e-05,
      "loss": 0.0698,
      "step": 35430
    },
    {
      "epoch": 1.085019747114472,
      "grad_norm": 0.07634927332401276,
      "learning_rate": 1.2766739123779202e-05,
      "loss": 0.0012,
      "step": 35440
    },
    {
      "epoch": 1.0853259039279919,
      "grad_norm": 0.0065190596505999565,
      "learning_rate": 1.2764698078355734e-05,
      "loss": 0.0009,
      "step": 35450
    },
    {
      "epoch": 1.0856320607415118,
      "grad_norm": 0.028840241953730583,
      "learning_rate": 1.2762657032932268e-05,
      "loss": 0.0011,
      "step": 35460
    },
    {
      "epoch": 1.0859382175550316,
      "grad_norm": 0.025115514174103737,
      "learning_rate": 1.2760615987508802e-05,
      "loss": 0.001,
      "step": 35470
    },
    {
      "epoch": 1.0862443743685515,
      "grad_norm": 0.014086741022765636,
      "learning_rate": 1.2758574942085337e-05,
      "loss": 0.0037,
      "step": 35480
    },
    {
      "epoch": 1.0865505311820716,
      "grad_norm": 0.016833296045660973,
      "learning_rate": 1.275653389666187e-05,
      "loss": 0.0327,
      "step": 35490
    },
    {
      "epoch": 1.0868566879955914,
      "grad_norm": 0.007676536217331886,
      "learning_rate": 1.2754492851238404e-05,
      "loss": 0.0415,
      "step": 35500
    },
    {
      "epoch": 1.0871628448091113,
      "grad_norm": 0.044210996478796005,
      "learning_rate": 1.2752451805814941e-05,
      "loss": 0.0338,
      "step": 35510
    },
    {
      "epoch": 1.0874690016226312,
      "grad_norm": 0.0146029656752944,
      "learning_rate": 1.2750410760391473e-05,
      "loss": 0.0012,
      "step": 35520
    },
    {
      "epoch": 1.087775158436151,
      "grad_norm": 0.04211302101612091,
      "learning_rate": 1.2748369714968007e-05,
      "loss": 0.0013,
      "step": 35530
    },
    {
      "epoch": 1.0880813152496709,
      "grad_norm": 0.027772322297096252,
      "learning_rate": 1.274632866954454e-05,
      "loss": 0.0012,
      "step": 35540
    },
    {
      "epoch": 1.0883874720631908,
      "grad_norm": 0.06950180977582932,
      "learning_rate": 1.2744287624121076e-05,
      "loss": 0.0014,
      "step": 35550
    },
    {
      "epoch": 1.0886936288767106,
      "grad_norm": 0.04601026326417923,
      "learning_rate": 1.274224657869761e-05,
      "loss": 0.0011,
      "step": 35560
    },
    {
      "epoch": 1.0889997856902305,
      "grad_norm": 0.0376436822116375,
      "learning_rate": 1.2740205533274143e-05,
      "loss": 0.0015,
      "step": 35570
    },
    {
      "epoch": 1.0893059425037503,
      "grad_norm": 0.028138399124145508,
      "learning_rate": 1.2738164487850677e-05,
      "loss": 0.0007,
      "step": 35580
    },
    {
      "epoch": 1.0896120993172702,
      "grad_norm": 0.009893368929624557,
      "learning_rate": 1.2736123442427212e-05,
      "loss": 0.0406,
      "step": 35590
    },
    {
      "epoch": 1.0899182561307903,
      "grad_norm": 0.010805419646203518,
      "learning_rate": 1.2734082397003746e-05,
      "loss": 0.0015,
      "step": 35600
    },
    {
      "epoch": 1.0902244129443102,
      "grad_norm": 0.007217227481305599,
      "learning_rate": 1.273204135158028e-05,
      "loss": 0.0383,
      "step": 35610
    },
    {
      "epoch": 1.09053056975783,
      "grad_norm": 1.6456799507141113,
      "learning_rate": 1.2730000306156816e-05,
      "loss": 0.0303,
      "step": 35620
    },
    {
      "epoch": 1.09083672657135,
      "grad_norm": 0.02950446493923664,
      "learning_rate": 1.2727959260733348e-05,
      "loss": 0.001,
      "step": 35630
    },
    {
      "epoch": 1.0911428833848698,
      "grad_norm": 0.015125972218811512,
      "learning_rate": 1.2725918215309882e-05,
      "loss": 0.0418,
      "step": 35640
    },
    {
      "epoch": 1.0914490401983896,
      "grad_norm": 0.029431680217385292,
      "learning_rate": 1.2723877169886416e-05,
      "loss": 0.0012,
      "step": 35650
    },
    {
      "epoch": 1.0917551970119095,
      "grad_norm": 0.02123883180320263,
      "learning_rate": 1.2721836124462951e-05,
      "loss": 0.0365,
      "step": 35660
    },
    {
      "epoch": 1.0920613538254293,
      "grad_norm": 0.028899796307086945,
      "learning_rate": 1.2719795079039485e-05,
      "loss": 0.0014,
      "step": 35670
    },
    {
      "epoch": 1.0923675106389492,
      "grad_norm": 0.03995960205793381,
      "learning_rate": 1.2717754033616018e-05,
      "loss": 0.001,
      "step": 35680
    },
    {
      "epoch": 1.092673667452469,
      "grad_norm": 0.0258929543197155,
      "learning_rate": 1.2715712988192552e-05,
      "loss": 0.0014,
      "step": 35690
    },
    {
      "epoch": 1.092979824265989,
      "grad_norm": 0.040614157915115356,
      "learning_rate": 1.2713671942769087e-05,
      "loss": 0.0014,
      "step": 35700
    },
    {
      "epoch": 1.093285981079509,
      "grad_norm": 0.03275260329246521,
      "learning_rate": 1.2711630897345621e-05,
      "loss": 0.0013,
      "step": 35710
    },
    {
      "epoch": 1.093592137893029,
      "grad_norm": 0.03275685757398605,
      "learning_rate": 1.2709589851922155e-05,
      "loss": 0.0011,
      "step": 35720
    },
    {
      "epoch": 1.0938982947065488,
      "grad_norm": 0.01814546063542366,
      "learning_rate": 1.270754880649869e-05,
      "loss": 0.0024,
      "step": 35730
    },
    {
      "epoch": 1.0942044515200686,
      "grad_norm": 0.7224647998809814,
      "learning_rate": 1.2705507761075224e-05,
      "loss": 0.0021,
      "step": 35740
    },
    {
      "epoch": 1.0945106083335885,
      "grad_norm": 0.02159484475851059,
      "learning_rate": 1.2703466715651757e-05,
      "loss": 0.0007,
      "step": 35750
    },
    {
      "epoch": 1.0948167651471084,
      "grad_norm": 0.04307837784290314,
      "learning_rate": 1.270142567022829e-05,
      "loss": 0.0006,
      "step": 35760
    },
    {
      "epoch": 1.0951229219606282,
      "grad_norm": 0.031548380851745605,
      "learning_rate": 1.2699384624804826e-05,
      "loss": 0.0381,
      "step": 35770
    },
    {
      "epoch": 1.095429078774148,
      "grad_norm": 0.015178839676082134,
      "learning_rate": 1.269734357938136e-05,
      "loss": 0.0362,
      "step": 35780
    },
    {
      "epoch": 1.095735235587668,
      "grad_norm": 0.006284869275987148,
      "learning_rate": 1.2695302533957893e-05,
      "loss": 0.0008,
      "step": 35790
    },
    {
      "epoch": 1.0960413924011878,
      "grad_norm": 0.022788459435105324,
      "learning_rate": 1.2693261488534427e-05,
      "loss": 0.0684,
      "step": 35800
    },
    {
      "epoch": 1.0963475492147077,
      "grad_norm": 0.006958368234336376,
      "learning_rate": 1.2691220443110962e-05,
      "loss": 0.0009,
      "step": 35810
    },
    {
      "epoch": 1.0966537060282278,
      "grad_norm": 0.06788641959428787,
      "learning_rate": 1.2689179397687496e-05,
      "loss": 0.0013,
      "step": 35820
    },
    {
      "epoch": 1.0969598628417476,
      "grad_norm": 0.03659695014357567,
      "learning_rate": 1.268713835226403e-05,
      "loss": 0.001,
      "step": 35830
    },
    {
      "epoch": 1.0972660196552675,
      "grad_norm": 0.02428007498383522,
      "learning_rate": 1.2685097306840565e-05,
      "loss": 0.0015,
      "step": 35840
    },
    {
      "epoch": 1.0975721764687874,
      "grad_norm": 0.020605891942977905,
      "learning_rate": 1.2683056261417099e-05,
      "loss": 0.0363,
      "step": 35850
    },
    {
      "epoch": 1.0978783332823072,
      "grad_norm": 0.02362450584769249,
      "learning_rate": 1.2681015215993632e-05,
      "loss": 0.0339,
      "step": 35860
    },
    {
      "epoch": 1.098184490095827,
      "grad_norm": 0.0512002594769001,
      "learning_rate": 1.2678974170570166e-05,
      "loss": 0.0013,
      "step": 35870
    },
    {
      "epoch": 1.098490646909347,
      "grad_norm": 0.021204661577939987,
      "learning_rate": 1.2676933125146701e-05,
      "loss": 0.0211,
      "step": 35880
    },
    {
      "epoch": 1.0987968037228668,
      "grad_norm": 0.05897524580359459,
      "learning_rate": 1.2674892079723235e-05,
      "loss": 0.026,
      "step": 35890
    },
    {
      "epoch": 1.0991029605363867,
      "grad_norm": 0.042458854615688324,
      "learning_rate": 1.2672851034299769e-05,
      "loss": 0.0013,
      "step": 35900
    },
    {
      "epoch": 1.0994091173499065,
      "grad_norm": 0.07188237458467484,
      "learning_rate": 1.2670809988876302e-05,
      "loss": 0.0434,
      "step": 35910
    },
    {
      "epoch": 1.0997152741634264,
      "grad_norm": 0.03261764347553253,
      "learning_rate": 1.2668768943452838e-05,
      "loss": 0.0313,
      "step": 35920
    },
    {
      "epoch": 1.1000214309769465,
      "grad_norm": 0.056084297597408295,
      "learning_rate": 1.2666727898029371e-05,
      "loss": 0.0025,
      "step": 35930
    },
    {
      "epoch": 1.1003275877904664,
      "grad_norm": 0.08452066034078598,
      "learning_rate": 1.2664686852605905e-05,
      "loss": 0.0027,
      "step": 35940
    },
    {
      "epoch": 1.1006337446039862,
      "grad_norm": 0.03177381679415703,
      "learning_rate": 1.266264580718244e-05,
      "loss": 0.0019,
      "step": 35950
    },
    {
      "epoch": 1.100939901417506,
      "grad_norm": 0.058672934770584106,
      "learning_rate": 1.2660604761758974e-05,
      "loss": 0.0016,
      "step": 35960
    },
    {
      "epoch": 1.101246058231026,
      "grad_norm": 0.021512040868401527,
      "learning_rate": 1.2658563716335508e-05,
      "loss": 0.0321,
      "step": 35970
    },
    {
      "epoch": 1.1015522150445458,
      "grad_norm": 0.023723524063825607,
      "learning_rate": 1.2656522670912041e-05,
      "loss": 0.0016,
      "step": 35980
    },
    {
      "epoch": 1.1018583718580657,
      "grad_norm": 0.019796378910541534,
      "learning_rate": 1.2654481625488577e-05,
      "loss": 0.0012,
      "step": 35990
    },
    {
      "epoch": 1.1021645286715855,
      "grad_norm": 0.0026065099518746138,
      "learning_rate": 1.265244058006511e-05,
      "loss": 0.0011,
      "step": 36000
    },
    {
      "epoch": 1.1024706854851054,
      "grad_norm": 0.016373436897993088,
      "learning_rate": 1.2650399534641644e-05,
      "loss": 0.0756,
      "step": 36010
    },
    {
      "epoch": 1.1027768422986253,
      "grad_norm": 0.038110293447971344,
      "learning_rate": 1.2648358489218177e-05,
      "loss": 0.001,
      "step": 36020
    },
    {
      "epoch": 1.1030829991121451,
      "grad_norm": 0.019117437303066254,
      "learning_rate": 1.2646317443794713e-05,
      "loss": 0.0606,
      "step": 36030
    },
    {
      "epoch": 1.1033891559256652,
      "grad_norm": 0.016853852197527885,
      "learning_rate": 1.2644276398371246e-05,
      "loss": 0.001,
      "step": 36040
    },
    {
      "epoch": 1.103695312739185,
      "grad_norm": 0.04543382674455643,
      "learning_rate": 1.264223535294778e-05,
      "loss": 0.0015,
      "step": 36050
    },
    {
      "epoch": 1.104001469552705,
      "grad_norm": 0.011859221383929253,
      "learning_rate": 1.2640194307524315e-05,
      "loss": 0.0011,
      "step": 36060
    },
    {
      "epoch": 1.1043076263662248,
      "grad_norm": 0.022316671907901764,
      "learning_rate": 1.2638153262100849e-05,
      "loss": 0.0358,
      "step": 36070
    },
    {
      "epoch": 1.1046137831797447,
      "grad_norm": 0.016450555995106697,
      "learning_rate": 1.2636112216677383e-05,
      "loss": 0.001,
      "step": 36080
    },
    {
      "epoch": 1.1049199399932645,
      "grad_norm": 0.005327582824975252,
      "learning_rate": 1.2634071171253916e-05,
      "loss": 0.0009,
      "step": 36090
    },
    {
      "epoch": 1.1052260968067844,
      "grad_norm": 0.04285791143774986,
      "learning_rate": 1.2632030125830452e-05,
      "loss": 0.0377,
      "step": 36100
    },
    {
      "epoch": 1.1055322536203043,
      "grad_norm": 0.0320010781288147,
      "learning_rate": 1.2629989080406985e-05,
      "loss": 0.0012,
      "step": 36110
    },
    {
      "epoch": 1.1058384104338241,
      "grad_norm": 0.0631004348397255,
      "learning_rate": 1.2627948034983519e-05,
      "loss": 0.001,
      "step": 36120
    },
    {
      "epoch": 1.106144567247344,
      "grad_norm": 0.0412888340651989,
      "learning_rate": 1.2625906989560053e-05,
      "loss": 0.0011,
      "step": 36130
    },
    {
      "epoch": 1.1064507240608639,
      "grad_norm": 0.023418843746185303,
      "learning_rate": 1.2623865944136588e-05,
      "loss": 0.0483,
      "step": 36140
    },
    {
      "epoch": 1.106756880874384,
      "grad_norm": 0.20008063316345215,
      "learning_rate": 1.2621824898713122e-05,
      "loss": 0.0328,
      "step": 36150
    },
    {
      "epoch": 1.1070630376879038,
      "grad_norm": 0.021128104999661446,
      "learning_rate": 1.2619783853289655e-05,
      "loss": 0.0013,
      "step": 36160
    },
    {
      "epoch": 1.1073691945014237,
      "grad_norm": 0.06196985021233559,
      "learning_rate": 1.2617742807866189e-05,
      "loss": 0.0016,
      "step": 36170
    },
    {
      "epoch": 1.1076753513149435,
      "grad_norm": 0.020085928961634636,
      "learning_rate": 1.2615701762442724e-05,
      "loss": 0.0014,
      "step": 36180
    },
    {
      "epoch": 1.1079815081284634,
      "grad_norm": 0.023765232414007187,
      "learning_rate": 1.2613660717019258e-05,
      "loss": 0.0445,
      "step": 36190
    },
    {
      "epoch": 1.1082876649419833,
      "grad_norm": 0.01893862895667553,
      "learning_rate": 1.2611619671595792e-05,
      "loss": 0.0006,
      "step": 36200
    },
    {
      "epoch": 1.1085938217555031,
      "grad_norm": 0.019059808924794197,
      "learning_rate": 1.2609578626172327e-05,
      "loss": 0.0011,
      "step": 36210
    },
    {
      "epoch": 1.108899978569023,
      "grad_norm": 0.022823922336101532,
      "learning_rate": 1.260753758074886e-05,
      "loss": 0.0099,
      "step": 36220
    },
    {
      "epoch": 1.1092061353825429,
      "grad_norm": 1.8268460035324097,
      "learning_rate": 1.2605496535325394e-05,
      "loss": 0.0739,
      "step": 36230
    },
    {
      "epoch": 1.1095122921960627,
      "grad_norm": 0.030750934034585953,
      "learning_rate": 1.2603455489901928e-05,
      "loss": 0.001,
      "step": 36240
    },
    {
      "epoch": 1.1098184490095826,
      "grad_norm": 0.11410412937402725,
      "learning_rate": 1.2601414444478463e-05,
      "loss": 0.1416,
      "step": 36250
    },
    {
      "epoch": 1.1101246058231027,
      "grad_norm": 0.033160094171762466,
      "learning_rate": 1.2599373399054997e-05,
      "loss": 0.0319,
      "step": 36260
    },
    {
      "epoch": 1.1104307626366225,
      "grad_norm": 0.10127482563257217,
      "learning_rate": 1.259733235363153e-05,
      "loss": 0.0053,
      "step": 36270
    },
    {
      "epoch": 1.1107369194501424,
      "grad_norm": 0.12929604947566986,
      "learning_rate": 1.2595291308208064e-05,
      "loss": 0.0028,
      "step": 36280
    },
    {
      "epoch": 1.1110430762636623,
      "grad_norm": 0.09098919481039047,
      "learning_rate": 1.25932502627846e-05,
      "loss": 0.0024,
      "step": 36290
    },
    {
      "epoch": 1.1113492330771821,
      "grad_norm": 0.03846052661538124,
      "learning_rate": 1.2591209217361133e-05,
      "loss": 0.002,
      "step": 36300
    },
    {
      "epoch": 1.111655389890702,
      "grad_norm": 0.03713538497686386,
      "learning_rate": 1.2589168171937667e-05,
      "loss": 0.0024,
      "step": 36310
    },
    {
      "epoch": 1.1119615467042219,
      "grad_norm": 0.09103131294250488,
      "learning_rate": 1.2587127126514202e-05,
      "loss": 0.0661,
      "step": 36320
    },
    {
      "epoch": 1.1122677035177417,
      "grad_norm": 0.11006432771682739,
      "learning_rate": 1.2585086081090736e-05,
      "loss": 0.0432,
      "step": 36330
    },
    {
      "epoch": 1.1125738603312616,
      "grad_norm": 0.04620896279811859,
      "learning_rate": 1.258304503566727e-05,
      "loss": 0.031,
      "step": 36340
    },
    {
      "epoch": 1.1128800171447815,
      "grad_norm": 0.10602111369371414,
      "learning_rate": 1.2581003990243803e-05,
      "loss": 0.002,
      "step": 36350
    },
    {
      "epoch": 1.1131861739583013,
      "grad_norm": 1.7631235122680664,
      "learning_rate": 1.2578962944820338e-05,
      "loss": 0.0275,
      "step": 36360
    },
    {
      "epoch": 1.1134923307718214,
      "grad_norm": 0.03190341219305992,
      "learning_rate": 1.2576921899396872e-05,
      "loss": 0.037,
      "step": 36370
    },
    {
      "epoch": 1.1137984875853413,
      "grad_norm": 0.06087490916252136,
      "learning_rate": 1.2574880853973406e-05,
      "loss": 0.0027,
      "step": 36380
    },
    {
      "epoch": 1.1141046443988611,
      "grad_norm": 0.0625608041882515,
      "learning_rate": 1.257283980854994e-05,
      "loss": 0.0023,
      "step": 36390
    },
    {
      "epoch": 1.114410801212381,
      "grad_norm": 0.041304342448711395,
      "learning_rate": 1.2570798763126475e-05,
      "loss": 0.1114,
      "step": 36400
    },
    {
      "epoch": 1.1147169580259009,
      "grad_norm": 0.05363164469599724,
      "learning_rate": 1.2568757717703008e-05,
      "loss": 0.004,
      "step": 36410
    },
    {
      "epoch": 1.1150231148394207,
      "grad_norm": 0.050512418150901794,
      "learning_rate": 1.2566716672279542e-05,
      "loss": 0.0027,
      "step": 36420
    },
    {
      "epoch": 1.1153292716529406,
      "grad_norm": 0.0932948961853981,
      "learning_rate": 1.2564675626856077e-05,
      "loss": 0.0033,
      "step": 36430
    },
    {
      "epoch": 1.1156354284664605,
      "grad_norm": 0.0592041090130806,
      "learning_rate": 1.256263458143261e-05,
      "loss": 0.0024,
      "step": 36440
    },
    {
      "epoch": 1.1159415852799803,
      "grad_norm": 0.06797243654727936,
      "learning_rate": 1.2560593536009144e-05,
      "loss": 0.0023,
      "step": 36450
    },
    {
      "epoch": 1.1162477420935002,
      "grad_norm": 0.00966509710997343,
      "learning_rate": 1.2558552490585678e-05,
      "loss": 0.0019,
      "step": 36460
    },
    {
      "epoch": 1.11655389890702,
      "grad_norm": 0.049684543162584305,
      "learning_rate": 1.2556511445162213e-05,
      "loss": 0.0645,
      "step": 36470
    },
    {
      "epoch": 1.1168600557205401,
      "grad_norm": 0.05969489365816116,
      "learning_rate": 1.2554470399738747e-05,
      "loss": 0.0022,
      "step": 36480
    },
    {
      "epoch": 1.11716621253406,
      "grad_norm": 0.017873728647828102,
      "learning_rate": 1.255242935431528e-05,
      "loss": 0.0355,
      "step": 36490
    },
    {
      "epoch": 1.1174723693475799,
      "grad_norm": 1.7515350580215454,
      "learning_rate": 1.2550388308891814e-05,
      "loss": 0.0291,
      "step": 36500
    },
    {
      "epoch": 1.1177785261610997,
      "grad_norm": 0.05036340281367302,
      "learning_rate": 1.254834726346835e-05,
      "loss": 0.0286,
      "step": 36510
    },
    {
      "epoch": 1.1180846829746196,
      "grad_norm": 0.03522306680679321,
      "learning_rate": 1.2546306218044883e-05,
      "loss": 0.0023,
      "step": 36520
    },
    {
      "epoch": 1.1183908397881395,
      "grad_norm": 1.3415805101394653,
      "learning_rate": 1.2544265172621417e-05,
      "loss": 0.0194,
      "step": 36530
    },
    {
      "epoch": 1.1186969966016593,
      "grad_norm": 0.13804656267166138,
      "learning_rate": 1.2542224127197952e-05,
      "loss": 0.0029,
      "step": 36540
    },
    {
      "epoch": 1.1190031534151792,
      "grad_norm": 0.03533081337809563,
      "learning_rate": 1.2540183081774486e-05,
      "loss": 0.0029,
      "step": 36550
    },
    {
      "epoch": 1.119309310228699,
      "grad_norm": 0.1422499120235443,
      "learning_rate": 1.253814203635102e-05,
      "loss": 0.0383,
      "step": 36560
    },
    {
      "epoch": 1.119615467042219,
      "grad_norm": 0.0346001572906971,
      "learning_rate": 1.2536100990927553e-05,
      "loss": 0.0022,
      "step": 36570
    },
    {
      "epoch": 1.119921623855739,
      "grad_norm": 0.06232331320643425,
      "learning_rate": 1.2534059945504089e-05,
      "loss": 0.0229,
      "step": 36580
    },
    {
      "epoch": 1.1202277806692589,
      "grad_norm": 0.05886011943221092,
      "learning_rate": 1.2532018900080622e-05,
      "loss": 0.0024,
      "step": 36590
    },
    {
      "epoch": 1.1205339374827787,
      "grad_norm": 0.05594560131430626,
      "learning_rate": 1.2529977854657156e-05,
      "loss": 0.0018,
      "step": 36600
    },
    {
      "epoch": 1.1208400942962986,
      "grad_norm": 0.02493223361670971,
      "learning_rate": 1.252793680923369e-05,
      "loss": 0.0013,
      "step": 36610
    },
    {
      "epoch": 1.1211462511098185,
      "grad_norm": 0.027154739946126938,
      "learning_rate": 1.2525895763810225e-05,
      "loss": 0.0014,
      "step": 36620
    },
    {
      "epoch": 1.1214524079233383,
      "grad_norm": 0.031896430999040604,
      "learning_rate": 1.2523854718386759e-05,
      "loss": 0.0301,
      "step": 36630
    },
    {
      "epoch": 1.1217585647368582,
      "grad_norm": 0.04554051533341408,
      "learning_rate": 1.2521813672963292e-05,
      "loss": 0.002,
      "step": 36640
    },
    {
      "epoch": 1.122064721550378,
      "grad_norm": 0.015951748937368393,
      "learning_rate": 1.2519772627539828e-05,
      "loss": 0.0012,
      "step": 36650
    },
    {
      "epoch": 1.122370878363898,
      "grad_norm": 0.04486576467752457,
      "learning_rate": 1.2517731582116361e-05,
      "loss": 0.0011,
      "step": 36660
    },
    {
      "epoch": 1.1226770351774178,
      "grad_norm": 0.014063048176467419,
      "learning_rate": 1.2515690536692895e-05,
      "loss": 0.0012,
      "step": 36670
    },
    {
      "epoch": 1.1229831919909377,
      "grad_norm": 0.03734920918941498,
      "learning_rate": 1.2513649491269428e-05,
      "loss": 0.0322,
      "step": 36680
    },
    {
      "epoch": 1.1232893488044577,
      "grad_norm": 0.04468804597854614,
      "learning_rate": 1.2511608445845964e-05,
      "loss": 0.0016,
      "step": 36690
    },
    {
      "epoch": 1.1235955056179776,
      "grad_norm": 0.034331515431404114,
      "learning_rate": 1.2509567400422497e-05,
      "loss": 0.038,
      "step": 36700
    },
    {
      "epoch": 1.1239016624314975,
      "grad_norm": 1.5981470346450806,
      "learning_rate": 1.2507526354999031e-05,
      "loss": 0.0603,
      "step": 36710
    },
    {
      "epoch": 1.1242078192450173,
      "grad_norm": 0.06156455725431442,
      "learning_rate": 1.2505485309575565e-05,
      "loss": 0.0025,
      "step": 36720
    },
    {
      "epoch": 1.1245139760585372,
      "grad_norm": 0.03668483346700668,
      "learning_rate": 1.25034442641521e-05,
      "loss": 0.002,
      "step": 36730
    },
    {
      "epoch": 1.124820132872057,
      "grad_norm": 0.044787295162677765,
      "learning_rate": 1.2501403218728634e-05,
      "loss": 0.0015,
      "step": 36740
    },
    {
      "epoch": 1.125126289685577,
      "grad_norm": 0.0512295626103878,
      "learning_rate": 1.2499362173305167e-05,
      "loss": 0.0348,
      "step": 36750
    },
    {
      "epoch": 1.1254324464990968,
      "grad_norm": 0.038273606449365616,
      "learning_rate": 1.2497321127881703e-05,
      "loss": 0.0363,
      "step": 36760
    },
    {
      "epoch": 1.1257386033126167,
      "grad_norm": 5.339587211608887,
      "learning_rate": 1.2495280082458236e-05,
      "loss": 0.0171,
      "step": 36770
    },
    {
      "epoch": 1.1260447601261365,
      "grad_norm": 0.05644487962126732,
      "learning_rate": 1.249323903703477e-05,
      "loss": 0.0017,
      "step": 36780
    },
    {
      "epoch": 1.1263509169396566,
      "grad_norm": 0.02517235279083252,
      "learning_rate": 1.2491197991611304e-05,
      "loss": 0.0015,
      "step": 36790
    },
    {
      "epoch": 1.1266570737531763,
      "grad_norm": 0.050055891275405884,
      "learning_rate": 1.2489156946187839e-05,
      "loss": 0.0562,
      "step": 36800
    },
    {
      "epoch": 1.1269632305666963,
      "grad_norm": 0.020690372213721275,
      "learning_rate": 1.2487115900764373e-05,
      "loss": 0.0009,
      "step": 36810
    },
    {
      "epoch": 1.1272693873802162,
      "grad_norm": 0.041501227766275406,
      "learning_rate": 1.2485074855340906e-05,
      "loss": 0.0161,
      "step": 36820
    },
    {
      "epoch": 1.127575544193736,
      "grad_norm": 0.014508092775940895,
      "learning_rate": 1.248303380991744e-05,
      "loss": 0.0442,
      "step": 36830
    },
    {
      "epoch": 1.127881701007256,
      "grad_norm": 0.005803931970149279,
      "learning_rate": 1.2480992764493975e-05,
      "loss": 0.0011,
      "step": 36840
    },
    {
      "epoch": 1.1281878578207758,
      "grad_norm": 0.04653666913509369,
      "learning_rate": 1.2478951719070509e-05,
      "loss": 0.0008,
      "step": 36850
    },
    {
      "epoch": 1.1284940146342957,
      "grad_norm": 1.8482235670089722,
      "learning_rate": 1.2476910673647043e-05,
      "loss": 0.0654,
      "step": 36860
    },
    {
      "epoch": 1.1288001714478155,
      "grad_norm": 0.0004840338369831443,
      "learning_rate": 1.2474869628223578e-05,
      "loss": 0.0014,
      "step": 36870
    },
    {
      "epoch": 1.1291063282613354,
      "grad_norm": 0.03999951854348183,
      "learning_rate": 1.2472828582800112e-05,
      "loss": 0.0595,
      "step": 36880
    },
    {
      "epoch": 1.1294124850748553,
      "grad_norm": 0.04424063861370087,
      "learning_rate": 1.2470787537376645e-05,
      "loss": 0.0024,
      "step": 36890
    },
    {
      "epoch": 1.1297186418883753,
      "grad_norm": 0.031142164021730423,
      "learning_rate": 1.2468746491953179e-05,
      "loss": 0.0391,
      "step": 36900
    },
    {
      "epoch": 1.1300247987018952,
      "grad_norm": 1.6729161739349365,
      "learning_rate": 1.2466705446529714e-05,
      "loss": 0.0302,
      "step": 36910
    },
    {
      "epoch": 1.130330955515415,
      "grad_norm": 0.0006529399543069303,
      "learning_rate": 1.2464664401106248e-05,
      "loss": 0.0604,
      "step": 36920
    },
    {
      "epoch": 1.130637112328935,
      "grad_norm": 0.04614434763789177,
      "learning_rate": 1.2462623355682781e-05,
      "loss": 0.0269,
      "step": 36930
    },
    {
      "epoch": 1.1309432691424548,
      "grad_norm": 0.10034304857254028,
      "learning_rate": 1.2460582310259315e-05,
      "loss": 0.0035,
      "step": 36940
    },
    {
      "epoch": 1.1312494259559747,
      "grad_norm": 0.09915471076965332,
      "learning_rate": 1.245854126483585e-05,
      "loss": 0.0289,
      "step": 36950
    },
    {
      "epoch": 1.1315555827694945,
      "grad_norm": 0.10027968138456345,
      "learning_rate": 1.2456500219412384e-05,
      "loss": 0.0034,
      "step": 36960
    },
    {
      "epoch": 1.1318617395830144,
      "grad_norm": 0.06776518374681473,
      "learning_rate": 1.2454459173988918e-05,
      "loss": 0.0031,
      "step": 36970
    },
    {
      "epoch": 1.1321678963965343,
      "grad_norm": 0.05052970349788666,
      "learning_rate": 1.2452418128565453e-05,
      "loss": 0.0031,
      "step": 36980
    },
    {
      "epoch": 1.1324740532100541,
      "grad_norm": 0.08236434310674667,
      "learning_rate": 1.2450377083141987e-05,
      "loss": 0.0023,
      "step": 36990
    },
    {
      "epoch": 1.132780210023574,
      "grad_norm": 1.7167118787765503,
      "learning_rate": 1.244833603771852e-05,
      "loss": 0.0302,
      "step": 37000
    },
    {
      "epoch": 1.133086366837094,
      "grad_norm": 0.04300648719072342,
      "learning_rate": 1.2446294992295054e-05,
      "loss": 0.003,
      "step": 37010
    },
    {
      "epoch": 1.133392523650614,
      "grad_norm": 0.01768813282251358,
      "learning_rate": 1.244425394687159e-05,
      "loss": 0.0018,
      "step": 37020
    },
    {
      "epoch": 1.1336986804641338,
      "grad_norm": 0.011280876584351063,
      "learning_rate": 1.2442212901448123e-05,
      "loss": 0.0019,
      "step": 37030
    },
    {
      "epoch": 1.1340048372776537,
      "grad_norm": 0.0146755026653409,
      "learning_rate": 1.2440171856024657e-05,
      "loss": 0.0157,
      "step": 37040
    },
    {
      "epoch": 1.1343109940911735,
      "grad_norm": 0.0381862074136734,
      "learning_rate": 1.243813081060119e-05,
      "loss": 0.0014,
      "step": 37050
    },
    {
      "epoch": 1.1346171509046934,
      "grad_norm": 0.03614908456802368,
      "learning_rate": 1.2436089765177726e-05,
      "loss": 0.0013,
      "step": 37060
    },
    {
      "epoch": 1.1349233077182133,
      "grad_norm": 0.032653652131557465,
      "learning_rate": 1.243404871975426e-05,
      "loss": 0.0011,
      "step": 37070
    },
    {
      "epoch": 1.1352294645317331,
      "grad_norm": 0.018611418083310127,
      "learning_rate": 1.2432007674330793e-05,
      "loss": 0.0008,
      "step": 37080
    },
    {
      "epoch": 1.135535621345253,
      "grad_norm": 0.031617969274520874,
      "learning_rate": 1.2429966628907328e-05,
      "loss": 0.0723,
      "step": 37090
    },
    {
      "epoch": 1.1358417781587729,
      "grad_norm": 0.01792464777827263,
      "learning_rate": 1.2427925583483862e-05,
      "loss": 0.0024,
      "step": 37100
    },
    {
      "epoch": 1.1361479349722927,
      "grad_norm": 0.01418844424188137,
      "learning_rate": 1.2425884538060395e-05,
      "loss": 0.0014,
      "step": 37110
    },
    {
      "epoch": 1.1364540917858128,
      "grad_norm": 0.012391540221869946,
      "learning_rate": 1.2423843492636929e-05,
      "loss": 0.0355,
      "step": 37120
    },
    {
      "epoch": 1.1367602485993327,
      "grad_norm": 0.0150950001552701,
      "learning_rate": 1.2421802447213464e-05,
      "loss": 0.001,
      "step": 37130
    },
    {
      "epoch": 1.1370664054128525,
      "grad_norm": 0.03075721673667431,
      "learning_rate": 1.2419761401789998e-05,
      "loss": 0.0014,
      "step": 37140
    },
    {
      "epoch": 1.1373725622263724,
      "grad_norm": 0.11845458298921585,
      "learning_rate": 1.2417720356366532e-05,
      "loss": 0.0011,
      "step": 37150
    },
    {
      "epoch": 1.1376787190398923,
      "grad_norm": 0.021880878135561943,
      "learning_rate": 1.2415679310943065e-05,
      "loss": 0.0011,
      "step": 37160
    },
    {
      "epoch": 1.1379848758534121,
      "grad_norm": 0.016948487609624863,
      "learning_rate": 1.24136382655196e-05,
      "loss": 0.0333,
      "step": 37170
    },
    {
      "epoch": 1.138291032666932,
      "grad_norm": 0.011645441874861717,
      "learning_rate": 1.2411597220096134e-05,
      "loss": 0.001,
      "step": 37180
    },
    {
      "epoch": 1.1385971894804519,
      "grad_norm": 0.023779211565852165,
      "learning_rate": 1.2409556174672668e-05,
      "loss": 0.0013,
      "step": 37190
    },
    {
      "epoch": 1.1389033462939717,
      "grad_norm": 0.12279129028320312,
      "learning_rate": 1.2407515129249203e-05,
      "loss": 0.001,
      "step": 37200
    },
    {
      "epoch": 1.1392095031074916,
      "grad_norm": 0.025782009586691856,
      "learning_rate": 1.2405474083825737e-05,
      "loss": 0.001,
      "step": 37210
    },
    {
      "epoch": 1.1395156599210114,
      "grad_norm": 0.03260115534067154,
      "learning_rate": 1.240343303840227e-05,
      "loss": 0.0355,
      "step": 37220
    },
    {
      "epoch": 1.1398218167345315,
      "grad_norm": 0.026727106422185898,
      "learning_rate": 1.2401391992978804e-05,
      "loss": 0.1044,
      "step": 37230
    },
    {
      "epoch": 1.1401279735480514,
      "grad_norm": 0.04359501600265503,
      "learning_rate": 1.239935094755534e-05,
      "loss": 0.0029,
      "step": 37240
    },
    {
      "epoch": 1.1404341303615713,
      "grad_norm": 0.06319023668766022,
      "learning_rate": 1.2397309902131873e-05,
      "loss": 0.0019,
      "step": 37250
    },
    {
      "epoch": 1.1407402871750911,
      "grad_norm": 0.02074635773897171,
      "learning_rate": 1.2395268856708407e-05,
      "loss": 0.0015,
      "step": 37260
    },
    {
      "epoch": 1.141046443988611,
      "grad_norm": 0.03368975594639778,
      "learning_rate": 1.239322781128494e-05,
      "loss": 0.0015,
      "step": 37270
    },
    {
      "epoch": 1.1413526008021309,
      "grad_norm": 0.027593383565545082,
      "learning_rate": 1.2391186765861476e-05,
      "loss": 0.0014,
      "step": 37280
    },
    {
      "epoch": 1.1416587576156507,
      "grad_norm": 0.01678593084216118,
      "learning_rate": 1.238914572043801e-05,
      "loss": 0.0017,
      "step": 37290
    },
    {
      "epoch": 1.1419649144291706,
      "grad_norm": 0.04205833375453949,
      "learning_rate": 1.2387104675014543e-05,
      "loss": 0.0011,
      "step": 37300
    },
    {
      "epoch": 1.1422710712426905,
      "grad_norm": 0.09873752295970917,
      "learning_rate": 1.2385063629591079e-05,
      "loss": 0.0017,
      "step": 37310
    },
    {
      "epoch": 1.1425772280562103,
      "grad_norm": 0.01832468993961811,
      "learning_rate": 1.2383022584167612e-05,
      "loss": 0.0008,
      "step": 37320
    },
    {
      "epoch": 1.1428833848697302,
      "grad_norm": 0.015765108168125153,
      "learning_rate": 1.2380981538744146e-05,
      "loss": 0.0007,
      "step": 37330
    },
    {
      "epoch": 1.1431895416832503,
      "grad_norm": 0.01690189726650715,
      "learning_rate": 1.237894049332068e-05,
      "loss": 0.0401,
      "step": 37340
    },
    {
      "epoch": 1.1434956984967701,
      "grad_norm": 0.019173018634319305,
      "learning_rate": 1.2376899447897215e-05,
      "loss": 0.0362,
      "step": 37350
    },
    {
      "epoch": 1.14380185531029,
      "grad_norm": 0.047811783850193024,
      "learning_rate": 1.2374858402473748e-05,
      "loss": 0.0016,
      "step": 37360
    },
    {
      "epoch": 1.1441080121238099,
      "grad_norm": 0.7892309427261353,
      "learning_rate": 1.2372817357050282e-05,
      "loss": 0.0664,
      "step": 37370
    },
    {
      "epoch": 1.1444141689373297,
      "grad_norm": 0.03382469713687897,
      "learning_rate": 1.2370776311626816e-05,
      "loss": 0.0295,
      "step": 37380
    },
    {
      "epoch": 1.1447203257508496,
      "grad_norm": 0.02977156825363636,
      "learning_rate": 1.2368735266203351e-05,
      "loss": 0.0389,
      "step": 37390
    },
    {
      "epoch": 1.1450264825643695,
      "grad_norm": 0.02310214750468731,
      "learning_rate": 1.2366694220779885e-05,
      "loss": 0.001,
      "step": 37400
    },
    {
      "epoch": 1.1453326393778893,
      "grad_norm": 0.026604820042848587,
      "learning_rate": 1.2364653175356418e-05,
      "loss": 0.0392,
      "step": 37410
    },
    {
      "epoch": 1.1456387961914092,
      "grad_norm": 0.1020294725894928,
      "learning_rate": 1.2362612129932952e-05,
      "loss": 0.0017,
      "step": 37420
    },
    {
      "epoch": 1.145944953004929,
      "grad_norm": 0.03039960004389286,
      "learning_rate": 1.2360571084509487e-05,
      "loss": 0.0378,
      "step": 37430
    },
    {
      "epoch": 1.146251109818449,
      "grad_norm": 0.013624205254018307,
      "learning_rate": 1.2358530039086021e-05,
      "loss": 0.0337,
      "step": 37440
    },
    {
      "epoch": 1.146557266631969,
      "grad_norm": 0.057501811534166336,
      "learning_rate": 1.2356488993662555e-05,
      "loss": 0.0016,
      "step": 37450
    },
    {
      "epoch": 1.1468634234454889,
      "grad_norm": 0.021175077185034752,
      "learning_rate": 1.235444794823909e-05,
      "loss": 0.0023,
      "step": 37460
    },
    {
      "epoch": 1.1471695802590087,
      "grad_norm": 0.054643720388412476,
      "learning_rate": 1.2352406902815624e-05,
      "loss": 0.0015,
      "step": 37470
    },
    {
      "epoch": 1.1474757370725286,
      "grad_norm": 0.010850496590137482,
      "learning_rate": 1.2350365857392157e-05,
      "loss": 0.0017,
      "step": 37480
    },
    {
      "epoch": 1.1477818938860485,
      "grad_norm": 0.014736332930624485,
      "learning_rate": 1.2348324811968691e-05,
      "loss": 0.0006,
      "step": 37490
    },
    {
      "epoch": 1.1480880506995683,
      "grad_norm": 0.029190532863140106,
      "learning_rate": 1.2346283766545226e-05,
      "loss": 0.0013,
      "step": 37500
    },
    {
      "epoch": 1.1483942075130882,
      "grad_norm": 0.06234016641974449,
      "learning_rate": 1.234424272112176e-05,
      "loss": 0.0014,
      "step": 37510
    },
    {
      "epoch": 1.148700364326608,
      "grad_norm": 0.06352265924215317,
      "learning_rate": 1.2342201675698294e-05,
      "loss": 0.0009,
      "step": 37520
    },
    {
      "epoch": 1.149006521140128,
      "grad_norm": 0.015005267225205898,
      "learning_rate": 1.2340160630274827e-05,
      "loss": 0.0009,
      "step": 37530
    },
    {
      "epoch": 1.1493126779536478,
      "grad_norm": 0.0030422855634242296,
      "learning_rate": 1.2338119584851363e-05,
      "loss": 0.0325,
      "step": 37540
    },
    {
      "epoch": 1.1496188347671676,
      "grad_norm": 0.041327085345983505,
      "learning_rate": 1.2336078539427896e-05,
      "loss": 0.0068,
      "step": 37550
    },
    {
      "epoch": 1.1499249915806877,
      "grad_norm": 0.012134027667343616,
      "learning_rate": 1.233403749400443e-05,
      "loss": 0.0008,
      "step": 37560
    },
    {
      "epoch": 1.1502311483942076,
      "grad_norm": 0.031153718009591103,
      "learning_rate": 1.2331996448580965e-05,
      "loss": 0.0009,
      "step": 37570
    },
    {
      "epoch": 1.1505373052077275,
      "grad_norm": 0.019062187522649765,
      "learning_rate": 1.2329955403157499e-05,
      "loss": 0.0691,
      "step": 37580
    },
    {
      "epoch": 1.1508434620212473,
      "grad_norm": 0.037239037454128265,
      "learning_rate": 1.2327914357734032e-05,
      "loss": 0.0018,
      "step": 37590
    },
    {
      "epoch": 1.1511496188347672,
      "grad_norm": 0.03998270258307457,
      "learning_rate": 1.2325873312310566e-05,
      "loss": 0.0008,
      "step": 37600
    },
    {
      "epoch": 1.151455775648287,
      "grad_norm": 0.010566627606749535,
      "learning_rate": 1.2323832266887101e-05,
      "loss": 0.0014,
      "step": 37610
    },
    {
      "epoch": 1.151761932461807,
      "grad_norm": 0.02720932476222515,
      "learning_rate": 1.2321791221463635e-05,
      "loss": 0.0011,
      "step": 37620
    },
    {
      "epoch": 1.1520680892753268,
      "grad_norm": 0.031670667231082916,
      "learning_rate": 1.2319750176040169e-05,
      "loss": 0.032,
      "step": 37630
    },
    {
      "epoch": 1.1523742460888466,
      "grad_norm": 0.002800754504278302,
      "learning_rate": 1.2317709130616702e-05,
      "loss": 0.0377,
      "step": 37640
    },
    {
      "epoch": 1.1526804029023665,
      "grad_norm": 0.07907532900571823,
      "learning_rate": 1.2315668085193238e-05,
      "loss": 0.0286,
      "step": 37650
    },
    {
      "epoch": 1.1529865597158864,
      "grad_norm": 0.0734366849064827,
      "learning_rate": 1.2313627039769771e-05,
      "loss": 0.0381,
      "step": 37660
    },
    {
      "epoch": 1.1532927165294065,
      "grad_norm": 0.01806596852838993,
      "learning_rate": 1.2311585994346305e-05,
      "loss": 0.0019,
      "step": 37670
    },
    {
      "epoch": 1.1535988733429263,
      "grad_norm": 0.025946466252207756,
      "learning_rate": 1.230954494892284e-05,
      "loss": 0.0015,
      "step": 37680
    },
    {
      "epoch": 1.1539050301564462,
      "grad_norm": 0.0556727796792984,
      "learning_rate": 1.2307503903499374e-05,
      "loss": 0.0376,
      "step": 37690
    },
    {
      "epoch": 1.154211186969966,
      "grad_norm": 0.048515334725379944,
      "learning_rate": 1.2305462858075908e-05,
      "loss": 0.0018,
      "step": 37700
    },
    {
      "epoch": 1.154517343783486,
      "grad_norm": 0.08653651177883148,
      "learning_rate": 1.2303421812652441e-05,
      "loss": 0.0017,
      "step": 37710
    },
    {
      "epoch": 1.1548235005970058,
      "grad_norm": 0.01465428713709116,
      "learning_rate": 1.2301380767228977e-05,
      "loss": 0.033,
      "step": 37720
    },
    {
      "epoch": 1.1551296574105256,
      "grad_norm": 0.07658950984477997,
      "learning_rate": 1.229933972180551e-05,
      "loss": 0.0018,
      "step": 37730
    },
    {
      "epoch": 1.1554358142240455,
      "grad_norm": 0.024960706010460854,
      "learning_rate": 1.2297298676382044e-05,
      "loss": 0.0287,
      "step": 37740
    },
    {
      "epoch": 1.1557419710375654,
      "grad_norm": 0.04716102406382561,
      "learning_rate": 1.2295257630958578e-05,
      "loss": 0.0016,
      "step": 37750
    },
    {
      "epoch": 1.1560481278510852,
      "grad_norm": 0.015117187984287739,
      "learning_rate": 1.2293216585535113e-05,
      "loss": 0.0011,
      "step": 37760
    },
    {
      "epoch": 1.156354284664605,
      "grad_norm": 0.019815079867839813,
      "learning_rate": 1.2291175540111647e-05,
      "loss": 0.0013,
      "step": 37770
    },
    {
      "epoch": 1.1566604414781252,
      "grad_norm": 0.018025333061814308,
      "learning_rate": 1.228913449468818e-05,
      "loss": 0.0103,
      "step": 37780
    },
    {
      "epoch": 1.156966598291645,
      "grad_norm": 0.03198991343379021,
      "learning_rate": 1.2287093449264715e-05,
      "loss": 0.0012,
      "step": 37790
    },
    {
      "epoch": 1.157272755105165,
      "grad_norm": 0.01857205294072628,
      "learning_rate": 1.2285052403841249e-05,
      "loss": 0.001,
      "step": 37800
    },
    {
      "epoch": 1.1575789119186848,
      "grad_norm": 0.029157551005482674,
      "learning_rate": 1.2283011358417783e-05,
      "loss": 0.0006,
      "step": 37810
    },
    {
      "epoch": 1.1578850687322046,
      "grad_norm": 0.011641724966466427,
      "learning_rate": 1.2280970312994316e-05,
      "loss": 0.0071,
      "step": 37820
    },
    {
      "epoch": 1.1581912255457245,
      "grad_norm": 0.016484465450048447,
      "learning_rate": 1.2278929267570852e-05,
      "loss": 0.001,
      "step": 37830
    },
    {
      "epoch": 1.1584973823592444,
      "grad_norm": 0.016375087201595306,
      "learning_rate": 1.2276888222147385e-05,
      "loss": 0.0005,
      "step": 37840
    },
    {
      "epoch": 1.1588035391727642,
      "grad_norm": 0.0012014784151688218,
      "learning_rate": 1.2274847176723919e-05,
      "loss": 0.0336,
      "step": 37850
    },
    {
      "epoch": 1.159109695986284,
      "grad_norm": 0.036451682448387146,
      "learning_rate": 1.2272806131300453e-05,
      "loss": 0.0729,
      "step": 37860
    },
    {
      "epoch": 1.159415852799804,
      "grad_norm": 0.03336569666862488,
      "learning_rate": 1.2270765085876988e-05,
      "loss": 0.0028,
      "step": 37870
    },
    {
      "epoch": 1.1597220096133238,
      "grad_norm": 0.04639274999499321,
      "learning_rate": 1.2268724040453522e-05,
      "loss": 0.0014,
      "step": 37880
    },
    {
      "epoch": 1.160028166426844,
      "grad_norm": 0.03680722042918205,
      "learning_rate": 1.2266682995030055e-05,
      "loss": 0.0385,
      "step": 37890
    },
    {
      "epoch": 1.1603343232403638,
      "grad_norm": 0.0586109422147274,
      "learning_rate": 1.226464194960659e-05,
      "loss": 0.0349,
      "step": 37900
    },
    {
      "epoch": 1.1606404800538836,
      "grad_norm": 0.040933091193437576,
      "learning_rate": 1.2262600904183124e-05,
      "loss": 0.0013,
      "step": 37910
    },
    {
      "epoch": 1.1609466368674035,
      "grad_norm": 1.8617342710494995,
      "learning_rate": 1.2260559858759658e-05,
      "loss": 0.0358,
      "step": 37920
    },
    {
      "epoch": 1.1612527936809234,
      "grad_norm": 0.0028050111141055822,
      "learning_rate": 1.2258518813336192e-05,
      "loss": 0.0235,
      "step": 37930
    },
    {
      "epoch": 1.1615589504944432,
      "grad_norm": 0.048168960958719254,
      "learning_rate": 1.2256477767912727e-05,
      "loss": 0.0016,
      "step": 37940
    },
    {
      "epoch": 1.161865107307963,
      "grad_norm": 0.014078523963689804,
      "learning_rate": 1.225443672248926e-05,
      "loss": 0.0019,
      "step": 37950
    },
    {
      "epoch": 1.162171264121483,
      "grad_norm": 0.06938539445400238,
      "learning_rate": 1.2252395677065794e-05,
      "loss": 0.0016,
      "step": 37960
    },
    {
      "epoch": 1.1624774209350028,
      "grad_norm": 0.01733803004026413,
      "learning_rate": 1.2250354631642328e-05,
      "loss": 0.002,
      "step": 37970
    },
    {
      "epoch": 1.1627835777485227,
      "grad_norm": 0.005994458217173815,
      "learning_rate": 1.2248313586218863e-05,
      "loss": 0.031,
      "step": 37980
    },
    {
      "epoch": 1.1630897345620426,
      "grad_norm": 0.07876001298427582,
      "learning_rate": 1.2246272540795397e-05,
      "loss": 0.0016,
      "step": 37990
    },
    {
      "epoch": 1.1633958913755627,
      "grad_norm": 0.026101810857653618,
      "learning_rate": 1.224423149537193e-05,
      "loss": 0.0034,
      "step": 38000
    },
    {
      "epoch": 1.1637020481890825,
      "grad_norm": 0.028586549684405327,
      "learning_rate": 1.2242190449948466e-05,
      "loss": 0.0014,
      "step": 38010
    },
    {
      "epoch": 1.1640082050026024,
      "grad_norm": 0.02809256874024868,
      "learning_rate": 1.2240149404525e-05,
      "loss": 0.0012,
      "step": 38020
    },
    {
      "epoch": 1.1643143618161222,
      "grad_norm": 0.06706131994724274,
      "learning_rate": 1.2238108359101533e-05,
      "loss": 0.0012,
      "step": 38030
    },
    {
      "epoch": 1.164620518629642,
      "grad_norm": 0.027650434523820877,
      "learning_rate": 1.2236067313678067e-05,
      "loss": 0.0007,
      "step": 38040
    },
    {
      "epoch": 1.164926675443162,
      "grad_norm": 0.014089705422520638,
      "learning_rate": 1.2234026268254602e-05,
      "loss": 0.0007,
      "step": 38050
    },
    {
      "epoch": 1.1652328322566818,
      "grad_norm": 0.02093607932329178,
      "learning_rate": 1.2231985222831136e-05,
      "loss": 0.0383,
      "step": 38060
    },
    {
      "epoch": 1.1655389890702017,
      "grad_norm": 0.028116319328546524,
      "learning_rate": 1.222994417740767e-05,
      "loss": 0.0005,
      "step": 38070
    },
    {
      "epoch": 1.1658451458837216,
      "grad_norm": 0.03291720896959305,
      "learning_rate": 1.2227903131984203e-05,
      "loss": 0.001,
      "step": 38080
    },
    {
      "epoch": 1.1661513026972414,
      "grad_norm": 0.016307709738612175,
      "learning_rate": 1.2225862086560738e-05,
      "loss": 0.0321,
      "step": 38090
    },
    {
      "epoch": 1.1664574595107613,
      "grad_norm": 0.02449343167245388,
      "learning_rate": 1.2223821041137272e-05,
      "loss": 0.0016,
      "step": 38100
    },
    {
      "epoch": 1.1667636163242814,
      "grad_norm": 0.05762265622615814,
      "learning_rate": 1.2221779995713806e-05,
      "loss": 0.0195,
      "step": 38110
    },
    {
      "epoch": 1.1670697731378012,
      "grad_norm": 0.02601505257189274,
      "learning_rate": 1.2219738950290341e-05,
      "loss": 0.0011,
      "step": 38120
    },
    {
      "epoch": 1.1673759299513211,
      "grad_norm": 0.024213125929236412,
      "learning_rate": 1.2217697904866875e-05,
      "loss": 0.001,
      "step": 38130
    },
    {
      "epoch": 1.167682086764841,
      "grad_norm": 0.02704552188515663,
      "learning_rate": 1.2215656859443408e-05,
      "loss": 0.001,
      "step": 38140
    },
    {
      "epoch": 1.1679882435783608,
      "grad_norm": 0.01718403957784176,
      "learning_rate": 1.2213615814019942e-05,
      "loss": 0.0238,
      "step": 38150
    },
    {
      "epoch": 1.1682944003918807,
      "grad_norm": 0.012995434924960136,
      "learning_rate": 1.2211574768596477e-05,
      "loss": 0.0378,
      "step": 38160
    },
    {
      "epoch": 1.1686005572054006,
      "grad_norm": 0.006484533194452524,
      "learning_rate": 1.2209533723173011e-05,
      "loss": 0.001,
      "step": 38170
    },
    {
      "epoch": 1.1689067140189204,
      "grad_norm": 0.02807583473622799,
      "learning_rate": 1.2207492677749545e-05,
      "loss": 0.0024,
      "step": 38180
    },
    {
      "epoch": 1.1692128708324403,
      "grad_norm": 0.021906182169914246,
      "learning_rate": 1.2205451632326078e-05,
      "loss": 0.0531,
      "step": 38190
    },
    {
      "epoch": 1.1695190276459604,
      "grad_norm": 0.02668302319943905,
      "learning_rate": 1.2203410586902614e-05,
      "loss": 0.0427,
      "step": 38200
    },
    {
      "epoch": 1.16982518445948,
      "grad_norm": 0.007979449816048145,
      "learning_rate": 1.2201369541479147e-05,
      "loss": 0.0009,
      "step": 38210
    },
    {
      "epoch": 1.1701313412730001,
      "grad_norm": 0.11280495673418045,
      "learning_rate": 1.219932849605568e-05,
      "loss": 0.0016,
      "step": 38220
    },
    {
      "epoch": 1.17043749808652,
      "grad_norm": 0.021437672898173332,
      "learning_rate": 1.2197287450632216e-05,
      "loss": 0.0344,
      "step": 38230
    },
    {
      "epoch": 1.1707436549000398,
      "grad_norm": 0.026379982009530067,
      "learning_rate": 1.219524640520875e-05,
      "loss": 0.039,
      "step": 38240
    },
    {
      "epoch": 1.1710498117135597,
      "grad_norm": 0.07083189487457275,
      "learning_rate": 1.2193205359785283e-05,
      "loss": 0.0011,
      "step": 38250
    },
    {
      "epoch": 1.1713559685270796,
      "grad_norm": 0.0051727755926549435,
      "learning_rate": 1.2191164314361817e-05,
      "loss": 0.0011,
      "step": 38260
    },
    {
      "epoch": 1.1716621253405994,
      "grad_norm": 0.022049665451049805,
      "learning_rate": 1.2189123268938352e-05,
      "loss": 0.0014,
      "step": 38270
    },
    {
      "epoch": 1.1719682821541193,
      "grad_norm": 0.0043151904828846455,
      "learning_rate": 1.2187082223514886e-05,
      "loss": 0.0008,
      "step": 38280
    },
    {
      "epoch": 1.1722744389676392,
      "grad_norm": 1.777601957321167,
      "learning_rate": 1.218504117809142e-05,
      "loss": 0.0565,
      "step": 38290
    },
    {
      "epoch": 1.172580595781159,
      "grad_norm": 0.061789944767951965,
      "learning_rate": 1.2183000132667953e-05,
      "loss": 0.0019,
      "step": 38300
    },
    {
      "epoch": 1.1728867525946791,
      "grad_norm": 0.015381402336061,
      "learning_rate": 1.2180959087244489e-05,
      "loss": 0.0327,
      "step": 38310
    },
    {
      "epoch": 1.1731929094081988,
      "grad_norm": 0.055037595331668854,
      "learning_rate": 1.2178918041821022e-05,
      "loss": 0.002,
      "step": 38320
    },
    {
      "epoch": 1.1734990662217188,
      "grad_norm": 0.04543667286634445,
      "learning_rate": 1.2176876996397556e-05,
      "loss": 0.0015,
      "step": 38330
    },
    {
      "epoch": 1.1738052230352387,
      "grad_norm": 0.03746368736028671,
      "learning_rate": 1.2174835950974091e-05,
      "loss": 0.0648,
      "step": 38340
    },
    {
      "epoch": 1.1741113798487586,
      "grad_norm": 0.033077824860811234,
      "learning_rate": 1.2172794905550625e-05,
      "loss": 0.0013,
      "step": 38350
    },
    {
      "epoch": 1.1744175366622784,
      "grad_norm": 0.000594848592299968,
      "learning_rate": 1.2170753860127159e-05,
      "loss": 0.0097,
      "step": 38360
    },
    {
      "epoch": 1.1747236934757983,
      "grad_norm": 0.016724085435271263,
      "learning_rate": 1.2168712814703692e-05,
      "loss": 0.0013,
      "step": 38370
    },
    {
      "epoch": 1.1750298502893182,
      "grad_norm": 0.02746296487748623,
      "learning_rate": 1.2166671769280228e-05,
      "loss": 0.0354,
      "step": 38380
    },
    {
      "epoch": 1.175336007102838,
      "grad_norm": 0.021144762635231018,
      "learning_rate": 1.2164630723856761e-05,
      "loss": 0.0306,
      "step": 38390
    },
    {
      "epoch": 1.175642163916358,
      "grad_norm": 0.05534280464053154,
      "learning_rate": 1.2162589678433295e-05,
      "loss": 0.0013,
      "step": 38400
    },
    {
      "epoch": 1.1759483207298778,
      "grad_norm": 0.035680897533893585,
      "learning_rate": 1.2160548633009827e-05,
      "loss": 0.0013,
      "step": 38410
    },
    {
      "epoch": 1.1762544775433978,
      "grad_norm": 0.021974096074700356,
      "learning_rate": 1.2158507587586364e-05,
      "loss": 0.0011,
      "step": 38420
    },
    {
      "epoch": 1.1765606343569175,
      "grad_norm": 0.01935272291302681,
      "learning_rate": 1.2156466542162898e-05,
      "loss": 0.0018,
      "step": 38430
    },
    {
      "epoch": 1.1768667911704376,
      "grad_norm": 0.03430639207363129,
      "learning_rate": 1.2154425496739431e-05,
      "loss": 0.0009,
      "step": 38440
    },
    {
      "epoch": 1.1771729479839574,
      "grad_norm": 0.02031582035124302,
      "learning_rate": 1.2152384451315967e-05,
      "loss": 0.001,
      "step": 38450
    },
    {
      "epoch": 1.1774791047974773,
      "grad_norm": 0.016442906111478806,
      "learning_rate": 1.21503434058925e-05,
      "loss": 0.0007,
      "step": 38460
    },
    {
      "epoch": 1.1777852616109972,
      "grad_norm": 0.04021858796477318,
      "learning_rate": 1.2148302360469034e-05,
      "loss": 0.0283,
      "step": 38470
    },
    {
      "epoch": 1.178091418424517,
      "grad_norm": 0.03376032039523125,
      "learning_rate": 1.2146261315045567e-05,
      "loss": 0.0009,
      "step": 38480
    },
    {
      "epoch": 1.178397575238037,
      "grad_norm": 0.009415697306394577,
      "learning_rate": 1.2144220269622103e-05,
      "loss": 0.0012,
      "step": 38490
    },
    {
      "epoch": 1.1787037320515568,
      "grad_norm": 0.009288489818572998,
      "learning_rate": 1.2142179224198636e-05,
      "loss": 0.0729,
      "step": 38500
    },
    {
      "epoch": 1.1790098888650766,
      "grad_norm": 0.02595476806163788,
      "learning_rate": 1.214013817877517e-05,
      "loss": 0.0014,
      "step": 38510
    },
    {
      "epoch": 1.1793160456785965,
      "grad_norm": 0.02336922101676464,
      "learning_rate": 1.2138097133351702e-05,
      "loss": 0.0013,
      "step": 38520
    },
    {
      "epoch": 1.1796222024921166,
      "grad_norm": 0.059030722826719284,
      "learning_rate": 1.2136056087928239e-05,
      "loss": 0.0022,
      "step": 38530
    },
    {
      "epoch": 1.1799283593056364,
      "grad_norm": 0.9594525098800659,
      "learning_rate": 1.2134015042504773e-05,
      "loss": 0.0407,
      "step": 38540
    },
    {
      "epoch": 1.1802345161191563,
      "grad_norm": 0.01656101644039154,
      "learning_rate": 1.2131973997081306e-05,
      "loss": 0.0355,
      "step": 38550
    },
    {
      "epoch": 1.1805406729326762,
      "grad_norm": 0.025341087952256203,
      "learning_rate": 1.2129932951657842e-05,
      "loss": 0.0343,
      "step": 38560
    },
    {
      "epoch": 1.180846829746196,
      "grad_norm": 0.03164051100611687,
      "learning_rate": 1.2127891906234375e-05,
      "loss": 0.0333,
      "step": 38570
    },
    {
      "epoch": 1.181152986559716,
      "grad_norm": 0.03652889281511307,
      "learning_rate": 1.2125850860810909e-05,
      "loss": 0.0284,
      "step": 38580
    },
    {
      "epoch": 1.1814591433732358,
      "grad_norm": 0.28691306710243225,
      "learning_rate": 1.2123809815387441e-05,
      "loss": 0.0023,
      "step": 38590
    },
    {
      "epoch": 1.1817653001867556,
      "grad_norm": 0.020440341904759407,
      "learning_rate": 1.2121768769963978e-05,
      "loss": 0.0389,
      "step": 38600
    },
    {
      "epoch": 1.1820714570002755,
      "grad_norm": 0.09753427654504776,
      "learning_rate": 1.2119727724540512e-05,
      "loss": 0.002,
      "step": 38610
    },
    {
      "epoch": 1.1823776138137954,
      "grad_norm": 0.04692189022898674,
      "learning_rate": 1.2117686679117045e-05,
      "loss": 0.0018,
      "step": 38620
    },
    {
      "epoch": 1.1826837706273152,
      "grad_norm": 0.06628156453371048,
      "learning_rate": 1.2115645633693577e-05,
      "loss": 0.002,
      "step": 38630
    },
    {
      "epoch": 1.1829899274408353,
      "grad_norm": 0.060217272490262985,
      "learning_rate": 1.2113604588270114e-05,
      "loss": 0.0388,
      "step": 38640
    },
    {
      "epoch": 1.1832960842543552,
      "grad_norm": 0.035013824701309204,
      "learning_rate": 1.2111563542846648e-05,
      "loss": 0.0137,
      "step": 38650
    },
    {
      "epoch": 1.183602241067875,
      "grad_norm": 0.032534707337617874,
      "learning_rate": 1.210952249742318e-05,
      "loss": 0.0012,
      "step": 38660
    },
    {
      "epoch": 1.183908397881395,
      "grad_norm": 0.027973540127277374,
      "learning_rate": 1.2107481451999713e-05,
      "loss": 0.0015,
      "step": 38670
    },
    {
      "epoch": 1.1842145546949148,
      "grad_norm": 0.03859095647931099,
      "learning_rate": 1.210544040657625e-05,
      "loss": 0.034,
      "step": 38680
    },
    {
      "epoch": 1.1845207115084346,
      "grad_norm": 0.03366000950336456,
      "learning_rate": 1.2103399361152784e-05,
      "loss": 0.0315,
      "step": 38690
    },
    {
      "epoch": 1.1848268683219545,
      "grad_norm": 0.007432068232446909,
      "learning_rate": 1.2101358315729316e-05,
      "loss": 0.0016,
      "step": 38700
    },
    {
      "epoch": 1.1851330251354744,
      "grad_norm": 0.03551546484231949,
      "learning_rate": 1.2099317270305853e-05,
      "loss": 0.0015,
      "step": 38710
    },
    {
      "epoch": 1.1854391819489942,
      "grad_norm": 0.06250543147325516,
      "learning_rate": 1.2097276224882387e-05,
      "loss": 0.0016,
      "step": 38720
    },
    {
      "epoch": 1.185745338762514,
      "grad_norm": 0.5023512840270996,
      "learning_rate": 1.209523517945892e-05,
      "loss": 0.0456,
      "step": 38730
    },
    {
      "epoch": 1.186051495576034,
      "grad_norm": 0.06429837644100189,
      "learning_rate": 1.2093194134035452e-05,
      "loss": 0.0281,
      "step": 38740
    },
    {
      "epoch": 1.186357652389554,
      "grad_norm": 0.04412788152694702,
      "learning_rate": 1.209115308861199e-05,
      "loss": 0.0584,
      "step": 38750
    },
    {
      "epoch": 1.186663809203074,
      "grad_norm": 0.03710797429084778,
      "learning_rate": 1.2089112043188523e-05,
      "loss": 0.0021,
      "step": 38760
    },
    {
      "epoch": 1.1869699660165938,
      "grad_norm": 0.04004921019077301,
      "learning_rate": 1.2087070997765055e-05,
      "loss": 0.0015,
      "step": 38770
    },
    {
      "epoch": 1.1872761228301136,
      "grad_norm": 0.05295027047395706,
      "learning_rate": 1.2085029952341589e-05,
      "loss": 0.0296,
      "step": 38780
    },
    {
      "epoch": 1.1875822796436335,
      "grad_norm": 0.012029183097183704,
      "learning_rate": 1.2082988906918126e-05,
      "loss": 0.0011,
      "step": 38790
    },
    {
      "epoch": 1.1878884364571534,
      "grad_norm": 0.053201399743556976,
      "learning_rate": 1.208094786149466e-05,
      "loss": 0.001,
      "step": 38800
    },
    {
      "epoch": 1.1881945932706732,
      "grad_norm": 0.04618555307388306,
      "learning_rate": 1.2078906816071191e-05,
      "loss": 0.0009,
      "step": 38810
    },
    {
      "epoch": 1.188500750084193,
      "grad_norm": 0.024819422513246536,
      "learning_rate": 1.2076865770647728e-05,
      "loss": 0.1013,
      "step": 38820
    },
    {
      "epoch": 1.188806906897713,
      "grad_norm": 0.028135184198617935,
      "learning_rate": 1.2074824725224262e-05,
      "loss": 0.0017,
      "step": 38830
    },
    {
      "epoch": 1.1891130637112328,
      "grad_norm": 0.029783425852656364,
      "learning_rate": 1.2072783679800794e-05,
      "loss": 0.002,
      "step": 38840
    },
    {
      "epoch": 1.1894192205247527,
      "grad_norm": 0.01362341083586216,
      "learning_rate": 1.2070742634377328e-05,
      "loss": 0.0017,
      "step": 38850
    },
    {
      "epoch": 1.1897253773382728,
      "grad_norm": 0.03715243563055992,
      "learning_rate": 1.2068701588953865e-05,
      "loss": 0.0018,
      "step": 38860
    },
    {
      "epoch": 1.1900315341517926,
      "grad_norm": 0.027991725131869316,
      "learning_rate": 1.2066660543530398e-05,
      "loss": 0.0013,
      "step": 38870
    },
    {
      "epoch": 1.1903376909653125,
      "grad_norm": 0.026461204513907433,
      "learning_rate": 1.206461949810693e-05,
      "loss": 0.0103,
      "step": 38880
    },
    {
      "epoch": 1.1906438477788324,
      "grad_norm": 0.011119581758975983,
      "learning_rate": 1.2062578452683464e-05,
      "loss": 0.0008,
      "step": 38890
    },
    {
      "epoch": 1.1909500045923522,
      "grad_norm": 0.036224085837602615,
      "learning_rate": 1.206053740726e-05,
      "loss": 0.0019,
      "step": 38900
    },
    {
      "epoch": 1.191256161405872,
      "grad_norm": 0.021280258893966675,
      "learning_rate": 1.2058496361836533e-05,
      "loss": 0.0102,
      "step": 38910
    },
    {
      "epoch": 1.191562318219392,
      "grad_norm": 0.015357665717601776,
      "learning_rate": 1.2056455316413066e-05,
      "loss": 0.0387,
      "step": 38920
    },
    {
      "epoch": 1.1918684750329118,
      "grad_norm": 0.04298175126314163,
      "learning_rate": 1.2054414270989603e-05,
      "loss": 0.0296,
      "step": 38930
    },
    {
      "epoch": 1.1921746318464317,
      "grad_norm": 0.046351026743650436,
      "learning_rate": 1.2052373225566137e-05,
      "loss": 0.0022,
      "step": 38940
    },
    {
      "epoch": 1.1924807886599516,
      "grad_norm": 0.026135414838790894,
      "learning_rate": 1.2050332180142669e-05,
      "loss": 0.0022,
      "step": 38950
    },
    {
      "epoch": 1.1927869454734714,
      "grad_norm": 0.0017323049250990152,
      "learning_rate": 1.2048291134719203e-05,
      "loss": 0.0396,
      "step": 38960
    },
    {
      "epoch": 1.1930931022869915,
      "grad_norm": 0.040212806314229965,
      "learning_rate": 1.204625008929574e-05,
      "loss": 0.0389,
      "step": 38970
    },
    {
      "epoch": 1.1933992591005114,
      "grad_norm": 0.038927607238292694,
      "learning_rate": 1.2044209043872272e-05,
      "loss": 0.0044,
      "step": 38980
    },
    {
      "epoch": 1.1937054159140312,
      "grad_norm": 0.12423747032880783,
      "learning_rate": 1.2042167998448805e-05,
      "loss": 0.0408,
      "step": 38990
    },
    {
      "epoch": 1.194011572727551,
      "grad_norm": 0.026186475530266762,
      "learning_rate": 1.2040126953025339e-05,
      "loss": 0.0022,
      "step": 39000
    },
    {
      "epoch": 1.194317729541071,
      "grad_norm": 0.0163939967751503,
      "learning_rate": 1.2038085907601876e-05,
      "loss": 0.0021,
      "step": 39010
    },
    {
      "epoch": 1.1946238863545908,
      "grad_norm": 0.04286503419280052,
      "learning_rate": 1.2036044862178408e-05,
      "loss": 0.0032,
      "step": 39020
    },
    {
      "epoch": 1.1949300431681107,
      "grad_norm": 0.032440435141325,
      "learning_rate": 1.2034003816754942e-05,
      "loss": 0.0344,
      "step": 39030
    },
    {
      "epoch": 1.1952361999816306,
      "grad_norm": 0.03105754777789116,
      "learning_rate": 1.2031962771331479e-05,
      "loss": 0.001,
      "step": 39040
    },
    {
      "epoch": 1.1955423567951504,
      "grad_norm": 0.015127632766962051,
      "learning_rate": 1.2029921725908012e-05,
      "loss": 0.001,
      "step": 39050
    },
    {
      "epoch": 1.1958485136086703,
      "grad_norm": 0.02696468122303486,
      "learning_rate": 1.2027880680484544e-05,
      "loss": 0.0353,
      "step": 39060
    },
    {
      "epoch": 1.1961546704221901,
      "grad_norm": 0.041741687804460526,
      "learning_rate": 1.2025839635061078e-05,
      "loss": 0.0011,
      "step": 39070
    },
    {
      "epoch": 1.1964608272357102,
      "grad_norm": 0.015438251197338104,
      "learning_rate": 1.2023798589637615e-05,
      "loss": 0.037,
      "step": 39080
    },
    {
      "epoch": 1.19676698404923,
      "grad_norm": 0.05492989718914032,
      "learning_rate": 1.2021757544214147e-05,
      "loss": 0.0488,
      "step": 39090
    },
    {
      "epoch": 1.19707314086275,
      "grad_norm": 0.4734390676021576,
      "learning_rate": 1.201971649879068e-05,
      "loss": 0.0032,
      "step": 39100
    },
    {
      "epoch": 1.1973792976762698,
      "grad_norm": 0.047048356384038925,
      "learning_rate": 1.2017675453367214e-05,
      "loss": 0.0279,
      "step": 39110
    },
    {
      "epoch": 1.1976854544897897,
      "grad_norm": 0.01355685479938984,
      "learning_rate": 1.2015634407943751e-05,
      "loss": 0.0011,
      "step": 39120
    },
    {
      "epoch": 1.1979916113033096,
      "grad_norm": 0.026581356301903725,
      "learning_rate": 1.2013593362520283e-05,
      "loss": 0.0022,
      "step": 39130
    },
    {
      "epoch": 1.1982977681168294,
      "grad_norm": 0.05572196841239929,
      "learning_rate": 1.2011552317096817e-05,
      "loss": 0.0015,
      "step": 39140
    },
    {
      "epoch": 1.1986039249303493,
      "grad_norm": 0.02426740899682045,
      "learning_rate": 1.2009511271673354e-05,
      "loss": 0.0016,
      "step": 39150
    },
    {
      "epoch": 1.1989100817438691,
      "grad_norm": 0.03568313643336296,
      "learning_rate": 1.2007470226249886e-05,
      "loss": 0.1331,
      "step": 39160
    },
    {
      "epoch": 1.199216238557389,
      "grad_norm": 0.04027869179844856,
      "learning_rate": 1.200542918082642e-05,
      "loss": 0.0697,
      "step": 39170
    },
    {
      "epoch": 1.1995223953709089,
      "grad_norm": 0.037620145827531815,
      "learning_rate": 1.2003388135402953e-05,
      "loss": 0.052,
      "step": 39180
    },
    {
      "epoch": 1.199828552184429,
      "grad_norm": 0.17238466441631317,
      "learning_rate": 1.200134708997949e-05,
      "loss": 0.0057,
      "step": 39190
    },
    {
      "epoch": 1.2001347089979488,
      "grad_norm": 0.02979290671646595,
      "learning_rate": 1.1999306044556022e-05,
      "loss": 0.0368,
      "step": 39200
    },
    {
      "epoch": 1.2004408658114687,
      "grad_norm": 0.20303142070770264,
      "learning_rate": 1.1997264999132556e-05,
      "loss": 0.0038,
      "step": 39210
    },
    {
      "epoch": 1.2007470226249886,
      "grad_norm": 0.08915262669324875,
      "learning_rate": 1.199522395370909e-05,
      "loss": 0.0293,
      "step": 39220
    },
    {
      "epoch": 1.2010531794385084,
      "grad_norm": 0.08308975398540497,
      "learning_rate": 1.1993182908285625e-05,
      "loss": 0.0034,
      "step": 39230
    },
    {
      "epoch": 1.2013593362520283,
      "grad_norm": 0.05903277546167374,
      "learning_rate": 1.1991141862862158e-05,
      "loss": 0.0027,
      "step": 39240
    },
    {
      "epoch": 1.2016654930655482,
      "grad_norm": 0.04424624145030975,
      "learning_rate": 1.1989100817438692e-05,
      "loss": 0.0068,
      "step": 39250
    },
    {
      "epoch": 1.201971649879068,
      "grad_norm": 0.04752059653401375,
      "learning_rate": 1.1987059772015229e-05,
      "loss": 0.003,
      "step": 39260
    },
    {
      "epoch": 1.2022778066925879,
      "grad_norm": 0.07848433405160904,
      "learning_rate": 1.1985018726591761e-05,
      "loss": 0.032,
      "step": 39270
    },
    {
      "epoch": 1.2025839635061077,
      "grad_norm": 0.03430159017443657,
      "learning_rate": 1.1982977681168295e-05,
      "loss": 0.0018,
      "step": 39280
    },
    {
      "epoch": 1.2028901203196276,
      "grad_norm": 0.038140829652547836,
      "learning_rate": 1.1980936635744828e-05,
      "loss": 0.0312,
      "step": 39290
    },
    {
      "epoch": 1.2031962771331477,
      "grad_norm": 0.2091689258813858,
      "learning_rate": 1.1978895590321365e-05,
      "loss": 0.0314,
      "step": 39300
    },
    {
      "epoch": 1.2035024339466676,
      "grad_norm": 0.028701500967144966,
      "learning_rate": 1.1976854544897897e-05,
      "loss": 0.0241,
      "step": 39310
    },
    {
      "epoch": 1.2038085907601874,
      "grad_norm": 0.07102729380130768,
      "learning_rate": 1.197481349947443e-05,
      "loss": 0.0023,
      "step": 39320
    },
    {
      "epoch": 1.2041147475737073,
      "grad_norm": 0.04270045459270477,
      "learning_rate": 1.1972772454050964e-05,
      "loss": 0.0019,
      "step": 39330
    },
    {
      "epoch": 1.2044209043872272,
      "grad_norm": 0.029467256739735603,
      "learning_rate": 1.19707314086275e-05,
      "loss": 0.032,
      "step": 39340
    },
    {
      "epoch": 1.204727061200747,
      "grad_norm": 0.031024783849716187,
      "learning_rate": 1.1968690363204033e-05,
      "loss": 0.0014,
      "step": 39350
    },
    {
      "epoch": 1.2050332180142669,
      "grad_norm": 0.010830636136233807,
      "learning_rate": 1.1966649317780567e-05,
      "loss": 0.0017,
      "step": 39360
    },
    {
      "epoch": 1.2053393748277867,
      "grad_norm": 0.03323940187692642,
      "learning_rate": 1.1964608272357104e-05,
      "loss": 0.0021,
      "step": 39370
    },
    {
      "epoch": 1.2056455316413066,
      "grad_norm": 0.027573199942708015,
      "learning_rate": 1.1962567226933636e-05,
      "loss": 0.0016,
      "step": 39380
    },
    {
      "epoch": 1.2059516884548265,
      "grad_norm": 0.009088699705898762,
      "learning_rate": 1.196052618151017e-05,
      "loss": 0.0368,
      "step": 39390
    },
    {
      "epoch": 1.2062578452683463,
      "grad_norm": 0.047129932790994644,
      "learning_rate": 1.1958485136086703e-05,
      "loss": 0.007,
      "step": 39400
    },
    {
      "epoch": 1.2065640020818664,
      "grad_norm": 0.09180090576410294,
      "learning_rate": 1.1956444090663239e-05,
      "loss": 0.0013,
      "step": 39410
    },
    {
      "epoch": 1.2068701588953863,
      "grad_norm": 0.24241109192371368,
      "learning_rate": 1.1954403045239772e-05,
      "loss": 0.0016,
      "step": 39420
    },
    {
      "epoch": 1.2071763157089062,
      "grad_norm": 0.04993259161710739,
      "learning_rate": 1.1952361999816306e-05,
      "loss": 0.0014,
      "step": 39430
    },
    {
      "epoch": 1.207482472522426,
      "grad_norm": 0.0405462272465229,
      "learning_rate": 1.195032095439284e-05,
      "loss": 0.0013,
      "step": 39440
    },
    {
      "epoch": 1.2077886293359459,
      "grad_norm": 0.023909885436296463,
      "learning_rate": 1.1948279908969375e-05,
      "loss": 0.0013,
      "step": 39450
    },
    {
      "epoch": 1.2080947861494657,
      "grad_norm": 0.031123772263526917,
      "learning_rate": 1.1946238863545909e-05,
      "loss": 0.001,
      "step": 39460
    },
    {
      "epoch": 1.2084009429629856,
      "grad_norm": 0.005419378634542227,
      "learning_rate": 1.1944197818122442e-05,
      "loss": 0.0006,
      "step": 39470
    },
    {
      "epoch": 1.2087070997765055,
      "grad_norm": 0.035007160156965256,
      "learning_rate": 1.1942156772698978e-05,
      "loss": 0.0015,
      "step": 39480
    },
    {
      "epoch": 1.2090132565900253,
      "grad_norm": 0.012465584091842175,
      "learning_rate": 1.1940115727275511e-05,
      "loss": 0.0012,
      "step": 39490
    },
    {
      "epoch": 1.2093194134035452,
      "grad_norm": 0.029297472909092903,
      "learning_rate": 1.1938074681852045e-05,
      "loss": 0.0007,
      "step": 39500
    },
    {
      "epoch": 1.209625570217065,
      "grad_norm": 0.025862671434879303,
      "learning_rate": 1.1936033636428579e-05,
      "loss": 0.0004,
      "step": 39510
    },
    {
      "epoch": 1.2099317270305852,
      "grad_norm": 0.025514476001262665,
      "learning_rate": 1.1933992591005114e-05,
      "loss": 0.0007,
      "step": 39520
    },
    {
      "epoch": 1.210237883844105,
      "grad_norm": 0.023312292993068695,
      "learning_rate": 1.1931951545581648e-05,
      "loss": 0.0353,
      "step": 39530
    },
    {
      "epoch": 1.2105440406576249,
      "grad_norm": 0.014039776287972927,
      "learning_rate": 1.1929910500158181e-05,
      "loss": 0.0326,
      "step": 39540
    },
    {
      "epoch": 1.2108501974711448,
      "grad_norm": 0.02212454378604889,
      "learning_rate": 1.1927869454734715e-05,
      "loss": 0.0008,
      "step": 39550
    },
    {
      "epoch": 1.2111563542846646,
      "grad_norm": 0.031168270856142044,
      "learning_rate": 1.192582840931125e-05,
      "loss": 0.0009,
      "step": 39560
    },
    {
      "epoch": 1.2114625110981845,
      "grad_norm": 0.04070692136883736,
      "learning_rate": 1.1923787363887784e-05,
      "loss": 0.0008,
      "step": 39570
    },
    {
      "epoch": 1.2117686679117043,
      "grad_norm": 0.03335321694612503,
      "learning_rate": 1.1921746318464317e-05,
      "loss": 0.0109,
      "step": 39580
    },
    {
      "epoch": 1.2120748247252242,
      "grad_norm": 0.021928058937191963,
      "learning_rate": 1.1919705273040853e-05,
      "loss": 0.001,
      "step": 39590
    },
    {
      "epoch": 1.212380981538744,
      "grad_norm": 0.033460620790719986,
      "learning_rate": 1.1917664227617386e-05,
      "loss": 0.0462,
      "step": 39600
    },
    {
      "epoch": 1.212687138352264,
      "grad_norm": 0.026801176369190216,
      "learning_rate": 1.191562318219392e-05,
      "loss": 0.0008,
      "step": 39610
    },
    {
      "epoch": 1.2129932951657838,
      "grad_norm": 0.017900891602039337,
      "learning_rate": 1.1913582136770454e-05,
      "loss": 0.0009,
      "step": 39620
    },
    {
      "epoch": 1.213299451979304,
      "grad_norm": 0.0003781926352530718,
      "learning_rate": 1.1911541091346989e-05,
      "loss": 0.0245,
      "step": 39630
    },
    {
      "epoch": 1.2136056087928238,
      "grad_norm": 0.047219980508089066,
      "learning_rate": 1.1909500045923523e-05,
      "loss": 0.0011,
      "step": 39640
    },
    {
      "epoch": 1.2139117656063436,
      "grad_norm": 0.04772691801190376,
      "learning_rate": 1.1907459000500056e-05,
      "loss": 0.0009,
      "step": 39650
    },
    {
      "epoch": 1.2142179224198635,
      "grad_norm": 0.030180001631379128,
      "learning_rate": 1.190541795507659e-05,
      "loss": 0.0226,
      "step": 39660
    },
    {
      "epoch": 1.2145240792333833,
      "grad_norm": 0.03074001707136631,
      "learning_rate": 1.1903376909653125e-05,
      "loss": 0.0012,
      "step": 39670
    },
    {
      "epoch": 1.2148302360469032,
      "grad_norm": 0.025278516113758087,
      "learning_rate": 1.1901335864229659e-05,
      "loss": 0.0007,
      "step": 39680
    },
    {
      "epoch": 1.215136392860423,
      "grad_norm": 0.013325108215212822,
      "learning_rate": 1.1899294818806193e-05,
      "loss": 0.0364,
      "step": 39690
    },
    {
      "epoch": 1.215442549673943,
      "grad_norm": 0.026840366423130035,
      "learning_rate": 1.1897253773382728e-05,
      "loss": 0.0318,
      "step": 39700
    },
    {
      "epoch": 1.2157487064874628,
      "grad_norm": 0.00821158941835165,
      "learning_rate": 1.1895212727959262e-05,
      "loss": 0.0212,
      "step": 39710
    },
    {
      "epoch": 1.2160548633009827,
      "grad_norm": 0.11531173437833786,
      "learning_rate": 1.1893171682535795e-05,
      "loss": 0.0657,
      "step": 39720
    },
    {
      "epoch": 1.2163610201145025,
      "grad_norm": 0.03070586360991001,
      "learning_rate": 1.1891130637112329e-05,
      "loss": 0.0294,
      "step": 39730
    },
    {
      "epoch": 1.2166671769280226,
      "grad_norm": 0.06611106544733047,
      "learning_rate": 1.1889089591688864e-05,
      "loss": 0.0018,
      "step": 39740
    },
    {
      "epoch": 1.2169733337415425,
      "grad_norm": 0.09714654833078384,
      "learning_rate": 1.1887048546265398e-05,
      "loss": 0.0026,
      "step": 39750
    },
    {
      "epoch": 1.2172794905550623,
      "grad_norm": 1.9236817359924316,
      "learning_rate": 1.1885007500841932e-05,
      "loss": 0.0349,
      "step": 39760
    },
    {
      "epoch": 1.2175856473685822,
      "grad_norm": 0.0728837251663208,
      "learning_rate": 1.1882966455418465e-05,
      "loss": 0.0019,
      "step": 39770
    },
    {
      "epoch": 1.217891804182102,
      "grad_norm": 0.043689925223588943,
      "learning_rate": 1.1880925409995e-05,
      "loss": 0.0027,
      "step": 39780
    },
    {
      "epoch": 1.218197960995622,
      "grad_norm": 0.0186697356402874,
      "learning_rate": 1.1878884364571534e-05,
      "loss": 0.0052,
      "step": 39790
    },
    {
      "epoch": 1.2185041178091418,
      "grad_norm": 0.062083713710308075,
      "learning_rate": 1.1876843319148068e-05,
      "loss": 0.0343,
      "step": 39800
    },
    {
      "epoch": 1.2188102746226617,
      "grad_norm": 0.050045426934957504,
      "learning_rate": 1.1874802273724603e-05,
      "loss": 0.0015,
      "step": 39810
    },
    {
      "epoch": 1.2191164314361815,
      "grad_norm": 0.0362766869366169,
      "learning_rate": 1.1872761228301137e-05,
      "loss": 0.003,
      "step": 39820
    },
    {
      "epoch": 1.2194225882497014,
      "grad_norm": 2.167527675628662,
      "learning_rate": 1.187072018287767e-05,
      "loss": 0.0817,
      "step": 39830
    },
    {
      "epoch": 1.2197287450632213,
      "grad_norm": 0.03803637623786926,
      "learning_rate": 1.1868679137454204e-05,
      "loss": 0.0013,
      "step": 39840
    },
    {
      "epoch": 1.2200349018767414,
      "grad_norm": 0.05165257304906845,
      "learning_rate": 1.186663809203074e-05,
      "loss": 0.0969,
      "step": 39850
    },
    {
      "epoch": 1.2203410586902612,
      "grad_norm": 0.043362125754356384,
      "learning_rate": 1.1864597046607273e-05,
      "loss": 0.0089,
      "step": 39860
    },
    {
      "epoch": 1.220647215503781,
      "grad_norm": 0.023708345368504524,
      "learning_rate": 1.1862556001183807e-05,
      "loss": 0.0023,
      "step": 39870
    },
    {
      "epoch": 1.220953372317301,
      "grad_norm": 1.6111876964569092,
      "learning_rate": 1.186051495576034e-05,
      "loss": 0.0295,
      "step": 39880
    },
    {
      "epoch": 1.2212595291308208,
      "grad_norm": 0.03296411782503128,
      "learning_rate": 1.1858473910336876e-05,
      "loss": 0.031,
      "step": 39890
    },
    {
      "epoch": 1.2215656859443407,
      "grad_norm": 0.04726763442158699,
      "learning_rate": 1.185643286491341e-05,
      "loss": 0.0647,
      "step": 39900
    },
    {
      "epoch": 1.2218718427578605,
      "grad_norm": 0.032958321273326874,
      "learning_rate": 1.1854391819489943e-05,
      "loss": 0.0019,
      "step": 39910
    },
    {
      "epoch": 1.2221779995713804,
      "grad_norm": 0.03096693754196167,
      "learning_rate": 1.1852350774066477e-05,
      "loss": 0.005,
      "step": 39920
    },
    {
      "epoch": 1.2224841563849003,
      "grad_norm": 0.056201063096523285,
      "learning_rate": 1.1850309728643012e-05,
      "loss": 0.002,
      "step": 39930
    },
    {
      "epoch": 1.2227903131984204,
      "grad_norm": 0.03706488013267517,
      "learning_rate": 1.1848268683219546e-05,
      "loss": 0.0024,
      "step": 39940
    },
    {
      "epoch": 1.22309647001194,
      "grad_norm": 0.02095707505941391,
      "learning_rate": 1.184622763779608e-05,
      "loss": 0.002,
      "step": 39950
    },
    {
      "epoch": 1.22340262682546,
      "grad_norm": 0.03674953803420067,
      "learning_rate": 1.1844186592372615e-05,
      "loss": 0.0017,
      "step": 39960
    },
    {
      "epoch": 1.22370878363898,
      "grad_norm": 0.06969257444143295,
      "learning_rate": 1.1842145546949148e-05,
      "loss": 0.0409,
      "step": 39970
    },
    {
      "epoch": 1.2240149404524998,
      "grad_norm": 0.03731141239404678,
      "learning_rate": 1.1840104501525682e-05,
      "loss": 0.0018,
      "step": 39980
    },
    {
      "epoch": 1.2243210972660197,
      "grad_norm": 0.02443220652639866,
      "learning_rate": 1.1838063456102215e-05,
      "loss": 0.0018,
      "step": 39990
    },
    {
      "epoch": 1.2246272540795395,
      "grad_norm": 0.014439349994063377,
      "learning_rate": 1.183602241067875e-05,
      "loss": 0.001,
      "step": 40000
    },
    {
      "epoch": 1.2249334108930594,
      "grad_norm": 0.013769291341304779,
      "learning_rate": 1.1833981365255284e-05,
      "loss": 0.0011,
      "step": 40010
    },
    {
      "epoch": 1.2252395677065793,
      "grad_norm": 0.023700488731265068,
      "learning_rate": 1.1831940319831818e-05,
      "loss": 0.0185,
      "step": 40020
    },
    {
      "epoch": 1.2255457245200991,
      "grad_norm": 0.032437920570373535,
      "learning_rate": 1.1829899274408352e-05,
      "loss": 0.0015,
      "step": 40030
    },
    {
      "epoch": 1.225851881333619,
      "grad_norm": 0.011792253702878952,
      "learning_rate": 1.1827858228984887e-05,
      "loss": 0.0011,
      "step": 40040
    },
    {
      "epoch": 1.226158038147139,
      "grad_norm": 0.01776542142033577,
      "learning_rate": 1.182581718356142e-05,
      "loss": 0.001,
      "step": 40050
    },
    {
      "epoch": 1.2264641949606587,
      "grad_norm": 0.05353108420968056,
      "learning_rate": 1.1823776138137954e-05,
      "loss": 0.0013,
      "step": 40060
    },
    {
      "epoch": 1.2267703517741788,
      "grad_norm": 0.04394102469086647,
      "learning_rate": 1.182173509271449e-05,
      "loss": 0.0011,
      "step": 40070
    },
    {
      "epoch": 1.2270765085876987,
      "grad_norm": 0.032105326652526855,
      "learning_rate": 1.1819694047291023e-05,
      "loss": 0.001,
      "step": 40080
    },
    {
      "epoch": 1.2273826654012185,
      "grad_norm": 0.020241713151335716,
      "learning_rate": 1.1817653001867557e-05,
      "loss": 0.001,
      "step": 40090
    },
    {
      "epoch": 1.2276888222147384,
      "grad_norm": 0.01414589025080204,
      "learning_rate": 1.181561195644409e-05,
      "loss": 0.041,
      "step": 40100
    },
    {
      "epoch": 1.2279949790282583,
      "grad_norm": 0.03515993431210518,
      "learning_rate": 1.1813570911020626e-05,
      "loss": 0.0009,
      "step": 40110
    },
    {
      "epoch": 1.2283011358417781,
      "grad_norm": 0.02206982858479023,
      "learning_rate": 1.181152986559716e-05,
      "loss": 0.0031,
      "step": 40120
    },
    {
      "epoch": 1.228607292655298,
      "grad_norm": 0.0251136627048254,
      "learning_rate": 1.1809488820173693e-05,
      "loss": 0.0009,
      "step": 40130
    },
    {
      "epoch": 1.2289134494688179,
      "grad_norm": 0.009778983891010284,
      "learning_rate": 1.1807447774750227e-05,
      "loss": 0.0008,
      "step": 40140
    },
    {
      "epoch": 1.2292196062823377,
      "grad_norm": 0.012949882075190544,
      "learning_rate": 1.1805406729326762e-05,
      "loss": 0.0007,
      "step": 40150
    },
    {
      "epoch": 1.2295257630958578,
      "grad_norm": 0.013324587605893612,
      "learning_rate": 1.1803365683903296e-05,
      "loss": 0.0008,
      "step": 40160
    },
    {
      "epoch": 1.2298319199093777,
      "grad_norm": 0.014863073825836182,
      "learning_rate": 1.180132463847983e-05,
      "loss": 0.0006,
      "step": 40170
    },
    {
      "epoch": 1.2301380767228975,
      "grad_norm": 0.014359657652676105,
      "learning_rate": 1.1799283593056365e-05,
      "loss": 0.0007,
      "step": 40180
    },
    {
      "epoch": 1.2304442335364174,
      "grad_norm": 0.0159583929926157,
      "learning_rate": 1.1797242547632899e-05,
      "loss": 0.042,
      "step": 40190
    },
    {
      "epoch": 1.2307503903499373,
      "grad_norm": 0.013767692260444164,
      "learning_rate": 1.1795201502209432e-05,
      "loss": 0.0007,
      "step": 40200
    },
    {
      "epoch": 1.2310565471634571,
      "grad_norm": 0.006800317205488682,
      "learning_rate": 1.1793160456785966e-05,
      "loss": 0.0007,
      "step": 40210
    },
    {
      "epoch": 1.231362703976977,
      "grad_norm": 0.02770279161632061,
      "learning_rate": 1.1791119411362501e-05,
      "loss": 0.0007,
      "step": 40220
    },
    {
      "epoch": 1.2316688607904969,
      "grad_norm": 0.015789059922099113,
      "learning_rate": 1.1789078365939035e-05,
      "loss": 0.0008,
      "step": 40230
    },
    {
      "epoch": 1.2319750176040167,
      "grad_norm": 0.023717572912573814,
      "learning_rate": 1.1787037320515568e-05,
      "loss": 0.0011,
      "step": 40240
    },
    {
      "epoch": 1.2322811744175366,
      "grad_norm": 0.39986008405685425,
      "learning_rate": 1.1784996275092102e-05,
      "loss": 0.0394,
      "step": 40250
    },
    {
      "epoch": 1.2325873312310565,
      "grad_norm": 2.301090717315674,
      "learning_rate": 1.1782955229668637e-05,
      "loss": 0.0043,
      "step": 40260
    },
    {
      "epoch": 1.2328934880445765,
      "grad_norm": 0.029874226078391075,
      "learning_rate": 1.1780914184245171e-05,
      "loss": 0.0006,
      "step": 40270
    },
    {
      "epoch": 1.2331996448580964,
      "grad_norm": 0.030825616791844368,
      "learning_rate": 1.1778873138821705e-05,
      "loss": 0.0011,
      "step": 40280
    },
    {
      "epoch": 1.2335058016716163,
      "grad_norm": 0.008240379393100739,
      "learning_rate": 1.177683209339824e-05,
      "loss": 0.0009,
      "step": 40290
    },
    {
      "epoch": 1.2338119584851361,
      "grad_norm": 0.04651762545108795,
      "learning_rate": 1.1774791047974774e-05,
      "loss": 0.0009,
      "step": 40300
    },
    {
      "epoch": 1.234118115298656,
      "grad_norm": 0.022076573222875595,
      "learning_rate": 1.1772750002551307e-05,
      "loss": 0.0005,
      "step": 40310
    },
    {
      "epoch": 1.2344242721121759,
      "grad_norm": 0.008606339804828167,
      "learning_rate": 1.1770708957127841e-05,
      "loss": 0.0006,
      "step": 40320
    },
    {
      "epoch": 1.2347304289256957,
      "grad_norm": 0.02358260378241539,
      "learning_rate": 1.1768667911704376e-05,
      "loss": 0.0005,
      "step": 40330
    },
    {
      "epoch": 1.2350365857392156,
      "grad_norm": 0.01184321753680706,
      "learning_rate": 1.176662686628091e-05,
      "loss": 0.0315,
      "step": 40340
    },
    {
      "epoch": 1.2353427425527355,
      "grad_norm": 0.011912867426872253,
      "learning_rate": 1.1764585820857444e-05,
      "loss": 0.036,
      "step": 40350
    },
    {
      "epoch": 1.2356488993662553,
      "grad_norm": 0.01130910124629736,
      "learning_rate": 1.1762544775433977e-05,
      "loss": 0.0006,
      "step": 40360
    },
    {
      "epoch": 1.2359550561797752,
      "grad_norm": 0.015510273166000843,
      "learning_rate": 1.1760503730010513e-05,
      "loss": 0.0087,
      "step": 40370
    },
    {
      "epoch": 1.2362612129932953,
      "grad_norm": 0.03734106943011284,
      "learning_rate": 1.1758462684587046e-05,
      "loss": 0.0015,
      "step": 40380
    },
    {
      "epoch": 1.2365673698068151,
      "grad_norm": 0.006592414807528257,
      "learning_rate": 1.175642163916358e-05,
      "loss": 0.0382,
      "step": 40390
    },
    {
      "epoch": 1.236873526620335,
      "grad_norm": 0.023989396169781685,
      "learning_rate": 1.1754380593740115e-05,
      "loss": 0.0091,
      "step": 40400
    },
    {
      "epoch": 1.2371796834338549,
      "grad_norm": 0.018015727400779724,
      "learning_rate": 1.1752339548316649e-05,
      "loss": 0.002,
      "step": 40410
    },
    {
      "epoch": 1.2374858402473747,
      "grad_norm": 0.019274268299341202,
      "learning_rate": 1.1750298502893183e-05,
      "loss": 0.001,
      "step": 40420
    },
    {
      "epoch": 1.2377919970608946,
      "grad_norm": 0.012134626507759094,
      "learning_rate": 1.1748257457469716e-05,
      "loss": 0.0007,
      "step": 40430
    },
    {
      "epoch": 1.2380981538744145,
      "grad_norm": 0.012620101682841778,
      "learning_rate": 1.1746216412046252e-05,
      "loss": 0.0019,
      "step": 40440
    },
    {
      "epoch": 1.2384043106879343,
      "grad_norm": 0.03259187564253807,
      "learning_rate": 1.1744175366622785e-05,
      "loss": 0.001,
      "step": 40450
    },
    {
      "epoch": 1.2387104675014542,
      "grad_norm": 0.03205625340342522,
      "learning_rate": 1.1742134321199319e-05,
      "loss": 0.0753,
      "step": 40460
    },
    {
      "epoch": 1.239016624314974,
      "grad_norm": 0.00965417642146349,
      "learning_rate": 1.1740093275775852e-05,
      "loss": 0.0006,
      "step": 40470
    },
    {
      "epoch": 1.239322781128494,
      "grad_norm": 0.004944106563925743,
      "learning_rate": 1.1738052230352388e-05,
      "loss": 0.0221,
      "step": 40480
    },
    {
      "epoch": 1.239628937942014,
      "grad_norm": 0.022774918004870415,
      "learning_rate": 1.1736011184928921e-05,
      "loss": 0.0011,
      "step": 40490
    },
    {
      "epoch": 1.2399350947555339,
      "grad_norm": 0.023060422390699387,
      "learning_rate": 1.1733970139505455e-05,
      "loss": 0.036,
      "step": 40500
    },
    {
      "epoch": 1.2402412515690537,
      "grad_norm": 0.017441369593143463,
      "learning_rate": 1.173192909408199e-05,
      "loss": 0.0016,
      "step": 40510
    },
    {
      "epoch": 1.2405474083825736,
      "grad_norm": 0.03230610117316246,
      "learning_rate": 1.1729888048658524e-05,
      "loss": 0.0345,
      "step": 40520
    },
    {
      "epoch": 1.2408535651960935,
      "grad_norm": 0.04410487040877342,
      "learning_rate": 1.1727847003235058e-05,
      "loss": 0.001,
      "step": 40530
    },
    {
      "epoch": 1.2411597220096133,
      "grad_norm": 0.013471865095198154,
      "learning_rate": 1.1725805957811591e-05,
      "loss": 0.0346,
      "step": 40540
    },
    {
      "epoch": 1.2414658788231332,
      "grad_norm": 0.02716083452105522,
      "learning_rate": 1.1723764912388127e-05,
      "loss": 0.0451,
      "step": 40550
    },
    {
      "epoch": 1.241772035636653,
      "grad_norm": 0.02014525793492794,
      "learning_rate": 1.172172386696466e-05,
      "loss": 0.0007,
      "step": 40560
    },
    {
      "epoch": 1.242078192450173,
      "grad_norm": 0.024824799969792366,
      "learning_rate": 1.1719682821541194e-05,
      "loss": 0.0012,
      "step": 40570
    },
    {
      "epoch": 1.2423843492636928,
      "grad_norm": 0.005277836695313454,
      "learning_rate": 1.1717641776117728e-05,
      "loss": 0.0036,
      "step": 40580
    },
    {
      "epoch": 1.2426905060772127,
      "grad_norm": 0.018090281635522842,
      "learning_rate": 1.1715600730694263e-05,
      "loss": 0.004,
      "step": 40590
    },
    {
      "epoch": 1.2429966628907327,
      "grad_norm": 0.01211655605584383,
      "learning_rate": 1.1713559685270797e-05,
      "loss": 0.0009,
      "step": 40600
    },
    {
      "epoch": 1.2433028197042526,
      "grad_norm": 0.0029371422715485096,
      "learning_rate": 1.171151863984733e-05,
      "loss": 0.0011,
      "step": 40610
    },
    {
      "epoch": 1.2436089765177725,
      "grad_norm": 0.020933691412210464,
      "learning_rate": 1.1709477594423866e-05,
      "loss": 0.0201,
      "step": 40620
    },
    {
      "epoch": 1.2439151333312923,
      "grad_norm": 0.013469025492668152,
      "learning_rate": 1.17074365490004e-05,
      "loss": 0.0009,
      "step": 40630
    },
    {
      "epoch": 1.2442212901448122,
      "grad_norm": 0.07103529572486877,
      "learning_rate": 1.1705395503576933e-05,
      "loss": 0.001,
      "step": 40640
    },
    {
      "epoch": 1.244527446958332,
      "grad_norm": 0.014391561038792133,
      "learning_rate": 1.1703354458153466e-05,
      "loss": 0.0007,
      "step": 40650
    },
    {
      "epoch": 1.244833603771852,
      "grad_norm": 0.021739786490797997,
      "learning_rate": 1.1701313412730002e-05,
      "loss": 0.0012,
      "step": 40660
    },
    {
      "epoch": 1.2451397605853718,
      "grad_norm": 0.009938382543623447,
      "learning_rate": 1.1699272367306535e-05,
      "loss": 0.0007,
      "step": 40670
    },
    {
      "epoch": 1.2454459173988917,
      "grad_norm": 0.006723017431795597,
      "learning_rate": 1.1697231321883069e-05,
      "loss": 0.034,
      "step": 40680
    },
    {
      "epoch": 1.2457520742124115,
      "grad_norm": 0.7830818295478821,
      "learning_rate": 1.1695190276459603e-05,
      "loss": 0.0838,
      "step": 40690
    },
    {
      "epoch": 1.2460582310259314,
      "grad_norm": 0.029971055686473846,
      "learning_rate": 1.1693149231036138e-05,
      "loss": 0.0387,
      "step": 40700
    },
    {
      "epoch": 1.2463643878394515,
      "grad_norm": 0.029154153540730476,
      "learning_rate": 1.1691108185612672e-05,
      "loss": 0.001,
      "step": 40710
    },
    {
      "epoch": 1.2466705446529713,
      "grad_norm": 0.024798378348350525,
      "learning_rate": 1.1689067140189205e-05,
      "loss": 0.0087,
      "step": 40720
    },
    {
      "epoch": 1.2469767014664912,
      "grad_norm": 0.030809957534074783,
      "learning_rate": 1.168702609476574e-05,
      "loss": 0.0706,
      "step": 40730
    },
    {
      "epoch": 1.247282858280011,
      "grad_norm": 0.04708045348525047,
      "learning_rate": 1.1684985049342274e-05,
      "loss": 0.0061,
      "step": 40740
    },
    {
      "epoch": 1.247589015093531,
      "grad_norm": 0.010645768605172634,
      "learning_rate": 1.1682944003918808e-05,
      "loss": 0.0425,
      "step": 40750
    },
    {
      "epoch": 1.2478951719070508,
      "grad_norm": 0.03967941179871559,
      "learning_rate": 1.1680902958495342e-05,
      "loss": 0.0287,
      "step": 40760
    },
    {
      "epoch": 1.2482013287205707,
      "grad_norm": 0.03366239741444588,
      "learning_rate": 1.1678861913071877e-05,
      "loss": 0.0013,
      "step": 40770
    },
    {
      "epoch": 1.2485074855340905,
      "grad_norm": 0.08171118050813675,
      "learning_rate": 1.167682086764841e-05,
      "loss": 0.0011,
      "step": 40780
    },
    {
      "epoch": 1.2488136423476104,
      "grad_norm": 0.050282545387744904,
      "learning_rate": 1.1674779822224944e-05,
      "loss": 0.0015,
      "step": 40790
    },
    {
      "epoch": 1.2491197991611303,
      "grad_norm": 0.07166342437267303,
      "learning_rate": 1.1672738776801478e-05,
      "loss": 0.0403,
      "step": 40800
    },
    {
      "epoch": 1.2494259559746501,
      "grad_norm": 0.010239013470709324,
      "learning_rate": 1.1670697731378013e-05,
      "loss": 0.0014,
      "step": 40810
    },
    {
      "epoch": 1.2497321127881702,
      "grad_norm": 0.017317818477749825,
      "learning_rate": 1.1668656685954547e-05,
      "loss": 0.0012,
      "step": 40820
    },
    {
      "epoch": 1.25003826960169,
      "grad_norm": 0.007760088890790939,
      "learning_rate": 1.166661564053108e-05,
      "loss": 0.0013,
      "step": 40830
    },
    {
      "epoch": 1.25034442641521,
      "grad_norm": 0.02144208364188671,
      "learning_rate": 1.1664574595107616e-05,
      "loss": 0.0407,
      "step": 40840
    },
    {
      "epoch": 1.2506505832287298,
      "grad_norm": 0.038227785378694534,
      "learning_rate": 1.166253354968415e-05,
      "loss": 0.04,
      "step": 40850
    },
    {
      "epoch": 1.2509567400422497,
      "grad_norm": 0.033615842461586,
      "learning_rate": 1.1660492504260683e-05,
      "loss": 0.0014,
      "step": 40860
    },
    {
      "epoch": 1.2512628968557695,
      "grad_norm": 0.04306899756193161,
      "learning_rate": 1.1658451458837217e-05,
      "loss": 0.0374,
      "step": 40870
    },
    {
      "epoch": 1.2515690536692894,
      "grad_norm": 0.018347667530179024,
      "learning_rate": 1.1656410413413752e-05,
      "loss": 0.0012,
      "step": 40880
    },
    {
      "epoch": 1.2518752104828093,
      "grad_norm": 0.07473952323198318,
      "learning_rate": 1.1654369367990286e-05,
      "loss": 0.0017,
      "step": 40890
    },
    {
      "epoch": 1.2521813672963291,
      "grad_norm": 0.045093946158885956,
      "learning_rate": 1.165232832256682e-05,
      "loss": 0.0699,
      "step": 40900
    },
    {
      "epoch": 1.252487524109849,
      "grad_norm": 0.0360494926571846,
      "learning_rate": 1.1650287277143353e-05,
      "loss": 0.0589,
      "step": 40910
    },
    {
      "epoch": 1.2527936809233688,
      "grad_norm": 0.03626904636621475,
      "learning_rate": 1.1648246231719888e-05,
      "loss": 0.0025,
      "step": 40920
    },
    {
      "epoch": 1.253099837736889,
      "grad_norm": 0.10304476320743561,
      "learning_rate": 1.1646205186296422e-05,
      "loss": 0.0606,
      "step": 40930
    },
    {
      "epoch": 1.2534059945504088,
      "grad_norm": 0.055635277181863785,
      "learning_rate": 1.1644164140872956e-05,
      "loss": 0.0024,
      "step": 40940
    },
    {
      "epoch": 1.2537121513639287,
      "grad_norm": 0.07133002579212189,
      "learning_rate": 1.1642123095449491e-05,
      "loss": 0.0302,
      "step": 40950
    },
    {
      "epoch": 1.2540183081774485,
      "grad_norm": 0.09759385138750076,
      "learning_rate": 1.1640082050026025e-05,
      "loss": 0.0027,
      "step": 40960
    },
    {
      "epoch": 1.2543244649909684,
      "grad_norm": 0.010552539490163326,
      "learning_rate": 1.1638041004602558e-05,
      "loss": 0.0032,
      "step": 40970
    },
    {
      "epoch": 1.2546306218044883,
      "grad_norm": 0.04787258803844452,
      "learning_rate": 1.1635999959179092e-05,
      "loss": 0.002,
      "step": 40980
    },
    {
      "epoch": 1.2549367786180081,
      "grad_norm": 0.023051554337143898,
      "learning_rate": 1.1633958913755627e-05,
      "loss": 0.0019,
      "step": 40990
    },
    {
      "epoch": 1.255242935431528,
      "grad_norm": 0.04159983620047569,
      "learning_rate": 1.1631917868332161e-05,
      "loss": 0.0385,
      "step": 41000
    },
    {
      "epoch": 1.2555490922450478,
      "grad_norm": 0.03562468662858009,
      "learning_rate": 1.1629876822908695e-05,
      "loss": 0.0016,
      "step": 41010
    },
    {
      "epoch": 1.255855249058568,
      "grad_norm": 0.04905169457197189,
      "learning_rate": 1.1627835777485228e-05,
      "loss": 0.0017,
      "step": 41020
    },
    {
      "epoch": 1.2561614058720876,
      "grad_norm": 0.04248208925127983,
      "learning_rate": 1.1625794732061764e-05,
      "loss": 0.0323,
      "step": 41030
    },
    {
      "epoch": 1.2564675626856077,
      "grad_norm": 0.08198165148496628,
      "learning_rate": 1.1623753686638297e-05,
      "loss": 0.0523,
      "step": 41040
    },
    {
      "epoch": 1.2567737194991275,
      "grad_norm": 0.03235756233334541,
      "learning_rate": 1.1621712641214831e-05,
      "loss": 0.0018,
      "step": 41050
    },
    {
      "epoch": 1.2570798763126474,
      "grad_norm": 0.06783858686685562,
      "learning_rate": 1.1619671595791366e-05,
      "loss": 0.0021,
      "step": 41060
    },
    {
      "epoch": 1.2573860331261673,
      "grad_norm": 0.03455091640353203,
      "learning_rate": 1.16176305503679e-05,
      "loss": 0.0294,
      "step": 41070
    },
    {
      "epoch": 1.2576921899396871,
      "grad_norm": 0.0277184396982193,
      "learning_rate": 1.1615589504944434e-05,
      "loss": 0.0364,
      "step": 41080
    },
    {
      "epoch": 1.257998346753207,
      "grad_norm": 0.006806609686464071,
      "learning_rate": 1.1613548459520967e-05,
      "loss": 0.0015,
      "step": 41090
    },
    {
      "epoch": 1.2583045035667269,
      "grad_norm": 0.020851274952292442,
      "learning_rate": 1.1611507414097503e-05,
      "loss": 0.0034,
      "step": 41100
    },
    {
      "epoch": 1.2586106603802467,
      "grad_norm": 0.059812989085912704,
      "learning_rate": 1.1609466368674036e-05,
      "loss": 0.0023,
      "step": 41110
    },
    {
      "epoch": 1.2589168171937666,
      "grad_norm": 0.05701448395848274,
      "learning_rate": 1.160742532325057e-05,
      "loss": 0.0624,
      "step": 41120
    },
    {
      "epoch": 1.2592229740072867,
      "grad_norm": 0.028810355812311172,
      "learning_rate": 1.1605384277827103e-05,
      "loss": 0.0024,
      "step": 41130
    },
    {
      "epoch": 1.2595291308208063,
      "grad_norm": 0.05289487540721893,
      "learning_rate": 1.1603343232403639e-05,
      "loss": 0.002,
      "step": 41140
    },
    {
      "epoch": 1.2598352876343264,
      "grad_norm": 0.06009303778409958,
      "learning_rate": 1.1601302186980172e-05,
      "loss": 0.0027,
      "step": 41150
    },
    {
      "epoch": 1.2601414444478463,
      "grad_norm": 0.03255616873502731,
      "learning_rate": 1.1599261141556706e-05,
      "loss": 0.0283,
      "step": 41160
    },
    {
      "epoch": 1.2604476012613661,
      "grad_norm": 0.033791251480579376,
      "learning_rate": 1.159722009613324e-05,
      "loss": 0.0016,
      "step": 41170
    },
    {
      "epoch": 1.260753758074886,
      "grad_norm": 0.0305496659129858,
      "learning_rate": 1.1595179050709775e-05,
      "loss": 0.0025,
      "step": 41180
    },
    {
      "epoch": 1.2610599148884059,
      "grad_norm": 2.1055426597595215,
      "learning_rate": 1.1593138005286309e-05,
      "loss": 0.004,
      "step": 41190
    },
    {
      "epoch": 1.2613660717019257,
      "grad_norm": 0.025153325870633125,
      "learning_rate": 1.1591096959862842e-05,
      "loss": 0.0012,
      "step": 41200
    },
    {
      "epoch": 1.2616722285154456,
      "grad_norm": 0.12824739515781403,
      "learning_rate": 1.1589055914439378e-05,
      "loss": 0.0017,
      "step": 41210
    },
    {
      "epoch": 1.2619783853289654,
      "grad_norm": 0.025104472413659096,
      "learning_rate": 1.1587014869015911e-05,
      "loss": 0.0299,
      "step": 41220
    },
    {
      "epoch": 1.2622845421424853,
      "grad_norm": 0.25731971859931946,
      "learning_rate": 1.1584973823592445e-05,
      "loss": 0.0015,
      "step": 41230
    },
    {
      "epoch": 1.2625906989560054,
      "grad_norm": 0.047877416014671326,
      "learning_rate": 1.1582932778168979e-05,
      "loss": 0.0013,
      "step": 41240
    },
    {
      "epoch": 1.262896855769525,
      "grad_norm": 0.06491952389478683,
      "learning_rate": 1.1580891732745514e-05,
      "loss": 0.0015,
      "step": 41250
    },
    {
      "epoch": 1.2632030125830451,
      "grad_norm": 1.7587374448776245,
      "learning_rate": 1.1578850687322048e-05,
      "loss": 0.0729,
      "step": 41260
    },
    {
      "epoch": 1.263509169396565,
      "grad_norm": 0.029307497665286064,
      "learning_rate": 1.1576809641898581e-05,
      "loss": 0.0016,
      "step": 41270
    },
    {
      "epoch": 1.2638153262100849,
      "grad_norm": 0.04119759798049927,
      "learning_rate": 1.1574768596475115e-05,
      "loss": 0.0018,
      "step": 41280
    },
    {
      "epoch": 1.2641214830236047,
      "grad_norm": 0.043082498013973236,
      "learning_rate": 1.157272755105165e-05,
      "loss": 0.0011,
      "step": 41290
    },
    {
      "epoch": 1.2644276398371246,
      "grad_norm": 0.018670476973056793,
      "learning_rate": 1.1570686505628184e-05,
      "loss": 0.0013,
      "step": 41300
    },
    {
      "epoch": 1.2647337966506444,
      "grad_norm": 0.020351596176624298,
      "learning_rate": 1.1568645460204718e-05,
      "loss": 0.0372,
      "step": 41310
    },
    {
      "epoch": 1.2650399534641643,
      "grad_norm": 0.056108780205249786,
      "learning_rate": 1.1566604414781253e-05,
      "loss": 0.0013,
      "step": 41320
    },
    {
      "epoch": 1.2653461102776842,
      "grad_norm": 0.04839670658111572,
      "learning_rate": 1.1564563369357786e-05,
      "loss": 0.001,
      "step": 41330
    },
    {
      "epoch": 1.265652267091204,
      "grad_norm": 0.029161715880036354,
      "learning_rate": 1.156252232393432e-05,
      "loss": 0.0011,
      "step": 41340
    },
    {
      "epoch": 1.2659584239047241,
      "grad_norm": 0.011333861388266087,
      "learning_rate": 1.1560481278510854e-05,
      "loss": 0.0013,
      "step": 41350
    },
    {
      "epoch": 1.2662645807182438,
      "grad_norm": 0.08252926170825958,
      "learning_rate": 1.1558440233087389e-05,
      "loss": 0.0011,
      "step": 41360
    },
    {
      "epoch": 1.2665707375317639,
      "grad_norm": 0.019970959052443504,
      "learning_rate": 1.1556399187663923e-05,
      "loss": 0.001,
      "step": 41370
    },
    {
      "epoch": 1.2668768943452837,
      "grad_norm": 0.019238607957959175,
      "learning_rate": 1.1554358142240456e-05,
      "loss": 0.0008,
      "step": 41380
    },
    {
      "epoch": 1.2671830511588036,
      "grad_norm": 0.006159414537250996,
      "learning_rate": 1.155231709681699e-05,
      "loss": 0.001,
      "step": 41390
    },
    {
      "epoch": 1.2674892079723235,
      "grad_norm": 1.972687840461731,
      "learning_rate": 1.1550276051393525e-05,
      "loss": 0.0537,
      "step": 41400
    },
    {
      "epoch": 1.2677953647858433,
      "grad_norm": 0.010084082372486591,
      "learning_rate": 1.1548235005970059e-05,
      "loss": 0.0008,
      "step": 41410
    },
    {
      "epoch": 1.2681015215993632,
      "grad_norm": 1.656215786933899,
      "learning_rate": 1.1546193960546593e-05,
      "loss": 0.0291,
      "step": 41420
    },
    {
      "epoch": 1.268407678412883,
      "grad_norm": 0.010051847435534,
      "learning_rate": 1.1544152915123128e-05,
      "loss": 0.0011,
      "step": 41430
    },
    {
      "epoch": 1.268713835226403,
      "grad_norm": 0.02106086164712906,
      "learning_rate": 1.1542111869699662e-05,
      "loss": 0.0185,
      "step": 41440
    },
    {
      "epoch": 1.2690199920399228,
      "grad_norm": 0.03807536140084267,
      "learning_rate": 1.1540070824276195e-05,
      "loss": 0.0012,
      "step": 41450
    },
    {
      "epoch": 1.2693261488534429,
      "grad_norm": 0.004434625152498484,
      "learning_rate": 1.1538029778852729e-05,
      "loss": 0.0009,
      "step": 41460
    },
    {
      "epoch": 1.2696323056669625,
      "grad_norm": 0.02212992124259472,
      "learning_rate": 1.1535988733429264e-05,
      "loss": 0.0009,
      "step": 41470
    },
    {
      "epoch": 1.2699384624804826,
      "grad_norm": 0.029918376356363297,
      "learning_rate": 1.1533947688005798e-05,
      "loss": 0.0014,
      "step": 41480
    },
    {
      "epoch": 1.2702446192940025,
      "grad_norm": 0.13690121471881866,
      "learning_rate": 1.1531906642582332e-05,
      "loss": 0.0371,
      "step": 41490
    },
    {
      "epoch": 1.2705507761075223,
      "grad_norm": 0.052308090031147,
      "learning_rate": 1.1529865597158865e-05,
      "loss": 0.0011,
      "step": 41500
    },
    {
      "epoch": 1.2708569329210422,
      "grad_norm": 0.048787545412778854,
      "learning_rate": 1.15278245517354e-05,
      "loss": 0.0011,
      "step": 41510
    },
    {
      "epoch": 1.271163089734562,
      "grad_norm": 0.06706739962100983,
      "learning_rate": 1.1525783506311934e-05,
      "loss": 0.0012,
      "step": 41520
    },
    {
      "epoch": 1.271469246548082,
      "grad_norm": 1.9501937627792358,
      "learning_rate": 1.1523742460888468e-05,
      "loss": 0.0406,
      "step": 41530
    },
    {
      "epoch": 1.2717754033616018,
      "grad_norm": 0.020305922254920006,
      "learning_rate": 1.1521701415465003e-05,
      "loss": 0.0013,
      "step": 41540
    },
    {
      "epoch": 1.2720815601751216,
      "grad_norm": 0.004135161638259888,
      "learning_rate": 1.1519660370041537e-05,
      "loss": 0.0008,
      "step": 41550
    },
    {
      "epoch": 1.2723877169886415,
      "grad_norm": 0.016787048429250717,
      "learning_rate": 1.151761932461807e-05,
      "loss": 0.0015,
      "step": 41560
    },
    {
      "epoch": 1.2726938738021616,
      "grad_norm": 0.04892468452453613,
      "learning_rate": 1.1515578279194604e-05,
      "loss": 0.001,
      "step": 41570
    },
    {
      "epoch": 1.2730000306156812,
      "grad_norm": 2.1180312633514404,
      "learning_rate": 1.151353723377114e-05,
      "loss": 0.0444,
      "step": 41580
    },
    {
      "epoch": 1.2733061874292013,
      "grad_norm": 0.02938655950129032,
      "learning_rate": 1.1511496188347673e-05,
      "loss": 0.0008,
      "step": 41590
    },
    {
      "epoch": 1.2736123442427212,
      "grad_norm": 0.020745525136590004,
      "learning_rate": 1.1509455142924207e-05,
      "loss": 0.0752,
      "step": 41600
    },
    {
      "epoch": 1.273918501056241,
      "grad_norm": 0.022004112601280212,
      "learning_rate": 1.150741409750074e-05,
      "loss": 0.0697,
      "step": 41610
    },
    {
      "epoch": 1.274224657869761,
      "grad_norm": 0.04173942655324936,
      "learning_rate": 1.1505373052077276e-05,
      "loss": 0.002,
      "step": 41620
    },
    {
      "epoch": 1.2745308146832808,
      "grad_norm": 0.031982555985450745,
      "learning_rate": 1.150333200665381e-05,
      "loss": 0.0019,
      "step": 41630
    },
    {
      "epoch": 1.2748369714968006,
      "grad_norm": 0.023713232949376106,
      "learning_rate": 1.1501290961230343e-05,
      "loss": 0.0756,
      "step": 41640
    },
    {
      "epoch": 1.2751431283103205,
      "grad_norm": 0.02093353495001793,
      "learning_rate": 1.1499249915806878e-05,
      "loss": 0.0015,
      "step": 41650
    },
    {
      "epoch": 1.2754492851238404,
      "grad_norm": 0.022099656984210014,
      "learning_rate": 1.1497208870383412e-05,
      "loss": 0.002,
      "step": 41660
    },
    {
      "epoch": 1.2757554419373602,
      "grad_norm": 0.027754638344049454,
      "learning_rate": 1.1495167824959946e-05,
      "loss": 0.0357,
      "step": 41670
    },
    {
      "epoch": 1.2760615987508803,
      "grad_norm": 0.018708817660808563,
      "learning_rate": 1.149312677953648e-05,
      "loss": 0.0012,
      "step": 41680
    },
    {
      "epoch": 1.2763677555644,
      "grad_norm": 0.02281169593334198,
      "learning_rate": 1.1491085734113015e-05,
      "loss": 0.0021,
      "step": 41690
    },
    {
      "epoch": 1.27667391237792,
      "grad_norm": 0.036401890218257904,
      "learning_rate": 1.1489044688689548e-05,
      "loss": 0.0118,
      "step": 41700
    },
    {
      "epoch": 1.27698006919144,
      "grad_norm": 0.01775537058711052,
      "learning_rate": 1.1487003643266082e-05,
      "loss": 0.0016,
      "step": 41710
    },
    {
      "epoch": 1.2772862260049598,
      "grad_norm": 0.02175161987543106,
      "learning_rate": 1.1484962597842616e-05,
      "loss": 0.0008,
      "step": 41720
    },
    {
      "epoch": 1.2775923828184796,
      "grad_norm": 0.028429511934518814,
      "learning_rate": 1.1482921552419151e-05,
      "loss": 0.0331,
      "step": 41730
    },
    {
      "epoch": 1.2778985396319995,
      "grad_norm": 0.07659229636192322,
      "learning_rate": 1.1480880506995685e-05,
      "loss": 0.0319,
      "step": 41740
    },
    {
      "epoch": 1.2782046964455194,
      "grad_norm": 0.026840532198548317,
      "learning_rate": 1.1478839461572218e-05,
      "loss": 0.0013,
      "step": 41750
    },
    {
      "epoch": 1.2785108532590392,
      "grad_norm": 0.06336259841918945,
      "learning_rate": 1.1476798416148754e-05,
      "loss": 0.0013,
      "step": 41760
    },
    {
      "epoch": 1.278817010072559,
      "grad_norm": 0.0455477349460125,
      "learning_rate": 1.1474757370725287e-05,
      "loss": 0.0013,
      "step": 41770
    },
    {
      "epoch": 1.279123166886079,
      "grad_norm": 0.06026146188378334,
      "learning_rate": 1.147271632530182e-05,
      "loss": 0.0015,
      "step": 41780
    },
    {
      "epoch": 1.279429323699599,
      "grad_norm": 8.005487442016602,
      "learning_rate": 1.1470675279878354e-05,
      "loss": 0.0205,
      "step": 41790
    },
    {
      "epoch": 1.2797354805131187,
      "grad_norm": 0.032173678278923035,
      "learning_rate": 1.146863423445489e-05,
      "loss": 0.0013,
      "step": 41800
    },
    {
      "epoch": 1.2800416373266388,
      "grad_norm": 0.005391803104430437,
      "learning_rate": 1.1466593189031423e-05,
      "loss": 0.0012,
      "step": 41810
    },
    {
      "epoch": 1.2803477941401586,
      "grad_norm": 0.019470904022455215,
      "learning_rate": 1.1464552143607957e-05,
      "loss": 0.0629,
      "step": 41820
    },
    {
      "epoch": 1.2806539509536785,
      "grad_norm": 0.01853821985423565,
      "learning_rate": 1.146251109818449e-05,
      "loss": 0.0007,
      "step": 41830
    },
    {
      "epoch": 1.2809601077671984,
      "grad_norm": 0.024738306179642677,
      "learning_rate": 1.1460470052761026e-05,
      "loss": 0.001,
      "step": 41840
    },
    {
      "epoch": 1.2812662645807182,
      "grad_norm": 0.02199454791843891,
      "learning_rate": 1.145842900733756e-05,
      "loss": 0.0011,
      "step": 41850
    },
    {
      "epoch": 1.281572421394238,
      "grad_norm": 0.01832999289035797,
      "learning_rate": 1.1456387961914093e-05,
      "loss": 0.0011,
      "step": 41860
    },
    {
      "epoch": 1.281878578207758,
      "grad_norm": 0.025599325075745583,
      "learning_rate": 1.1454346916490629e-05,
      "loss": 0.0374,
      "step": 41870
    },
    {
      "epoch": 1.2821847350212778,
      "grad_norm": 0.02541990578174591,
      "learning_rate": 1.1452305871067162e-05,
      "loss": 0.0008,
      "step": 41880
    },
    {
      "epoch": 1.2824908918347977,
      "grad_norm": 0.01176305953413248,
      "learning_rate": 1.1450264825643696e-05,
      "loss": 0.0009,
      "step": 41890
    },
    {
      "epoch": 1.2827970486483178,
      "grad_norm": 0.013759937137365341,
      "learning_rate": 1.144822378022023e-05,
      "loss": 0.0006,
      "step": 41900
    },
    {
      "epoch": 1.2831032054618374,
      "grad_norm": 0.06801508367061615,
      "learning_rate": 1.1446182734796765e-05,
      "loss": 0.0332,
      "step": 41910
    },
    {
      "epoch": 1.2834093622753575,
      "grad_norm": 0.042470067739486694,
      "learning_rate": 1.1444141689373299e-05,
      "loss": 0.001,
      "step": 41920
    },
    {
      "epoch": 1.2837155190888774,
      "grad_norm": 0.018562205135822296,
      "learning_rate": 1.1442100643949832e-05,
      "loss": 0.0009,
      "step": 41930
    },
    {
      "epoch": 1.2840216759023972,
      "grad_norm": 0.024087263271212578,
      "learning_rate": 1.1440059598526366e-05,
      "loss": 0.0008,
      "step": 41940
    },
    {
      "epoch": 1.284327832715917,
      "grad_norm": 0.01092151552438736,
      "learning_rate": 1.1438018553102901e-05,
      "loss": 0.0387,
      "step": 41950
    },
    {
      "epoch": 1.284633989529437,
      "grad_norm": 0.03557291254401207,
      "learning_rate": 1.1435977507679435e-05,
      "loss": 0.0008,
      "step": 41960
    },
    {
      "epoch": 1.2849401463429568,
      "grad_norm": 0.007866966538131237,
      "learning_rate": 1.1433936462255969e-05,
      "loss": 0.0759,
      "step": 41970
    },
    {
      "epoch": 1.2852463031564767,
      "grad_norm": 0.03154968097805977,
      "learning_rate": 1.1431895416832504e-05,
      "loss": 0.0008,
      "step": 41980
    },
    {
      "epoch": 1.2855524599699966,
      "grad_norm": 0.04529198259115219,
      "learning_rate": 1.1429854371409038e-05,
      "loss": 0.0011,
      "step": 41990
    },
    {
      "epoch": 1.2858586167835164,
      "grad_norm": 0.01990632712841034,
      "learning_rate": 1.1427813325985571e-05,
      "loss": 0.0012,
      "step": 42000
    },
    {
      "epoch": 1.2861647735970365,
      "grad_norm": 0.027565108612179756,
      "learning_rate": 1.1425772280562105e-05,
      "loss": 0.0377,
      "step": 42010
    },
    {
      "epoch": 1.2864709304105562,
      "grad_norm": 0.029202597215771675,
      "learning_rate": 1.142373123513864e-05,
      "loss": 0.0009,
      "step": 42020
    },
    {
      "epoch": 1.2867770872240762,
      "grad_norm": 0.013593927025794983,
      "learning_rate": 1.1421690189715174e-05,
      "loss": 0.0439,
      "step": 42030
    },
    {
      "epoch": 1.287083244037596,
      "grad_norm": 0.02174072526395321,
      "learning_rate": 1.1419649144291707e-05,
      "loss": 0.0411,
      "step": 42040
    },
    {
      "epoch": 1.287389400851116,
      "grad_norm": 0.058155640959739685,
      "learning_rate": 1.1417608098868241e-05,
      "loss": 0.0014,
      "step": 42050
    },
    {
      "epoch": 1.2876955576646358,
      "grad_norm": 0.043953366577625275,
      "learning_rate": 1.1415567053444776e-05,
      "loss": 0.0014,
      "step": 42060
    },
    {
      "epoch": 1.2880017144781557,
      "grad_norm": 0.010356465354561806,
      "learning_rate": 1.141352600802131e-05,
      "loss": 0.0368,
      "step": 42070
    },
    {
      "epoch": 1.2883078712916756,
      "grad_norm": 0.028708891943097115,
      "learning_rate": 1.1411484962597844e-05,
      "loss": 0.0012,
      "step": 42080
    },
    {
      "epoch": 1.2886140281051954,
      "grad_norm": 0.03699508309364319,
      "learning_rate": 1.1409443917174379e-05,
      "loss": 0.0011,
      "step": 42090
    },
    {
      "epoch": 1.2889201849187153,
      "grad_norm": 0.029055675491690636,
      "learning_rate": 1.1407402871750913e-05,
      "loss": 0.0376,
      "step": 42100
    },
    {
      "epoch": 1.2892263417322352,
      "grad_norm": 0.015254599042236805,
      "learning_rate": 1.1405361826327446e-05,
      "loss": 0.0012,
      "step": 42110
    },
    {
      "epoch": 1.2895324985457552,
      "grad_norm": 0.01838529482483864,
      "learning_rate": 1.140332078090398e-05,
      "loss": 0.0009,
      "step": 42120
    },
    {
      "epoch": 1.2898386553592749,
      "grad_norm": 0.03636319562792778,
      "learning_rate": 1.1401279735480515e-05,
      "loss": 0.0007,
      "step": 42130
    },
    {
      "epoch": 1.290144812172795,
      "grad_norm": 0.020276453346014023,
      "learning_rate": 1.1399238690057049e-05,
      "loss": 0.0363,
      "step": 42140
    },
    {
      "epoch": 1.2904509689863148,
      "grad_norm": 0.018534565344452858,
      "learning_rate": 1.1397197644633583e-05,
      "loss": 0.0428,
      "step": 42150
    },
    {
      "epoch": 1.2907571257998347,
      "grad_norm": 0.02167084440588951,
      "learning_rate": 1.1395156599210116e-05,
      "loss": 0.0026,
      "step": 42160
    },
    {
      "epoch": 1.2910632826133546,
      "grad_norm": 0.01969635672867298,
      "learning_rate": 1.1393115553786652e-05,
      "loss": 0.0013,
      "step": 42170
    },
    {
      "epoch": 1.2913694394268744,
      "grad_norm": 0.047147613018751144,
      "learning_rate": 1.1391074508363185e-05,
      "loss": 0.1296,
      "step": 42180
    },
    {
      "epoch": 1.2916755962403943,
      "grad_norm": 0.021256832405924797,
      "learning_rate": 1.1389033462939719e-05,
      "loss": 0.0011,
      "step": 42190
    },
    {
      "epoch": 1.2919817530539142,
      "grad_norm": 0.039619412273168564,
      "learning_rate": 1.1386992417516254e-05,
      "loss": 0.0009,
      "step": 42200
    },
    {
      "epoch": 1.292287909867434,
      "grad_norm": 0.03794856369495392,
      "learning_rate": 1.1384951372092788e-05,
      "loss": 0.0393,
      "step": 42210
    },
    {
      "epoch": 1.292594066680954,
      "grad_norm": 0.05116032809019089,
      "learning_rate": 1.1382910326669321e-05,
      "loss": 0.0022,
      "step": 42220
    },
    {
      "epoch": 1.292900223494474,
      "grad_norm": 0.07992084324359894,
      "learning_rate": 1.1380869281245855e-05,
      "loss": 0.0014,
      "step": 42230
    },
    {
      "epoch": 1.2932063803079936,
      "grad_norm": 0.0411551408469677,
      "learning_rate": 1.137882823582239e-05,
      "loss": 0.0019,
      "step": 42240
    },
    {
      "epoch": 1.2935125371215137,
      "grad_norm": 0.025275425985455513,
      "learning_rate": 1.1376787190398924e-05,
      "loss": 0.001,
      "step": 42250
    },
    {
      "epoch": 1.2938186939350336,
      "grad_norm": 0.02626228891313076,
      "learning_rate": 1.1374746144975458e-05,
      "loss": 0.0377,
      "step": 42260
    },
    {
      "epoch": 1.2941248507485534,
      "grad_norm": 0.04756278917193413,
      "learning_rate": 1.137270509955199e-05,
      "loss": 0.0016,
      "step": 42270
    },
    {
      "epoch": 1.2944310075620733,
      "grad_norm": 0.028761031106114388,
      "learning_rate": 1.1370664054128527e-05,
      "loss": 0.038,
      "step": 42280
    },
    {
      "epoch": 1.2947371643755932,
      "grad_norm": 0.02341144159436226,
      "learning_rate": 1.136862300870506e-05,
      "loss": 0.0012,
      "step": 42290
    },
    {
      "epoch": 1.295043321189113,
      "grad_norm": 0.02286204881966114,
      "learning_rate": 1.1366581963281594e-05,
      "loss": 0.0011,
      "step": 42300
    },
    {
      "epoch": 1.295349478002633,
      "grad_norm": 0.024494320154190063,
      "learning_rate": 1.136454091785813e-05,
      "loss": 0.0023,
      "step": 42310
    },
    {
      "epoch": 1.2956556348161528,
      "grad_norm": 0.05671937018632889,
      "learning_rate": 1.1362499872434663e-05,
      "loss": 0.0012,
      "step": 42320
    },
    {
      "epoch": 1.2959617916296726,
      "grad_norm": 0.02125217765569687,
      "learning_rate": 1.1360458827011197e-05,
      "loss": 0.0318,
      "step": 42330
    },
    {
      "epoch": 1.2962679484431927,
      "grad_norm": 0.04576634243130684,
      "learning_rate": 1.1358417781587729e-05,
      "loss": 0.0011,
      "step": 42340
    },
    {
      "epoch": 1.2965741052567124,
      "grad_norm": 0.025311579927802086,
      "learning_rate": 1.1356376736164266e-05,
      "loss": 0.001,
      "step": 42350
    },
    {
      "epoch": 1.2968802620702324,
      "grad_norm": 0.011234641075134277,
      "learning_rate": 1.13543356907408e-05,
      "loss": 0.0016,
      "step": 42360
    },
    {
      "epoch": 1.2971864188837523,
      "grad_norm": 0.0178673192858696,
      "learning_rate": 1.1352294645317333e-05,
      "loss": 0.041,
      "step": 42370
    },
    {
      "epoch": 1.2974925756972722,
      "grad_norm": 0.015283294953405857,
      "learning_rate": 1.1350253599893865e-05,
      "loss": 0.0013,
      "step": 42380
    },
    {
      "epoch": 1.297798732510792,
      "grad_norm": 0.04122675955295563,
      "learning_rate": 1.1348212554470402e-05,
      "loss": 0.0013,
      "step": 42390
    },
    {
      "epoch": 1.298104889324312,
      "grad_norm": 0.01582968607544899,
      "learning_rate": 1.1346171509046936e-05,
      "loss": 0.001,
      "step": 42400
    },
    {
      "epoch": 1.2984110461378318,
      "grad_norm": 0.02680380269885063,
      "learning_rate": 1.134413046362347e-05,
      "loss": 0.1284,
      "step": 42410
    },
    {
      "epoch": 1.2987172029513516,
      "grad_norm": 0.057985663414001465,
      "learning_rate": 1.1342089418200001e-05,
      "loss": 0.0385,
      "step": 42420
    },
    {
      "epoch": 1.2990233597648715,
      "grad_norm": 0.04853253439068794,
      "learning_rate": 1.1340048372776538e-05,
      "loss": 0.0412,
      "step": 42430
    },
    {
      "epoch": 1.2993295165783914,
      "grad_norm": 0.060836948454380035,
      "learning_rate": 1.1338007327353072e-05,
      "loss": 0.0019,
      "step": 42440
    },
    {
      "epoch": 1.2996356733919114,
      "grad_norm": 0.03198681399226189,
      "learning_rate": 1.1335966281929604e-05,
      "loss": 0.0021,
      "step": 42450
    },
    {
      "epoch": 1.2999418302054313,
      "grad_norm": 0.06869059801101685,
      "learning_rate": 1.133392523650614e-05,
      "loss": 0.0349,
      "step": 42460
    },
    {
      "epoch": 1.3002479870189512,
      "grad_norm": 0.01905459351837635,
      "learning_rate": 1.1331884191082674e-05,
      "loss": 0.0019,
      "step": 42470
    },
    {
      "epoch": 1.300554143832471,
      "grad_norm": 0.025410478934645653,
      "learning_rate": 1.1329843145659208e-05,
      "loss": 0.0017,
      "step": 42480
    },
    {
      "epoch": 1.300860300645991,
      "grad_norm": 0.12574218213558197,
      "learning_rate": 1.132780210023574e-05,
      "loss": 0.0022,
      "step": 42490
    },
    {
      "epoch": 1.3011664574595108,
      "grad_norm": 1.7285196781158447,
      "learning_rate": 1.1325761054812277e-05,
      "loss": 0.0576,
      "step": 42500
    },
    {
      "epoch": 1.3014726142730306,
      "grad_norm": 0.06748230755329132,
      "learning_rate": 1.132372000938881e-05,
      "loss": 0.0022,
      "step": 42510
    },
    {
      "epoch": 1.3017787710865505,
      "grad_norm": 0.06564105302095413,
      "learning_rate": 1.1321678963965343e-05,
      "loss": 0.0016,
      "step": 42520
    },
    {
      "epoch": 1.3020849279000704,
      "grad_norm": 0.09614331275224686,
      "learning_rate": 1.1319637918541876e-05,
      "loss": 0.0287,
      "step": 42530
    },
    {
      "epoch": 1.3023910847135902,
      "grad_norm": 0.05059918761253357,
      "learning_rate": 1.1317596873118413e-05,
      "loss": 0.0014,
      "step": 42540
    },
    {
      "epoch": 1.30269724152711,
      "grad_norm": 0.028134873136878014,
      "learning_rate": 1.1315555827694947e-05,
      "loss": 0.0388,
      "step": 42550
    },
    {
      "epoch": 1.3030033983406302,
      "grad_norm": 0.0838385671377182,
      "learning_rate": 1.1313514782271479e-05,
      "loss": 0.0303,
      "step": 42560
    },
    {
      "epoch": 1.30330955515415,
      "grad_norm": 0.03996967896819115,
      "learning_rate": 1.1311473736848016e-05,
      "loss": 0.0044,
      "step": 42570
    },
    {
      "epoch": 1.30361571196767,
      "grad_norm": 0.029913926497101784,
      "learning_rate": 1.130943269142455e-05,
      "loss": 0.0258,
      "step": 42580
    },
    {
      "epoch": 1.3039218687811898,
      "grad_norm": 0.02525792457163334,
      "learning_rate": 1.1307391646001082e-05,
      "loss": 0.0017,
      "step": 42590
    },
    {
      "epoch": 1.3042280255947096,
      "grad_norm": 0.03675385192036629,
      "learning_rate": 1.1305350600577615e-05,
      "loss": 0.0492,
      "step": 42600
    },
    {
      "epoch": 1.3045341824082295,
      "grad_norm": 0.0851585641503334,
      "learning_rate": 1.1303309555154152e-05,
      "loss": 0.0022,
      "step": 42610
    },
    {
      "epoch": 1.3048403392217494,
      "grad_norm": 0.07729163765907288,
      "learning_rate": 1.1301268509730686e-05,
      "loss": 0.0283,
      "step": 42620
    },
    {
      "epoch": 1.3051464960352692,
      "grad_norm": 0.038721323013305664,
      "learning_rate": 1.1299227464307218e-05,
      "loss": 0.0017,
      "step": 42630
    },
    {
      "epoch": 1.305452652848789,
      "grad_norm": 0.06729684770107269,
      "learning_rate": 1.1297186418883751e-05,
      "loss": 0.002,
      "step": 42640
    },
    {
      "epoch": 1.3057588096623092,
      "grad_norm": 0.04820205643773079,
      "learning_rate": 1.1295145373460289e-05,
      "loss": 0.0016,
      "step": 42650
    },
    {
      "epoch": 1.3060649664758288,
      "grad_norm": 1.5315200090408325,
      "learning_rate": 1.1293104328036822e-05,
      "loss": 0.0309,
      "step": 42660
    },
    {
      "epoch": 1.306371123289349,
      "grad_norm": 0.014090210199356079,
      "learning_rate": 1.1291063282613354e-05,
      "loss": 0.0019,
      "step": 42670
    },
    {
      "epoch": 1.3066772801028688,
      "grad_norm": 0.07631700485944748,
      "learning_rate": 1.1289022237189891e-05,
      "loss": 0.0224,
      "step": 42680
    },
    {
      "epoch": 1.3069834369163886,
      "grad_norm": 0.04915260151028633,
      "learning_rate": 1.1286981191766425e-05,
      "loss": 0.0356,
      "step": 42690
    },
    {
      "epoch": 1.3072895937299085,
      "grad_norm": 0.05011560767889023,
      "learning_rate": 1.1284940146342957e-05,
      "loss": 0.0674,
      "step": 42700
    },
    {
      "epoch": 1.3075957505434284,
      "grad_norm": 0.08911459147930145,
      "learning_rate": 1.128289910091949e-05,
      "loss": 0.0024,
      "step": 42710
    },
    {
      "epoch": 1.3079019073569482,
      "grad_norm": 0.0466066338121891,
      "learning_rate": 1.1280858055496027e-05,
      "loss": 0.0596,
      "step": 42720
    },
    {
      "epoch": 1.308208064170468,
      "grad_norm": 0.11290828138589859,
      "learning_rate": 1.1278817010072561e-05,
      "loss": 0.0035,
      "step": 42730
    },
    {
      "epoch": 1.308514220983988,
      "grad_norm": 0.12068773061037064,
      "learning_rate": 1.1276775964649093e-05,
      "loss": 0.0036,
      "step": 42740
    },
    {
      "epoch": 1.3088203777975078,
      "grad_norm": 0.030114131048321724,
      "learning_rate": 1.1274734919225627e-05,
      "loss": 0.0307,
      "step": 42750
    },
    {
      "epoch": 1.309126534611028,
      "grad_norm": 0.003347333986312151,
      "learning_rate": 1.1272693873802164e-05,
      "loss": 0.0032,
      "step": 42760
    },
    {
      "epoch": 1.3094326914245475,
      "grad_norm": 0.04827497527003288,
      "learning_rate": 1.1270652828378696e-05,
      "loss": 0.0021,
      "step": 42770
    },
    {
      "epoch": 1.3097388482380676,
      "grad_norm": 0.07022707164287567,
      "learning_rate": 1.126861178295523e-05,
      "loss": 0.0206,
      "step": 42780
    },
    {
      "epoch": 1.3100450050515875,
      "grad_norm": 0.08092603832483292,
      "learning_rate": 1.1266570737531766e-05,
      "loss": 0.0018,
      "step": 42790
    },
    {
      "epoch": 1.3103511618651074,
      "grad_norm": 0.04749760404229164,
      "learning_rate": 1.12645296921083e-05,
      "loss": 0.0049,
      "step": 42800
    },
    {
      "epoch": 1.3106573186786272,
      "grad_norm": 0.03479311987757683,
      "learning_rate": 1.1262488646684832e-05,
      "loss": 0.0621,
      "step": 42810
    },
    {
      "epoch": 1.310963475492147,
      "grad_norm": 0.02081298641860485,
      "learning_rate": 1.1260447601261366e-05,
      "loss": 0.0655,
      "step": 42820
    },
    {
      "epoch": 1.311269632305667,
      "grad_norm": 0.03452092781662941,
      "learning_rate": 1.1258406555837903e-05,
      "loss": 0.0018,
      "step": 42830
    },
    {
      "epoch": 1.3115757891191868,
      "grad_norm": 0.07042617350816727,
      "learning_rate": 1.1256365510414435e-05,
      "loss": 0.0013,
      "step": 42840
    },
    {
      "epoch": 1.3118819459327067,
      "grad_norm": 0.020971737802028656,
      "learning_rate": 1.1254324464990968e-05,
      "loss": 0.0014,
      "step": 42850
    },
    {
      "epoch": 1.3121881027462265,
      "grad_norm": 0.028187554329633713,
      "learning_rate": 1.1252283419567502e-05,
      "loss": 0.0013,
      "step": 42860
    },
    {
      "epoch": 1.3124942595597466,
      "grad_norm": 0.02444290742278099,
      "learning_rate": 1.1250242374144039e-05,
      "loss": 0.0014,
      "step": 42870
    },
    {
      "epoch": 1.3128004163732663,
      "grad_norm": 0.05953076481819153,
      "learning_rate": 1.124820132872057e-05,
      "loss": 0.0022,
      "step": 42880
    },
    {
      "epoch": 1.3131065731867864,
      "grad_norm": 0.02848317101597786,
      "learning_rate": 1.1246160283297104e-05,
      "loss": 0.0677,
      "step": 42890
    },
    {
      "epoch": 1.3134127300003062,
      "grad_norm": 0.039994027465581894,
      "learning_rate": 1.1244119237873641e-05,
      "loss": 0.035,
      "step": 42900
    },
    {
      "epoch": 1.313718886813826,
      "grad_norm": 0.05008720979094505,
      "learning_rate": 1.1242078192450175e-05,
      "loss": 0.002,
      "step": 42910
    },
    {
      "epoch": 1.314025043627346,
      "grad_norm": 0.0826716497540474,
      "learning_rate": 1.1240037147026707e-05,
      "loss": 0.002,
      "step": 42920
    },
    {
      "epoch": 1.3143312004408658,
      "grad_norm": 0.0031374215614050627,
      "learning_rate": 1.123799610160324e-05,
      "loss": 0.0011,
      "step": 42930
    },
    {
      "epoch": 1.3146373572543857,
      "grad_norm": 0.030718525871634483,
      "learning_rate": 1.1235955056179778e-05,
      "loss": 0.0045,
      "step": 42940
    },
    {
      "epoch": 1.3149435140679056,
      "grad_norm": 0.014392921701073647,
      "learning_rate": 1.123391401075631e-05,
      "loss": 0.0382,
      "step": 42950
    },
    {
      "epoch": 1.3152496708814254,
      "grad_norm": 1.6297575235366821,
      "learning_rate": 1.1231872965332843e-05,
      "loss": 0.0366,
      "step": 42960
    },
    {
      "epoch": 1.3155558276949453,
      "grad_norm": 0.04584857448935509,
      "learning_rate": 1.1229831919909377e-05,
      "loss": 0.0012,
      "step": 42970
    },
    {
      "epoch": 1.3158619845084654,
      "grad_norm": 0.026249196380376816,
      "learning_rate": 1.1227790874485914e-05,
      "loss": 0.0364,
      "step": 42980
    },
    {
      "epoch": 1.316168141321985,
      "grad_norm": 0.03406813368201256,
      "learning_rate": 1.1225749829062446e-05,
      "loss": 0.0054,
      "step": 42990
    },
    {
      "epoch": 1.316474298135505,
      "grad_norm": 0.015431743115186691,
      "learning_rate": 1.122370878363898e-05,
      "loss": 0.0332,
      "step": 43000
    },
    {
      "epoch": 1.316780454949025,
      "grad_norm": 0.0382780097424984,
      "learning_rate": 1.1221667738215517e-05,
      "loss": 0.0017,
      "step": 43010
    },
    {
      "epoch": 1.3170866117625448,
      "grad_norm": 0.039989858865737915,
      "learning_rate": 1.1219626692792049e-05,
      "loss": 0.002,
      "step": 43020
    },
    {
      "epoch": 1.3173927685760647,
      "grad_norm": 0.019402040168642998,
      "learning_rate": 1.1217585647368582e-05,
      "loss": 0.0251,
      "step": 43030
    },
    {
      "epoch": 1.3176989253895846,
      "grad_norm": 0.09356674551963806,
      "learning_rate": 1.1215544601945116e-05,
      "loss": 0.0018,
      "step": 43040
    },
    {
      "epoch": 1.3180050822031044,
      "grad_norm": 0.020740952342748642,
      "learning_rate": 1.1213503556521653e-05,
      "loss": 0.0018,
      "step": 43050
    },
    {
      "epoch": 1.3183112390166243,
      "grad_norm": 0.008293528109788895,
      "learning_rate": 1.1211462511098185e-05,
      "loss": 0.0343,
      "step": 43060
    },
    {
      "epoch": 1.3186173958301441,
      "grad_norm": 0.02237265557050705,
      "learning_rate": 1.1209421465674719e-05,
      "loss": 0.0015,
      "step": 43070
    },
    {
      "epoch": 1.318923552643664,
      "grad_norm": 0.025427483022212982,
      "learning_rate": 1.1207380420251252e-05,
      "loss": 0.0014,
      "step": 43080
    },
    {
      "epoch": 1.319229709457184,
      "grad_norm": 0.02019861899316311,
      "learning_rate": 1.1205339374827788e-05,
      "loss": 0.0019,
      "step": 43090
    },
    {
      "epoch": 1.3195358662707037,
      "grad_norm": 0.03364228084683418,
      "learning_rate": 1.1203298329404321e-05,
      "loss": 0.0317,
      "step": 43100
    },
    {
      "epoch": 1.3198420230842238,
      "grad_norm": 0.017154710367321968,
      "learning_rate": 1.1201257283980855e-05,
      "loss": 0.0013,
      "step": 43110
    },
    {
      "epoch": 1.3201481798977437,
      "grad_norm": 0.009295282885432243,
      "learning_rate": 1.1199216238557392e-05,
      "loss": 0.023,
      "step": 43120
    },
    {
      "epoch": 1.3204543367112636,
      "grad_norm": 0.03889307752251625,
      "learning_rate": 1.1197175193133924e-05,
      "loss": 0.0245,
      "step": 43130
    },
    {
      "epoch": 1.3207604935247834,
      "grad_norm": 0.036529961973428726,
      "learning_rate": 1.1195134147710457e-05,
      "loss": 0.0305,
      "step": 43140
    },
    {
      "epoch": 1.3210666503383033,
      "grad_norm": 0.042690459638834,
      "learning_rate": 1.1193093102286991e-05,
      "loss": 0.0022,
      "step": 43150
    },
    {
      "epoch": 1.3213728071518231,
      "grad_norm": 0.07946038991212845,
      "learning_rate": 1.1191052056863526e-05,
      "loss": 0.0017,
      "step": 43160
    },
    {
      "epoch": 1.321678963965343,
      "grad_norm": 0.048190873116254807,
      "learning_rate": 1.118901101144006e-05,
      "loss": 0.0287,
      "step": 43170
    },
    {
      "epoch": 1.3219851207788629,
      "grad_norm": 0.017154434695839882,
      "learning_rate": 1.1186969966016594e-05,
      "loss": 0.0016,
      "step": 43180
    },
    {
      "epoch": 1.3222912775923827,
      "grad_norm": 0.04307827353477478,
      "learning_rate": 1.1184928920593127e-05,
      "loss": 0.0024,
      "step": 43190
    },
    {
      "epoch": 1.3225974344059028,
      "grad_norm": 0.017712298780679703,
      "learning_rate": 1.1182887875169663e-05,
      "loss": 0.0014,
      "step": 43200
    },
    {
      "epoch": 1.3229035912194225,
      "grad_norm": 0.038649238646030426,
      "learning_rate": 1.1180846829746196e-05,
      "loss": 0.0013,
      "step": 43210
    },
    {
      "epoch": 1.3232097480329426,
      "grad_norm": 0.055049095302820206,
      "learning_rate": 1.117880578432273e-05,
      "loss": 0.0671,
      "step": 43220
    },
    {
      "epoch": 1.3235159048464624,
      "grad_norm": 0.44673770666122437,
      "learning_rate": 1.1176764738899267e-05,
      "loss": 0.0027,
      "step": 43230
    },
    {
      "epoch": 1.3238220616599823,
      "grad_norm": 0.02709604986011982,
      "learning_rate": 1.1174723693475799e-05,
      "loss": 0.0011,
      "step": 43240
    },
    {
      "epoch": 1.3241282184735021,
      "grad_norm": 0.029604140669107437,
      "learning_rate": 1.1172682648052333e-05,
      "loss": 0.0015,
      "step": 43250
    },
    {
      "epoch": 1.324434375287022,
      "grad_norm": 0.046241164207458496,
      "learning_rate": 1.1170641602628866e-05,
      "loss": 0.0354,
      "step": 43260
    },
    {
      "epoch": 1.3247405321005419,
      "grad_norm": 0.059174004942178726,
      "learning_rate": 1.1168600557205402e-05,
      "loss": 0.0022,
      "step": 43270
    },
    {
      "epoch": 1.3250466889140617,
      "grad_norm": 0.00025172741152346134,
      "learning_rate": 1.1166559511781935e-05,
      "loss": 0.0516,
      "step": 43280
    },
    {
      "epoch": 1.3253528457275816,
      "grad_norm": 0.02786867506802082,
      "learning_rate": 1.1164518466358469e-05,
      "loss": 0.0012,
      "step": 43290
    },
    {
      "epoch": 1.3256590025411015,
      "grad_norm": 0.0065701669082045555,
      "learning_rate": 1.1162477420935003e-05,
      "loss": 0.0184,
      "step": 43300
    },
    {
      "epoch": 1.3259651593546216,
      "grad_norm": 0.014608624391257763,
      "learning_rate": 1.1160436375511538e-05,
      "loss": 0.0311,
      "step": 43310
    },
    {
      "epoch": 1.3262713161681412,
      "grad_norm": 0.019193492829799652,
      "learning_rate": 1.1158395330088071e-05,
      "loss": 0.0034,
      "step": 43320
    },
    {
      "epoch": 1.3265774729816613,
      "grad_norm": 0.033720746636390686,
      "learning_rate": 1.1156354284664605e-05,
      "loss": 0.0045,
      "step": 43330
    },
    {
      "epoch": 1.3268836297951812,
      "grad_norm": 0.05835868418216705,
      "learning_rate": 1.115431323924114e-05,
      "loss": 0.0365,
      "step": 43340
    },
    {
      "epoch": 1.327189786608701,
      "grad_norm": 0.05849792808294296,
      "learning_rate": 1.1152272193817674e-05,
      "loss": 0.0935,
      "step": 43350
    },
    {
      "epoch": 1.3274959434222209,
      "grad_norm": 0.03449532762169838,
      "learning_rate": 1.1150231148394208e-05,
      "loss": 0.0027,
      "step": 43360
    },
    {
      "epoch": 1.3278021002357407,
      "grad_norm": 0.07098191231489182,
      "learning_rate": 1.1148190102970741e-05,
      "loss": 0.0019,
      "step": 43370
    },
    {
      "epoch": 1.3281082570492606,
      "grad_norm": 0.017577476799488068,
      "learning_rate": 1.1146149057547277e-05,
      "loss": 0.0017,
      "step": 43380
    },
    {
      "epoch": 1.3284144138627805,
      "grad_norm": 0.06748372316360474,
      "learning_rate": 1.114410801212381e-05,
      "loss": 0.0017,
      "step": 43390
    },
    {
      "epoch": 1.3287205706763003,
      "grad_norm": 0.02036871388554573,
      "learning_rate": 1.1142066966700344e-05,
      "loss": 0.0023,
      "step": 43400
    },
    {
      "epoch": 1.3290267274898202,
      "grad_norm": 0.02792840078473091,
      "learning_rate": 1.1140025921276878e-05,
      "loss": 0.0019,
      "step": 43410
    },
    {
      "epoch": 1.3293328843033403,
      "grad_norm": 0.03873509168624878,
      "learning_rate": 1.1137984875853413e-05,
      "loss": 0.0434,
      "step": 43420
    },
    {
      "epoch": 1.32963904111686,
      "grad_norm": 0.029774103313684464,
      "learning_rate": 1.1135943830429947e-05,
      "loss": 0.0367,
      "step": 43430
    },
    {
      "epoch": 1.32994519793038,
      "grad_norm": 0.03100982867181301,
      "learning_rate": 1.113390278500648e-05,
      "loss": 0.0013,
      "step": 43440
    },
    {
      "epoch": 1.3302513547438999,
      "grad_norm": 0.04082002490758896,
      "learning_rate": 1.1131861739583016e-05,
      "loss": 0.0029,
      "step": 43450
    },
    {
      "epoch": 1.3305575115574197,
      "grad_norm": 0.027117876335978508,
      "learning_rate": 1.112982069415955e-05,
      "loss": 0.0014,
      "step": 43460
    },
    {
      "epoch": 1.3308636683709396,
      "grad_norm": 0.03362688422203064,
      "learning_rate": 1.1127779648736083e-05,
      "loss": 0.0015,
      "step": 43470
    },
    {
      "epoch": 1.3311698251844595,
      "grad_norm": 2.7107467651367188,
      "learning_rate": 1.1125738603312617e-05,
      "loss": 0.0117,
      "step": 43480
    },
    {
      "epoch": 1.3314759819979793,
      "grad_norm": 0.03707917779684067,
      "learning_rate": 1.1123697557889152e-05,
      "loss": 0.0009,
      "step": 43490
    },
    {
      "epoch": 1.3317821388114992,
      "grad_norm": 0.035083524882793427,
      "learning_rate": 1.1121656512465686e-05,
      "loss": 0.0015,
      "step": 43500
    },
    {
      "epoch": 1.332088295625019,
      "grad_norm": 5.397819995880127,
      "learning_rate": 1.111961546704222e-05,
      "loss": 0.0185,
      "step": 43510
    },
    {
      "epoch": 1.332394452438539,
      "grad_norm": 0.0254686139523983,
      "learning_rate": 1.1117574421618753e-05,
      "loss": 0.0009,
      "step": 43520
    },
    {
      "epoch": 1.332700609252059,
      "grad_norm": 0.0014925564173609018,
      "learning_rate": 1.1115533376195288e-05,
      "loss": 0.0013,
      "step": 43530
    },
    {
      "epoch": 1.3330067660655787,
      "grad_norm": 0.07353534549474716,
      "learning_rate": 1.1113492330771822e-05,
      "loss": 0.0011,
      "step": 43540
    },
    {
      "epoch": 1.3333129228790987,
      "grad_norm": 0.028250521048903465,
      "learning_rate": 1.1111451285348355e-05,
      "loss": 0.0416,
      "step": 43550
    },
    {
      "epoch": 1.3336190796926186,
      "grad_norm": 0.021433304995298386,
      "learning_rate": 1.110941023992489e-05,
      "loss": 0.0011,
      "step": 43560
    },
    {
      "epoch": 1.3339252365061385,
      "grad_norm": 0.02486909180879593,
      "learning_rate": 1.1107369194501424e-05,
      "loss": 0.0208,
      "step": 43570
    },
    {
      "epoch": 1.3342313933196583,
      "grad_norm": 0.016009608283638954,
      "learning_rate": 1.1105328149077958e-05,
      "loss": 0.0007,
      "step": 43580
    },
    {
      "epoch": 1.3345375501331782,
      "grad_norm": 0.03659119829535484,
      "learning_rate": 1.1103287103654492e-05,
      "loss": 0.0012,
      "step": 43590
    },
    {
      "epoch": 1.334843706946698,
      "grad_norm": 0.026407258585095406,
      "learning_rate": 1.1101246058231027e-05,
      "loss": 0.035,
      "step": 43600
    },
    {
      "epoch": 1.335149863760218,
      "grad_norm": 1.8971164226531982,
      "learning_rate": 1.109920501280756e-05,
      "loss": 0.0401,
      "step": 43610
    },
    {
      "epoch": 1.3354560205737378,
      "grad_norm": 1.782585620880127,
      "learning_rate": 1.1097163967384094e-05,
      "loss": 0.0372,
      "step": 43620
    },
    {
      "epoch": 1.3357621773872577,
      "grad_norm": 0.018465809524059296,
      "learning_rate": 1.1095122921960628e-05,
      "loss": 0.001,
      "step": 43630
    },
    {
      "epoch": 1.3360683342007778,
      "grad_norm": 0.009364957921206951,
      "learning_rate": 1.1093081876537163e-05,
      "loss": 0.0011,
      "step": 43640
    },
    {
      "epoch": 1.3363744910142974,
      "grad_norm": 0.02918519824743271,
      "learning_rate": 1.1091040831113697e-05,
      "loss": 0.0394,
      "step": 43650
    },
    {
      "epoch": 1.3366806478278175,
      "grad_norm": 0.03906543552875519,
      "learning_rate": 1.108899978569023e-05,
      "loss": 0.0013,
      "step": 43660
    },
    {
      "epoch": 1.3369868046413373,
      "grad_norm": 0.026410361751914024,
      "learning_rate": 1.1086958740266764e-05,
      "loss": 0.0009,
      "step": 43670
    },
    {
      "epoch": 1.3372929614548572,
      "grad_norm": 0.033107008785009384,
      "learning_rate": 1.10849176948433e-05,
      "loss": 0.0012,
      "step": 43680
    },
    {
      "epoch": 1.337599118268377,
      "grad_norm": 0.03310399129986763,
      "learning_rate": 1.1082876649419833e-05,
      "loss": 0.001,
      "step": 43690
    },
    {
      "epoch": 1.337905275081897,
      "grad_norm": 0.016547201201319695,
      "learning_rate": 1.1080835603996367e-05,
      "loss": 0.0032,
      "step": 43700
    },
    {
      "epoch": 1.3382114318954168,
      "grad_norm": 0.01507041696459055,
      "learning_rate": 1.1078794558572902e-05,
      "loss": 0.001,
      "step": 43710
    },
    {
      "epoch": 1.3385175887089367,
      "grad_norm": 0.01936945505440235,
      "learning_rate": 1.1076753513149436e-05,
      "loss": 0.0008,
      "step": 43720
    },
    {
      "epoch": 1.3388237455224565,
      "grad_norm": 0.015017644502222538,
      "learning_rate": 1.107471246772597e-05,
      "loss": 0.0337,
      "step": 43730
    },
    {
      "epoch": 1.3391299023359764,
      "grad_norm": 0.003555587725713849,
      "learning_rate": 1.1072671422302503e-05,
      "loss": 0.0051,
      "step": 43740
    },
    {
      "epoch": 1.3394360591494965,
      "grad_norm": 0.048387955874204636,
      "learning_rate": 1.1070630376879039e-05,
      "loss": 0.0008,
      "step": 43750
    },
    {
      "epoch": 1.3397422159630161,
      "grad_norm": 0.020965244621038437,
      "learning_rate": 1.1068589331455572e-05,
      "loss": 0.0384,
      "step": 43760
    },
    {
      "epoch": 1.3400483727765362,
      "grad_norm": 0.038306135684251785,
      "learning_rate": 1.1066548286032106e-05,
      "loss": 0.0012,
      "step": 43770
    },
    {
      "epoch": 1.340354529590056,
      "grad_norm": 0.003996155224740505,
      "learning_rate": 1.106450724060864e-05,
      "loss": 0.0006,
      "step": 43780
    },
    {
      "epoch": 1.340660686403576,
      "grad_norm": 0.006194720510393381,
      "learning_rate": 1.1062466195185175e-05,
      "loss": 0.0132,
      "step": 43790
    },
    {
      "epoch": 1.3409668432170958,
      "grad_norm": 0.0937705859541893,
      "learning_rate": 1.1060425149761708e-05,
      "loss": 0.0011,
      "step": 43800
    },
    {
      "epoch": 1.3412730000306157,
      "grad_norm": 0.02029556967318058,
      "learning_rate": 1.1058384104338242e-05,
      "loss": 0.0007,
      "step": 43810
    },
    {
      "epoch": 1.3415791568441355,
      "grad_norm": 0.006885565351694822,
      "learning_rate": 1.1056343058914777e-05,
      "loss": 0.0301,
      "step": 43820
    },
    {
      "epoch": 1.3418853136576554,
      "grad_norm": 0.013740564696490765,
      "learning_rate": 1.1054302013491311e-05,
      "loss": 0.001,
      "step": 43830
    },
    {
      "epoch": 1.3421914704711753,
      "grad_norm": 0.011608961969614029,
      "learning_rate": 1.1052260968067845e-05,
      "loss": 0.0075,
      "step": 43840
    },
    {
      "epoch": 1.3424976272846951,
      "grad_norm": 0.009217490442097187,
      "learning_rate": 1.1050219922644378e-05,
      "loss": 0.0013,
      "step": 43850
    },
    {
      "epoch": 1.3428037840982152,
      "grad_norm": 0.06693000346422195,
      "learning_rate": 1.1048178877220914e-05,
      "loss": 0.0341,
      "step": 43860
    },
    {
      "epoch": 1.3431099409117349,
      "grad_norm": 0.03244344890117645,
      "learning_rate": 1.1046137831797447e-05,
      "loss": 0.0013,
      "step": 43870
    },
    {
      "epoch": 1.343416097725255,
      "grad_norm": 0.02588260918855667,
      "learning_rate": 1.1044096786373981e-05,
      "loss": 0.0306,
      "step": 43880
    },
    {
      "epoch": 1.3437222545387748,
      "grad_norm": 0.03828186169266701,
      "learning_rate": 1.1042055740950515e-05,
      "loss": 0.0014,
      "step": 43890
    },
    {
      "epoch": 1.3440284113522947,
      "grad_norm": 0.03419829532504082,
      "learning_rate": 1.104001469552705e-05,
      "loss": 0.0022,
      "step": 43900
    },
    {
      "epoch": 1.3443345681658145,
      "grad_norm": 0.0058966572396457195,
      "learning_rate": 1.1037973650103584e-05,
      "loss": 0.0011,
      "step": 43910
    },
    {
      "epoch": 1.3446407249793344,
      "grad_norm": 1.9740303754806519,
      "learning_rate": 1.1035932604680117e-05,
      "loss": 0.0384,
      "step": 43920
    },
    {
      "epoch": 1.3449468817928543,
      "grad_norm": 0.012537344358861446,
      "learning_rate": 1.1033891559256653e-05,
      "loss": 0.0007,
      "step": 43930
    },
    {
      "epoch": 1.3452530386063741,
      "grad_norm": 0.0415278859436512,
      "learning_rate": 1.1031850513833186e-05,
      "loss": 0.0014,
      "step": 43940
    },
    {
      "epoch": 1.345559195419894,
      "grad_norm": 0.01785684935748577,
      "learning_rate": 1.102980946840972e-05,
      "loss": 0.0009,
      "step": 43950
    },
    {
      "epoch": 1.3458653522334139,
      "grad_norm": 0.012279422953724861,
      "learning_rate": 1.1027768422986254e-05,
      "loss": 0.0011,
      "step": 43960
    },
    {
      "epoch": 1.346171509046934,
      "grad_norm": 0.028669780120253563,
      "learning_rate": 1.1025727377562789e-05,
      "loss": 0.0007,
      "step": 43970
    },
    {
      "epoch": 1.3464776658604536,
      "grad_norm": 0.04659124091267586,
      "learning_rate": 1.1023686332139323e-05,
      "loss": 0.0013,
      "step": 43980
    },
    {
      "epoch": 1.3467838226739737,
      "grad_norm": 0.014334608800709248,
      "learning_rate": 1.1021645286715856e-05,
      "loss": 0.072,
      "step": 43990
    },
    {
      "epoch": 1.3470899794874935,
      "grad_norm": 0.012574585154652596,
      "learning_rate": 1.101960424129239e-05,
      "loss": 0.0011,
      "step": 44000
    },
    {
      "epoch": 1.3473961363010134,
      "grad_norm": 0.02562021277844906,
      "learning_rate": 1.1017563195868925e-05,
      "loss": 0.001,
      "step": 44010
    },
    {
      "epoch": 1.3477022931145333,
      "grad_norm": 0.025607923045754433,
      "learning_rate": 1.1015522150445459e-05,
      "loss": 0.0654,
      "step": 44020
    },
    {
      "epoch": 1.3480084499280531,
      "grad_norm": 0.017123280093073845,
      "learning_rate": 1.1013481105021992e-05,
      "loss": 0.0057,
      "step": 44030
    },
    {
      "epoch": 1.348314606741573,
      "grad_norm": 0.08044398576021194,
      "learning_rate": 1.1011440059598528e-05,
      "loss": 0.0626,
      "step": 44040
    },
    {
      "epoch": 1.3486207635550929,
      "grad_norm": 0.024603288620710373,
      "learning_rate": 1.1009399014175061e-05,
      "loss": 0.0273,
      "step": 44050
    },
    {
      "epoch": 1.3489269203686127,
      "grad_norm": 0.060228072106838226,
      "learning_rate": 1.1007357968751595e-05,
      "loss": 0.0026,
      "step": 44060
    },
    {
      "epoch": 1.3492330771821326,
      "grad_norm": 0.11198928207159042,
      "learning_rate": 1.1005316923328129e-05,
      "loss": 0.0221,
      "step": 44070
    },
    {
      "epoch": 1.3495392339956527,
      "grad_norm": 0.05400761216878891,
      "learning_rate": 1.1003275877904664e-05,
      "loss": 0.003,
      "step": 44080
    },
    {
      "epoch": 1.3498453908091725,
      "grad_norm": 0.030276954174041748,
      "learning_rate": 1.1001234832481198e-05,
      "loss": 0.0022,
      "step": 44090
    },
    {
      "epoch": 1.3501515476226924,
      "grad_norm": 2.1211233139038086,
      "learning_rate": 1.0999193787057731e-05,
      "loss": 0.0734,
      "step": 44100
    },
    {
      "epoch": 1.3504577044362123,
      "grad_norm": 0.05623510107398033,
      "learning_rate": 1.0997152741634265e-05,
      "loss": 0.0305,
      "step": 44110
    },
    {
      "epoch": 1.3507638612497321,
      "grad_norm": 0.03970261290669441,
      "learning_rate": 1.09951116962108e-05,
      "loss": 0.0019,
      "step": 44120
    },
    {
      "epoch": 1.351070018063252,
      "grad_norm": 0.08706887066364288,
      "learning_rate": 1.0993070650787334e-05,
      "loss": 0.0035,
      "step": 44130
    },
    {
      "epoch": 1.3513761748767719,
      "grad_norm": 0.031563594937324524,
      "learning_rate": 1.0991029605363868e-05,
      "loss": 0.0346,
      "step": 44140
    },
    {
      "epoch": 1.3516823316902917,
      "grad_norm": 0.06966578960418701,
      "learning_rate": 1.0988988559940403e-05,
      "loss": 0.0045,
      "step": 44150
    },
    {
      "epoch": 1.3519884885038116,
      "grad_norm": 0.02143089845776558,
      "learning_rate": 1.0986947514516937e-05,
      "loss": 0.002,
      "step": 44160
    },
    {
      "epoch": 1.3522946453173315,
      "grad_norm": 0.021265000104904175,
      "learning_rate": 1.098490646909347e-05,
      "loss": 0.0013,
      "step": 44170
    },
    {
      "epoch": 1.3526008021308513,
      "grad_norm": 0.057277828454971313,
      "learning_rate": 1.0982865423670004e-05,
      "loss": 0.0011,
      "step": 44180
    },
    {
      "epoch": 1.3529069589443714,
      "grad_norm": 0.020995931699872017,
      "learning_rate": 1.098082437824654e-05,
      "loss": 0.0014,
      "step": 44190
    },
    {
      "epoch": 1.3532131157578913,
      "grad_norm": 0.038994260132312775,
      "learning_rate": 1.0978783332823073e-05,
      "loss": 0.0016,
      "step": 44200
    },
    {
      "epoch": 1.3535192725714111,
      "grad_norm": 0.03343169391155243,
      "learning_rate": 1.0976742287399606e-05,
      "loss": 0.0329,
      "step": 44210
    },
    {
      "epoch": 1.353825429384931,
      "grad_norm": 2.464182138442993,
      "learning_rate": 1.097470124197614e-05,
      "loss": 0.0369,
      "step": 44220
    },
    {
      "epoch": 1.3541315861984509,
      "grad_norm": 0.015572788193821907,
      "learning_rate": 1.0972660196552675e-05,
      "loss": 0.0014,
      "step": 44230
    },
    {
      "epoch": 1.3544377430119707,
      "grad_norm": 0.03213327005505562,
      "learning_rate": 1.0970619151129209e-05,
      "loss": 0.0016,
      "step": 44240
    },
    {
      "epoch": 1.3547438998254906,
      "grad_norm": 0.022026019170880318,
      "learning_rate": 1.0968578105705743e-05,
      "loss": 0.0018,
      "step": 44250
    },
    {
      "epoch": 1.3550500566390105,
      "grad_norm": 0.013603520579636097,
      "learning_rate": 1.0966537060282278e-05,
      "loss": 0.0009,
      "step": 44260
    },
    {
      "epoch": 1.3553562134525303,
      "grad_norm": 0.03593821823596954,
      "learning_rate": 1.0964496014858812e-05,
      "loss": 0.0011,
      "step": 44270
    },
    {
      "epoch": 1.3556623702660504,
      "grad_norm": 0.02071397751569748,
      "learning_rate": 1.0962454969435345e-05,
      "loss": 0.0011,
      "step": 44280
    },
    {
      "epoch": 1.35596852707957,
      "grad_norm": 0.011772260069847107,
      "learning_rate": 1.0960413924011879e-05,
      "loss": 0.0008,
      "step": 44290
    },
    {
      "epoch": 1.3562746838930901,
      "grad_norm": 0.06103583425283432,
      "learning_rate": 1.0958372878588414e-05,
      "loss": 0.0012,
      "step": 44300
    },
    {
      "epoch": 1.35658084070661,
      "grad_norm": 0.01238745916634798,
      "learning_rate": 1.0956331833164948e-05,
      "loss": 0.0267,
      "step": 44310
    },
    {
      "epoch": 1.3568869975201299,
      "grad_norm": 0.012568136677145958,
      "learning_rate": 1.0954290787741482e-05,
      "loss": 0.0385,
      "step": 44320
    },
    {
      "epoch": 1.3571931543336497,
      "grad_norm": 3.165067434310913,
      "learning_rate": 1.0952249742318015e-05,
      "loss": 0.0113,
      "step": 44330
    },
    {
      "epoch": 1.3574993111471696,
      "grad_norm": 0.023476071655750275,
      "learning_rate": 1.095020869689455e-05,
      "loss": 0.0008,
      "step": 44340
    },
    {
      "epoch": 1.3578054679606895,
      "grad_norm": 0.06978487968444824,
      "learning_rate": 1.0948167651471084e-05,
      "loss": 0.017,
      "step": 44350
    },
    {
      "epoch": 1.3581116247742093,
      "grad_norm": 0.09157507121562958,
      "learning_rate": 1.0946126606047618e-05,
      "loss": 0.0014,
      "step": 44360
    },
    {
      "epoch": 1.3584177815877292,
      "grad_norm": 0.03463679179549217,
      "learning_rate": 1.0944085560624153e-05,
      "loss": 0.0859,
      "step": 44370
    },
    {
      "epoch": 1.358723938401249,
      "grad_norm": 0.04736058786511421,
      "learning_rate": 1.0942044515200687e-05,
      "loss": 0.0015,
      "step": 44380
    },
    {
      "epoch": 1.3590300952147691,
      "grad_norm": 0.03434661403298378,
      "learning_rate": 1.094000346977722e-05,
      "loss": 0.0012,
      "step": 44390
    },
    {
      "epoch": 1.3593362520282888,
      "grad_norm": 0.037813689559698105,
      "learning_rate": 1.0937962424353754e-05,
      "loss": 0.0018,
      "step": 44400
    },
    {
      "epoch": 1.3596424088418089,
      "grad_norm": 0.01606515236198902,
      "learning_rate": 1.093592137893029e-05,
      "loss": 0.001,
      "step": 44410
    },
    {
      "epoch": 1.3599485656553287,
      "grad_norm": 0.03263444826006889,
      "learning_rate": 1.0933880333506823e-05,
      "loss": 0.0013,
      "step": 44420
    },
    {
      "epoch": 1.3602547224688486,
      "grad_norm": 0.060846857726573944,
      "learning_rate": 1.0931839288083357e-05,
      "loss": 0.031,
      "step": 44430
    },
    {
      "epoch": 1.3605608792823685,
      "grad_norm": 0.030995303764939308,
      "learning_rate": 1.092979824265989e-05,
      "loss": 0.0008,
      "step": 44440
    },
    {
      "epoch": 1.3608670360958883,
      "grad_norm": 0.5402281880378723,
      "learning_rate": 1.0927757197236426e-05,
      "loss": 0.0012,
      "step": 44450
    },
    {
      "epoch": 1.3611731929094082,
      "grad_norm": 0.011966786347329617,
      "learning_rate": 1.092571615181296e-05,
      "loss": 0.0389,
      "step": 44460
    },
    {
      "epoch": 1.361479349722928,
      "grad_norm": 0.059903502464294434,
      "learning_rate": 1.0923675106389493e-05,
      "loss": 0.001,
      "step": 44470
    },
    {
      "epoch": 1.361785506536448,
      "grad_norm": 0.03528057411313057,
      "learning_rate": 1.0921634060966028e-05,
      "loss": 0.0017,
      "step": 44480
    },
    {
      "epoch": 1.3620916633499678,
      "grad_norm": 0.027881436049938202,
      "learning_rate": 1.0919593015542562e-05,
      "loss": 0.0099,
      "step": 44490
    },
    {
      "epoch": 1.3623978201634879,
      "grad_norm": 0.025935670360922813,
      "learning_rate": 1.0917551970119096e-05,
      "loss": 0.0391,
      "step": 44500
    },
    {
      "epoch": 1.3627039769770075,
      "grad_norm": 0.019565438851714134,
      "learning_rate": 1.091551092469563e-05,
      "loss": 0.0022,
      "step": 44510
    },
    {
      "epoch": 1.3630101337905276,
      "grad_norm": 0.010328699834644794,
      "learning_rate": 1.0913469879272165e-05,
      "loss": 0.0029,
      "step": 44520
    },
    {
      "epoch": 1.3633162906040475,
      "grad_norm": 0.022294828668236732,
      "learning_rate": 1.0911428833848698e-05,
      "loss": 0.0008,
      "step": 44530
    },
    {
      "epoch": 1.3636224474175673,
      "grad_norm": 0.028001191094517708,
      "learning_rate": 1.0909387788425232e-05,
      "loss": 0.0321,
      "step": 44540
    },
    {
      "epoch": 1.3639286042310872,
      "grad_norm": 0.02618817612528801,
      "learning_rate": 1.0907346743001766e-05,
      "loss": 0.0012,
      "step": 44550
    },
    {
      "epoch": 1.364234761044607,
      "grad_norm": 0.013124590739607811,
      "learning_rate": 1.0905305697578301e-05,
      "loss": 0.0011,
      "step": 44560
    },
    {
      "epoch": 1.364540917858127,
      "grad_norm": 0.030432291328907013,
      "learning_rate": 1.0903264652154835e-05,
      "loss": 0.0012,
      "step": 44570
    },
    {
      "epoch": 1.3648470746716468,
      "grad_norm": 0.013534842990338802,
      "learning_rate": 1.0901223606731368e-05,
      "loss": 0.0006,
      "step": 44580
    },
    {
      "epoch": 1.3651532314851667,
      "grad_norm": 0.01186038926243782,
      "learning_rate": 1.0899182561307904e-05,
      "loss": 0.0013,
      "step": 44590
    },
    {
      "epoch": 1.3654593882986865,
      "grad_norm": 0.015957176685333252,
      "learning_rate": 1.0897141515884437e-05,
      "loss": 0.0011,
      "step": 44600
    },
    {
      "epoch": 1.3657655451122066,
      "grad_norm": 0.019769074395298958,
      "learning_rate": 1.0895100470460971e-05,
      "loss": 0.0764,
      "step": 44610
    },
    {
      "epoch": 1.3660717019257262,
      "grad_norm": 0.04143771156668663,
      "learning_rate": 1.0893059425037505e-05,
      "loss": 0.0016,
      "step": 44620
    },
    {
      "epoch": 1.3663778587392463,
      "grad_norm": 0.02883712388575077,
      "learning_rate": 1.089101837961404e-05,
      "loss": 0.0009,
      "step": 44630
    },
    {
      "epoch": 1.3666840155527662,
      "grad_norm": 0.04427703469991684,
      "learning_rate": 1.0888977334190574e-05,
      "loss": 0.0008,
      "step": 44640
    },
    {
      "epoch": 1.366990172366286,
      "grad_norm": 0.009674887172877789,
      "learning_rate": 1.0886936288767107e-05,
      "loss": 0.0011,
      "step": 44650
    },
    {
      "epoch": 1.367296329179806,
      "grad_norm": 0.007099320646375418,
      "learning_rate": 1.088489524334364e-05,
      "loss": 0.0007,
      "step": 44660
    },
    {
      "epoch": 1.3676024859933258,
      "grad_norm": 0.019052807241678238,
      "learning_rate": 1.0882854197920176e-05,
      "loss": 0.0005,
      "step": 44670
    },
    {
      "epoch": 1.3679086428068457,
      "grad_norm": 3.4713051319122314,
      "learning_rate": 1.088081315249671e-05,
      "loss": 0.0771,
      "step": 44680
    },
    {
      "epoch": 1.3682147996203655,
      "grad_norm": 0.026944462209939957,
      "learning_rate": 1.0878772107073243e-05,
      "loss": 0.0006,
      "step": 44690
    },
    {
      "epoch": 1.3685209564338854,
      "grad_norm": 0.009646591730415821,
      "learning_rate": 1.0876731061649779e-05,
      "loss": 0.0121,
      "step": 44700
    },
    {
      "epoch": 1.3688271132474052,
      "grad_norm": 0.035105641931295395,
      "learning_rate": 1.0874690016226312e-05,
      "loss": 0.0012,
      "step": 44710
    },
    {
      "epoch": 1.3691332700609253,
      "grad_norm": 0.010486364364624023,
      "learning_rate": 1.0872648970802846e-05,
      "loss": 0.0388,
      "step": 44720
    },
    {
      "epoch": 1.369439426874445,
      "grad_norm": 0.03503773361444473,
      "learning_rate": 1.087060792537938e-05,
      "loss": 0.0012,
      "step": 44730
    },
    {
      "epoch": 1.369745583687965,
      "grad_norm": 0.031451184302568436,
      "learning_rate": 1.0868566879955915e-05,
      "loss": 0.0009,
      "step": 44740
    },
    {
      "epoch": 1.370051740501485,
      "grad_norm": 2.9855918884277344,
      "learning_rate": 1.0866525834532449e-05,
      "loss": 0.0588,
      "step": 44750
    },
    {
      "epoch": 1.3703578973150048,
      "grad_norm": 0.04894271492958069,
      "learning_rate": 1.0864484789108982e-05,
      "loss": 0.0011,
      "step": 44760
    },
    {
      "epoch": 1.3706640541285247,
      "grad_norm": 0.02162420190870762,
      "learning_rate": 1.0862443743685516e-05,
      "loss": 0.0386,
      "step": 44770
    },
    {
      "epoch": 1.3709702109420445,
      "grad_norm": 0.04228407144546509,
      "learning_rate": 1.0860402698262051e-05,
      "loss": 0.0744,
      "step": 44780
    },
    {
      "epoch": 1.3712763677555644,
      "grad_norm": 0.024686386808753014,
      "learning_rate": 1.0858361652838585e-05,
      "loss": 0.0015,
      "step": 44790
    },
    {
      "epoch": 1.3715825245690842,
      "grad_norm": 0.01744692027568817,
      "learning_rate": 1.0856320607415119e-05,
      "loss": 0.0016,
      "step": 44800
    },
    {
      "epoch": 1.3718886813826041,
      "grad_norm": 2.4335341453552246,
      "learning_rate": 1.0854279561991654e-05,
      "loss": 0.0271,
      "step": 44810
    },
    {
      "epoch": 1.372194838196124,
      "grad_norm": 0.021200252696871758,
      "learning_rate": 1.0852238516568188e-05,
      "loss": 0.0008,
      "step": 44820
    },
    {
      "epoch": 1.372500995009644,
      "grad_norm": 0.019755573943257332,
      "learning_rate": 1.0850197471144721e-05,
      "loss": 0.0011,
      "step": 44830
    },
    {
      "epoch": 1.3728071518231637,
      "grad_norm": 0.048821739852428436,
      "learning_rate": 1.0848156425721255e-05,
      "loss": 0.0332,
      "step": 44840
    },
    {
      "epoch": 1.3731133086366838,
      "grad_norm": 0.03703286871314049,
      "learning_rate": 1.084611538029779e-05,
      "loss": 0.0017,
      "step": 44850
    },
    {
      "epoch": 1.3734194654502037,
      "grad_norm": 1.828072428703308,
      "learning_rate": 1.0844074334874324e-05,
      "loss": 0.069,
      "step": 44860
    },
    {
      "epoch": 1.3737256222637235,
      "grad_norm": 0.025165287777781487,
      "learning_rate": 1.0842033289450857e-05,
      "loss": 0.0012,
      "step": 44870
    },
    {
      "epoch": 1.3740317790772434,
      "grad_norm": 0.037034712731838226,
      "learning_rate": 1.0839992244027391e-05,
      "loss": 0.0038,
      "step": 44880
    },
    {
      "epoch": 1.3743379358907633,
      "grad_norm": 0.04168960079550743,
      "learning_rate": 1.0837951198603926e-05,
      "loss": 0.0372,
      "step": 44890
    },
    {
      "epoch": 1.3746440927042831,
      "grad_norm": 0.06428595632314682,
      "learning_rate": 1.083591015318046e-05,
      "loss": 0.0627,
      "step": 44900
    },
    {
      "epoch": 1.374950249517803,
      "grad_norm": 0.02631998248398304,
      "learning_rate": 1.0833869107756994e-05,
      "loss": 0.0014,
      "step": 44910
    },
    {
      "epoch": 1.3752564063313228,
      "grad_norm": 0.015996195375919342,
      "learning_rate": 1.0831828062333527e-05,
      "loss": 0.0032,
      "step": 44920
    },
    {
      "epoch": 1.3755625631448427,
      "grad_norm": 0.03129153698682785,
      "learning_rate": 1.0829787016910063e-05,
      "loss": 0.0023,
      "step": 44930
    },
    {
      "epoch": 1.3758687199583628,
      "grad_norm": 0.03142571821808815,
      "learning_rate": 1.0827745971486596e-05,
      "loss": 0.0011,
      "step": 44940
    },
    {
      "epoch": 1.3761748767718824,
      "grad_norm": 0.06094212457537651,
      "learning_rate": 1.082570492606313e-05,
      "loss": 0.0016,
      "step": 44950
    },
    {
      "epoch": 1.3764810335854025,
      "grad_norm": 0.010828499682247639,
      "learning_rate": 1.0823663880639665e-05,
      "loss": 0.0015,
      "step": 44960
    },
    {
      "epoch": 1.3767871903989224,
      "grad_norm": 0.08451758325099945,
      "learning_rate": 1.0821622835216199e-05,
      "loss": 0.002,
      "step": 44970
    },
    {
      "epoch": 1.3770933472124423,
      "grad_norm": 0.03849323093891144,
      "learning_rate": 1.0819581789792733e-05,
      "loss": 0.0015,
      "step": 44980
    },
    {
      "epoch": 1.3773995040259621,
      "grad_norm": 0.04842035472393036,
      "learning_rate": 1.0817540744369266e-05,
      "loss": 0.0014,
      "step": 44990
    },
    {
      "epoch": 1.377705660839482,
      "grad_norm": 0.040064118802547455,
      "learning_rate": 1.0815499698945802e-05,
      "loss": 0.0157,
      "step": 45000
    },
    {
      "epoch": 1.3780118176530018,
      "grad_norm": 0.03622037172317505,
      "learning_rate": 1.0813458653522335e-05,
      "loss": 0.0672,
      "step": 45010
    },
    {
      "epoch": 1.3783179744665217,
      "grad_norm": 0.07970374077558517,
      "learning_rate": 1.0811417608098869e-05,
      "loss": 0.0013,
      "step": 45020
    },
    {
      "epoch": 1.3786241312800416,
      "grad_norm": 0.03418990224599838,
      "learning_rate": 1.0809376562675403e-05,
      "loss": 0.0013,
      "step": 45030
    },
    {
      "epoch": 1.3789302880935614,
      "grad_norm": 0.03673480078577995,
      "learning_rate": 1.0807335517251938e-05,
      "loss": 0.0267,
      "step": 45040
    },
    {
      "epoch": 1.3792364449070815,
      "grad_norm": 0.013305461034178734,
      "learning_rate": 1.0805294471828472e-05,
      "loss": 0.0014,
      "step": 45050
    },
    {
      "epoch": 1.3795426017206012,
      "grad_norm": 0.05362871661782265,
      "learning_rate": 1.0803253426405005e-05,
      "loss": 0.0361,
      "step": 45060
    },
    {
      "epoch": 1.3798487585341213,
      "grad_norm": 0.07603617012500763,
      "learning_rate": 1.080121238098154e-05,
      "loss": 0.0104,
      "step": 45070
    },
    {
      "epoch": 1.3801549153476411,
      "grad_norm": 0.030414709821343422,
      "learning_rate": 1.0799171335558074e-05,
      "loss": 0.0014,
      "step": 45080
    },
    {
      "epoch": 1.380461072161161,
      "grad_norm": 0.017932943999767303,
      "learning_rate": 1.0797130290134608e-05,
      "loss": 0.0048,
      "step": 45090
    },
    {
      "epoch": 1.3807672289746808,
      "grad_norm": 0.07022760063409805,
      "learning_rate": 1.0795089244711141e-05,
      "loss": 0.0017,
      "step": 45100
    },
    {
      "epoch": 1.3810733857882007,
      "grad_norm": 0.025651471689343452,
      "learning_rate": 1.0793048199287677e-05,
      "loss": 0.0013,
      "step": 45110
    },
    {
      "epoch": 1.3813795426017206,
      "grad_norm": 0.015620432794094086,
      "learning_rate": 1.079100715386421e-05,
      "loss": 0.0012,
      "step": 45120
    },
    {
      "epoch": 1.3816856994152404,
      "grad_norm": 0.021728970110416412,
      "learning_rate": 1.0788966108440744e-05,
      "loss": 0.0021,
      "step": 45130
    },
    {
      "epoch": 1.3819918562287603,
      "grad_norm": 0.022428512573242188,
      "learning_rate": 1.0786925063017278e-05,
      "loss": 0.1193,
      "step": 45140
    },
    {
      "epoch": 1.3822980130422802,
      "grad_norm": 5.985305309295654,
      "learning_rate": 1.0784884017593813e-05,
      "loss": 0.0227,
      "step": 45150
    },
    {
      "epoch": 1.3826041698558003,
      "grad_norm": 0.020136818289756775,
      "learning_rate": 1.0782842972170347e-05,
      "loss": 0.0338,
      "step": 45160
    },
    {
      "epoch": 1.38291032666932,
      "grad_norm": 0.047373298555612564,
      "learning_rate": 1.078080192674688e-05,
      "loss": 0.0288,
      "step": 45170
    },
    {
      "epoch": 1.38321648348284,
      "grad_norm": 0.16478851437568665,
      "learning_rate": 1.0778760881323416e-05,
      "loss": 0.0014,
      "step": 45180
    },
    {
      "epoch": 1.3835226402963599,
      "grad_norm": 0.07817378640174866,
      "learning_rate": 1.077671983589995e-05,
      "loss": 0.0014,
      "step": 45190
    },
    {
      "epoch": 1.3838287971098797,
      "grad_norm": 0.0601513609290123,
      "learning_rate": 1.0774678790476483e-05,
      "loss": 0.0016,
      "step": 45200
    },
    {
      "epoch": 1.3841349539233996,
      "grad_norm": 0.049405358731746674,
      "learning_rate": 1.0772637745053017e-05,
      "loss": 0.0015,
      "step": 45210
    },
    {
      "epoch": 1.3844411107369194,
      "grad_norm": 0.008752827532589436,
      "learning_rate": 1.0770596699629552e-05,
      "loss": 0.0013,
      "step": 45220
    },
    {
      "epoch": 1.3847472675504393,
      "grad_norm": 0.04014734551310539,
      "learning_rate": 1.0768555654206086e-05,
      "loss": 0.0017,
      "step": 45230
    },
    {
      "epoch": 1.3850534243639592,
      "grad_norm": 0.14957205951213837,
      "learning_rate": 1.076651460878262e-05,
      "loss": 0.001,
      "step": 45240
    },
    {
      "epoch": 1.385359581177479,
      "grad_norm": 0.011324984021484852,
      "learning_rate": 1.0764473563359153e-05,
      "loss": 0.0011,
      "step": 45250
    },
    {
      "epoch": 1.385665737990999,
      "grad_norm": 0.023245621472597122,
      "learning_rate": 1.0762432517935688e-05,
      "loss": 0.0008,
      "step": 45260
    },
    {
      "epoch": 1.385971894804519,
      "grad_norm": 0.049861762672662735,
      "learning_rate": 1.0760391472512222e-05,
      "loss": 0.001,
      "step": 45270
    },
    {
      "epoch": 1.3862780516180386,
      "grad_norm": 0.006770308129489422,
      "learning_rate": 1.0758350427088756e-05,
      "loss": 0.0006,
      "step": 45280
    },
    {
      "epoch": 1.3865842084315587,
      "grad_norm": 0.009561239741742611,
      "learning_rate": 1.0756309381665291e-05,
      "loss": 0.0007,
      "step": 45290
    },
    {
      "epoch": 1.3868903652450786,
      "grad_norm": 0.024597477167844772,
      "learning_rate": 1.0754268336241825e-05,
      "loss": 0.0453,
      "step": 45300
    },
    {
      "epoch": 1.3871965220585984,
      "grad_norm": 0.016673777252435684,
      "learning_rate": 1.0752227290818358e-05,
      "loss": 0.0005,
      "step": 45310
    },
    {
      "epoch": 1.3875026788721183,
      "grad_norm": 0.03413259610533714,
      "learning_rate": 1.0750186245394892e-05,
      "loss": 0.0012,
      "step": 45320
    },
    {
      "epoch": 1.3878088356856382,
      "grad_norm": 0.016836483031511307,
      "learning_rate": 1.0748145199971427e-05,
      "loss": 0.0008,
      "step": 45330
    },
    {
      "epoch": 1.388114992499158,
      "grad_norm": 0.021847626194357872,
      "learning_rate": 1.074610415454796e-05,
      "loss": 0.0011,
      "step": 45340
    },
    {
      "epoch": 1.388421149312678,
      "grad_norm": 0.02920292504131794,
      "learning_rate": 1.0744063109124494e-05,
      "loss": 0.0009,
      "step": 45350
    },
    {
      "epoch": 1.3887273061261978,
      "grad_norm": 0.00968447607010603,
      "learning_rate": 1.0742022063701028e-05,
      "loss": 0.001,
      "step": 45360
    },
    {
      "epoch": 1.3890334629397176,
      "grad_norm": 0.01707249879837036,
      "learning_rate": 1.0739981018277563e-05,
      "loss": 0.0012,
      "step": 45370
    },
    {
      "epoch": 1.3893396197532377,
      "grad_norm": 1.7880316972732544,
      "learning_rate": 1.0737939972854097e-05,
      "loss": 0.043,
      "step": 45380
    },
    {
      "epoch": 1.3896457765667574,
      "grad_norm": 0.00835332553833723,
      "learning_rate": 1.073589892743063e-05,
      "loss": 0.0008,
      "step": 45390
    },
    {
      "epoch": 1.3899519333802774,
      "grad_norm": 0.02197364903986454,
      "learning_rate": 1.0733857882007166e-05,
      "loss": 0.0371,
      "step": 45400
    },
    {
      "epoch": 1.3902580901937973,
      "grad_norm": 0.016042524948716164,
      "learning_rate": 1.07318168365837e-05,
      "loss": 0.0007,
      "step": 45410
    },
    {
      "epoch": 1.3905642470073172,
      "grad_norm": 0.03741683438420296,
      "learning_rate": 1.0729775791160233e-05,
      "loss": 0.0009,
      "step": 45420
    },
    {
      "epoch": 1.390870403820837,
      "grad_norm": 0.30484625697135925,
      "learning_rate": 1.0727734745736767e-05,
      "loss": 0.0359,
      "step": 45430
    },
    {
      "epoch": 1.391176560634357,
      "grad_norm": 0.018842509016394615,
      "learning_rate": 1.0725693700313302e-05,
      "loss": 0.0007,
      "step": 45440
    },
    {
      "epoch": 1.3914827174478768,
      "grad_norm": 0.042256321758031845,
      "learning_rate": 1.0723652654889836e-05,
      "loss": 0.0471,
      "step": 45450
    },
    {
      "epoch": 1.3917888742613966,
      "grad_norm": 0.005361991003155708,
      "learning_rate": 1.072161160946637e-05,
      "loss": 0.0009,
      "step": 45460
    },
    {
      "epoch": 1.3920950310749165,
      "grad_norm": 0.08332810550928116,
      "learning_rate": 1.0719570564042903e-05,
      "loss": 0.0343,
      "step": 45470
    },
    {
      "epoch": 1.3924011878884364,
      "grad_norm": 0.0180825088173151,
      "learning_rate": 1.0717529518619439e-05,
      "loss": 0.0295,
      "step": 45480
    },
    {
      "epoch": 1.3927073447019565,
      "grad_norm": 0.0477168969810009,
      "learning_rate": 1.0715488473195972e-05,
      "loss": 0.0342,
      "step": 45490
    },
    {
      "epoch": 1.393013501515476,
      "grad_norm": 1.8989193439483643,
      "learning_rate": 1.0713447427772506e-05,
      "loss": 0.0328,
      "step": 45500
    },
    {
      "epoch": 1.3933196583289962,
      "grad_norm": 1.7901841402053833,
      "learning_rate": 1.0711406382349041e-05,
      "loss": 0.0346,
      "step": 45510
    },
    {
      "epoch": 1.393625815142516,
      "grad_norm": 0.056873999536037445,
      "learning_rate": 1.0709365336925575e-05,
      "loss": 0.0739,
      "step": 45520
    },
    {
      "epoch": 1.393931971956036,
      "grad_norm": 0.05032539740204811,
      "learning_rate": 1.0707324291502109e-05,
      "loss": 0.0025,
      "step": 45530
    },
    {
      "epoch": 1.3942381287695558,
      "grad_norm": 0.029440637677907944,
      "learning_rate": 1.0705283246078642e-05,
      "loss": 0.0039,
      "step": 45540
    },
    {
      "epoch": 1.3945442855830756,
      "grad_norm": 0.05815233290195465,
      "learning_rate": 1.0703242200655177e-05,
      "loss": 0.0018,
      "step": 45550
    },
    {
      "epoch": 1.3948504423965955,
      "grad_norm": 1.843888282775879,
      "learning_rate": 1.0701201155231711e-05,
      "loss": 0.0158,
      "step": 45560
    },
    {
      "epoch": 1.3951565992101154,
      "grad_norm": 0.053279418498277664,
      "learning_rate": 1.0699160109808245e-05,
      "loss": 0.0013,
      "step": 45570
    },
    {
      "epoch": 1.3954627560236352,
      "grad_norm": 0.02543991431593895,
      "learning_rate": 1.0697119064384778e-05,
      "loss": 0.0433,
      "step": 45580
    },
    {
      "epoch": 1.395768912837155,
      "grad_norm": 0.09819250553846359,
      "learning_rate": 1.0695078018961314e-05,
      "loss": 0.0381,
      "step": 45590
    },
    {
      "epoch": 1.3960750696506752,
      "grad_norm": 0.03576701134443283,
      "learning_rate": 1.0693036973537847e-05,
      "loss": 0.0016,
      "step": 45600
    },
    {
      "epoch": 1.3963812264641948,
      "grad_norm": 0.06558551639318466,
      "learning_rate": 1.0690995928114381e-05,
      "loss": 0.0394,
      "step": 45610
    },
    {
      "epoch": 1.396687383277715,
      "grad_norm": 0.16711822152137756,
      "learning_rate": 1.0688954882690916e-05,
      "loss": 0.0028,
      "step": 45620
    },
    {
      "epoch": 1.3969935400912348,
      "grad_norm": 0.010318925604224205,
      "learning_rate": 1.068691383726745e-05,
      "loss": 0.0021,
      "step": 45630
    },
    {
      "epoch": 1.3972996969047546,
      "grad_norm": 0.05068392679095268,
      "learning_rate": 1.0684872791843984e-05,
      "loss": 0.0017,
      "step": 45640
    },
    {
      "epoch": 1.3976058537182745,
      "grad_norm": 0.036502655595541,
      "learning_rate": 1.0682831746420517e-05,
      "loss": 0.0014,
      "step": 45650
    },
    {
      "epoch": 1.3979120105317944,
      "grad_norm": 0.03589022159576416,
      "learning_rate": 1.0680790700997053e-05,
      "loss": 0.001,
      "step": 45660
    },
    {
      "epoch": 1.3982181673453142,
      "grad_norm": 0.0690355971455574,
      "learning_rate": 1.0678749655573586e-05,
      "loss": 0.0734,
      "step": 45670
    },
    {
      "epoch": 1.398524324158834,
      "grad_norm": 0.03942690044641495,
      "learning_rate": 1.067670861015012e-05,
      "loss": 0.0012,
      "step": 45680
    },
    {
      "epoch": 1.398830480972354,
      "grad_norm": 0.007044760510325432,
      "learning_rate": 1.0674667564726654e-05,
      "loss": 0.0012,
      "step": 45690
    },
    {
      "epoch": 1.3991366377858738,
      "grad_norm": 0.02505125291645527,
      "learning_rate": 1.0672626519303189e-05,
      "loss": 0.0162,
      "step": 45700
    },
    {
      "epoch": 1.399442794599394,
      "grad_norm": 0.030254201963543892,
      "learning_rate": 1.0670585473879723e-05,
      "loss": 0.0028,
      "step": 45710
    },
    {
      "epoch": 1.3997489514129136,
      "grad_norm": 0.03401610627770424,
      "learning_rate": 1.0668544428456256e-05,
      "loss": 0.0466,
      "step": 45720
    },
    {
      "epoch": 1.4000551082264336,
      "grad_norm": 0.05306723713874817,
      "learning_rate": 1.0666503383032792e-05,
      "loss": 0.0009,
      "step": 45730
    },
    {
      "epoch": 1.4003612650399535,
      "grad_norm": 0.08095419406890869,
      "learning_rate": 1.0664462337609325e-05,
      "loss": 0.0096,
      "step": 45740
    },
    {
      "epoch": 1.4006674218534734,
      "grad_norm": 2.263918399810791,
      "learning_rate": 1.0662421292185859e-05,
      "loss": 0.0205,
      "step": 45750
    },
    {
      "epoch": 1.4009735786669932,
      "grad_norm": 0.06246516481041908,
      "learning_rate": 1.0660380246762392e-05,
      "loss": 0.0313,
      "step": 45760
    },
    {
      "epoch": 1.401279735480513,
      "grad_norm": 1.7076681852340698,
      "learning_rate": 1.0658339201338928e-05,
      "loss": 0.0348,
      "step": 45770
    },
    {
      "epoch": 1.401585892294033,
      "grad_norm": 0.014513094909489155,
      "learning_rate": 1.0656298155915461e-05,
      "loss": 0.0011,
      "step": 45780
    },
    {
      "epoch": 1.4018920491075528,
      "grad_norm": 0.004813504405319691,
      "learning_rate": 1.0654257110491995e-05,
      "loss": 0.0013,
      "step": 45790
    },
    {
      "epoch": 1.4021982059210727,
      "grad_norm": 0.005408724304288626,
      "learning_rate": 1.0652216065068529e-05,
      "loss": 0.0015,
      "step": 45800
    },
    {
      "epoch": 1.4025043627345926,
      "grad_norm": 0.0462261363863945,
      "learning_rate": 1.0650175019645064e-05,
      "loss": 0.0013,
      "step": 45810
    },
    {
      "epoch": 1.4028105195481126,
      "grad_norm": 2.0660884380340576,
      "learning_rate": 1.0648133974221598e-05,
      "loss": 0.0343,
      "step": 45820
    },
    {
      "epoch": 1.4031166763616325,
      "grad_norm": 0.043794143944978714,
      "learning_rate": 1.0646092928798131e-05,
      "loss": 0.0021,
      "step": 45830
    },
    {
      "epoch": 1.4034228331751524,
      "grad_norm": 0.0058013442903757095,
      "learning_rate": 1.0644051883374667e-05,
      "loss": 0.0014,
      "step": 45840
    },
    {
      "epoch": 1.4037289899886722,
      "grad_norm": 0.06673556566238403,
      "learning_rate": 1.06420108379512e-05,
      "loss": 0.0275,
      "step": 45850
    },
    {
      "epoch": 1.404035146802192,
      "grad_norm": 0.036024514585733414,
      "learning_rate": 1.0639969792527734e-05,
      "loss": 0.0156,
      "step": 45860
    },
    {
      "epoch": 1.404341303615712,
      "grad_norm": 0.015193991363048553,
      "learning_rate": 1.0637928747104268e-05,
      "loss": 0.0013,
      "step": 45870
    },
    {
      "epoch": 1.4046474604292318,
      "grad_norm": 0.0934959203004837,
      "learning_rate": 1.0635887701680803e-05,
      "loss": 0.0015,
      "step": 45880
    },
    {
      "epoch": 1.4049536172427517,
      "grad_norm": 0.036411352455616,
      "learning_rate": 1.0633846656257337e-05,
      "loss": 0.0698,
      "step": 45890
    },
    {
      "epoch": 1.4052597740562716,
      "grad_norm": 0.05498741567134857,
      "learning_rate": 1.063180561083387e-05,
      "loss": 0.0014,
      "step": 45900
    },
    {
      "epoch": 1.4055659308697914,
      "grad_norm": 0.015608739107847214,
      "learning_rate": 1.0629764565410404e-05,
      "loss": 0.0018,
      "step": 45910
    },
    {
      "epoch": 1.4058720876833113,
      "grad_norm": 0.07549342513084412,
      "learning_rate": 1.062772351998694e-05,
      "loss": 0.0023,
      "step": 45920
    },
    {
      "epoch": 1.4061782444968314,
      "grad_norm": 0.009306401945650578,
      "learning_rate": 1.0625682474563473e-05,
      "loss": 0.0014,
      "step": 45930
    },
    {
      "epoch": 1.4064844013103512,
      "grad_norm": 0.03711581975221634,
      "learning_rate": 1.0623641429140007e-05,
      "loss": 0.0013,
      "step": 45940
    },
    {
      "epoch": 1.406790558123871,
      "grad_norm": 0.01388236042112112,
      "learning_rate": 1.0621600383716542e-05,
      "loss": 0.0009,
      "step": 45950
    },
    {
      "epoch": 1.407096714937391,
      "grad_norm": 0.25537025928497314,
      "learning_rate": 1.0619559338293076e-05,
      "loss": 0.0016,
      "step": 45960
    },
    {
      "epoch": 1.4074028717509108,
      "grad_norm": 0.019338540732860565,
      "learning_rate": 1.061751829286961e-05,
      "loss": 0.0012,
      "step": 45970
    },
    {
      "epoch": 1.4077090285644307,
      "grad_norm": 0.030092911794781685,
      "learning_rate": 1.0615477247446143e-05,
      "loss": 0.001,
      "step": 45980
    },
    {
      "epoch": 1.4080151853779506,
      "grad_norm": 0.02087898924946785,
      "learning_rate": 1.0613436202022678e-05,
      "loss": 0.0174,
      "step": 45990
    },
    {
      "epoch": 1.4083213421914704,
      "grad_norm": 0.019532721489667892,
      "learning_rate": 1.0611395156599212e-05,
      "loss": 0.0009,
      "step": 46000
    },
    {
      "epoch": 1.4086274990049903,
      "grad_norm": 0.019363628700375557,
      "learning_rate": 1.0609354111175745e-05,
      "loss": 0.0359,
      "step": 46010
    },
    {
      "epoch": 1.4089336558185104,
      "grad_norm": 0.022852327674627304,
      "learning_rate": 1.0607313065752279e-05,
      "loss": 0.0009,
      "step": 46020
    },
    {
      "epoch": 1.40923981263203,
      "grad_norm": 0.004657819867134094,
      "learning_rate": 1.0605272020328814e-05,
      "loss": 0.0006,
      "step": 46030
    },
    {
      "epoch": 1.40954596944555,
      "grad_norm": 0.024751771241426468,
      "learning_rate": 1.0603230974905348e-05,
      "loss": 0.0614,
      "step": 46040
    },
    {
      "epoch": 1.40985212625907,
      "grad_norm": 0.439586341381073,
      "learning_rate": 1.0601189929481882e-05,
      "loss": 0.0017,
      "step": 46050
    },
    {
      "epoch": 1.4101582830725898,
      "grad_norm": 0.004781258758157492,
      "learning_rate": 1.0599148884058417e-05,
      "loss": 0.0007,
      "step": 46060
    },
    {
      "epoch": 1.4104644398861097,
      "grad_norm": 1.8576513528823853,
      "learning_rate": 1.059710783863495e-05,
      "loss": 0.1021,
      "step": 46070
    },
    {
      "epoch": 1.4107705966996296,
      "grad_norm": 0.007674405816942453,
      "learning_rate": 1.0595066793211484e-05,
      "loss": 0.0008,
      "step": 46080
    },
    {
      "epoch": 1.4110767535131494,
      "grad_norm": 0.011211293749511242,
      "learning_rate": 1.0593025747788018e-05,
      "loss": 0.0011,
      "step": 46090
    },
    {
      "epoch": 1.4113829103266693,
      "grad_norm": 0.033817920833826065,
      "learning_rate": 1.0590984702364553e-05,
      "loss": 0.0014,
      "step": 46100
    },
    {
      "epoch": 1.4116890671401892,
      "grad_norm": 0.054495494812726974,
      "learning_rate": 1.0588943656941087e-05,
      "loss": 0.0269,
      "step": 46110
    },
    {
      "epoch": 1.411995223953709,
      "grad_norm": 0.025487255305051804,
      "learning_rate": 1.058690261151762e-05,
      "loss": 0.0011,
      "step": 46120
    },
    {
      "epoch": 1.412301380767229,
      "grad_norm": 0.01522853970527649,
      "learning_rate": 1.0584861566094153e-05,
      "loss": 0.0008,
      "step": 46130
    },
    {
      "epoch": 1.4126075375807488,
      "grad_norm": 0.027280546724796295,
      "learning_rate": 1.058282052067069e-05,
      "loss": 0.0012,
      "step": 46140
    },
    {
      "epoch": 1.4129136943942688,
      "grad_norm": 0.011023004539310932,
      "learning_rate": 1.0580779475247223e-05,
      "loss": 0.0708,
      "step": 46150
    },
    {
      "epoch": 1.4132198512077887,
      "grad_norm": 0.0806959941983223,
      "learning_rate": 1.0578738429823757e-05,
      "loss": 0.0061,
      "step": 46160
    },
    {
      "epoch": 1.4135260080213086,
      "grad_norm": 0.017140937969088554,
      "learning_rate": 1.0576697384400289e-05,
      "loss": 0.0011,
      "step": 46170
    },
    {
      "epoch": 1.4138321648348284,
      "grad_norm": 0.023752201348543167,
      "learning_rate": 1.0574656338976826e-05,
      "loss": 0.03,
      "step": 46180
    },
    {
      "epoch": 1.4141383216483483,
      "grad_norm": 0.05617392435669899,
      "learning_rate": 1.057261529355336e-05,
      "loss": 0.0652,
      "step": 46190
    },
    {
      "epoch": 1.4144444784618682,
      "grad_norm": 0.04568988457322121,
      "learning_rate": 1.0570574248129891e-05,
      "loss": 0.0012,
      "step": 46200
    },
    {
      "epoch": 1.414750635275388,
      "grad_norm": 0.031978435814380646,
      "learning_rate": 1.0568533202706429e-05,
      "loss": 0.0322,
      "step": 46210
    },
    {
      "epoch": 1.4150567920889079,
      "grad_norm": 0.0342864990234375,
      "learning_rate": 1.0566492157282962e-05,
      "loss": 0.0027,
      "step": 46220
    },
    {
      "epoch": 1.4153629489024278,
      "grad_norm": 0.015404799953103065,
      "learning_rate": 1.0564451111859496e-05,
      "loss": 0.0018,
      "step": 46230
    },
    {
      "epoch": 1.4156691057159478,
      "grad_norm": 0.0331159383058548,
      "learning_rate": 1.0562410066436028e-05,
      "loss": 0.0017,
      "step": 46240
    },
    {
      "epoch": 1.4159752625294675,
      "grad_norm": 0.05025120824575424,
      "learning_rate": 1.0560369021012565e-05,
      "loss": 0.0011,
      "step": 46250
    },
    {
      "epoch": 1.4162814193429876,
      "grad_norm": 0.3047983646392822,
      "learning_rate": 1.0558327975589098e-05,
      "loss": 0.0684,
      "step": 46260
    },
    {
      "epoch": 1.4165875761565074,
      "grad_norm": 0.018257269635796547,
      "learning_rate": 1.055628693016563e-05,
      "loss": 0.0011,
      "step": 46270
    },
    {
      "epoch": 1.4168937329700273,
      "grad_norm": 0.014771335758268833,
      "learning_rate": 1.0554245884742164e-05,
      "loss": 0.0017,
      "step": 46280
    },
    {
      "epoch": 1.4171998897835472,
      "grad_norm": 0.013373380526900291,
      "learning_rate": 1.0552204839318701e-05,
      "loss": 0.0014,
      "step": 46290
    },
    {
      "epoch": 1.417506046597067,
      "grad_norm": 0.01836605928838253,
      "learning_rate": 1.0550163793895235e-05,
      "loss": 0.0015,
      "step": 46300
    },
    {
      "epoch": 1.417812203410587,
      "grad_norm": 0.027327077463269234,
      "learning_rate": 1.0548122748471767e-05,
      "loss": 0.0012,
      "step": 46310
    },
    {
      "epoch": 1.4181183602241068,
      "grad_norm": 0.29178932309150696,
      "learning_rate": 1.0546081703048304e-05,
      "loss": 0.0022,
      "step": 46320
    },
    {
      "epoch": 1.4184245170376266,
      "grad_norm": 0.013978456147015095,
      "learning_rate": 1.0544040657624837e-05,
      "loss": 0.0025,
      "step": 46330
    },
    {
      "epoch": 1.4187306738511465,
      "grad_norm": 0.03986382111907005,
      "learning_rate": 1.0541999612201371e-05,
      "loss": 0.0009,
      "step": 46340
    },
    {
      "epoch": 1.4190368306646666,
      "grad_norm": 0.026714615523815155,
      "learning_rate": 1.0539958566777903e-05,
      "loss": 0.0363,
      "step": 46350
    },
    {
      "epoch": 1.4193429874781862,
      "grad_norm": 0.033638712018728256,
      "learning_rate": 1.053791752135444e-05,
      "loss": 0.0016,
      "step": 46360
    },
    {
      "epoch": 1.4196491442917063,
      "grad_norm": 0.021036844700574875,
      "learning_rate": 1.0535876475930974e-05,
      "loss": 0.0335,
      "step": 46370
    },
    {
      "epoch": 1.4199553011052262,
      "grad_norm": 0.016059527173638344,
      "learning_rate": 1.0533835430507506e-05,
      "loss": 0.0008,
      "step": 46380
    },
    {
      "epoch": 1.420261457918746,
      "grad_norm": 0.013731974177062511,
      "learning_rate": 1.053179438508404e-05,
      "loss": 0.0008,
      "step": 46390
    },
    {
      "epoch": 1.420567614732266,
      "grad_norm": 0.020182345062494278,
      "learning_rate": 1.0529753339660576e-05,
      "loss": 0.037,
      "step": 46400
    },
    {
      "epoch": 1.4208737715457858,
      "grad_norm": 0.05906803160905838,
      "learning_rate": 1.052771229423711e-05,
      "loss": 0.0014,
      "step": 46410
    },
    {
      "epoch": 1.4211799283593056,
      "grad_norm": 0.004636017140001059,
      "learning_rate": 1.0525671248813642e-05,
      "loss": 0.0349,
      "step": 46420
    },
    {
      "epoch": 1.4214860851728255,
      "grad_norm": 0.03165925294160843,
      "learning_rate": 1.0523630203390179e-05,
      "loss": 0.0011,
      "step": 46430
    },
    {
      "epoch": 1.4217922419863454,
      "grad_norm": 0.038437120616436005,
      "learning_rate": 1.0521589157966712e-05,
      "loss": 0.0016,
      "step": 46440
    },
    {
      "epoch": 1.4220983987998652,
      "grad_norm": 0.032047685235738754,
      "learning_rate": 1.0519548112543244e-05,
      "loss": 0.0016,
      "step": 46450
    },
    {
      "epoch": 1.4224045556133853,
      "grad_norm": 0.044728320091962814,
      "learning_rate": 1.0517507067119778e-05,
      "loss": 0.0011,
      "step": 46460
    },
    {
      "epoch": 1.422710712426905,
      "grad_norm": 0.028433291241526604,
      "learning_rate": 1.0515466021696315e-05,
      "loss": 0.0014,
      "step": 46470
    },
    {
      "epoch": 1.423016869240425,
      "grad_norm": 0.012256115674972534,
      "learning_rate": 1.0513424976272849e-05,
      "loss": 0.0006,
      "step": 46480
    },
    {
      "epoch": 1.423323026053945,
      "grad_norm": 0.0971093699336052,
      "learning_rate": 1.051138393084938e-05,
      "loss": 0.0013,
      "step": 46490
    },
    {
      "epoch": 1.4236291828674648,
      "grad_norm": 0.009966121055185795,
      "learning_rate": 1.0509342885425914e-05,
      "loss": 0.001,
      "step": 46500
    },
    {
      "epoch": 1.4239353396809846,
      "grad_norm": 0.02219797670841217,
      "learning_rate": 1.0507301840002451e-05,
      "loss": 0.0763,
      "step": 46510
    },
    {
      "epoch": 1.4242414964945045,
      "grad_norm": 0.015183673240244389,
      "learning_rate": 1.0505260794578983e-05,
      "loss": 0.039,
      "step": 46520
    },
    {
      "epoch": 1.4245476533080244,
      "grad_norm": 0.02732825092971325,
      "learning_rate": 1.0503219749155517e-05,
      "loss": 0.0668,
      "step": 46530
    },
    {
      "epoch": 1.4248538101215442,
      "grad_norm": 1.5357959270477295,
      "learning_rate": 1.0501178703732054e-05,
      "loss": 0.0259,
      "step": 46540
    },
    {
      "epoch": 1.425159966935064,
      "grad_norm": 0.057916637510061264,
      "learning_rate": 1.0499137658308588e-05,
      "loss": 0.0016,
      "step": 46550
    },
    {
      "epoch": 1.425466123748584,
      "grad_norm": 0.024050060659646988,
      "learning_rate": 1.049709661288512e-05,
      "loss": 0.077,
      "step": 46560
    },
    {
      "epoch": 1.425772280562104,
      "grad_norm": 0.008477380499243736,
      "learning_rate": 1.0495055567461653e-05,
      "loss": 0.0251,
      "step": 46570
    },
    {
      "epoch": 1.4260784373756237,
      "grad_norm": 0.0611625537276268,
      "learning_rate": 1.049301452203819e-05,
      "loss": 0.0032,
      "step": 46580
    },
    {
      "epoch": 1.4263845941891438,
      "grad_norm": 0.030218103900551796,
      "learning_rate": 1.0490973476614724e-05,
      "loss": 0.0018,
      "step": 46590
    },
    {
      "epoch": 1.4266907510026636,
      "grad_norm": 0.04688991978764534,
      "learning_rate": 1.0488932431191256e-05,
      "loss": 0.0017,
      "step": 46600
    },
    {
      "epoch": 1.4269969078161835,
      "grad_norm": 0.015608659014105797,
      "learning_rate": 1.048689138576779e-05,
      "loss": 0.0318,
      "step": 46610
    },
    {
      "epoch": 1.4273030646297034,
      "grad_norm": 0.03030373528599739,
      "learning_rate": 1.0484850340344327e-05,
      "loss": 0.0017,
      "step": 46620
    },
    {
      "epoch": 1.4276092214432232,
      "grad_norm": 0.017948145046830177,
      "learning_rate": 1.0482809294920859e-05,
      "loss": 0.0019,
      "step": 46630
    },
    {
      "epoch": 1.427915378256743,
      "grad_norm": 0.04876682162284851,
      "learning_rate": 1.0480768249497392e-05,
      "loss": 0.0018,
      "step": 46640
    },
    {
      "epoch": 1.428221535070263,
      "grad_norm": 0.00543494988232851,
      "learning_rate": 1.047872720407393e-05,
      "loss": 0.0027,
      "step": 46650
    },
    {
      "epoch": 1.4285276918837828,
      "grad_norm": 1.7790623903274536,
      "learning_rate": 1.0476686158650463e-05,
      "loss": 0.034,
      "step": 46660
    },
    {
      "epoch": 1.4288338486973027,
      "grad_norm": 0.008965025655925274,
      "learning_rate": 1.0474645113226995e-05,
      "loss": 0.0022,
      "step": 46670
    },
    {
      "epoch": 1.4291400055108228,
      "grad_norm": 0.03423907235264778,
      "learning_rate": 1.0472604067803528e-05,
      "loss": 0.0014,
      "step": 46680
    },
    {
      "epoch": 1.4294461623243424,
      "grad_norm": 0.02912875823676586,
      "learning_rate": 1.0470563022380065e-05,
      "loss": 0.0019,
      "step": 46690
    },
    {
      "epoch": 1.4297523191378625,
      "grad_norm": 0.02552027627825737,
      "learning_rate": 1.0468521976956597e-05,
      "loss": 0.0012,
      "step": 46700
    },
    {
      "epoch": 1.4300584759513824,
      "grad_norm": 0.04692639783024788,
      "learning_rate": 1.0466480931533131e-05,
      "loss": 0.0014,
      "step": 46710
    },
    {
      "epoch": 1.4303646327649022,
      "grad_norm": 0.02320384792983532,
      "learning_rate": 1.0464439886109665e-05,
      "loss": 0.0011,
      "step": 46720
    },
    {
      "epoch": 1.430670789578422,
      "grad_norm": 0.023032933473587036,
      "learning_rate": 1.0462398840686202e-05,
      "loss": 0.0009,
      "step": 46730
    },
    {
      "epoch": 1.430976946391942,
      "grad_norm": 0.01656222715973854,
      "learning_rate": 1.0460357795262734e-05,
      "loss": 0.0365,
      "step": 46740
    },
    {
      "epoch": 1.4312831032054618,
      "grad_norm": 0.017147796228528023,
      "learning_rate": 1.0458316749839267e-05,
      "loss": 0.0377,
      "step": 46750
    },
    {
      "epoch": 1.4315892600189817,
      "grad_norm": 0.008742881938815117,
      "learning_rate": 1.0456275704415804e-05,
      "loss": 0.0354,
      "step": 46760
    },
    {
      "epoch": 1.4318954168325015,
      "grad_norm": 0.027190325781702995,
      "learning_rate": 1.0454234658992336e-05,
      "loss": 0.0318,
      "step": 46770
    },
    {
      "epoch": 1.4322015736460214,
      "grad_norm": 0.04314678907394409,
      "learning_rate": 1.045219361356887e-05,
      "loss": 0.0374,
      "step": 46780
    },
    {
      "epoch": 1.4325077304595415,
      "grad_norm": 0.03155035898089409,
      "learning_rate": 1.0450152568145404e-05,
      "loss": 0.0021,
      "step": 46790
    },
    {
      "epoch": 1.4328138872730611,
      "grad_norm": 1.9706299304962158,
      "learning_rate": 1.044811152272194e-05,
      "loss": 0.041,
      "step": 46800
    },
    {
      "epoch": 1.4331200440865812,
      "grad_norm": 0.03910711035132408,
      "learning_rate": 1.0446070477298473e-05,
      "loss": 0.0019,
      "step": 46810
    },
    {
      "epoch": 1.433426200900101,
      "grad_norm": 0.04734213650226593,
      "learning_rate": 1.0444029431875006e-05,
      "loss": 0.0015,
      "step": 46820
    },
    {
      "epoch": 1.433732357713621,
      "grad_norm": 0.028144972398877144,
      "learning_rate": 1.044198838645154e-05,
      "loss": 0.0014,
      "step": 46830
    },
    {
      "epoch": 1.4340385145271408,
      "grad_norm": 0.06945694983005524,
      "learning_rate": 1.0439947341028077e-05,
      "loss": 0.0316,
      "step": 46840
    },
    {
      "epoch": 1.4343446713406607,
      "grad_norm": 0.047805652022361755,
      "learning_rate": 1.0437906295604609e-05,
      "loss": 0.0341,
      "step": 46850
    },
    {
      "epoch": 1.4346508281541805,
      "grad_norm": 0.0775737538933754,
      "learning_rate": 1.0435865250181142e-05,
      "loss": 0.0016,
      "step": 46860
    },
    {
      "epoch": 1.4349569849677004,
      "grad_norm": 0.0116677051410079,
      "learning_rate": 1.043382420475768e-05,
      "loss": 0.0238,
      "step": 46870
    },
    {
      "epoch": 1.4352631417812203,
      "grad_norm": 0.031918201595544815,
      "learning_rate": 1.0431783159334211e-05,
      "loss": 0.0017,
      "step": 46880
    },
    {
      "epoch": 1.4355692985947401,
      "grad_norm": 0.04255872219800949,
      "learning_rate": 1.0429742113910745e-05,
      "loss": 0.0015,
      "step": 46890
    },
    {
      "epoch": 1.4358754554082602,
      "grad_norm": 0.05476764217019081,
      "learning_rate": 1.0427701068487279e-05,
      "loss": 0.0015,
      "step": 46900
    },
    {
      "epoch": 1.4361816122217799,
      "grad_norm": 0.019161755219101906,
      "learning_rate": 1.0425660023063816e-05,
      "loss": 0.0012,
      "step": 46910
    },
    {
      "epoch": 1.4364877690353,
      "grad_norm": 0.012718496844172478,
      "learning_rate": 1.0423618977640348e-05,
      "loss": 0.0016,
      "step": 46920
    },
    {
      "epoch": 1.4367939258488198,
      "grad_norm": 1.8357367515563965,
      "learning_rate": 1.0421577932216881e-05,
      "loss": 0.0382,
      "step": 46930
    },
    {
      "epoch": 1.4371000826623397,
      "grad_norm": 0.02973596565425396,
      "learning_rate": 1.0419536886793415e-05,
      "loss": 0.0354,
      "step": 46940
    },
    {
      "epoch": 1.4374062394758595,
      "grad_norm": 0.035241853445768356,
      "learning_rate": 1.041749584136995e-05,
      "loss": 0.0192,
      "step": 46950
    },
    {
      "epoch": 1.4377123962893794,
      "grad_norm": 0.05116194486618042,
      "learning_rate": 1.0415454795946484e-05,
      "loss": 0.0022,
      "step": 46960
    },
    {
      "epoch": 1.4380185531028993,
      "grad_norm": 0.02598920650780201,
      "learning_rate": 1.0413413750523018e-05,
      "loss": 0.0014,
      "step": 46970
    },
    {
      "epoch": 1.4383247099164191,
      "grad_norm": 0.020119713619351387,
      "learning_rate": 1.0411372705099555e-05,
      "loss": 0.0012,
      "step": 46980
    },
    {
      "epoch": 1.438630866729939,
      "grad_norm": 0.06446066498756409,
      "learning_rate": 1.0409331659676087e-05,
      "loss": 0.0294,
      "step": 46990
    },
    {
      "epoch": 1.4389370235434589,
      "grad_norm": 0.023258164525032043,
      "learning_rate": 1.040729061425262e-05,
      "loss": 0.0014,
      "step": 47000
    },
    {
      "epoch": 1.439243180356979,
      "grad_norm": 0.02265816181898117,
      "learning_rate": 1.0405249568829154e-05,
      "loss": 0.074,
      "step": 47010
    },
    {
      "epoch": 1.4395493371704986,
      "grad_norm": 0.0701424777507782,
      "learning_rate": 1.040320852340569e-05,
      "loss": 0.0014,
      "step": 47020
    },
    {
      "epoch": 1.4398554939840187,
      "grad_norm": 0.03735450282692909,
      "learning_rate": 1.0401167477982223e-05,
      "loss": 0.0017,
      "step": 47030
    },
    {
      "epoch": 1.4401616507975386,
      "grad_norm": 0.21628545224666595,
      "learning_rate": 1.0399126432558757e-05,
      "loss": 0.0017,
      "step": 47040
    },
    {
      "epoch": 1.4404678076110584,
      "grad_norm": 1.8146874904632568,
      "learning_rate": 1.039708538713529e-05,
      "loss": 0.0752,
      "step": 47050
    },
    {
      "epoch": 1.4407739644245783,
      "grad_norm": 0.06366260349750519,
      "learning_rate": 1.0395044341711826e-05,
      "loss": 0.0019,
      "step": 47060
    },
    {
      "epoch": 1.4410801212380981,
      "grad_norm": 0.10358136147260666,
      "learning_rate": 1.039300329628836e-05,
      "loss": 0.0284,
      "step": 47070
    },
    {
      "epoch": 1.441386278051618,
      "grad_norm": 0.04747757315635681,
      "learning_rate": 1.0390962250864893e-05,
      "loss": 0.0017,
      "step": 47080
    },
    {
      "epoch": 1.4416924348651379,
      "grad_norm": 0.04333769530057907,
      "learning_rate": 1.0388921205441428e-05,
      "loss": 0.0018,
      "step": 47090
    },
    {
      "epoch": 1.4419985916786577,
      "grad_norm": 0.03270363062620163,
      "learning_rate": 1.0386880160017962e-05,
      "loss": 0.0017,
      "step": 47100
    },
    {
      "epoch": 1.4423047484921776,
      "grad_norm": 0.04688448831439018,
      "learning_rate": 1.0384839114594495e-05,
      "loss": 0.0017,
      "step": 47110
    },
    {
      "epoch": 1.4426109053056977,
      "grad_norm": 2.672931671142578,
      "learning_rate": 1.0382798069171029e-05,
      "loss": 0.0464,
      "step": 47120
    },
    {
      "epoch": 1.4429170621192173,
      "grad_norm": 0.03133385628461838,
      "learning_rate": 1.0380757023747564e-05,
      "loss": 0.001,
      "step": 47130
    },
    {
      "epoch": 1.4432232189327374,
      "grad_norm": 0.043949637562036514,
      "learning_rate": 1.0378715978324098e-05,
      "loss": 0.0018,
      "step": 47140
    },
    {
      "epoch": 1.4435293757462573,
      "grad_norm": 0.047486286610364914,
      "learning_rate": 1.0376674932900632e-05,
      "loss": 0.0011,
      "step": 47150
    },
    {
      "epoch": 1.4438355325597771,
      "grad_norm": 0.025566179305315018,
      "learning_rate": 1.0374633887477165e-05,
      "loss": 0.0013,
      "step": 47160
    },
    {
      "epoch": 1.444141689373297,
      "grad_norm": 0.019325464963912964,
      "learning_rate": 1.03725928420537e-05,
      "loss": 0.001,
      "step": 47170
    },
    {
      "epoch": 1.4444478461868169,
      "grad_norm": 0.0445103757083416,
      "learning_rate": 1.0370551796630234e-05,
      "loss": 0.0315,
      "step": 47180
    },
    {
      "epoch": 1.4447540030003367,
      "grad_norm": 0.02872488833963871,
      "learning_rate": 1.0368510751206768e-05,
      "loss": 0.0013,
      "step": 47190
    },
    {
      "epoch": 1.4450601598138566,
      "grad_norm": 0.03111623041331768,
      "learning_rate": 1.0366469705783303e-05,
      "loss": 0.0399,
      "step": 47200
    },
    {
      "epoch": 1.4453663166273765,
      "grad_norm": 0.2777526080608368,
      "learning_rate": 1.0364428660359837e-05,
      "loss": 0.0016,
      "step": 47210
    },
    {
      "epoch": 1.4456724734408963,
      "grad_norm": 0.052680715918540955,
      "learning_rate": 1.036238761493637e-05,
      "loss": 0.0015,
      "step": 47220
    },
    {
      "epoch": 1.4459786302544164,
      "grad_norm": 0.02513265796005726,
      "learning_rate": 1.0360346569512904e-05,
      "loss": 0.0011,
      "step": 47230
    },
    {
      "epoch": 1.446284787067936,
      "grad_norm": 0.010904897935688496,
      "learning_rate": 1.035830552408944e-05,
      "loss": 0.0012,
      "step": 47240
    },
    {
      "epoch": 1.4465909438814561,
      "grad_norm": 0.013948825187981129,
      "learning_rate": 1.0356264478665973e-05,
      "loss": 0.0011,
      "step": 47250
    },
    {
      "epoch": 1.446897100694976,
      "grad_norm": 0.05557487905025482,
      "learning_rate": 1.0354223433242507e-05,
      "loss": 0.0008,
      "step": 47260
    },
    {
      "epoch": 1.4472032575084959,
      "grad_norm": 0.012308225966989994,
      "learning_rate": 1.035218238781904e-05,
      "loss": 0.007,
      "step": 47270
    },
    {
      "epoch": 1.4475094143220157,
      "grad_norm": 0.015264411456882954,
      "learning_rate": 1.0350141342395576e-05,
      "loss": 0.0009,
      "step": 47280
    },
    {
      "epoch": 1.4478155711355356,
      "grad_norm": 0.025691119953989983,
      "learning_rate": 1.034810029697211e-05,
      "loss": 0.0264,
      "step": 47290
    },
    {
      "epoch": 1.4481217279490555,
      "grad_norm": 0.04409398138523102,
      "learning_rate": 1.0346059251548643e-05,
      "loss": 0.001,
      "step": 47300
    },
    {
      "epoch": 1.4484278847625753,
      "grad_norm": 1.8816441297531128,
      "learning_rate": 1.0344018206125179e-05,
      "loss": 0.0394,
      "step": 47310
    },
    {
      "epoch": 1.4487340415760952,
      "grad_norm": 0.06040921434760094,
      "learning_rate": 1.0341977160701712e-05,
      "loss": 0.0016,
      "step": 47320
    },
    {
      "epoch": 1.449040198389615,
      "grad_norm": 0.02818879298865795,
      "learning_rate": 1.0339936115278246e-05,
      "loss": 0.0527,
      "step": 47330
    },
    {
      "epoch": 1.4493463552031352,
      "grad_norm": 0.019224930554628372,
      "learning_rate": 1.033789506985478e-05,
      "loss": 0.0013,
      "step": 47340
    },
    {
      "epoch": 1.4496525120166548,
      "grad_norm": 0.02433849312365055,
      "learning_rate": 1.0335854024431315e-05,
      "loss": 0.0291,
      "step": 47350
    },
    {
      "epoch": 1.4499586688301749,
      "grad_norm": 0.0398988276720047,
      "learning_rate": 1.0333812979007848e-05,
      "loss": 0.0011,
      "step": 47360
    },
    {
      "epoch": 1.4502648256436947,
      "grad_norm": 0.014578629285097122,
      "learning_rate": 1.0331771933584382e-05,
      "loss": 0.0362,
      "step": 47370
    },
    {
      "epoch": 1.4505709824572146,
      "grad_norm": 0.015367900021374226,
      "learning_rate": 1.0329730888160916e-05,
      "loss": 0.001,
      "step": 47380
    },
    {
      "epoch": 1.4508771392707345,
      "grad_norm": 0.04174458980560303,
      "learning_rate": 1.0327689842737451e-05,
      "loss": 0.0011,
      "step": 47390
    },
    {
      "epoch": 1.4511832960842543,
      "grad_norm": 0.08545085042715073,
      "learning_rate": 1.0325648797313985e-05,
      "loss": 0.0712,
      "step": 47400
    },
    {
      "epoch": 1.4514894528977742,
      "grad_norm": 3.114656686782837,
      "learning_rate": 1.0323607751890518e-05,
      "loss": 0.0649,
      "step": 47410
    },
    {
      "epoch": 1.451795609711294,
      "grad_norm": 0.0025342819280922413,
      "learning_rate": 1.0321566706467052e-05,
      "loss": 0.0012,
      "step": 47420
    },
    {
      "epoch": 1.452101766524814,
      "grad_norm": 0.05574856325984001,
      "learning_rate": 1.0319525661043587e-05,
      "loss": 0.0015,
      "step": 47430
    },
    {
      "epoch": 1.4524079233383338,
      "grad_norm": 0.02231333777308464,
      "learning_rate": 1.0317484615620121e-05,
      "loss": 0.0014,
      "step": 47440
    },
    {
      "epoch": 1.4527140801518539,
      "grad_norm": 0.05144951120018959,
      "learning_rate": 1.0315443570196655e-05,
      "loss": 0.0466,
      "step": 47450
    },
    {
      "epoch": 1.4530202369653737,
      "grad_norm": 0.03928293287754059,
      "learning_rate": 1.031340252477319e-05,
      "loss": 0.0018,
      "step": 47460
    },
    {
      "epoch": 1.4533263937788936,
      "grad_norm": 0.03074285387992859,
      "learning_rate": 1.0311361479349724e-05,
      "loss": 0.0016,
      "step": 47470
    },
    {
      "epoch": 1.4536325505924135,
      "grad_norm": 0.02754167467355728,
      "learning_rate": 1.0309320433926257e-05,
      "loss": 0.0017,
      "step": 47480
    },
    {
      "epoch": 1.4539387074059333,
      "grad_norm": 0.046856511384248734,
      "learning_rate": 1.0307279388502791e-05,
      "loss": 0.0015,
      "step": 47490
    },
    {
      "epoch": 1.4542448642194532,
      "grad_norm": 0.014700637198984623,
      "learning_rate": 1.0305238343079326e-05,
      "loss": 0.001,
      "step": 47500
    },
    {
      "epoch": 1.454551021032973,
      "grad_norm": 0.020713405683636665,
      "learning_rate": 1.030319729765586e-05,
      "loss": 0.0011,
      "step": 47510
    },
    {
      "epoch": 1.454857177846493,
      "grad_norm": 0.04165218397974968,
      "learning_rate": 1.0301156252232394e-05,
      "loss": 0.0017,
      "step": 47520
    },
    {
      "epoch": 1.4551633346600128,
      "grad_norm": 0.023848306387662888,
      "learning_rate": 1.0299115206808927e-05,
      "loss": 0.0013,
      "step": 47530
    },
    {
      "epoch": 1.4554694914735327,
      "grad_norm": 0.007959672249853611,
      "learning_rate": 1.0297074161385462e-05,
      "loss": 0.0005,
      "step": 47540
    },
    {
      "epoch": 1.4557756482870525,
      "grad_norm": 0.04644708335399628,
      "learning_rate": 1.0295033115961996e-05,
      "loss": 0.0011,
      "step": 47550
    },
    {
      "epoch": 1.4560818051005726,
      "grad_norm": 0.018284812569618225,
      "learning_rate": 1.029299207053853e-05,
      "loss": 0.071,
      "step": 47560
    },
    {
      "epoch": 1.4563879619140925,
      "grad_norm": 0.014246444217860699,
      "learning_rate": 1.0290951025115065e-05,
      "loss": 0.0014,
      "step": 47570
    },
    {
      "epoch": 1.4566941187276123,
      "grad_norm": 0.024605412036180496,
      "learning_rate": 1.0288909979691599e-05,
      "loss": 0.0012,
      "step": 47580
    },
    {
      "epoch": 1.4570002755411322,
      "grad_norm": 0.04525318369269371,
      "learning_rate": 1.0286868934268132e-05,
      "loss": 0.001,
      "step": 47590
    },
    {
      "epoch": 1.457306432354652,
      "grad_norm": 0.03813156113028526,
      "learning_rate": 1.0284827888844666e-05,
      "loss": 0.0013,
      "step": 47600
    },
    {
      "epoch": 1.457612589168172,
      "grad_norm": 0.042540229856967926,
      "learning_rate": 1.0282786843421201e-05,
      "loss": 0.0009,
      "step": 47610
    },
    {
      "epoch": 1.4579187459816918,
      "grad_norm": 0.020107587799429893,
      "learning_rate": 1.0280745797997735e-05,
      "loss": 0.0294,
      "step": 47620
    },
    {
      "epoch": 1.4582249027952117,
      "grad_norm": 0.024979833513498306,
      "learning_rate": 1.0278704752574269e-05,
      "loss": 0.0337,
      "step": 47630
    },
    {
      "epoch": 1.4585310596087315,
      "grad_norm": 0.037923771888017654,
      "learning_rate": 1.0276663707150802e-05,
      "loss": 0.0341,
      "step": 47640
    },
    {
      "epoch": 1.4588372164222516,
      "grad_norm": 0.026805773377418518,
      "learning_rate": 1.0274622661727338e-05,
      "loss": 0.0016,
      "step": 47650
    },
    {
      "epoch": 1.4591433732357713,
      "grad_norm": 0.05089334025979042,
      "learning_rate": 1.0272581616303871e-05,
      "loss": 0.0013,
      "step": 47660
    },
    {
      "epoch": 1.4594495300492913,
      "grad_norm": 0.044929251074790955,
      "learning_rate": 1.0270540570880405e-05,
      "loss": 0.0015,
      "step": 47670
    },
    {
      "epoch": 1.4597556868628112,
      "grad_norm": 0.022743001580238342,
      "learning_rate": 1.026849952545694e-05,
      "loss": 0.0379,
      "step": 47680
    },
    {
      "epoch": 1.460061843676331,
      "grad_norm": 2.1906542778015137,
      "learning_rate": 1.0266458480033474e-05,
      "loss": 0.0445,
      "step": 47690
    },
    {
      "epoch": 1.460368000489851,
      "grad_norm": 0.059923380613327026,
      "learning_rate": 1.0264417434610008e-05,
      "loss": 0.0016,
      "step": 47700
    },
    {
      "epoch": 1.4606741573033708,
      "grad_norm": 0.007988469675183296,
      "learning_rate": 1.0262376389186541e-05,
      "loss": 0.0239,
      "step": 47710
    },
    {
      "epoch": 1.4609803141168907,
      "grad_norm": 0.03217620030045509,
      "learning_rate": 1.0260335343763077e-05,
      "loss": 0.0015,
      "step": 47720
    },
    {
      "epoch": 1.4612864709304105,
      "grad_norm": 0.034225910902023315,
      "learning_rate": 1.025829429833961e-05,
      "loss": 0.0246,
      "step": 47730
    },
    {
      "epoch": 1.4615926277439304,
      "grad_norm": 0.09829237312078476,
      "learning_rate": 1.0256253252916144e-05,
      "loss": 0.0021,
      "step": 47740
    },
    {
      "epoch": 1.4618987845574503,
      "grad_norm": 0.04208967089653015,
      "learning_rate": 1.0254212207492677e-05,
      "loss": 0.0092,
      "step": 47750
    },
    {
      "epoch": 1.4622049413709703,
      "grad_norm": 0.4086819887161255,
      "learning_rate": 1.0252171162069213e-05,
      "loss": 0.0027,
      "step": 47760
    },
    {
      "epoch": 1.46251109818449,
      "grad_norm": 0.03914225101470947,
      "learning_rate": 1.0250130116645746e-05,
      "loss": 0.0018,
      "step": 47770
    },
    {
      "epoch": 1.46281725499801,
      "grad_norm": 0.016996338963508606,
      "learning_rate": 1.024808907122228e-05,
      "loss": 0.0029,
      "step": 47780
    },
    {
      "epoch": 1.46312341181153,
      "grad_norm": 0.027129853144288063,
      "learning_rate": 1.0246048025798815e-05,
      "loss": 0.0381,
      "step": 47790
    },
    {
      "epoch": 1.4634295686250498,
      "grad_norm": 0.03931616246700287,
      "learning_rate": 1.0244006980375349e-05,
      "loss": 0.035,
      "step": 47800
    },
    {
      "epoch": 1.4637357254385697,
      "grad_norm": 0.056471578776836395,
      "learning_rate": 1.0241965934951883e-05,
      "loss": 0.0018,
      "step": 47810
    },
    {
      "epoch": 1.4640418822520895,
      "grad_norm": 0.055428143590688705,
      "learning_rate": 1.0239924889528416e-05,
      "loss": 0.0014,
      "step": 47820
    },
    {
      "epoch": 1.4643480390656094,
      "grad_norm": 0.045996326953172684,
      "learning_rate": 1.0237883844104952e-05,
      "loss": 0.0343,
      "step": 47830
    },
    {
      "epoch": 1.4646541958791293,
      "grad_norm": 0.05936919152736664,
      "learning_rate": 1.0235842798681485e-05,
      "loss": 0.0014,
      "step": 47840
    },
    {
      "epoch": 1.4649603526926491,
      "grad_norm": 0.0423363633453846,
      "learning_rate": 1.0233801753258019e-05,
      "loss": 0.0012,
      "step": 47850
    },
    {
      "epoch": 1.465266509506169,
      "grad_norm": 0.035999078303575516,
      "learning_rate": 1.0231760707834553e-05,
      "loss": 0.0383,
      "step": 47860
    },
    {
      "epoch": 1.465572666319689,
      "grad_norm": 0.019174892455339432,
      "learning_rate": 1.0229719662411088e-05,
      "loss": 0.0016,
      "step": 47870
    },
    {
      "epoch": 1.4658788231332087,
      "grad_norm": 0.026822008192539215,
      "learning_rate": 1.0227678616987622e-05,
      "loss": 0.0023,
      "step": 47880
    },
    {
      "epoch": 1.4661849799467288,
      "grad_norm": 0.026153184473514557,
      "learning_rate": 1.0225637571564155e-05,
      "loss": 0.0378,
      "step": 47890
    },
    {
      "epoch": 1.4664911367602487,
      "grad_norm": 0.02589423954486847,
      "learning_rate": 1.022359652614069e-05,
      "loss": 0.0017,
      "step": 47900
    },
    {
      "epoch": 1.4667972935737685,
      "grad_norm": 0.060371797531843185,
      "learning_rate": 1.0221555480717224e-05,
      "loss": 0.0012,
      "step": 47910
    },
    {
      "epoch": 1.4671034503872884,
      "grad_norm": 0.0398206003010273,
      "learning_rate": 1.0219514435293758e-05,
      "loss": 0.0365,
      "step": 47920
    },
    {
      "epoch": 1.4674096072008083,
      "grad_norm": 0.022013643756508827,
      "learning_rate": 1.0217473389870292e-05,
      "loss": 0.0304,
      "step": 47930
    },
    {
      "epoch": 1.4677157640143281,
      "grad_norm": 0.04285246133804321,
      "learning_rate": 1.0215432344446827e-05,
      "loss": 0.0365,
      "step": 47940
    },
    {
      "epoch": 1.468021920827848,
      "grad_norm": 0.019556349143385887,
      "learning_rate": 1.021339129902336e-05,
      "loss": 0.0014,
      "step": 47950
    },
    {
      "epoch": 1.4683280776413679,
      "grad_norm": 0.01342572271823883,
      "learning_rate": 1.0211350253599894e-05,
      "loss": 0.0337,
      "step": 47960
    },
    {
      "epoch": 1.4686342344548877,
      "grad_norm": 0.03674931451678276,
      "learning_rate": 1.0209309208176428e-05,
      "loss": 0.0698,
      "step": 47970
    },
    {
      "epoch": 1.4689403912684078,
      "grad_norm": 0.07164882868528366,
      "learning_rate": 1.0207268162752963e-05,
      "loss": 0.0023,
      "step": 47980
    },
    {
      "epoch": 1.4692465480819275,
      "grad_norm": 0.044430922716856,
      "learning_rate": 1.0205227117329497e-05,
      "loss": 0.0018,
      "step": 47990
    },
    {
      "epoch": 1.4695527048954475,
      "grad_norm": 0.05089133232831955,
      "learning_rate": 1.020318607190603e-05,
      "loss": 0.0018,
      "step": 48000
    },
    {
      "epoch": 1.4698588617089674,
      "grad_norm": 0.026431545615196228,
      "learning_rate": 1.0201145026482566e-05,
      "loss": 0.0347,
      "step": 48010
    },
    {
      "epoch": 1.4701650185224873,
      "grad_norm": 0.15622548758983612,
      "learning_rate": 1.01991039810591e-05,
      "loss": 0.0355,
      "step": 48020
    },
    {
      "epoch": 1.4704711753360071,
      "grad_norm": 0.03899069130420685,
      "learning_rate": 1.0197062935635633e-05,
      "loss": 0.0682,
      "step": 48030
    },
    {
      "epoch": 1.470777332149527,
      "grad_norm": 0.08572514355182648,
      "learning_rate": 1.0195021890212167e-05,
      "loss": 0.003,
      "step": 48040
    },
    {
      "epoch": 1.4710834889630469,
      "grad_norm": 0.05693907290697098,
      "learning_rate": 1.0192980844788702e-05,
      "loss": 0.0612,
      "step": 48050
    },
    {
      "epoch": 1.4713896457765667,
      "grad_norm": 0.11153411865234375,
      "learning_rate": 1.0190939799365236e-05,
      "loss": 0.0032,
      "step": 48060
    },
    {
      "epoch": 1.4716958025900866,
      "grad_norm": 0.061032913625240326,
      "learning_rate": 1.018889875394177e-05,
      "loss": 0.0024,
      "step": 48070
    },
    {
      "epoch": 1.4720019594036065,
      "grad_norm": 0.05450966954231262,
      "learning_rate": 1.0186857708518303e-05,
      "loss": 0.0118,
      "step": 48080
    },
    {
      "epoch": 1.4723081162171265,
      "grad_norm": 0.04618951678276062,
      "learning_rate": 1.0184816663094838e-05,
      "loss": 0.002,
      "step": 48090
    },
    {
      "epoch": 1.4726142730306462,
      "grad_norm": 0.04444142431020737,
      "learning_rate": 1.0182775617671372e-05,
      "loss": 0.002,
      "step": 48100
    },
    {
      "epoch": 1.4729204298441663,
      "grad_norm": 0.0294781606644392,
      "learning_rate": 1.0180734572247906e-05,
      "loss": 0.001,
      "step": 48110
    },
    {
      "epoch": 1.4732265866576861,
      "grad_norm": 0.04181944206357002,
      "learning_rate": 1.0178693526824441e-05,
      "loss": 0.0018,
      "step": 48120
    },
    {
      "epoch": 1.473532743471206,
      "grad_norm": 0.018614374101161957,
      "learning_rate": 1.0176652481400975e-05,
      "loss": 0.0014,
      "step": 48130
    },
    {
      "epoch": 1.4738389002847259,
      "grad_norm": 0.023806508630514145,
      "learning_rate": 1.0174611435977508e-05,
      "loss": 0.0116,
      "step": 48140
    },
    {
      "epoch": 1.4741450570982457,
      "grad_norm": 0.018594546243548393,
      "learning_rate": 1.0172570390554042e-05,
      "loss": 0.0014,
      "step": 48150
    },
    {
      "epoch": 1.4744512139117656,
      "grad_norm": 0.06307545304298401,
      "learning_rate": 1.0170529345130577e-05,
      "loss": 0.0014,
      "step": 48160
    },
    {
      "epoch": 1.4747573707252855,
      "grad_norm": 0.0051637375727295876,
      "learning_rate": 1.0168488299707111e-05,
      "loss": 0.034,
      "step": 48170
    },
    {
      "epoch": 1.4750635275388053,
      "grad_norm": 0.010705316439270973,
      "learning_rate": 1.0166447254283645e-05,
      "loss": 0.1183,
      "step": 48180
    },
    {
      "epoch": 1.4753696843523252,
      "grad_norm": 0.08481068164110184,
      "learning_rate": 1.0164406208860178e-05,
      "loss": 0.0018,
      "step": 48190
    },
    {
      "epoch": 1.4756758411658453,
      "grad_norm": 0.03231558948755264,
      "learning_rate": 1.0162365163436714e-05,
      "loss": 0.0015,
      "step": 48200
    },
    {
      "epoch": 1.475981997979365,
      "grad_norm": 0.012265153229236603,
      "learning_rate": 1.0160324118013247e-05,
      "loss": 0.0262,
      "step": 48210
    },
    {
      "epoch": 1.476288154792885,
      "grad_norm": 0.03523237630724907,
      "learning_rate": 1.015828307258978e-05,
      "loss": 0.0084,
      "step": 48220
    },
    {
      "epoch": 1.4765943116064049,
      "grad_norm": 0.017976652830839157,
      "learning_rate": 1.0156242027166316e-05,
      "loss": 0.0249,
      "step": 48230
    },
    {
      "epoch": 1.4769004684199247,
      "grad_norm": 0.01552362460643053,
      "learning_rate": 1.015420098174285e-05,
      "loss": 0.0332,
      "step": 48240
    },
    {
      "epoch": 1.4772066252334446,
      "grad_norm": 0.027081262320280075,
      "learning_rate": 1.0152159936319383e-05,
      "loss": 0.0348,
      "step": 48250
    },
    {
      "epoch": 1.4775127820469645,
      "grad_norm": 0.03109888546168804,
      "learning_rate": 1.0150118890895917e-05,
      "loss": 0.0014,
      "step": 48260
    },
    {
      "epoch": 1.4778189388604843,
      "grad_norm": 0.024363908916711807,
      "learning_rate": 1.0148077845472452e-05,
      "loss": 0.0347,
      "step": 48270
    },
    {
      "epoch": 1.4781250956740042,
      "grad_norm": 0.04013911634683609,
      "learning_rate": 1.0146036800048986e-05,
      "loss": 0.0015,
      "step": 48280
    },
    {
      "epoch": 1.478431252487524,
      "grad_norm": 0.03956757113337517,
      "learning_rate": 1.014399575462552e-05,
      "loss": 0.0018,
      "step": 48290
    },
    {
      "epoch": 1.478737409301044,
      "grad_norm": 0.04792477563023567,
      "learning_rate": 1.0141954709202053e-05,
      "loss": 0.0016,
      "step": 48300
    },
    {
      "epoch": 1.479043566114564,
      "grad_norm": 0.028373416513204575,
      "learning_rate": 1.0139913663778589e-05,
      "loss": 0.0017,
      "step": 48310
    },
    {
      "epoch": 1.4793497229280836,
      "grad_norm": 0.06475786864757538,
      "learning_rate": 1.0137872618355122e-05,
      "loss": 0.0017,
      "step": 48320
    },
    {
      "epoch": 1.4796558797416037,
      "grad_norm": 0.015485896728932858,
      "learning_rate": 1.0135831572931656e-05,
      "loss": 0.003,
      "step": 48330
    },
    {
      "epoch": 1.4799620365551236,
      "grad_norm": 0.05117236077785492,
      "learning_rate": 1.0133790527508191e-05,
      "loss": 0.0016,
      "step": 48340
    },
    {
      "epoch": 1.4802681933686435,
      "grad_norm": 0.014107834547758102,
      "learning_rate": 1.0131749482084725e-05,
      "loss": 0.0059,
      "step": 48350
    },
    {
      "epoch": 1.4805743501821633,
      "grad_norm": 0.03733431547880173,
      "learning_rate": 1.0129708436661259e-05,
      "loss": 0.034,
      "step": 48360
    },
    {
      "epoch": 1.4808805069956832,
      "grad_norm": 1.8505078554153442,
      "learning_rate": 1.0127667391237792e-05,
      "loss": 0.0382,
      "step": 48370
    },
    {
      "epoch": 1.481186663809203,
      "grad_norm": 0.03008628822863102,
      "learning_rate": 1.0125626345814328e-05,
      "loss": 0.029,
      "step": 48380
    },
    {
      "epoch": 1.481492820622723,
      "grad_norm": 0.11415370553731918,
      "learning_rate": 1.0123585300390861e-05,
      "loss": 0.0014,
      "step": 48390
    },
    {
      "epoch": 1.4817989774362428,
      "grad_norm": 0.06029214709997177,
      "learning_rate": 1.0121544254967395e-05,
      "loss": 0.0073,
      "step": 48400
    },
    {
      "epoch": 1.4821051342497626,
      "grad_norm": 0.04050879552960396,
      "learning_rate": 1.0119503209543929e-05,
      "loss": 0.0301,
      "step": 48410
    },
    {
      "epoch": 1.4824112910632827,
      "grad_norm": 0.02467309683561325,
      "learning_rate": 1.0117462164120464e-05,
      "loss": 0.0129,
      "step": 48420
    },
    {
      "epoch": 1.4827174478768024,
      "grad_norm": 0.0655410885810852,
      "learning_rate": 1.0115421118696997e-05,
      "loss": 0.0274,
      "step": 48430
    },
    {
      "epoch": 1.4830236046903225,
      "grad_norm": 0.01133442111313343,
      "learning_rate": 1.0113380073273531e-05,
      "loss": 0.0015,
      "step": 48440
    },
    {
      "epoch": 1.4833297615038423,
      "grad_norm": 0.019522765651345253,
      "learning_rate": 1.0111339027850066e-05,
      "loss": 0.0337,
      "step": 48450
    },
    {
      "epoch": 1.4836359183173622,
      "grad_norm": 0.069220170378685,
      "learning_rate": 1.01092979824266e-05,
      "loss": 0.036,
      "step": 48460
    },
    {
      "epoch": 1.483942075130882,
      "grad_norm": 0.050671666860580444,
      "learning_rate": 1.0107256937003134e-05,
      "loss": 0.0327,
      "step": 48470
    },
    {
      "epoch": 1.484248231944402,
      "grad_norm": 0.01665596291422844,
      "learning_rate": 1.0105215891579667e-05,
      "loss": 0.0097,
      "step": 48480
    },
    {
      "epoch": 1.4845543887579218,
      "grad_norm": 0.053388386964797974,
      "learning_rate": 1.0103174846156203e-05,
      "loss": 0.0231,
      "step": 48490
    },
    {
      "epoch": 1.4848605455714416,
      "grad_norm": 0.045003216713666916,
      "learning_rate": 1.0101133800732736e-05,
      "loss": 0.0643,
      "step": 48500
    },
    {
      "epoch": 1.4851667023849615,
      "grad_norm": 0.0893130823969841,
      "learning_rate": 1.009909275530927e-05,
      "loss": 0.0311,
      "step": 48510
    },
    {
      "epoch": 1.4854728591984814,
      "grad_norm": 0.04070371761918068,
      "learning_rate": 1.0097051709885804e-05,
      "loss": 0.0568,
      "step": 48520
    },
    {
      "epoch": 1.4857790160120015,
      "grad_norm": 0.02841816656291485,
      "learning_rate": 1.0095010664462339e-05,
      "loss": 0.0019,
      "step": 48530
    },
    {
      "epoch": 1.486085172825521,
      "grad_norm": 0.06934265792369843,
      "learning_rate": 1.0092969619038873e-05,
      "loss": 0.0024,
      "step": 48540
    },
    {
      "epoch": 1.4863913296390412,
      "grad_norm": 0.015169021673500538,
      "learning_rate": 1.0090928573615406e-05,
      "loss": 0.0022,
      "step": 48550
    },
    {
      "epoch": 1.486697486452561,
      "grad_norm": 0.22170595824718475,
      "learning_rate": 1.0088887528191942e-05,
      "loss": 0.03,
      "step": 48560
    },
    {
      "epoch": 1.487003643266081,
      "grad_norm": 0.01982925459742546,
      "learning_rate": 1.0086846482768475e-05,
      "loss": 0.0307,
      "step": 48570
    },
    {
      "epoch": 1.4873098000796008,
      "grad_norm": 0.04713742434978485,
      "learning_rate": 1.0084805437345009e-05,
      "loss": 0.0325,
      "step": 48580
    },
    {
      "epoch": 1.4876159568931207,
      "grad_norm": 0.04647527262568474,
      "learning_rate": 1.0082764391921543e-05,
      "loss": 0.0018,
      "step": 48590
    },
    {
      "epoch": 1.4879221137066405,
      "grad_norm": 0.007996303029358387,
      "learning_rate": 1.0080723346498078e-05,
      "loss": 0.0017,
      "step": 48600
    },
    {
      "epoch": 1.4882282705201604,
      "grad_norm": 0.06114659830927849,
      "learning_rate": 1.0078682301074612e-05,
      "loss": 0.0352,
      "step": 48610
    },
    {
      "epoch": 1.4885344273336802,
      "grad_norm": 0.057908087968826294,
      "learning_rate": 1.0076641255651145e-05,
      "loss": 0.002,
      "step": 48620
    },
    {
      "epoch": 1.4888405841472,
      "grad_norm": 0.02611260488629341,
      "learning_rate": 1.0074600210227679e-05,
      "loss": 0.0016,
      "step": 48630
    },
    {
      "epoch": 1.4891467409607202,
      "grad_norm": 0.06101132184267044,
      "learning_rate": 1.0072559164804214e-05,
      "loss": 0.0015,
      "step": 48640
    },
    {
      "epoch": 1.4894528977742398,
      "grad_norm": 0.027574488893151283,
      "learning_rate": 1.0070518119380748e-05,
      "loss": 0.0037,
      "step": 48650
    },
    {
      "epoch": 1.48975905458776,
      "grad_norm": 0.011968406848609447,
      "learning_rate": 1.0068477073957281e-05,
      "loss": 0.0017,
      "step": 48660
    },
    {
      "epoch": 1.4900652114012798,
      "grad_norm": 0.01618891768157482,
      "learning_rate": 1.0066436028533815e-05,
      "loss": 0.0014,
      "step": 48670
    },
    {
      "epoch": 1.4903713682147997,
      "grad_norm": 0.017203524708747864,
      "learning_rate": 1.006439498311035e-05,
      "loss": 0.0366,
      "step": 48680
    },
    {
      "epoch": 1.4906775250283195,
      "grad_norm": 0.050234194844961166,
      "learning_rate": 1.0062353937686884e-05,
      "loss": 0.0013,
      "step": 48690
    },
    {
      "epoch": 1.4909836818418394,
      "grad_norm": 0.03875165805220604,
      "learning_rate": 1.0060312892263418e-05,
      "loss": 0.0346,
      "step": 48700
    },
    {
      "epoch": 1.4912898386553592,
      "grad_norm": 0.029323887079954147,
      "learning_rate": 1.0058271846839953e-05,
      "loss": 0.0013,
      "step": 48710
    },
    {
      "epoch": 1.491595995468879,
      "grad_norm": 0.06541559100151062,
      "learning_rate": 1.0056230801416487e-05,
      "loss": 0.0015,
      "step": 48720
    },
    {
      "epoch": 1.491902152282399,
      "grad_norm": 0.05294332280755043,
      "learning_rate": 1.005418975599302e-05,
      "loss": 0.018,
      "step": 48730
    },
    {
      "epoch": 1.4922083090959188,
      "grad_norm": 0.06683497875928879,
      "learning_rate": 1.0052148710569554e-05,
      "loss": 0.0397,
      "step": 48740
    },
    {
      "epoch": 1.492514465909439,
      "grad_norm": 0.049538902938365936,
      "learning_rate": 1.005010766514609e-05,
      "loss": 0.0023,
      "step": 48750
    },
    {
      "epoch": 1.4928206227229586,
      "grad_norm": 0.023062516003847122,
      "learning_rate": 1.0048066619722623e-05,
      "loss": 0.0013,
      "step": 48760
    },
    {
      "epoch": 1.4931267795364787,
      "grad_norm": 0.03392426669597626,
      "learning_rate": 1.0046025574299157e-05,
      "loss": 0.0011,
      "step": 48770
    },
    {
      "epoch": 1.4934329363499985,
      "grad_norm": 0.028034117072820663,
      "learning_rate": 1.004398452887569e-05,
      "loss": 0.031,
      "step": 48780
    },
    {
      "epoch": 1.4937390931635184,
      "grad_norm": 0.0470813550055027,
      "learning_rate": 1.0041943483452226e-05,
      "loss": 0.0289,
      "step": 48790
    },
    {
      "epoch": 1.4940452499770382,
      "grad_norm": 0.03145782649517059,
      "learning_rate": 1.003990243802876e-05,
      "loss": 0.0285,
      "step": 48800
    },
    {
      "epoch": 1.4943514067905581,
      "grad_norm": 0.059146542102098465,
      "learning_rate": 1.0037861392605293e-05,
      "loss": 0.0022,
      "step": 48810
    },
    {
      "epoch": 1.494657563604078,
      "grad_norm": 0.01000863965600729,
      "learning_rate": 1.0035820347181828e-05,
      "loss": 0.0018,
      "step": 48820
    },
    {
      "epoch": 1.4949637204175978,
      "grad_norm": 0.020548494532704353,
      "learning_rate": 1.0033779301758362e-05,
      "loss": 0.0309,
      "step": 48830
    },
    {
      "epoch": 1.4952698772311177,
      "grad_norm": 0.013321340084075928,
      "learning_rate": 1.0031738256334896e-05,
      "loss": 0.0013,
      "step": 48840
    },
    {
      "epoch": 1.4955760340446376,
      "grad_norm": 0.014251038432121277,
      "learning_rate": 1.002969721091143e-05,
      "loss": 0.0012,
      "step": 48850
    },
    {
      "epoch": 1.4958821908581577,
      "grad_norm": 0.05093274638056755,
      "learning_rate": 1.0027656165487965e-05,
      "loss": 0.034,
      "step": 48860
    },
    {
      "epoch": 1.4961883476716773,
      "grad_norm": 0.08797476440668106,
      "learning_rate": 1.0025615120064498e-05,
      "loss": 0.0024,
      "step": 48870
    },
    {
      "epoch": 1.4964945044851974,
      "grad_norm": 0.015393264591693878,
      "learning_rate": 1.0023574074641032e-05,
      "loss": 0.0009,
      "step": 48880
    },
    {
      "epoch": 1.4968006612987172,
      "grad_norm": 0.03990716114640236,
      "learning_rate": 1.0021533029217565e-05,
      "loss": 0.0194,
      "step": 48890
    },
    {
      "epoch": 1.4971068181122371,
      "grad_norm": 0.03282110393047333,
      "learning_rate": 1.00194919837941e-05,
      "loss": 0.0303,
      "step": 48900
    },
    {
      "epoch": 1.497412974925757,
      "grad_norm": 0.0857698991894722,
      "learning_rate": 1.0017450938370634e-05,
      "loss": 0.0296,
      "step": 48910
    },
    {
      "epoch": 1.4977191317392768,
      "grad_norm": 0.08925172686576843,
      "learning_rate": 1.0015409892947168e-05,
      "loss": 0.0385,
      "step": 48920
    },
    {
      "epoch": 1.4980252885527967,
      "grad_norm": 0.0668385922908783,
      "learning_rate": 1.0013368847523703e-05,
      "loss": 0.0305,
      "step": 48930
    },
    {
      "epoch": 1.4983314453663166,
      "grad_norm": 0.0705379992723465,
      "learning_rate": 1.0011327802100237e-05,
      "loss": 0.0023,
      "step": 48940
    },
    {
      "epoch": 1.4986376021798364,
      "grad_norm": 0.04614868760108948,
      "learning_rate": 1.000928675667677e-05,
      "loss": 0.0025,
      "step": 48950
    },
    {
      "epoch": 1.4989437589933563,
      "grad_norm": 0.035398244857788086,
      "learning_rate": 1.0007245711253304e-05,
      "loss": 0.0018,
      "step": 48960
    },
    {
      "epoch": 1.4992499158068764,
      "grad_norm": 0.046608101576566696,
      "learning_rate": 1.000520466582984e-05,
      "loss": 0.0018,
      "step": 48970
    },
    {
      "epoch": 1.499556072620396,
      "grad_norm": 0.02209502086043358,
      "learning_rate": 1.0003163620406373e-05,
      "loss": 0.0018,
      "step": 48980
    },
    {
      "epoch": 1.4998622294339161,
      "grad_norm": 0.04499956965446472,
      "learning_rate": 1.0001122574982907e-05,
      "loss": 0.0016,
      "step": 48990
    },
    {
      "epoch": 1.500168386247436,
      "grad_norm": 0.02599499374628067,
      "learning_rate": 9.99908152955944e-06,
      "loss": 0.0017,
      "step": 49000
    },
    {
      "epoch": 1.5004745430609558,
      "grad_norm": 0.046041443943977356,
      "learning_rate": 9.997040484135974e-06,
      "loss": 0.0012,
      "step": 49010
    },
    {
      "epoch": 1.5007806998744757,
      "grad_norm": 0.011719302274286747,
      "learning_rate": 9.99499943871251e-06,
      "loss": 0.0011,
      "step": 49020
    },
    {
      "epoch": 1.5010868566879956,
      "grad_norm": 0.030751418322324753,
      "learning_rate": 9.992958393289043e-06,
      "loss": 0.0097,
      "step": 49030
    },
    {
      "epoch": 1.5013930135015154,
      "grad_norm": 0.03342325612902641,
      "learning_rate": 9.990917347865577e-06,
      "loss": 0.0251,
      "step": 49040
    },
    {
      "epoch": 1.5016991703150353,
      "grad_norm": 0.012332389131188393,
      "learning_rate": 9.988876302442112e-06,
      "loss": 0.0012,
      "step": 49050
    },
    {
      "epoch": 1.5020053271285554,
      "grad_norm": 0.011602918617427349,
      "learning_rate": 9.986835257018646e-06,
      "loss": 0.0015,
      "step": 49060
    },
    {
      "epoch": 1.502311483942075,
      "grad_norm": 2.456409454345703,
      "learning_rate": 9.98479421159518e-06,
      "loss": 0.0347,
      "step": 49070
    },
    {
      "epoch": 1.5026176407555951,
      "grad_norm": 0.008211102336645126,
      "learning_rate": 9.982753166171713e-06,
      "loss": 0.001,
      "step": 49080
    },
    {
      "epoch": 1.5029237975691148,
      "grad_norm": 0.02426612563431263,
      "learning_rate": 9.980712120748248e-06,
      "loss": 0.0008,
      "step": 49090
    },
    {
      "epoch": 1.5032299543826348,
      "grad_norm": 0.02000785619020462,
      "learning_rate": 9.978671075324782e-06,
      "loss": 0.0255,
      "step": 49100
    },
    {
      "epoch": 1.5035361111961547,
      "grad_norm": 0.03966982290148735,
      "learning_rate": 9.976630029901316e-06,
      "loss": 0.0013,
      "step": 49110
    },
    {
      "epoch": 1.5038422680096746,
      "grad_norm": 0.009671688079833984,
      "learning_rate": 9.97458898447785e-06,
      "loss": 0.0014,
      "step": 49120
    },
    {
      "epoch": 1.5041484248231944,
      "grad_norm": 0.034998200833797455,
      "learning_rate": 9.972547939054385e-06,
      "loss": 0.0812,
      "step": 49130
    },
    {
      "epoch": 1.5044545816367143,
      "grad_norm": 0.019592680037021637,
      "learning_rate": 9.970506893630918e-06,
      "loss": 0.0011,
      "step": 49140
    },
    {
      "epoch": 1.5047607384502342,
      "grad_norm": 0.007686861790716648,
      "learning_rate": 9.968465848207452e-06,
      "loss": 0.0009,
      "step": 49150
    },
    {
      "epoch": 1.505066895263754,
      "grad_norm": 0.022449355572462082,
      "learning_rate": 9.966424802783987e-06,
      "loss": 0.0009,
      "step": 49160
    },
    {
      "epoch": 1.5053730520772741,
      "grad_norm": 0.0193906519562006,
      "learning_rate": 9.964383757360521e-06,
      "loss": 0.0017,
      "step": 49170
    },
    {
      "epoch": 1.5056792088907938,
      "grad_norm": 0.019964348524808884,
      "learning_rate": 9.962342711937055e-06,
      "loss": 0.0217,
      "step": 49180
    },
    {
      "epoch": 1.5059853657043138,
      "grad_norm": 0.015381080098450184,
      "learning_rate": 9.960301666513588e-06,
      "loss": 0.0008,
      "step": 49190
    },
    {
      "epoch": 1.5062915225178335,
      "grad_norm": 0.00688615208491683,
      "learning_rate": 9.958260621090124e-06,
      "loss": 0.0012,
      "step": 49200
    },
    {
      "epoch": 1.5065976793313536,
      "grad_norm": 0.03159044682979584,
      "learning_rate": 9.956219575666657e-06,
      "loss": 0.0008,
      "step": 49210
    },
    {
      "epoch": 1.5069038361448734,
      "grad_norm": 0.02320064790546894,
      "learning_rate": 9.954178530243191e-06,
      "loss": 0.0033,
      "step": 49220
    },
    {
      "epoch": 1.5072099929583933,
      "grad_norm": 0.010105138644576073,
      "learning_rate": 9.952137484819725e-06,
      "loss": 0.032,
      "step": 49230
    },
    {
      "epoch": 1.5075161497719132,
      "grad_norm": 0.0060891807079315186,
      "learning_rate": 9.95009643939626e-06,
      "loss": 0.0408,
      "step": 49240
    },
    {
      "epoch": 1.507822306585433,
      "grad_norm": 0.03327510133385658,
      "learning_rate": 9.948055393972794e-06,
      "loss": 0.0336,
      "step": 49250
    },
    {
      "epoch": 1.508128463398953,
      "grad_norm": 0.03346797823905945,
      "learning_rate": 9.946014348549327e-06,
      "loss": 0.001,
      "step": 49260
    },
    {
      "epoch": 1.5084346202124728,
      "grad_norm": 0.021982992067933083,
      "learning_rate": 9.943973303125863e-06,
      "loss": 0.0009,
      "step": 49270
    },
    {
      "epoch": 1.5087407770259929,
      "grad_norm": 0.01874656416475773,
      "learning_rate": 9.941932257702396e-06,
      "loss": 0.0008,
      "step": 49280
    },
    {
      "epoch": 1.5090469338395125,
      "grad_norm": 0.04452645406126976,
      "learning_rate": 9.93989121227893e-06,
      "loss": 0.0421,
      "step": 49290
    },
    {
      "epoch": 1.5093530906530326,
      "grad_norm": 0.010122612118721008,
      "learning_rate": 9.937850166855463e-06,
      "loss": 0.0009,
      "step": 49300
    },
    {
      "epoch": 1.5096592474665522,
      "grad_norm": 0.020310787484049797,
      "learning_rate": 9.935809121431999e-06,
      "loss": 0.0011,
      "step": 49310
    },
    {
      "epoch": 1.5099654042800723,
      "grad_norm": 0.034166060388088226,
      "learning_rate": 9.933768076008532e-06,
      "loss": 0.0057,
      "step": 49320
    },
    {
      "epoch": 1.5102715610935922,
      "grad_norm": 0.007994159124791622,
      "learning_rate": 9.931727030585066e-06,
      "loss": 0.0007,
      "step": 49330
    },
    {
      "epoch": 1.510577717907112,
      "grad_norm": 0.010392976924777031,
      "learning_rate": 9.9296859851616e-06,
      "loss": 0.0347,
      "step": 49340
    },
    {
      "epoch": 1.510883874720632,
      "grad_norm": 0.015579355880618095,
      "learning_rate": 9.927644939738135e-06,
      "loss": 0.001,
      "step": 49350
    },
    {
      "epoch": 1.5111900315341518,
      "grad_norm": 0.03195098415017128,
      "learning_rate": 9.925603894314669e-06,
      "loss": 0.0014,
      "step": 49360
    },
    {
      "epoch": 1.5114961883476716,
      "grad_norm": 0.023941723629832268,
      "learning_rate": 9.923562848891202e-06,
      "loss": 0.0381,
      "step": 49370
    },
    {
      "epoch": 1.5118023451611915,
      "grad_norm": 4.783707618713379,
      "learning_rate": 9.921521803467738e-06,
      "loss": 0.0487,
      "step": 49380
    },
    {
      "epoch": 1.5121085019747116,
      "grad_norm": 0.006832203362137079,
      "learning_rate": 9.919480758044271e-06,
      "loss": 0.0005,
      "step": 49390
    },
    {
      "epoch": 1.5124146587882312,
      "grad_norm": 0.011136897839605808,
      "learning_rate": 9.917439712620805e-06,
      "loss": 0.0007,
      "step": 49400
    },
    {
      "epoch": 1.5127208156017513,
      "grad_norm": 0.039318110793828964,
      "learning_rate": 9.915398667197339e-06,
      "loss": 0.0008,
      "step": 49410
    },
    {
      "epoch": 1.513026972415271,
      "grad_norm": 0.038677312433719635,
      "learning_rate": 9.913357621773874e-06,
      "loss": 0.0009,
      "step": 49420
    },
    {
      "epoch": 1.513333129228791,
      "grad_norm": 0.02051890641450882,
      "learning_rate": 9.911316576350408e-06,
      "loss": 0.0047,
      "step": 49430
    },
    {
      "epoch": 1.513639286042311,
      "grad_norm": 0.013855361379683018,
      "learning_rate": 9.909275530926941e-06,
      "loss": 0.0006,
      "step": 49440
    },
    {
      "epoch": 1.5139454428558308,
      "grad_norm": 0.012535707093775272,
      "learning_rate": 9.907234485503475e-06,
      "loss": 0.0005,
      "step": 49450
    },
    {
      "epoch": 1.5142515996693506,
      "grad_norm": 0.016782812774181366,
      "learning_rate": 9.90519344008001e-06,
      "loss": 0.0007,
      "step": 49460
    },
    {
      "epoch": 1.5145577564828705,
      "grad_norm": 0.019410930573940277,
      "learning_rate": 9.903152394656544e-06,
      "loss": 0.0006,
      "step": 49470
    },
    {
      "epoch": 1.5148639132963904,
      "grad_norm": 0.010561417788267136,
      "learning_rate": 9.901111349233078e-06,
      "loss": 0.0331,
      "step": 49480
    },
    {
      "epoch": 1.5151700701099102,
      "grad_norm": 0.0063641308806836605,
      "learning_rate": 9.899070303809613e-06,
      "loss": 0.0006,
      "step": 49490
    },
    {
      "epoch": 1.5154762269234303,
      "grad_norm": 0.014474849216639996,
      "learning_rate": 9.897029258386147e-06,
      "loss": 0.0006,
      "step": 49500
    },
    {
      "epoch": 1.51578238373695,
      "grad_norm": 0.02274194359779358,
      "learning_rate": 9.89498821296268e-06,
      "loss": 0.0327,
      "step": 49510
    },
    {
      "epoch": 1.51608854055047,
      "grad_norm": 1.9660630226135254,
      "learning_rate": 9.892947167539214e-06,
      "loss": 0.0407,
      "step": 49520
    },
    {
      "epoch": 1.5163946973639897,
      "grad_norm": 1.9980835914611816,
      "learning_rate": 9.89090612211575e-06,
      "loss": 0.0331,
      "step": 49530
    },
    {
      "epoch": 1.5167008541775098,
      "grad_norm": 0.032037295401096344,
      "learning_rate": 9.888865076692283e-06,
      "loss": 0.0012,
      "step": 49540
    },
    {
      "epoch": 1.5170070109910296,
      "grad_norm": 0.01806996949017048,
      "learning_rate": 9.886824031268816e-06,
      "loss": 0.0026,
      "step": 49550
    },
    {
      "epoch": 1.5173131678045495,
      "grad_norm": 0.018669117242097855,
      "learning_rate": 9.88478298584535e-06,
      "loss": 0.001,
      "step": 49560
    },
    {
      "epoch": 1.5176193246180694,
      "grad_norm": 0.02180344983935356,
      "learning_rate": 9.882741940421885e-06,
      "loss": 0.001,
      "step": 49570
    },
    {
      "epoch": 1.5179254814315892,
      "grad_norm": 0.033594876527786255,
      "learning_rate": 9.880700894998419e-06,
      "loss": 0.0009,
      "step": 49580
    },
    {
      "epoch": 1.518231638245109,
      "grad_norm": 0.02991003356873989,
      "learning_rate": 9.878659849574953e-06,
      "loss": 0.0008,
      "step": 49590
    },
    {
      "epoch": 1.518537795058629,
      "grad_norm": 0.020607180893421173,
      "learning_rate": 9.876618804151488e-06,
      "loss": 0.0792,
      "step": 49600
    },
    {
      "epoch": 1.518843951872149,
      "grad_norm": 0.025364777073264122,
      "learning_rate": 9.874577758728022e-06,
      "loss": 0.0011,
      "step": 49610
    },
    {
      "epoch": 1.5191501086856687,
      "grad_norm": 0.07429365068674088,
      "learning_rate": 9.872536713304555e-06,
      "loss": 0.0121,
      "step": 49620
    },
    {
      "epoch": 1.5194562654991888,
      "grad_norm": 0.041435226798057556,
      "learning_rate": 9.870495667881089e-06,
      "loss": 0.0009,
      "step": 49630
    },
    {
      "epoch": 1.5197624223127084,
      "grad_norm": 0.022035757079720497,
      "learning_rate": 9.868454622457624e-06,
      "loss": 0.0344,
      "step": 49640
    },
    {
      "epoch": 1.5200685791262285,
      "grad_norm": 3.2728538513183594,
      "learning_rate": 9.866413577034158e-06,
      "loss": 0.0928,
      "step": 49650
    },
    {
      "epoch": 1.5203747359397484,
      "grad_norm": 0.010331835597753525,
      "learning_rate": 9.864372531610692e-06,
      "loss": 0.0295,
      "step": 49660
    },
    {
      "epoch": 1.5206808927532682,
      "grad_norm": 0.04779605567455292,
      "learning_rate": 9.862331486187225e-06,
      "loss": 0.0014,
      "step": 49670
    },
    {
      "epoch": 1.520987049566788,
      "grad_norm": 0.042774781584739685,
      "learning_rate": 9.86029044076376e-06,
      "loss": 0.0342,
      "step": 49680
    },
    {
      "epoch": 1.521293206380308,
      "grad_norm": 0.09411364048719406,
      "learning_rate": 9.858249395340294e-06,
      "loss": 0.0344,
      "step": 49690
    },
    {
      "epoch": 1.5215993631938278,
      "grad_norm": 0.06056402623653412,
      "learning_rate": 9.856208349916828e-06,
      "loss": 0.1143,
      "step": 49700
    },
    {
      "epoch": 1.5219055200073477,
      "grad_norm": 0.1426839977502823,
      "learning_rate": 9.854167304493363e-06,
      "loss": 0.0037,
      "step": 49710
    },
    {
      "epoch": 1.5222116768208678,
      "grad_norm": 0.05517834052443504,
      "learning_rate": 9.852126259069897e-06,
      "loss": 0.0048,
      "step": 49720
    },
    {
      "epoch": 1.5225178336343874,
      "grad_norm": 0.07229164987802505,
      "learning_rate": 9.85008521364643e-06,
      "loss": 0.0022,
      "step": 49730
    },
    {
      "epoch": 1.5228239904479075,
      "grad_norm": 0.026746921241283417,
      "learning_rate": 9.848044168222964e-06,
      "loss": 0.0054,
      "step": 49740
    },
    {
      "epoch": 1.5231301472614271,
      "grad_norm": 0.6807765364646912,
      "learning_rate": 9.8460031227995e-06,
      "loss": 0.0034,
      "step": 49750
    },
    {
      "epoch": 1.5234363040749472,
      "grad_norm": 0.0004421304911375046,
      "learning_rate": 9.843962077376033e-06,
      "loss": 0.0022,
      "step": 49760
    },
    {
      "epoch": 1.523742460888467,
      "grad_norm": 0.03724386915564537,
      "learning_rate": 9.841921031952567e-06,
      "loss": 0.0021,
      "step": 49770
    },
    {
      "epoch": 1.524048617701987,
      "grad_norm": 0.025539850816130638,
      "learning_rate": 9.8398799865291e-06,
      "loss": 0.0014,
      "step": 49780
    },
    {
      "epoch": 1.5243547745155068,
      "grad_norm": 0.03516601026058197,
      "learning_rate": 9.837838941105636e-06,
      "loss": 0.001,
      "step": 49790
    },
    {
      "epoch": 1.5246609313290267,
      "grad_norm": 0.04435557499527931,
      "learning_rate": 9.83579789568217e-06,
      "loss": 0.0011,
      "step": 49800
    },
    {
      "epoch": 1.5249670881425468,
      "grad_norm": 0.008254065178334713,
      "learning_rate": 9.833756850258703e-06,
      "loss": 0.0009,
      "step": 49810
    },
    {
      "epoch": 1.5252732449560664,
      "grad_norm": 0.04461568966507912,
      "learning_rate": 9.831715804835238e-06,
      "loss": 0.0014,
      "step": 49820
    },
    {
      "epoch": 1.5255794017695865,
      "grad_norm": 0.008465928956866264,
      "learning_rate": 9.829674759411772e-06,
      "loss": 0.0403,
      "step": 49830
    },
    {
      "epoch": 1.5258855585831061,
      "grad_norm": 0.13280020654201508,
      "learning_rate": 9.827633713988306e-06,
      "loss": 0.0016,
      "step": 49840
    },
    {
      "epoch": 1.5261917153966262,
      "grad_norm": 1.770890712738037,
      "learning_rate": 9.82559266856484e-06,
      "loss": 0.1038,
      "step": 49850
    },
    {
      "epoch": 1.5264978722101459,
      "grad_norm": 0.05443556606769562,
      "learning_rate": 9.823551623141375e-06,
      "loss": 0.0395,
      "step": 49860
    },
    {
      "epoch": 1.526804029023666,
      "grad_norm": 0.08615303784608841,
      "learning_rate": 9.821510577717908e-06,
      "loss": 0.0016,
      "step": 49870
    },
    {
      "epoch": 1.5271101858371858,
      "grad_norm": 0.0629424974322319,
      "learning_rate": 9.819469532294442e-06,
      "loss": 0.0018,
      "step": 49880
    },
    {
      "epoch": 1.5274163426507057,
      "grad_norm": 0.03967657685279846,
      "learning_rate": 9.817428486870976e-06,
      "loss": 0.0625,
      "step": 49890
    },
    {
      "epoch": 1.5277224994642256,
      "grad_norm": 0.031023787334561348,
      "learning_rate": 9.815387441447511e-06,
      "loss": 0.0018,
      "step": 49900
    },
    {
      "epoch": 1.5280286562777454,
      "grad_norm": 0.09770459681749344,
      "learning_rate": 9.813346396024045e-06,
      "loss": 0.0021,
      "step": 49910
    },
    {
      "epoch": 1.5283348130912655,
      "grad_norm": 0.05046873167157173,
      "learning_rate": 9.811305350600578e-06,
      "loss": 0.0285,
      "step": 49920
    },
    {
      "epoch": 1.5286409699047852,
      "grad_norm": 0.03248485550284386,
      "learning_rate": 9.809264305177114e-06,
      "loss": 0.0028,
      "step": 49930
    },
    {
      "epoch": 1.5289471267183052,
      "grad_norm": 0.030943401157855988,
      "learning_rate": 9.807223259753647e-06,
      "loss": 0.0658,
      "step": 49940
    },
    {
      "epoch": 1.5292532835318249,
      "grad_norm": 0.10259358584880829,
      "learning_rate": 9.805182214330181e-06,
      "loss": 0.0023,
      "step": 49950
    },
    {
      "epoch": 1.529559440345345,
      "grad_norm": 0.024134447798132896,
      "learning_rate": 9.803141168906715e-06,
      "loss": 0.0021,
      "step": 49960
    },
    {
      "epoch": 1.5298655971588646,
      "grad_norm": 0.03631015494465828,
      "learning_rate": 9.80110012348325e-06,
      "loss": 0.0018,
      "step": 49970
    },
    {
      "epoch": 1.5301717539723847,
      "grad_norm": 0.01795981265604496,
      "learning_rate": 9.799059078059783e-06,
      "loss": 0.0012,
      "step": 49980
    },
    {
      "epoch": 1.5304779107859046,
      "grad_norm": 0.01738104410469532,
      "learning_rate": 9.797018032636317e-06,
      "loss": 0.003,
      "step": 49990
    },
    {
      "epoch": 1.5307840675994244,
      "grad_norm": 0.04168201610445976,
      "learning_rate": 9.79497698721285e-06,
      "loss": 0.0017,
      "step": 50000
    },
    {
      "epoch": 1.5310902244129443,
      "grad_norm": 0.010886190459132195,
      "learning_rate": 9.792935941789386e-06,
      "loss": 0.0361,
      "step": 50010
    },
    {
      "epoch": 1.5313963812264642,
      "grad_norm": 0.04121853783726692,
      "learning_rate": 9.79089489636592e-06,
      "loss": 0.0014,
      "step": 50020
    },
    {
      "epoch": 1.5317025380399842,
      "grad_norm": 0.02336329035460949,
      "learning_rate": 9.788853850942453e-06,
      "loss": 0.0013,
      "step": 50030
    },
    {
      "epoch": 1.5320086948535039,
      "grad_norm": 0.0320686437189579,
      "learning_rate": 9.786812805518989e-06,
      "loss": 0.0013,
      "step": 50040
    },
    {
      "epoch": 1.532314851667024,
      "grad_norm": 0.012441380880773067,
      "learning_rate": 9.784771760095522e-06,
      "loss": 0.0009,
      "step": 50050
    },
    {
      "epoch": 1.5326210084805436,
      "grad_norm": 0.03538939356803894,
      "learning_rate": 9.782730714672056e-06,
      "loss": 0.0017,
      "step": 50060
    },
    {
      "epoch": 1.5329271652940637,
      "grad_norm": 0.05963176116347313,
      "learning_rate": 9.78068966924859e-06,
      "loss": 0.001,
      "step": 50070
    },
    {
      "epoch": 1.5332333221075833,
      "grad_norm": 0.045060910284519196,
      "learning_rate": 9.778648623825125e-06,
      "loss": 0.0314,
      "step": 50080
    },
    {
      "epoch": 1.5335394789211034,
      "grad_norm": 0.04033488407731056,
      "learning_rate": 9.776607578401659e-06,
      "loss": 0.0014,
      "step": 50090
    },
    {
      "epoch": 1.5338456357346233,
      "grad_norm": 0.0660494714975357,
      "learning_rate": 9.774566532978192e-06,
      "loss": 0.0648,
      "step": 50100
    },
    {
      "epoch": 1.5341517925481432,
      "grad_norm": 0.08266746997833252,
      "learning_rate": 9.772525487554726e-06,
      "loss": 0.0018,
      "step": 50110
    },
    {
      "epoch": 1.534457949361663,
      "grad_norm": 0.03449469432234764,
      "learning_rate": 9.770484442131261e-06,
      "loss": 0.0013,
      "step": 50120
    },
    {
      "epoch": 1.5347641061751829,
      "grad_norm": 0.021187879145145416,
      "learning_rate": 9.768443396707793e-06,
      "loss": 0.0013,
      "step": 50130
    },
    {
      "epoch": 1.535070262988703,
      "grad_norm": 0.04890995845198631,
      "learning_rate": 9.766402351284329e-06,
      "loss": 0.0014,
      "step": 50140
    },
    {
      "epoch": 1.5353764198022226,
      "grad_norm": 0.020360171794891357,
      "learning_rate": 9.764361305860864e-06,
      "loss": 0.0341,
      "step": 50150
    },
    {
      "epoch": 1.5356825766157427,
      "grad_norm": 0.03159688040614128,
      "learning_rate": 9.762320260437398e-06,
      "loss": 0.0176,
      "step": 50160
    },
    {
      "epoch": 1.5359887334292623,
      "grad_norm": 0.034176792949438095,
      "learning_rate": 9.760279215013931e-06,
      "loss": 0.0381,
      "step": 50170
    },
    {
      "epoch": 1.5362948902427824,
      "grad_norm": 0.02185588702559471,
      "learning_rate": 9.758238169590465e-06,
      "loss": 0.0013,
      "step": 50180
    },
    {
      "epoch": 1.536601047056302,
      "grad_norm": 0.025930577889084816,
      "learning_rate": 9.756197124167e-06,
      "loss": 0.0369,
      "step": 50190
    },
    {
      "epoch": 1.5369072038698222,
      "grad_norm": 0.05184292793273926,
      "learning_rate": 9.754156078743532e-06,
      "loss": 0.0361,
      "step": 50200
    },
    {
      "epoch": 1.537213360683342,
      "grad_norm": 0.023226158693432808,
      "learning_rate": 9.752115033320067e-06,
      "loss": 0.0016,
      "step": 50210
    },
    {
      "epoch": 1.5375195174968619,
      "grad_norm": 0.011866784654557705,
      "learning_rate": 9.750073987896601e-06,
      "loss": 0.0289,
      "step": 50220
    },
    {
      "epoch": 1.5378256743103818,
      "grad_norm": 0.0949045941233635,
      "learning_rate": 9.748032942473136e-06,
      "loss": 0.0339,
      "step": 50230
    },
    {
      "epoch": 1.5381318311239016,
      "grad_norm": 0.03516228124499321,
      "learning_rate": 9.745991897049668e-06,
      "loss": 0.0016,
      "step": 50240
    },
    {
      "epoch": 1.5384379879374217,
      "grad_norm": 0.06888233870267868,
      "learning_rate": 9.743950851626204e-06,
      "loss": 0.0017,
      "step": 50250
    },
    {
      "epoch": 1.5387441447509413,
      "grad_norm": 0.04123895987868309,
      "learning_rate": 9.741909806202737e-06,
      "loss": 0.0014,
      "step": 50260
    },
    {
      "epoch": 1.5390503015644614,
      "grad_norm": 0.05665423721075058,
      "learning_rate": 9.739868760779273e-06,
      "loss": 0.0263,
      "step": 50270
    },
    {
      "epoch": 1.539356458377981,
      "grad_norm": 0.010057538747787476,
      "learning_rate": 9.737827715355806e-06,
      "loss": 0.0017,
      "step": 50280
    },
    {
      "epoch": 1.5396626151915012,
      "grad_norm": 0.055190760642290115,
      "learning_rate": 9.73578666993234e-06,
      "loss": 0.0579,
      "step": 50290
    },
    {
      "epoch": 1.539968772005021,
      "grad_norm": 0.08094483613967896,
      "learning_rate": 9.733745624508875e-06,
      "loss": 0.0017,
      "step": 50300
    },
    {
      "epoch": 1.540274928818541,
      "grad_norm": 0.034786779433488846,
      "learning_rate": 9.731704579085407e-06,
      "loss": 0.0021,
      "step": 50310
    },
    {
      "epoch": 1.5405810856320608,
      "grad_norm": 0.030581356957554817,
      "learning_rate": 9.729663533661943e-06,
      "loss": 0.0018,
      "step": 50320
    },
    {
      "epoch": 1.5408872424455806,
      "grad_norm": 0.0510307215154171,
      "learning_rate": 9.727622488238476e-06,
      "loss": 0.0017,
      "step": 50330
    },
    {
      "epoch": 1.5411933992591005,
      "grad_norm": 0.756008505821228,
      "learning_rate": 9.725581442815012e-06,
      "loss": 0.0032,
      "step": 50340
    },
    {
      "epoch": 1.5414995560726203,
      "grad_norm": 0.026062341406941414,
      "learning_rate": 9.723540397391544e-06,
      "loss": 0.0015,
      "step": 50350
    },
    {
      "epoch": 1.5418057128861404,
      "grad_norm": 0.013602047227323055,
      "learning_rate": 9.721499351968079e-06,
      "loss": 0.0522,
      "step": 50360
    },
    {
      "epoch": 1.54211186969966,
      "grad_norm": 0.03438558056950569,
      "learning_rate": 9.719458306544613e-06,
      "loss": 0.0405,
      "step": 50370
    },
    {
      "epoch": 1.5424180265131802,
      "grad_norm": 0.009636507369577885,
      "learning_rate": 9.717417261121146e-06,
      "loss": 0.0017,
      "step": 50380
    },
    {
      "epoch": 1.5427241833266998,
      "grad_norm": 0.036183763295412064,
      "learning_rate": 9.715376215697682e-06,
      "loss": 0.0373,
      "step": 50390
    },
    {
      "epoch": 1.54303034014022,
      "grad_norm": 0.028014909476041794,
      "learning_rate": 9.713335170274215e-06,
      "loss": 0.0023,
      "step": 50400
    },
    {
      "epoch": 1.5433364969537398,
      "grad_norm": 0.05291466414928436,
      "learning_rate": 9.71129412485075e-06,
      "loss": 0.0028,
      "step": 50410
    },
    {
      "epoch": 1.5436426537672596,
      "grad_norm": 0.014791471883654594,
      "learning_rate": 9.709253079427282e-06,
      "loss": 0.0419,
      "step": 50420
    },
    {
      "epoch": 1.5439488105807795,
      "grad_norm": 0.1546631008386612,
      "learning_rate": 9.707212034003818e-06,
      "loss": 0.0239,
      "step": 50430
    },
    {
      "epoch": 1.5442549673942993,
      "grad_norm": 0.2174490988254547,
      "learning_rate": 9.705170988580351e-06,
      "loss": 0.0656,
      "step": 50440
    },
    {
      "epoch": 1.5445611242078192,
      "grad_norm": 0.06251740455627441,
      "learning_rate": 9.703129943156885e-06,
      "loss": 0.0017,
      "step": 50450
    },
    {
      "epoch": 1.544867281021339,
      "grad_norm": 0.02389378659427166,
      "learning_rate": 9.701088897733419e-06,
      "loss": 0.0264,
      "step": 50460
    },
    {
      "epoch": 1.5451734378348592,
      "grad_norm": 0.12961627542972565,
      "learning_rate": 9.699047852309954e-06,
      "loss": 0.0281,
      "step": 50470
    },
    {
      "epoch": 1.5454795946483788,
      "grad_norm": 0.07696966826915741,
      "learning_rate": 9.697006806886488e-06,
      "loss": 0.0028,
      "step": 50480
    },
    {
      "epoch": 1.545785751461899,
      "grad_norm": 0.1367669701576233,
      "learning_rate": 9.694965761463021e-06,
      "loss": 0.0028,
      "step": 50490
    },
    {
      "epoch": 1.5460919082754185,
      "grad_norm": 0.03723903372883797,
      "learning_rate": 9.692924716039557e-06,
      "loss": 0.0319,
      "step": 50500
    },
    {
      "epoch": 1.5463980650889386,
      "grad_norm": 0.017634736374020576,
      "learning_rate": 9.69088367061609e-06,
      "loss": 0.0317,
      "step": 50510
    },
    {
      "epoch": 1.5467042219024585,
      "grad_norm": 0.11840900778770447,
      "learning_rate": 9.688842625192626e-06,
      "loss": 0.0037,
      "step": 50520
    },
    {
      "epoch": 1.5470103787159784,
      "grad_norm": 0.0071012401022017,
      "learning_rate": 9.686801579769158e-06,
      "loss": 0.0021,
      "step": 50530
    },
    {
      "epoch": 1.5473165355294982,
      "grad_norm": 0.0720275416970253,
      "learning_rate": 9.684760534345693e-06,
      "loss": 0.0018,
      "step": 50540
    },
    {
      "epoch": 1.547622692343018,
      "grad_norm": 0.06779580563306808,
      "learning_rate": 9.682719488922227e-06,
      "loss": 0.0022,
      "step": 50550
    },
    {
      "epoch": 1.547928849156538,
      "grad_norm": 0.02644682489335537,
      "learning_rate": 9.68067844349876e-06,
      "loss": 0.0022,
      "step": 50560
    },
    {
      "epoch": 1.5482350059700578,
      "grad_norm": 0.024786481633782387,
      "learning_rate": 9.678637398075294e-06,
      "loss": 0.002,
      "step": 50570
    },
    {
      "epoch": 1.548541162783578,
      "grad_norm": 0.02906974032521248,
      "learning_rate": 9.67659635265183e-06,
      "loss": 0.0282,
      "step": 50580
    },
    {
      "epoch": 1.5488473195970975,
      "grad_norm": 0.059731725603342056,
      "learning_rate": 9.674555307228363e-06,
      "loss": 0.003,
      "step": 50590
    },
    {
      "epoch": 1.5491534764106176,
      "grad_norm": 0.00971079058945179,
      "learning_rate": 9.672514261804897e-06,
      "loss": 0.0014,
      "step": 50600
    },
    {
      "epoch": 1.5494596332241373,
      "grad_norm": 0.045472707599401474,
      "learning_rate": 9.670473216381432e-06,
      "loss": 0.0014,
      "step": 50610
    },
    {
      "epoch": 1.5497657900376574,
      "grad_norm": 0.04031126946210861,
      "learning_rate": 9.668432170957966e-06,
      "loss": 0.0347,
      "step": 50620
    },
    {
      "epoch": 1.5500719468511772,
      "grad_norm": 0.027770020067691803,
      "learning_rate": 9.6663911255345e-06,
      "loss": 0.0016,
      "step": 50630
    },
    {
      "epoch": 1.550378103664697,
      "grad_norm": 0.018551670014858246,
      "learning_rate": 9.664350080111033e-06,
      "loss": 0.0009,
      "step": 50640
    },
    {
      "epoch": 1.550684260478217,
      "grad_norm": 0.02820405922830105,
      "learning_rate": 9.662309034687568e-06,
      "loss": 0.0017,
      "step": 50650
    },
    {
      "epoch": 1.5509904172917368,
      "grad_norm": 0.03531811386346817,
      "learning_rate": 9.660267989264102e-06,
      "loss": 0.0013,
      "step": 50660
    },
    {
      "epoch": 1.5512965741052567,
      "grad_norm": 0.015276079997420311,
      "learning_rate": 9.658226943840635e-06,
      "loss": 0.001,
      "step": 50670
    },
    {
      "epoch": 1.5516027309187765,
      "grad_norm": 0.03150048106908798,
      "learning_rate": 9.656185898417169e-06,
      "loss": 0.001,
      "step": 50680
    },
    {
      "epoch": 1.5519088877322966,
      "grad_norm": 0.0313672311604023,
      "learning_rate": 9.654144852993704e-06,
      "loss": 0.0013,
      "step": 50690
    },
    {
      "epoch": 1.5522150445458163,
      "grad_norm": 0.015611992217600346,
      "learning_rate": 9.652103807570238e-06,
      "loss": 0.0011,
      "step": 50700
    },
    {
      "epoch": 1.5525212013593364,
      "grad_norm": 0.00369638716802001,
      "learning_rate": 9.650062762146772e-06,
      "loss": 0.0011,
      "step": 50710
    },
    {
      "epoch": 1.552827358172856,
      "grad_norm": 0.021459296345710754,
      "learning_rate": 9.648021716723307e-06,
      "loss": 0.0012,
      "step": 50720
    },
    {
      "epoch": 1.553133514986376,
      "grad_norm": 0.008607364259660244,
      "learning_rate": 9.64598067129984e-06,
      "loss": 0.0008,
      "step": 50730
    },
    {
      "epoch": 1.553439671799896,
      "grad_norm": 0.011399900540709496,
      "learning_rate": 9.643939625876374e-06,
      "loss": 0.0007,
      "step": 50740
    },
    {
      "epoch": 1.5537458286134158,
      "grad_norm": 0.023504719138145447,
      "learning_rate": 9.641898580452908e-06,
      "loss": 0.0443,
      "step": 50750
    },
    {
      "epoch": 1.5540519854269357,
      "grad_norm": 0.03127934783697128,
      "learning_rate": 9.639857535029443e-06,
      "loss": 0.0009,
      "step": 50760
    },
    {
      "epoch": 1.5543581422404555,
      "grad_norm": 0.018132198601961136,
      "learning_rate": 9.637816489605977e-06,
      "loss": 0.001,
      "step": 50770
    },
    {
      "epoch": 1.5546642990539754,
      "grad_norm": 0.03536161035299301,
      "learning_rate": 9.63577544418251e-06,
      "loss": 0.0452,
      "step": 50780
    },
    {
      "epoch": 1.5549704558674953,
      "grad_norm": 0.05537542328238487,
      "learning_rate": 9.633734398759044e-06,
      "loss": 0.0009,
      "step": 50790
    },
    {
      "epoch": 1.5552766126810154,
      "grad_norm": 0.013489753007888794,
      "learning_rate": 9.63169335333558e-06,
      "loss": 0.0008,
      "step": 50800
    },
    {
      "epoch": 1.555582769494535,
      "grad_norm": 0.02322433702647686,
      "learning_rate": 9.629652307912113e-06,
      "loss": 0.0009,
      "step": 50810
    },
    {
      "epoch": 1.555888926308055,
      "grad_norm": 0.006769588682800531,
      "learning_rate": 9.627611262488647e-06,
      "loss": 0.0007,
      "step": 50820
    },
    {
      "epoch": 1.5561950831215747,
      "grad_norm": 0.02443617396056652,
      "learning_rate": 9.62557021706518e-06,
      "loss": 0.0423,
      "step": 50830
    },
    {
      "epoch": 1.5565012399350948,
      "grad_norm": 0.022142911329865456,
      "learning_rate": 9.623529171641716e-06,
      "loss": 0.0007,
      "step": 50840
    },
    {
      "epoch": 1.5568073967486147,
      "grad_norm": 0.019442686811089516,
      "learning_rate": 9.62148812621825e-06,
      "loss": 0.0384,
      "step": 50850
    },
    {
      "epoch": 1.5571135535621345,
      "grad_norm": 0.021249951794743538,
      "learning_rate": 9.619447080794783e-06,
      "loss": 0.0014,
      "step": 50860
    },
    {
      "epoch": 1.5574197103756544,
      "grad_norm": 1.8112967014312744,
      "learning_rate": 9.617406035371318e-06,
      "loss": 0.0345,
      "step": 50870
    },
    {
      "epoch": 1.5577258671891743,
      "grad_norm": 0.029075000435113907,
      "learning_rate": 9.615364989947852e-06,
      "loss": 0.0423,
      "step": 50880
    },
    {
      "epoch": 1.5580320240026941,
      "grad_norm": 0.021752020344138145,
      "learning_rate": 9.613323944524386e-06,
      "loss": 0.0389,
      "step": 50890
    },
    {
      "epoch": 1.558338180816214,
      "grad_norm": 0.02212679572403431,
      "learning_rate": 9.61128289910092e-06,
      "loss": 0.0013,
      "step": 50900
    },
    {
      "epoch": 1.558644337629734,
      "grad_norm": 0.08421513438224792,
      "learning_rate": 9.609241853677455e-06,
      "loss": 0.0009,
      "step": 50910
    },
    {
      "epoch": 1.5589504944432537,
      "grad_norm": 0.023550231009721756,
      "learning_rate": 9.607200808253988e-06,
      "loss": 0.0009,
      "step": 50920
    },
    {
      "epoch": 1.5592566512567738,
      "grad_norm": 0.10504016280174255,
      "learning_rate": 9.605159762830522e-06,
      "loss": 0.0089,
      "step": 50930
    },
    {
      "epoch": 1.5595628080702935,
      "grad_norm": 0.03956563398241997,
      "learning_rate": 9.603118717407056e-06,
      "loss": 0.0398,
      "step": 50940
    },
    {
      "epoch": 1.5598689648838135,
      "grad_norm": 0.01837661676108837,
      "learning_rate": 9.601077671983591e-06,
      "loss": 0.0399,
      "step": 50950
    },
    {
      "epoch": 1.5601751216973334,
      "grad_norm": 0.04580872505903244,
      "learning_rate": 9.599036626560125e-06,
      "loss": 0.0393,
      "step": 50960
    },
    {
      "epoch": 1.5604812785108533,
      "grad_norm": 0.031031399965286255,
      "learning_rate": 9.596995581136658e-06,
      "loss": 0.0012,
      "step": 50970
    },
    {
      "epoch": 1.5607874353243731,
      "grad_norm": 0.01619436778128147,
      "learning_rate": 9.594954535713194e-06,
      "loss": 0.0015,
      "step": 50980
    },
    {
      "epoch": 1.561093592137893,
      "grad_norm": 0.0114869000390172,
      "learning_rate": 9.592913490289727e-06,
      "loss": 0.0012,
      "step": 50990
    },
    {
      "epoch": 1.5613997489514129,
      "grad_norm": 0.039403725415468216,
      "learning_rate": 9.590872444866261e-06,
      "loss": 0.0014,
      "step": 51000
    },
    {
      "epoch": 1.5617059057649327,
      "grad_norm": 0.022586317732930183,
      "learning_rate": 9.588831399442795e-06,
      "loss": 0.0016,
      "step": 51010
    },
    {
      "epoch": 1.5620120625784528,
      "grad_norm": 0.026110637933015823,
      "learning_rate": 9.58679035401933e-06,
      "loss": 0.0299,
      "step": 51020
    },
    {
      "epoch": 1.5623182193919725,
      "grad_norm": 0.02825641818344593,
      "learning_rate": 9.584749308595864e-06,
      "loss": 0.0014,
      "step": 51030
    },
    {
      "epoch": 1.5626243762054925,
      "grad_norm": 0.005034857429563999,
      "learning_rate": 9.582708263172397e-06,
      "loss": 0.0014,
      "step": 51040
    },
    {
      "epoch": 1.5629305330190122,
      "grad_norm": 0.017844069749116898,
      "learning_rate": 9.580667217748931e-06,
      "loss": 0.0016,
      "step": 51050
    },
    {
      "epoch": 1.5632366898325323,
      "grad_norm": 0.04958521947264671,
      "learning_rate": 9.578626172325466e-06,
      "loss": 0.0015,
      "step": 51060
    },
    {
      "epoch": 1.5635428466460521,
      "grad_norm": 0.027913160622119904,
      "learning_rate": 9.576585126902e-06,
      "loss": 0.0008,
      "step": 51070
    },
    {
      "epoch": 1.563849003459572,
      "grad_norm": 0.030737999826669693,
      "learning_rate": 9.574544081478533e-06,
      "loss": 0.0009,
      "step": 51080
    },
    {
      "epoch": 1.5641551602730919,
      "grad_norm": 0.02888946421444416,
      "learning_rate": 9.572503036055069e-06,
      "loss": 0.001,
      "step": 51090
    },
    {
      "epoch": 1.5644613170866117,
      "grad_norm": 0.05366695672273636,
      "learning_rate": 9.570461990631602e-06,
      "loss": 0.0009,
      "step": 51100
    },
    {
      "epoch": 1.5647674739001316,
      "grad_norm": 0.029556533321738243,
      "learning_rate": 9.568420945208136e-06,
      "loss": 0.0008,
      "step": 51110
    },
    {
      "epoch": 1.5650736307136515,
      "grad_norm": 0.014798454940319061,
      "learning_rate": 9.56637989978467e-06,
      "loss": 0.0371,
      "step": 51120
    },
    {
      "epoch": 1.5653797875271716,
      "grad_norm": 0.027029192075133324,
      "learning_rate": 9.564338854361205e-06,
      "loss": 0.0448,
      "step": 51130
    },
    {
      "epoch": 1.5656859443406912,
      "grad_norm": 0.014695510268211365,
      "learning_rate": 9.562297808937739e-06,
      "loss": 0.0348,
      "step": 51140
    },
    {
      "epoch": 1.5659921011542113,
      "grad_norm": 0.025955624878406525,
      "learning_rate": 9.560256763514272e-06,
      "loss": 0.0012,
      "step": 51150
    },
    {
      "epoch": 1.566298257967731,
      "grad_norm": 0.02066817134618759,
      "learning_rate": 9.558215718090806e-06,
      "loss": 0.0011,
      "step": 51160
    },
    {
      "epoch": 1.566604414781251,
      "grad_norm": 0.005316798575222492,
      "learning_rate": 9.556174672667341e-06,
      "loss": 0.0011,
      "step": 51170
    },
    {
      "epoch": 1.5669105715947709,
      "grad_norm": 1.9861602783203125,
      "learning_rate": 9.554133627243875e-06,
      "loss": 0.0388,
      "step": 51180
    },
    {
      "epoch": 1.5672167284082907,
      "grad_norm": 0.05471571907401085,
      "learning_rate": 9.552092581820409e-06,
      "loss": 0.0012,
      "step": 51190
    },
    {
      "epoch": 1.5675228852218106,
      "grad_norm": 0.026134230196475983,
      "learning_rate": 9.550051536396944e-06,
      "loss": 0.0009,
      "step": 51200
    },
    {
      "epoch": 1.5678290420353305,
      "grad_norm": 0.06906741112470627,
      "learning_rate": 9.548010490973478e-06,
      "loss": 0.0015,
      "step": 51210
    },
    {
      "epoch": 1.5681351988488503,
      "grad_norm": 0.0357813686132431,
      "learning_rate": 9.545969445550011e-06,
      "loss": 0.0008,
      "step": 51220
    },
    {
      "epoch": 1.5684413556623702,
      "grad_norm": 0.02078973315656185,
      "learning_rate": 9.543928400126545e-06,
      "loss": 0.0011,
      "step": 51230
    },
    {
      "epoch": 1.5687475124758903,
      "grad_norm": 0.036802180111408234,
      "learning_rate": 9.54188735470308e-06,
      "loss": 0.001,
      "step": 51240
    },
    {
      "epoch": 1.56905366928941,
      "grad_norm": 0.019067291170358658,
      "learning_rate": 9.539846309279614e-06,
      "loss": 0.001,
      "step": 51250
    },
    {
      "epoch": 1.56935982610293,
      "grad_norm": 0.02250521443784237,
      "learning_rate": 9.537805263856148e-06,
      "loss": 0.0007,
      "step": 51260
    },
    {
      "epoch": 1.5696659829164497,
      "grad_norm": 0.02241314947605133,
      "learning_rate": 9.535764218432681e-06,
      "loss": 0.0328,
      "step": 51270
    },
    {
      "epoch": 1.5699721397299697,
      "grad_norm": 0.021291658282279968,
      "learning_rate": 9.533723173009217e-06,
      "loss": 0.0005,
      "step": 51280
    },
    {
      "epoch": 1.5702782965434896,
      "grad_norm": 0.01856853812932968,
      "learning_rate": 9.53168212758575e-06,
      "loss": 0.0035,
      "step": 51290
    },
    {
      "epoch": 1.5705844533570095,
      "grad_norm": 0.0474015437066555,
      "learning_rate": 9.529641082162284e-06,
      "loss": 0.0213,
      "step": 51300
    },
    {
      "epoch": 1.5708906101705293,
      "grad_norm": 0.0024081941228359938,
      "learning_rate": 9.52760003673882e-06,
      "loss": 0.0007,
      "step": 51310
    },
    {
      "epoch": 1.5711967669840492,
      "grad_norm": 0.004069372545927763,
      "learning_rate": 9.525558991315353e-06,
      "loss": 0.0005,
      "step": 51320
    },
    {
      "epoch": 1.571502923797569,
      "grad_norm": 0.011883998289704323,
      "learning_rate": 9.523517945891886e-06,
      "loss": 0.0013,
      "step": 51330
    },
    {
      "epoch": 1.571809080611089,
      "grad_norm": 0.020132018253207207,
      "learning_rate": 9.52147690046842e-06,
      "loss": 0.0009,
      "step": 51340
    },
    {
      "epoch": 1.572115237424609,
      "grad_norm": 0.02303621917963028,
      "learning_rate": 9.519435855044955e-06,
      "loss": 0.0397,
      "step": 51350
    },
    {
      "epoch": 1.5724213942381287,
      "grad_norm": 0.014266850426793098,
      "learning_rate": 9.517394809621489e-06,
      "loss": 0.001,
      "step": 51360
    },
    {
      "epoch": 1.5727275510516487,
      "grad_norm": 0.019817618653178215,
      "learning_rate": 9.515353764198023e-06,
      "loss": 0.0017,
      "step": 51370
    },
    {
      "epoch": 1.5730337078651684,
      "grad_norm": 0.024779537692666054,
      "learning_rate": 9.513312718774556e-06,
      "loss": 0.001,
      "step": 51380
    },
    {
      "epoch": 1.5733398646786885,
      "grad_norm": 0.015149294398725033,
      "learning_rate": 9.511271673351092e-06,
      "loss": 0.032,
      "step": 51390
    },
    {
      "epoch": 1.5736460214922083,
      "grad_norm": 0.012125656940042973,
      "learning_rate": 9.509230627927625e-06,
      "loss": 0.0408,
      "step": 51400
    },
    {
      "epoch": 1.5739521783057282,
      "grad_norm": 0.02335991896688938,
      "learning_rate": 9.507189582504159e-06,
      "loss": 0.0013,
      "step": 51410
    },
    {
      "epoch": 1.574258335119248,
      "grad_norm": 0.0492468886077404,
      "learning_rate": 9.505148537080694e-06,
      "loss": 0.0351,
      "step": 51420
    },
    {
      "epoch": 1.574564491932768,
      "grad_norm": 0.023146970197558403,
      "learning_rate": 9.503107491657228e-06,
      "loss": 0.0015,
      "step": 51430
    },
    {
      "epoch": 1.5748706487462878,
      "grad_norm": 0.02589046210050583,
      "learning_rate": 9.501066446233762e-06,
      "loss": 0.0011,
      "step": 51440
    },
    {
      "epoch": 1.5751768055598077,
      "grad_norm": 0.015364469960331917,
      "learning_rate": 9.499025400810295e-06,
      "loss": 0.0353,
      "step": 51450
    },
    {
      "epoch": 1.5754829623733277,
      "grad_norm": 0.03520086035132408,
      "learning_rate": 9.49698435538683e-06,
      "loss": 0.0015,
      "step": 51460
    },
    {
      "epoch": 1.5757891191868474,
      "grad_norm": 0.03295420855283737,
      "learning_rate": 9.494943309963364e-06,
      "loss": 0.0294,
      "step": 51470
    },
    {
      "epoch": 1.5760952760003675,
      "grad_norm": 0.030234038829803467,
      "learning_rate": 9.492902264539898e-06,
      "loss": 0.0327,
      "step": 51480
    },
    {
      "epoch": 1.5764014328138871,
      "grad_norm": 0.012118091806769371,
      "learning_rate": 9.490861219116432e-06,
      "loss": 0.0336,
      "step": 51490
    },
    {
      "epoch": 1.5767075896274072,
      "grad_norm": 0.15806148946285248,
      "learning_rate": 9.488820173692967e-06,
      "loss": 0.0351,
      "step": 51500
    },
    {
      "epoch": 1.577013746440927,
      "grad_norm": 0.04304317757487297,
      "learning_rate": 9.4867791282695e-06,
      "loss": 0.0014,
      "step": 51510
    },
    {
      "epoch": 1.577319903254447,
      "grad_norm": 0.07842478901147842,
      "learning_rate": 9.484738082846034e-06,
      "loss": 0.0127,
      "step": 51520
    },
    {
      "epoch": 1.5776260600679668,
      "grad_norm": 0.042808566242456436,
      "learning_rate": 9.48269703742257e-06,
      "loss": 0.0409,
      "step": 51530
    },
    {
      "epoch": 1.5779322168814867,
      "grad_norm": 0.01742899976670742,
      "learning_rate": 9.480655991999103e-06,
      "loss": 0.0013,
      "step": 51540
    },
    {
      "epoch": 1.5782383736950067,
      "grad_norm": 0.04690906032919884,
      "learning_rate": 9.478614946575637e-06,
      "loss": 0.0213,
      "step": 51550
    },
    {
      "epoch": 1.5785445305085264,
      "grad_norm": 0.05412359535694122,
      "learning_rate": 9.47657390115217e-06,
      "loss": 0.0394,
      "step": 51560
    },
    {
      "epoch": 1.5788506873220465,
      "grad_norm": 0.019128771498799324,
      "learning_rate": 9.474532855728706e-06,
      "loss": 0.0272,
      "step": 51570
    },
    {
      "epoch": 1.5791568441355661,
      "grad_norm": 0.030344830825924873,
      "learning_rate": 9.47249181030524e-06,
      "loss": 0.001,
      "step": 51580
    },
    {
      "epoch": 1.5794630009490862,
      "grad_norm": 0.00022153630561660975,
      "learning_rate": 9.470450764881773e-06,
      "loss": 0.0013,
      "step": 51590
    },
    {
      "epoch": 1.5797691577626058,
      "grad_norm": 0.021826066076755524,
      "learning_rate": 9.468409719458307e-06,
      "loss": 0.0124,
      "step": 51600
    },
    {
      "epoch": 1.580075314576126,
      "grad_norm": 0.02569797821342945,
      "learning_rate": 9.466368674034842e-06,
      "loss": 0.0017,
      "step": 51610
    },
    {
      "epoch": 1.5803814713896458,
      "grad_norm": 0.01737382635474205,
      "learning_rate": 9.464327628611376e-06,
      "loss": 0.0012,
      "step": 51620
    },
    {
      "epoch": 1.5806876282031657,
      "grad_norm": 0.05647919699549675,
      "learning_rate": 9.46228658318791e-06,
      "loss": 0.0588,
      "step": 51630
    },
    {
      "epoch": 1.5809937850166855,
      "grad_norm": 0.059207260608673096,
      "learning_rate": 9.460245537764445e-06,
      "loss": 0.0366,
      "step": 51640
    },
    {
      "epoch": 1.5812999418302054,
      "grad_norm": 0.04794643446803093,
      "learning_rate": 9.458204492340978e-06,
      "loss": 0.0011,
      "step": 51650
    },
    {
      "epoch": 1.5816060986437255,
      "grad_norm": 0.02634323574602604,
      "learning_rate": 9.456163446917512e-06,
      "loss": 0.0114,
      "step": 51660
    },
    {
      "epoch": 1.5819122554572451,
      "grad_norm": 0.06040825694799423,
      "learning_rate": 9.454122401494046e-06,
      "loss": 0.0018,
      "step": 51670
    },
    {
      "epoch": 1.5822184122707652,
      "grad_norm": 0.04384184256196022,
      "learning_rate": 9.452081356070581e-06,
      "loss": 0.0367,
      "step": 51680
    },
    {
      "epoch": 1.5825245690842848,
      "grad_norm": 0.06303729116916656,
      "learning_rate": 9.450040310647115e-06,
      "loss": 0.0015,
      "step": 51690
    },
    {
      "epoch": 1.582830725897805,
      "grad_norm": 0.03662216290831566,
      "learning_rate": 9.447999265223648e-06,
      "loss": 0.0012,
      "step": 51700
    },
    {
      "epoch": 1.5831368827113246,
      "grad_norm": 0.011826553381979465,
      "learning_rate": 9.445958219800182e-06,
      "loss": 0.0011,
      "step": 51710
    },
    {
      "epoch": 1.5834430395248447,
      "grad_norm": 0.015866674482822418,
      "learning_rate": 9.443917174376717e-06,
      "loss": 0.0014,
      "step": 51720
    },
    {
      "epoch": 1.5837491963383645,
      "grad_norm": 0.023553436622023582,
      "learning_rate": 9.441876128953251e-06,
      "loss": 0.0088,
      "step": 51730
    },
    {
      "epoch": 1.5840553531518844,
      "grad_norm": 0.02393229864537716,
      "learning_rate": 9.439835083529785e-06,
      "loss": 0.002,
      "step": 51740
    },
    {
      "epoch": 1.5843615099654043,
      "grad_norm": 0.021438147872686386,
      "learning_rate": 9.43779403810632e-06,
      "loss": 0.0009,
      "step": 51750
    },
    {
      "epoch": 1.5846676667789241,
      "grad_norm": 0.041001152247190475,
      "learning_rate": 9.435752992682853e-06,
      "loss": 0.0325,
      "step": 51760
    },
    {
      "epoch": 1.5849738235924442,
      "grad_norm": 0.047583386301994324,
      "learning_rate": 9.433711947259387e-06,
      "loss": 0.0012,
      "step": 51770
    },
    {
      "epoch": 1.5852799804059639,
      "grad_norm": 0.043590694665908813,
      "learning_rate": 9.43167090183592e-06,
      "loss": 0.0398,
      "step": 51780
    },
    {
      "epoch": 1.585586137219484,
      "grad_norm": 0.030023925006389618,
      "learning_rate": 9.429629856412456e-06,
      "loss": 0.0328,
      "step": 51790
    },
    {
      "epoch": 1.5858922940330036,
      "grad_norm": 0.0375218391418457,
      "learning_rate": 9.42758881098899e-06,
      "loss": 0.0012,
      "step": 51800
    },
    {
      "epoch": 1.5861984508465237,
      "grad_norm": 0.013098896481096745,
      "learning_rate": 9.425547765565523e-06,
      "loss": 0.0012,
      "step": 51810
    },
    {
      "epoch": 1.5865046076600433,
      "grad_norm": 0.0052571976557374,
      "learning_rate": 9.423506720142057e-06,
      "loss": 0.0012,
      "step": 51820
    },
    {
      "epoch": 1.5868107644735634,
      "grad_norm": 0.03061142936348915,
      "learning_rate": 9.421465674718592e-06,
      "loss": 0.0018,
      "step": 51830
    },
    {
      "epoch": 1.5871169212870833,
      "grad_norm": 0.005160424392670393,
      "learning_rate": 9.419424629295126e-06,
      "loss": 0.0009,
      "step": 51840
    },
    {
      "epoch": 1.5874230781006031,
      "grad_norm": 0.026589959859848022,
      "learning_rate": 9.41738358387166e-06,
      "loss": 0.0009,
      "step": 51850
    },
    {
      "epoch": 1.587729234914123,
      "grad_norm": 0.04878828302025795,
      "learning_rate": 9.415342538448195e-06,
      "loss": 0.0011,
      "step": 51860
    },
    {
      "epoch": 1.5880353917276429,
      "grad_norm": 0.02634994126856327,
      "learning_rate": 9.413301493024729e-06,
      "loss": 0.0241,
      "step": 51870
    },
    {
      "epoch": 1.588341548541163,
      "grad_norm": 0.039004527032375336,
      "learning_rate": 9.411260447601262e-06,
      "loss": 0.0426,
      "step": 51880
    },
    {
      "epoch": 1.5886477053546826,
      "grad_norm": 0.03968483954668045,
      "learning_rate": 9.409219402177796e-06,
      "loss": 0.0446,
      "step": 51890
    },
    {
      "epoch": 1.5889538621682027,
      "grad_norm": 0.005830507259815931,
      "learning_rate": 9.407178356754331e-06,
      "loss": 0.0018,
      "step": 51900
    },
    {
      "epoch": 1.5892600189817223,
      "grad_norm": 0.01279107853770256,
      "learning_rate": 9.405137311330865e-06,
      "loss": 0.0014,
      "step": 51910
    },
    {
      "epoch": 1.5895661757952424,
      "grad_norm": 0.016607040539383888,
      "learning_rate": 9.403096265907399e-06,
      "loss": 0.0015,
      "step": 51920
    },
    {
      "epoch": 1.5898723326087623,
      "grad_norm": 0.017768342047929764,
      "learning_rate": 9.401055220483932e-06,
      "loss": 0.0395,
      "step": 51930
    },
    {
      "epoch": 1.5901784894222821,
      "grad_norm": 0.04352904111146927,
      "learning_rate": 9.399014175060468e-06,
      "loss": 0.0011,
      "step": 51940
    },
    {
      "epoch": 1.590484646235802,
      "grad_norm": 0.027854183688759804,
      "learning_rate": 9.396973129637001e-06,
      "loss": 0.0022,
      "step": 51950
    },
    {
      "epoch": 1.5907908030493219,
      "grad_norm": 0.028736501932144165,
      "learning_rate": 9.394932084213535e-06,
      "loss": 0.0179,
      "step": 51960
    },
    {
      "epoch": 1.5910969598628417,
      "grad_norm": 0.050519611686468124,
      "learning_rate": 9.39289103879007e-06,
      "loss": 0.0307,
      "step": 51970
    },
    {
      "epoch": 1.5914031166763616,
      "grad_norm": 0.01661193184554577,
      "learning_rate": 9.390849993366604e-06,
      "loss": 0.001,
      "step": 51980
    },
    {
      "epoch": 1.5917092734898817,
      "grad_norm": 0.0142615782096982,
      "learning_rate": 9.388808947943137e-06,
      "loss": 0.0025,
      "step": 51990
    },
    {
      "epoch": 1.5920154303034013,
      "grad_norm": 0.027723172679543495,
      "learning_rate": 9.386767902519671e-06,
      "loss": 0.0008,
      "step": 52000
    },
    {
      "epoch": 1.5923215871169214,
      "grad_norm": 0.031223351135849953,
      "learning_rate": 9.384726857096206e-06,
      "loss": 0.0009,
      "step": 52010
    },
    {
      "epoch": 1.592627743930441,
      "grad_norm": 0.0421590581536293,
      "learning_rate": 9.38268581167274e-06,
      "loss": 0.0294,
      "step": 52020
    },
    {
      "epoch": 1.5929339007439611,
      "grad_norm": 0.04875661060214043,
      "learning_rate": 9.380644766249274e-06,
      "loss": 0.0401,
      "step": 52030
    },
    {
      "epoch": 1.593240057557481,
      "grad_norm": 0.00924612209200859,
      "learning_rate": 9.378603720825807e-06,
      "loss": 0.0036,
      "step": 52040
    },
    {
      "epoch": 1.5935462143710009,
      "grad_norm": 0.008152264170348644,
      "learning_rate": 9.376562675402343e-06,
      "loss": 0.0013,
      "step": 52050
    },
    {
      "epoch": 1.5938523711845207,
      "grad_norm": 0.027569951489567757,
      "learning_rate": 9.374521629978875e-06,
      "loss": 0.0007,
      "step": 52060
    },
    {
      "epoch": 1.5941585279980406,
      "grad_norm": 1.7237021923065186,
      "learning_rate": 9.37248058455541e-06,
      "loss": 0.0641,
      "step": 52070
    },
    {
      "epoch": 1.5944646848115605,
      "grad_norm": 0.031578417867422104,
      "learning_rate": 9.370439539131944e-06,
      "loss": 0.0388,
      "step": 52080
    },
    {
      "epoch": 1.5947708416250803,
      "grad_norm": 0.04339829087257385,
      "learning_rate": 9.368398493708479e-06,
      "loss": 0.0013,
      "step": 52090
    },
    {
      "epoch": 1.5950769984386004,
      "grad_norm": 0.03830898180603981,
      "learning_rate": 9.366357448285013e-06,
      "loss": 0.0011,
      "step": 52100
    },
    {
      "epoch": 1.59538315525212,
      "grad_norm": 0.028213849291205406,
      "learning_rate": 9.364316402861546e-06,
      "loss": 0.001,
      "step": 52110
    },
    {
      "epoch": 1.5956893120656401,
      "grad_norm": 0.033172424882650375,
      "learning_rate": 9.362275357438082e-06,
      "loss": 0.0014,
      "step": 52120
    },
    {
      "epoch": 1.5959954688791598,
      "grad_norm": 0.03543836995959282,
      "learning_rate": 9.360234312014614e-06,
      "loss": 0.0013,
      "step": 52130
    },
    {
      "epoch": 1.5963016256926799,
      "grad_norm": 0.03325033560395241,
      "learning_rate": 9.358193266591149e-06,
      "loss": 0.0014,
      "step": 52140
    },
    {
      "epoch": 1.5966077825061997,
      "grad_norm": 0.011668306775391102,
      "learning_rate": 9.356152221167683e-06,
      "loss": 0.002,
      "step": 52150
    },
    {
      "epoch": 1.5969139393197196,
      "grad_norm": 0.013254024088382721,
      "learning_rate": 9.354111175744218e-06,
      "loss": 0.0383,
      "step": 52160
    },
    {
      "epoch": 1.5972200961332395,
      "grad_norm": 0.04154246300458908,
      "learning_rate": 9.35207013032075e-06,
      "loss": 0.0013,
      "step": 52170
    },
    {
      "epoch": 1.5975262529467593,
      "grad_norm": 1.5946803092956543,
      "learning_rate": 9.350029084897285e-06,
      "loss": 0.0641,
      "step": 52180
    },
    {
      "epoch": 1.5978324097602792,
      "grad_norm": 0.03440896421670914,
      "learning_rate": 9.347988039473819e-06,
      "loss": 0.0014,
      "step": 52190
    },
    {
      "epoch": 1.598138566573799,
      "grad_norm": 0.03352462872862816,
      "learning_rate": 9.345946994050354e-06,
      "loss": 0.0324,
      "step": 52200
    },
    {
      "epoch": 1.5984447233873191,
      "grad_norm": 0.051021184772253036,
      "learning_rate": 9.343905948626888e-06,
      "loss": 0.0017,
      "step": 52210
    },
    {
      "epoch": 1.5987508802008388,
      "grad_norm": 0.03078339621424675,
      "learning_rate": 9.341864903203421e-06,
      "loss": 0.0012,
      "step": 52220
    },
    {
      "epoch": 1.5990570370143589,
      "grad_norm": 0.042641788721084595,
      "learning_rate": 9.339823857779957e-06,
      "loss": 0.0016,
      "step": 52230
    },
    {
      "epoch": 1.5993631938278785,
      "grad_norm": 0.030335741117596626,
      "learning_rate": 9.337782812356489e-06,
      "loss": 0.0012,
      "step": 52240
    },
    {
      "epoch": 1.5996693506413986,
      "grad_norm": 0.004664307925850153,
      "learning_rate": 9.335741766933024e-06,
      "loss": 0.0009,
      "step": 52250
    },
    {
      "epoch": 1.5999755074549185,
      "grad_norm": 0.038835231214761734,
      "learning_rate": 9.333700721509558e-06,
      "loss": 0.0008,
      "step": 52260
    },
    {
      "epoch": 1.6002816642684383,
      "grad_norm": 1.9994512796401978,
      "learning_rate": 9.331659676086093e-06,
      "loss": 0.0434,
      "step": 52270
    },
    {
      "epoch": 1.6005878210819582,
      "grad_norm": 0.01869315654039383,
      "learning_rate": 9.329618630662625e-06,
      "loss": 0.0009,
      "step": 52280
    },
    {
      "epoch": 1.600893977895478,
      "grad_norm": 0.04822811484336853,
      "learning_rate": 9.32757758523916e-06,
      "loss": 0.001,
      "step": 52290
    },
    {
      "epoch": 1.601200134708998,
      "grad_norm": 0.021628864109516144,
      "learning_rate": 9.325536539815694e-06,
      "loss": 0.0026,
      "step": 52300
    },
    {
      "epoch": 1.6015062915225178,
      "grad_norm": 0.027012234553694725,
      "learning_rate": 9.323495494392228e-06,
      "loss": 0.0015,
      "step": 52310
    },
    {
      "epoch": 1.6018124483360379,
      "grad_norm": 0.058410875499248505,
      "learning_rate": 9.321454448968763e-06,
      "loss": 0.0013,
      "step": 52320
    },
    {
      "epoch": 1.6021186051495575,
      "grad_norm": 0.0360318161547184,
      "learning_rate": 9.319413403545297e-06,
      "loss": 0.001,
      "step": 52330
    },
    {
      "epoch": 1.6024247619630776,
      "grad_norm": 0.03134065866470337,
      "learning_rate": 9.317372358121832e-06,
      "loss": 0.0008,
      "step": 52340
    },
    {
      "epoch": 1.6027309187765972,
      "grad_norm": 0.3306531310081482,
      "learning_rate": 9.315331312698364e-06,
      "loss": 0.0022,
      "step": 52350
    },
    {
      "epoch": 1.6030370755901173,
      "grad_norm": 0.04143036529421806,
      "learning_rate": 9.3132902672749e-06,
      "loss": 0.0335,
      "step": 52360
    },
    {
      "epoch": 1.6033432324036372,
      "grad_norm": 0.03728815168142319,
      "learning_rate": 9.311249221851433e-06,
      "loss": 0.001,
      "step": 52370
    },
    {
      "epoch": 1.603649389217157,
      "grad_norm": 0.014323347248136997,
      "learning_rate": 9.309208176427967e-06,
      "loss": 0.0008,
      "step": 52380
    },
    {
      "epoch": 1.603955546030677,
      "grad_norm": 0.027157900854945183,
      "learning_rate": 9.3071671310045e-06,
      "loss": 0.0008,
      "step": 52390
    },
    {
      "epoch": 1.6042617028441968,
      "grad_norm": 0.026628073304891586,
      "learning_rate": 9.305126085581036e-06,
      "loss": 0.0026,
      "step": 52400
    },
    {
      "epoch": 1.6045678596577166,
      "grad_norm": 0.011917655356228352,
      "learning_rate": 9.30308504015757e-06,
      "loss": 0.0384,
      "step": 52410
    },
    {
      "epoch": 1.6048740164712365,
      "grad_norm": 0.024005571380257607,
      "learning_rate": 9.301043994734103e-06,
      "loss": 0.0351,
      "step": 52420
    },
    {
      "epoch": 1.6051801732847566,
      "grad_norm": 0.039804451167583466,
      "learning_rate": 9.299002949310638e-06,
      "loss": 0.0011,
      "step": 52430
    },
    {
      "epoch": 1.6054863300982762,
      "grad_norm": 0.029297014698386192,
      "learning_rate": 9.296961903887172e-06,
      "loss": 0.001,
      "step": 52440
    },
    {
      "epoch": 1.6057924869117963,
      "grad_norm": 0.005881293676793575,
      "learning_rate": 9.294920858463707e-06,
      "loss": 0.0008,
      "step": 52450
    },
    {
      "epoch": 1.606098643725316,
      "grad_norm": 0.02119595743715763,
      "learning_rate": 9.292879813040239e-06,
      "loss": 0.0077,
      "step": 52460
    },
    {
      "epoch": 1.606404800538836,
      "grad_norm": 0.00990434642881155,
      "learning_rate": 9.290838767616774e-06,
      "loss": 0.0006,
      "step": 52470
    },
    {
      "epoch": 1.606710957352356,
      "grad_norm": 1.6578483581542969,
      "learning_rate": 9.288797722193308e-06,
      "loss": 0.034,
      "step": 52480
    },
    {
      "epoch": 1.6070171141658758,
      "grad_norm": 0.020593086257576942,
      "learning_rate": 9.286756676769842e-06,
      "loss": 0.0008,
      "step": 52490
    },
    {
      "epoch": 1.6073232709793956,
      "grad_norm": 0.00694279232993722,
      "learning_rate": 9.284715631346375e-06,
      "loss": 0.0009,
      "step": 52500
    },
    {
      "epoch": 1.6076294277929155,
      "grad_norm": 0.019604532048106194,
      "learning_rate": 9.28267458592291e-06,
      "loss": 0.0009,
      "step": 52510
    },
    {
      "epoch": 1.6079355846064354,
      "grad_norm": 0.028804494068026543,
      "learning_rate": 9.280633540499444e-06,
      "loss": 0.0398,
      "step": 52520
    },
    {
      "epoch": 1.6082417414199552,
      "grad_norm": 0.017774635925889015,
      "learning_rate": 9.278592495075978e-06,
      "loss": 0.0009,
      "step": 52530
    },
    {
      "epoch": 1.6085478982334753,
      "grad_norm": 0.0335952490568161,
      "learning_rate": 9.276551449652513e-06,
      "loss": 0.001,
      "step": 52540
    },
    {
      "epoch": 1.608854055046995,
      "grad_norm": 0.021161237731575966,
      "learning_rate": 9.274510404229047e-06,
      "loss": 0.0361,
      "step": 52550
    },
    {
      "epoch": 1.609160211860515,
      "grad_norm": 0.03659656643867493,
      "learning_rate": 9.27246935880558e-06,
      "loss": 0.001,
      "step": 52560
    },
    {
      "epoch": 1.6094663686740347,
      "grad_norm": 0.012957149185240269,
      "learning_rate": 9.270428313382114e-06,
      "loss": 0.0415,
      "step": 52570
    },
    {
      "epoch": 1.6097725254875548,
      "grad_norm": 0.02036096714437008,
      "learning_rate": 9.26838726795865e-06,
      "loss": 0.0014,
      "step": 52580
    },
    {
      "epoch": 1.6100786823010746,
      "grad_norm": 0.08215327560901642,
      "learning_rate": 9.266346222535183e-06,
      "loss": 0.0972,
      "step": 52590
    },
    {
      "epoch": 1.6103848391145945,
      "grad_norm": 0.03633252903819084,
      "learning_rate": 9.264305177111717e-06,
      "loss": 0.0011,
      "step": 52600
    },
    {
      "epoch": 1.6106909959281144,
      "grad_norm": 0.039823997765779495,
      "learning_rate": 9.26226413168825e-06,
      "loss": 0.0015,
      "step": 52610
    },
    {
      "epoch": 1.6109971527416342,
      "grad_norm": 0.005994120612740517,
      "learning_rate": 9.260223086264786e-06,
      "loss": 0.0014,
      "step": 52620
    },
    {
      "epoch": 1.611303309555154,
      "grad_norm": 0.012949223630130291,
      "learning_rate": 9.25818204084132e-06,
      "loss": 0.0336,
      "step": 52630
    },
    {
      "epoch": 1.611609466368674,
      "grad_norm": 0.014236416667699814,
      "learning_rate": 9.256140995417853e-06,
      "loss": 0.0009,
      "step": 52640
    },
    {
      "epoch": 1.611915623182194,
      "grad_norm": 1.8783519268035889,
      "learning_rate": 9.254099949994388e-06,
      "loss": 0.0708,
      "step": 52650
    },
    {
      "epoch": 1.6122217799957137,
      "grad_norm": 0.03798767924308777,
      "learning_rate": 9.252058904570922e-06,
      "loss": 0.0117,
      "step": 52660
    },
    {
      "epoch": 1.6125279368092338,
      "grad_norm": 0.09499184787273407,
      "learning_rate": 9.250017859147456e-06,
      "loss": 0.0017,
      "step": 52670
    },
    {
      "epoch": 1.6128340936227534,
      "grad_norm": 0.022346975281834602,
      "learning_rate": 9.24797681372399e-06,
      "loss": 0.0556,
      "step": 52680
    },
    {
      "epoch": 1.6131402504362735,
      "grad_norm": 0.04406309127807617,
      "learning_rate": 9.245935768300525e-06,
      "loss": 0.0017,
      "step": 52690
    },
    {
      "epoch": 1.6134464072497934,
      "grad_norm": 0.04296397045254707,
      "learning_rate": 9.243894722877058e-06,
      "loss": 0.0311,
      "step": 52700
    },
    {
      "epoch": 1.6137525640633132,
      "grad_norm": 0.23871031403541565,
      "learning_rate": 9.241853677453592e-06,
      "loss": 0.0021,
      "step": 52710
    },
    {
      "epoch": 1.614058720876833,
      "grad_norm": 0.03758402168750763,
      "learning_rate": 9.239812632030126e-06,
      "loss": 0.116,
      "step": 52720
    },
    {
      "epoch": 1.614364877690353,
      "grad_norm": 0.015954062342643738,
      "learning_rate": 9.237771586606661e-06,
      "loss": 0.0021,
      "step": 52730
    },
    {
      "epoch": 1.6146710345038728,
      "grad_norm": 0.047770705074071884,
      "learning_rate": 9.235730541183195e-06,
      "loss": 0.0017,
      "step": 52740
    },
    {
      "epoch": 1.6149771913173927,
      "grad_norm": 1.424169898033142,
      "learning_rate": 9.233689495759728e-06,
      "loss": 0.0699,
      "step": 52750
    },
    {
      "epoch": 1.6152833481309128,
      "grad_norm": 0.04496335983276367,
      "learning_rate": 9.231648450336262e-06,
      "loss": 0.0025,
      "step": 52760
    },
    {
      "epoch": 1.6155895049444324,
      "grad_norm": 0.06496153771877289,
      "learning_rate": 9.229607404912797e-06,
      "loss": 0.0041,
      "step": 52770
    },
    {
      "epoch": 1.6158956617579525,
      "grad_norm": 0.06588852405548096,
      "learning_rate": 9.227566359489331e-06,
      "loss": 0.0615,
      "step": 52780
    },
    {
      "epoch": 1.6162018185714722,
      "grad_norm": 0.14880476891994476,
      "learning_rate": 9.225525314065865e-06,
      "loss": 0.0333,
      "step": 52790
    },
    {
      "epoch": 1.6165079753849922,
      "grad_norm": 0.06154802069067955,
      "learning_rate": 9.2234842686424e-06,
      "loss": 0.0041,
      "step": 52800
    },
    {
      "epoch": 1.616814132198512,
      "grad_norm": 0.07061877846717834,
      "learning_rate": 9.221443223218934e-06,
      "loss": 0.0309,
      "step": 52810
    },
    {
      "epoch": 1.617120289012032,
      "grad_norm": 0.06191152706742287,
      "learning_rate": 9.219402177795467e-06,
      "loss": 0.0025,
      "step": 52820
    },
    {
      "epoch": 1.6174264458255518,
      "grad_norm": 0.07144417613744736,
      "learning_rate": 9.217361132372001e-06,
      "loss": 0.0281,
      "step": 52830
    },
    {
      "epoch": 1.6177326026390717,
      "grad_norm": 0.07227224856615067,
      "learning_rate": 9.215320086948536e-06,
      "loss": 0.0022,
      "step": 52840
    },
    {
      "epoch": 1.6180387594525916,
      "grad_norm": 0.03498711809515953,
      "learning_rate": 9.21327904152507e-06,
      "loss": 0.0346,
      "step": 52850
    },
    {
      "epoch": 1.6183449162661114,
      "grad_norm": 0.05206558108329773,
      "learning_rate": 9.211237996101603e-06,
      "loss": 0.0386,
      "step": 52860
    },
    {
      "epoch": 1.6186510730796315,
      "grad_norm": 0.11582206189632416,
      "learning_rate": 9.209196950678137e-06,
      "loss": 0.0269,
      "step": 52870
    },
    {
      "epoch": 1.6189572298931512,
      "grad_norm": 0.11366394907236099,
      "learning_rate": 9.207155905254672e-06,
      "loss": 0.0026,
      "step": 52880
    },
    {
      "epoch": 1.6192633867066712,
      "grad_norm": 0.09565071016550064,
      "learning_rate": 9.205114859831206e-06,
      "loss": 0.003,
      "step": 52890
    },
    {
      "epoch": 1.619569543520191,
      "grad_norm": 0.03730875998735428,
      "learning_rate": 9.20307381440774e-06,
      "loss": 0.0271,
      "step": 52900
    },
    {
      "epoch": 1.619875700333711,
      "grad_norm": 0.06201896816492081,
      "learning_rate": 9.201032768984275e-06,
      "loss": 0.0316,
      "step": 52910
    },
    {
      "epoch": 1.6201818571472308,
      "grad_norm": 0.036227140575647354,
      "learning_rate": 9.198991723560809e-06,
      "loss": 0.0018,
      "step": 52920
    },
    {
      "epoch": 1.6204880139607507,
      "grad_norm": 0.050062865018844604,
      "learning_rate": 9.196950678137342e-06,
      "loss": 0.0281,
      "step": 52930
    },
    {
      "epoch": 1.6207941707742706,
      "grad_norm": 0.02339584194123745,
      "learning_rate": 9.194909632713876e-06,
      "loss": 0.0021,
      "step": 52940
    },
    {
      "epoch": 1.6211003275877904,
      "grad_norm": 0.046199023723602295,
      "learning_rate": 9.192868587290411e-06,
      "loss": 0.0065,
      "step": 52950
    },
    {
      "epoch": 1.6214064844013103,
      "grad_norm": 0.03189960867166519,
      "learning_rate": 9.190827541866945e-06,
      "loss": 0.0021,
      "step": 52960
    },
    {
      "epoch": 1.6217126412148302,
      "grad_norm": 0.0465526282787323,
      "learning_rate": 9.188786496443479e-06,
      "loss": 0.0047,
      "step": 52970
    },
    {
      "epoch": 1.6220187980283503,
      "grad_norm": 0.08026646077632904,
      "learning_rate": 9.186745451020012e-06,
      "loss": 0.0022,
      "step": 52980
    },
    {
      "epoch": 1.62232495484187,
      "grad_norm": 0.04644537344574928,
      "learning_rate": 9.184704405596548e-06,
      "loss": 0.0028,
      "step": 52990
    },
    {
      "epoch": 1.62263111165539,
      "grad_norm": 0.05208192393183708,
      "learning_rate": 9.182663360173081e-06,
      "loss": 0.0343,
      "step": 53000
    },
    {
      "epoch": 1.6229372684689096,
      "grad_norm": 0.059506334364414215,
      "learning_rate": 9.180622314749615e-06,
      "loss": 0.0022,
      "step": 53010
    },
    {
      "epoch": 1.6232434252824297,
      "grad_norm": 0.004442049190402031,
      "learning_rate": 9.17858126932615e-06,
      "loss": 0.0195,
      "step": 53020
    },
    {
      "epoch": 1.6235495820959496,
      "grad_norm": 0.04810556024312973,
      "learning_rate": 9.176540223902684e-06,
      "loss": 0.0009,
      "step": 53030
    },
    {
      "epoch": 1.6238557389094694,
      "grad_norm": 0.038670219480991364,
      "learning_rate": 9.174499178479218e-06,
      "loss": 0.0379,
      "step": 53040
    },
    {
      "epoch": 1.6241618957229893,
      "grad_norm": 0.032034385949373245,
      "learning_rate": 9.172458133055751e-06,
      "loss": 0.0018,
      "step": 53050
    },
    {
      "epoch": 1.6244680525365092,
      "grad_norm": 0.023377060890197754,
      "learning_rate": 9.170417087632287e-06,
      "loss": 0.0361,
      "step": 53060
    },
    {
      "epoch": 1.624774209350029,
      "grad_norm": 0.03706071898341179,
      "learning_rate": 9.16837604220882e-06,
      "loss": 0.0017,
      "step": 53070
    },
    {
      "epoch": 1.625080366163549,
      "grad_norm": 0.042443808168172836,
      "learning_rate": 9.166334996785354e-06,
      "loss": 0.0021,
      "step": 53080
    },
    {
      "epoch": 1.625386522977069,
      "grad_norm": 0.03697313740849495,
      "learning_rate": 9.164293951361887e-06,
      "loss": 0.0308,
      "step": 53090
    },
    {
      "epoch": 1.6256926797905886,
      "grad_norm": 0.046701930463314056,
      "learning_rate": 9.162252905938423e-06,
      "loss": 0.0015,
      "step": 53100
    },
    {
      "epoch": 1.6259988366041087,
      "grad_norm": 0.006820491049438715,
      "learning_rate": 9.160211860514956e-06,
      "loss": 0.0015,
      "step": 53110
    },
    {
      "epoch": 1.6263049934176284,
      "grad_norm": 0.01798168756067753,
      "learning_rate": 9.15817081509149e-06,
      "loss": 0.0016,
      "step": 53120
    },
    {
      "epoch": 1.6266111502311484,
      "grad_norm": 0.021084988489747047,
      "learning_rate": 9.156129769668025e-06,
      "loss": 0.0009,
      "step": 53130
    },
    {
      "epoch": 1.6269173070446683,
      "grad_norm": 0.05537325143814087,
      "learning_rate": 9.154088724244559e-06,
      "loss": 0.0285,
      "step": 53140
    },
    {
      "epoch": 1.6272234638581882,
      "grad_norm": 0.017745327204465866,
      "learning_rate": 9.152047678821093e-06,
      "loss": 0.0031,
      "step": 53150
    },
    {
      "epoch": 1.627529620671708,
      "grad_norm": 0.03298367187380791,
      "learning_rate": 9.150006633397626e-06,
      "loss": 0.0368,
      "step": 53160
    },
    {
      "epoch": 1.627835777485228,
      "grad_norm": 2.6961662769317627,
      "learning_rate": 9.147965587974162e-06,
      "loss": 0.0099,
      "step": 53170
    },
    {
      "epoch": 1.628141934298748,
      "grad_norm": 0.015546631067991257,
      "learning_rate": 9.145924542550695e-06,
      "loss": 0.001,
      "step": 53180
    },
    {
      "epoch": 1.6284480911122676,
      "grad_norm": 0.05060163512825966,
      "learning_rate": 9.143883497127229e-06,
      "loss": 0.0012,
      "step": 53190
    },
    {
      "epoch": 1.6287542479257877,
      "grad_norm": 0.032385535538196564,
      "learning_rate": 9.141842451703763e-06,
      "loss": 0.001,
      "step": 53200
    },
    {
      "epoch": 1.6290604047393074,
      "grad_norm": 0.024342579767107964,
      "learning_rate": 9.139801406280298e-06,
      "loss": 0.0008,
      "step": 53210
    },
    {
      "epoch": 1.6293665615528274,
      "grad_norm": 0.0026294991839677095,
      "learning_rate": 9.137760360856832e-06,
      "loss": 0.0009,
      "step": 53220
    },
    {
      "epoch": 1.629672718366347,
      "grad_norm": 0.034572478383779526,
      "learning_rate": 9.135719315433365e-06,
      "loss": 0.001,
      "step": 53230
    },
    {
      "epoch": 1.6299788751798672,
      "grad_norm": 0.03140103816986084,
      "learning_rate": 9.1336782700099e-06,
      "loss": 0.0012,
      "step": 53240
    },
    {
      "epoch": 1.630285031993387,
      "grad_norm": 0.02831786684691906,
      "learning_rate": 9.131637224586434e-06,
      "loss": 0.0018,
      "step": 53250
    },
    {
      "epoch": 1.630591188806907,
      "grad_norm": 0.007217218168079853,
      "learning_rate": 9.129596179162968e-06,
      "loss": 0.0009,
      "step": 53260
    },
    {
      "epoch": 1.6308973456204268,
      "grad_norm": 0.0062677753157913685,
      "learning_rate": 9.127555133739502e-06,
      "loss": 0.0009,
      "step": 53270
    },
    {
      "epoch": 1.6312035024339466,
      "grad_norm": 0.012322026304900646,
      "learning_rate": 9.125514088316037e-06,
      "loss": 0.0009,
      "step": 53280
    },
    {
      "epoch": 1.6315096592474667,
      "grad_norm": 0.010300558060407639,
      "learning_rate": 9.12347304289257e-06,
      "loss": 0.0007,
      "step": 53290
    },
    {
      "epoch": 1.6318158160609864,
      "grad_norm": 0.01451016589999199,
      "learning_rate": 9.121431997469104e-06,
      "loss": 0.0331,
      "step": 53300
    },
    {
      "epoch": 1.6321219728745064,
      "grad_norm": 0.04126190021634102,
      "learning_rate": 9.119390952045638e-06,
      "loss": 0.0364,
      "step": 53310
    },
    {
      "epoch": 1.632428129688026,
      "grad_norm": 0.00685863196849823,
      "learning_rate": 9.117349906622173e-06,
      "loss": 0.0007,
      "step": 53320
    },
    {
      "epoch": 1.6327342865015462,
      "grad_norm": 0.020110437646508217,
      "learning_rate": 9.115308861198707e-06,
      "loss": 0.0011,
      "step": 53330
    },
    {
      "epoch": 1.6330404433150658,
      "grad_norm": 0.028909770771861076,
      "learning_rate": 9.11326781577524e-06,
      "loss": 0.0329,
      "step": 53340
    },
    {
      "epoch": 1.633346600128586,
      "grad_norm": 0.022090967744588852,
      "learning_rate": 9.111226770351776e-06,
      "loss": 0.0333,
      "step": 53350
    },
    {
      "epoch": 1.6336527569421058,
      "grad_norm": 0.059604186564683914,
      "learning_rate": 9.10918572492831e-06,
      "loss": 0.001,
      "step": 53360
    },
    {
      "epoch": 1.6339589137556256,
      "grad_norm": 0.05751612037420273,
      "learning_rate": 9.107144679504843e-06,
      "loss": 0.0013,
      "step": 53370
    },
    {
      "epoch": 1.6342650705691455,
      "grad_norm": 0.03167733550071716,
      "learning_rate": 9.105103634081377e-06,
      "loss": 0.0011,
      "step": 53380
    },
    {
      "epoch": 1.6345712273826654,
      "grad_norm": 0.018395399674773216,
      "learning_rate": 9.103062588657912e-06,
      "loss": 0.0297,
      "step": 53390
    },
    {
      "epoch": 1.6348773841961854,
      "grad_norm": 0.007581870071589947,
      "learning_rate": 9.101021543234446e-06,
      "loss": 0.0011,
      "step": 53400
    },
    {
      "epoch": 1.635183541009705,
      "grad_norm": 0.024378258734941483,
      "learning_rate": 9.09898049781098e-06,
      "loss": 0.0373,
      "step": 53410
    },
    {
      "epoch": 1.6354896978232252,
      "grad_norm": 0.012122956104576588,
      "learning_rate": 9.096939452387513e-06,
      "loss": 0.0007,
      "step": 53420
    },
    {
      "epoch": 1.6357958546367448,
      "grad_norm": 0.0028554650489240885,
      "learning_rate": 9.094898406964048e-06,
      "loss": 0.001,
      "step": 53430
    },
    {
      "epoch": 1.636102011450265,
      "grad_norm": 0.033841364085674286,
      "learning_rate": 9.092857361540582e-06,
      "loss": 0.0006,
      "step": 53440
    },
    {
      "epoch": 1.6364081682637845,
      "grad_norm": 0.023296406492590904,
      "learning_rate": 9.090816316117116e-06,
      "loss": 0.0032,
      "step": 53450
    },
    {
      "epoch": 1.6367143250773046,
      "grad_norm": 0.0392572246491909,
      "learning_rate": 9.088775270693651e-06,
      "loss": 0.0009,
      "step": 53460
    },
    {
      "epoch": 1.6370204818908245,
      "grad_norm": 0.007048274856060743,
      "learning_rate": 9.086734225270185e-06,
      "loss": 0.0006,
      "step": 53470
    },
    {
      "epoch": 1.6373266387043444,
      "grad_norm": 0.015911098569631577,
      "learning_rate": 9.084693179846718e-06,
      "loss": 0.0012,
      "step": 53480
    },
    {
      "epoch": 1.6376327955178642,
      "grad_norm": 0.006586611270904541,
      "learning_rate": 9.082652134423252e-06,
      "loss": 0.0007,
      "step": 53490
    },
    {
      "epoch": 1.637938952331384,
      "grad_norm": 0.01680011861026287,
      "learning_rate": 9.080611088999787e-06,
      "loss": 0.0012,
      "step": 53500
    },
    {
      "epoch": 1.6382451091449042,
      "grad_norm": 0.0036569309886544943,
      "learning_rate": 9.078570043576321e-06,
      "loss": 0.0008,
      "step": 53510
    },
    {
      "epoch": 1.6385512659584238,
      "grad_norm": 0.010218141600489616,
      "learning_rate": 9.076528998152854e-06,
      "loss": 0.0495,
      "step": 53520
    },
    {
      "epoch": 1.638857422771944,
      "grad_norm": 0.019296571612358093,
      "learning_rate": 9.074487952729388e-06,
      "loss": 0.0077,
      "step": 53530
    },
    {
      "epoch": 1.6391635795854635,
      "grad_norm": 0.017098095268011093,
      "learning_rate": 9.072446907305923e-06,
      "loss": 0.0007,
      "step": 53540
    },
    {
      "epoch": 1.6394697363989836,
      "grad_norm": 0.009318380616605282,
      "learning_rate": 9.070405861882457e-06,
      "loss": 0.0007,
      "step": 53550
    },
    {
      "epoch": 1.6397758932125035,
      "grad_norm": 0.019258569926023483,
      "learning_rate": 9.06836481645899e-06,
      "loss": 0.0006,
      "step": 53560
    },
    {
      "epoch": 1.6400820500260234,
      "grad_norm": 0.012730867601931095,
      "learning_rate": 9.066323771035526e-06,
      "loss": 0.034,
      "step": 53570
    },
    {
      "epoch": 1.6403882068395432,
      "grad_norm": 0.036867666989564896,
      "learning_rate": 9.06428272561206e-06,
      "loss": 0.0008,
      "step": 53580
    },
    {
      "epoch": 1.640694363653063,
      "grad_norm": 0.04771822690963745,
      "learning_rate": 9.062241680188593e-06,
      "loss": 0.0011,
      "step": 53590
    },
    {
      "epoch": 1.641000520466583,
      "grad_norm": 1.6501688957214355,
      "learning_rate": 9.060200634765127e-06,
      "loss": 0.0302,
      "step": 53600
    },
    {
      "epoch": 1.6413066772801028,
      "grad_norm": 0.007912827655673027,
      "learning_rate": 9.058159589341662e-06,
      "loss": 0.0007,
      "step": 53610
    },
    {
      "epoch": 1.641612834093623,
      "grad_norm": 0.014245705679059029,
      "learning_rate": 9.056118543918196e-06,
      "loss": 0.0007,
      "step": 53620
    },
    {
      "epoch": 1.6419189909071426,
      "grad_norm": 0.02856372483074665,
      "learning_rate": 9.05407749849473e-06,
      "loss": 0.0231,
      "step": 53630
    },
    {
      "epoch": 1.6422251477206626,
      "grad_norm": 0.01848630979657173,
      "learning_rate": 9.052036453071263e-06,
      "loss": 0.0009,
      "step": 53640
    },
    {
      "epoch": 1.6425313045341823,
      "grad_norm": 1.7652335166931152,
      "learning_rate": 9.049995407647799e-06,
      "loss": 0.0362,
      "step": 53650
    },
    {
      "epoch": 1.6428374613477024,
      "grad_norm": 0.03484039008617401,
      "learning_rate": 9.047954362224332e-06,
      "loss": 0.0008,
      "step": 53660
    },
    {
      "epoch": 1.6431436181612222,
      "grad_norm": 0.025224564597010612,
      "learning_rate": 9.045913316800866e-06,
      "loss": 0.0361,
      "step": 53670
    },
    {
      "epoch": 1.643449774974742,
      "grad_norm": 0.027230950072407722,
      "learning_rate": 9.043872271377401e-06,
      "loss": 0.0009,
      "step": 53680
    },
    {
      "epoch": 1.643755931788262,
      "grad_norm": 0.017222953960299492,
      "learning_rate": 9.041831225953935e-06,
      "loss": 0.0008,
      "step": 53690
    },
    {
      "epoch": 1.6440620886017818,
      "grad_norm": 0.023875605314970016,
      "learning_rate": 9.039790180530469e-06,
      "loss": 0.0011,
      "step": 53700
    },
    {
      "epoch": 1.6443682454153017,
      "grad_norm": 0.007096864283084869,
      "learning_rate": 9.037749135107002e-06,
      "loss": 0.0008,
      "step": 53710
    },
    {
      "epoch": 1.6446744022288216,
      "grad_norm": 0.015317713841795921,
      "learning_rate": 9.035708089683538e-06,
      "loss": 0.0009,
      "step": 53720
    },
    {
      "epoch": 1.6449805590423416,
      "grad_norm": 0.012088416144251823,
      "learning_rate": 9.033667044260071e-06,
      "loss": 0.0008,
      "step": 53730
    },
    {
      "epoch": 1.6452867158558613,
      "grad_norm": 0.026353968307375908,
      "learning_rate": 9.031625998836605e-06,
      "loss": 0.0008,
      "step": 53740
    },
    {
      "epoch": 1.6455928726693814,
      "grad_norm": 0.030199913308024406,
      "learning_rate": 9.029584953413138e-06,
      "loss": 0.0006,
      "step": 53750
    },
    {
      "epoch": 1.645899029482901,
      "grad_norm": 0.022795433178544044,
      "learning_rate": 9.027543907989674e-06,
      "loss": 0.0359,
      "step": 53760
    },
    {
      "epoch": 1.646205186296421,
      "grad_norm": 0.021829169243574142,
      "learning_rate": 9.025502862566207e-06,
      "loss": 0.0765,
      "step": 53770
    },
    {
      "epoch": 1.646511343109941,
      "grad_norm": 0.0211549773812294,
      "learning_rate": 9.023461817142741e-06,
      "loss": 0.0006,
      "step": 53780
    },
    {
      "epoch": 1.6468174999234608,
      "grad_norm": 0.02990240789949894,
      "learning_rate": 9.021420771719276e-06,
      "loss": 0.085,
      "step": 53790
    },
    {
      "epoch": 1.6471236567369807,
      "grad_norm": 0.050974782556295395,
      "learning_rate": 9.01937972629581e-06,
      "loss": 0.0011,
      "step": 53800
    },
    {
      "epoch": 1.6474298135505006,
      "grad_norm": 0.00932736974209547,
      "learning_rate": 9.017338680872344e-06,
      "loss": 0.001,
      "step": 53810
    },
    {
      "epoch": 1.6477359703640204,
      "grad_norm": 0.0001921845250762999,
      "learning_rate": 9.015297635448877e-06,
      "loss": 0.0416,
      "step": 53820
    },
    {
      "epoch": 1.6480421271775403,
      "grad_norm": 0.032986145466566086,
      "learning_rate": 9.013256590025413e-06,
      "loss": 0.0104,
      "step": 53830
    },
    {
      "epoch": 1.6483482839910604,
      "grad_norm": 1.8391127586364746,
      "learning_rate": 9.011215544601946e-06,
      "loss": 0.0334,
      "step": 53840
    },
    {
      "epoch": 1.64865444080458,
      "grad_norm": 0.010401951149106026,
      "learning_rate": 9.00917449917848e-06,
      "loss": 0.0017,
      "step": 53850
    },
    {
      "epoch": 1.6489605976181,
      "grad_norm": 0.03620011731982231,
      "learning_rate": 9.007133453755014e-06,
      "loss": 0.0011,
      "step": 53860
    },
    {
      "epoch": 1.6492667544316197,
      "grad_norm": 0.017592227086424828,
      "learning_rate": 9.005092408331549e-06,
      "loss": 0.0011,
      "step": 53870
    },
    {
      "epoch": 1.6495729112451398,
      "grad_norm": 0.019793236628174782,
      "learning_rate": 9.003051362908083e-06,
      "loss": 0.0241,
      "step": 53880
    },
    {
      "epoch": 1.6498790680586597,
      "grad_norm": 0.02806677855551243,
      "learning_rate": 9.001010317484616e-06,
      "loss": 0.0012,
      "step": 53890
    },
    {
      "epoch": 1.6501852248721796,
      "grad_norm": 0.03650224581360817,
      "learning_rate": 8.998969272061152e-06,
      "loss": 0.0372,
      "step": 53900
    },
    {
      "epoch": 1.6504913816856994,
      "grad_norm": 0.025428378954529762,
      "learning_rate": 8.996928226637685e-06,
      "loss": 0.0011,
      "step": 53910
    },
    {
      "epoch": 1.6507975384992193,
      "grad_norm": 0.03438910096883774,
      "learning_rate": 8.994887181214219e-06,
      "loss": 0.0352,
      "step": 53920
    },
    {
      "epoch": 1.6511036953127392,
      "grad_norm": 0.01901978626847267,
      "learning_rate": 8.992846135790753e-06,
      "loss": 0.0011,
      "step": 53930
    },
    {
      "epoch": 1.651409852126259,
      "grad_norm": 0.04470021650195122,
      "learning_rate": 8.990805090367288e-06,
      "loss": 0.0385,
      "step": 53940
    },
    {
      "epoch": 1.651716008939779,
      "grad_norm": 1.6031442880630493,
      "learning_rate": 8.988764044943822e-06,
      "loss": 0.0309,
      "step": 53950
    },
    {
      "epoch": 1.6520221657532987,
      "grad_norm": 0.025707989931106567,
      "learning_rate": 8.986722999520355e-06,
      "loss": 0.0012,
      "step": 53960
    },
    {
      "epoch": 1.6523283225668188,
      "grad_norm": 0.028906049206852913,
      "learning_rate": 8.984681954096889e-06,
      "loss": 0.0012,
      "step": 53970
    },
    {
      "epoch": 1.6526344793803385,
      "grad_norm": 0.01500791497528553,
      "learning_rate": 8.982640908673424e-06,
      "loss": 0.0294,
      "step": 53980
    },
    {
      "epoch": 1.6529406361938586,
      "grad_norm": 0.0720573365688324,
      "learning_rate": 8.980599863249956e-06,
      "loss": 0.0021,
      "step": 53990
    },
    {
      "epoch": 1.6532467930073784,
      "grad_norm": 0.04265535995364189,
      "learning_rate": 8.978558817826491e-06,
      "loss": 0.0407,
      "step": 54000
    },
    {
      "epoch": 1.6535529498208983,
      "grad_norm": 0.04550211504101753,
      "learning_rate": 8.976517772403025e-06,
      "loss": 0.0019,
      "step": 54010
    },
    {
      "epoch": 1.6538591066344182,
      "grad_norm": 1.0340100526809692,
      "learning_rate": 8.97447672697956e-06,
      "loss": 0.0025,
      "step": 54020
    },
    {
      "epoch": 1.654165263447938,
      "grad_norm": 1.6644190549850464,
      "learning_rate": 8.972435681556094e-06,
      "loss": 0.0556,
      "step": 54030
    },
    {
      "epoch": 1.6544714202614579,
      "grad_norm": 0.011612196452915668,
      "learning_rate": 8.970394636132628e-06,
      "loss": 0.0053,
      "step": 54040
    },
    {
      "epoch": 1.6547775770749777,
      "grad_norm": 0.0689958855509758,
      "learning_rate": 8.968353590709163e-06,
      "loss": 0.0653,
      "step": 54050
    },
    {
      "epoch": 1.6550837338884978,
      "grad_norm": 0.031195273622870445,
      "learning_rate": 8.966312545285695e-06,
      "loss": 0.0085,
      "step": 54060
    },
    {
      "epoch": 1.6553898907020175,
      "grad_norm": 0.03176051005721092,
      "learning_rate": 8.96427149986223e-06,
      "loss": 0.0145,
      "step": 54070
    },
    {
      "epoch": 1.6556960475155376,
      "grad_norm": 0.007766767404973507,
      "learning_rate": 8.962230454438764e-06,
      "loss": 0.002,
      "step": 54080
    },
    {
      "epoch": 1.6560022043290572,
      "grad_norm": 0.016836432740092278,
      "learning_rate": 8.9601894090153e-06,
      "loss": 0.0016,
      "step": 54090
    },
    {
      "epoch": 1.6563083611425773,
      "grad_norm": 0.06387608498334885,
      "learning_rate": 8.958148363591831e-06,
      "loss": 0.0282,
      "step": 54100
    },
    {
      "epoch": 1.6566145179560972,
      "grad_norm": 0.0792555958032608,
      "learning_rate": 8.956107318168367e-06,
      "loss": 0.0017,
      "step": 54110
    },
    {
      "epoch": 1.656920674769617,
      "grad_norm": 0.03759153187274933,
      "learning_rate": 8.9540662727449e-06,
      "loss": 0.002,
      "step": 54120
    },
    {
      "epoch": 1.6572268315831369,
      "grad_norm": 0.06218605488538742,
      "learning_rate": 8.952025227321436e-06,
      "loss": 0.0015,
      "step": 54130
    },
    {
      "epoch": 1.6575329883966567,
      "grad_norm": 0.03820833936333656,
      "learning_rate": 8.94998418189797e-06,
      "loss": 0.0016,
      "step": 54140
    },
    {
      "epoch": 1.6578391452101766,
      "grad_norm": 0.024509264156222343,
      "learning_rate": 8.947943136474503e-06,
      "loss": 0.001,
      "step": 54150
    },
    {
      "epoch": 1.6581453020236965,
      "grad_norm": 0.04140709340572357,
      "learning_rate": 8.945902091051038e-06,
      "loss": 0.0347,
      "step": 54160
    },
    {
      "epoch": 1.6584514588372166,
      "grad_norm": 0.049110088497400284,
      "learning_rate": 8.94386104562757e-06,
      "loss": 0.0379,
      "step": 54170
    },
    {
      "epoch": 1.6587576156507362,
      "grad_norm": 4.548840045928955,
      "learning_rate": 8.941820000204106e-06,
      "loss": 0.0079,
      "step": 54180
    },
    {
      "epoch": 1.6590637724642563,
      "grad_norm": 1.5265966653823853,
      "learning_rate": 8.93977895478064e-06,
      "loss": 0.0621,
      "step": 54190
    },
    {
      "epoch": 1.659369929277776,
      "grad_norm": 0.019273119047284126,
      "learning_rate": 8.937737909357174e-06,
      "loss": 0.0017,
      "step": 54200
    },
    {
      "epoch": 1.659676086091296,
      "grad_norm": 0.05474210903048515,
      "learning_rate": 8.935696863933706e-06,
      "loss": 0.0605,
      "step": 54210
    },
    {
      "epoch": 1.6599822429048159,
      "grad_norm": 0.07645027339458466,
      "learning_rate": 8.933655818510242e-06,
      "loss": 0.1244,
      "step": 54220
    },
    {
      "epoch": 1.6602883997183358,
      "grad_norm": 0.05004328116774559,
      "learning_rate": 8.931614773086775e-06,
      "loss": 0.004,
      "step": 54230
    },
    {
      "epoch": 1.6605945565318556,
      "grad_norm": 0.06486780941486359,
      "learning_rate": 8.929573727663309e-06,
      "loss": 0.0295,
      "step": 54240
    },
    {
      "epoch": 1.6609007133453755,
      "grad_norm": 0.16054204106330872,
      "learning_rate": 8.927532682239844e-06,
      "loss": 0.0884,
      "step": 54250
    },
    {
      "epoch": 1.6612068701588953,
      "grad_norm": 0.10832604765892029,
      "learning_rate": 8.925491636816378e-06,
      "loss": 0.0037,
      "step": 54260
    },
    {
      "epoch": 1.6615130269724152,
      "grad_norm": 0.036738451570272446,
      "learning_rate": 8.923450591392913e-06,
      "loss": 0.0042,
      "step": 54270
    },
    {
      "epoch": 1.6618191837859353,
      "grad_norm": 1.6416863203048706,
      "learning_rate": 8.921409545969445e-06,
      "loss": 0.0314,
      "step": 54280
    },
    {
      "epoch": 1.662125340599455,
      "grad_norm": 0.07631988078355789,
      "learning_rate": 8.91936850054598e-06,
      "loss": 0.0279,
      "step": 54290
    },
    {
      "epoch": 1.662431497412975,
      "grad_norm": 0.06716413795948029,
      "learning_rate": 8.917327455122514e-06,
      "loss": 0.0045,
      "step": 54300
    },
    {
      "epoch": 1.6627376542264947,
      "grad_norm": 0.054331306368112564,
      "learning_rate": 8.915286409699048e-06,
      "loss": 0.0026,
      "step": 54310
    },
    {
      "epoch": 1.6630438110400148,
      "grad_norm": 0.03924517333507538,
      "learning_rate": 8.913245364275582e-06,
      "loss": 0.0018,
      "step": 54320
    },
    {
      "epoch": 1.6633499678535346,
      "grad_norm": 0.05063087120652199,
      "learning_rate": 8.911204318852117e-06,
      "loss": 0.0022,
      "step": 54330
    },
    {
      "epoch": 1.6636561246670545,
      "grad_norm": 0.059715114533901215,
      "learning_rate": 8.90916327342865e-06,
      "loss": 0.0353,
      "step": 54340
    },
    {
      "epoch": 1.6639622814805743,
      "grad_norm": 0.0924183800816536,
      "learning_rate": 8.907122228005184e-06,
      "loss": 0.0024,
      "step": 54350
    },
    {
      "epoch": 1.6642684382940942,
      "grad_norm": 0.07547137886285782,
      "learning_rate": 8.90508118258172e-06,
      "loss": 0.0027,
      "step": 54360
    },
    {
      "epoch": 1.664574595107614,
      "grad_norm": 0.012352477759122849,
      "learning_rate": 8.903040137158253e-06,
      "loss": 0.0125,
      "step": 54370
    },
    {
      "epoch": 1.664880751921134,
      "grad_norm": 0.07370682805776596,
      "learning_rate": 8.900999091734787e-06,
      "loss": 0.0394,
      "step": 54380
    },
    {
      "epoch": 1.665186908734654,
      "grad_norm": 0.05187346413731575,
      "learning_rate": 8.89895804631132e-06,
      "loss": 0.0344,
      "step": 54390
    },
    {
      "epoch": 1.6654930655481737,
      "grad_norm": 0.01714698225259781,
      "learning_rate": 8.896917000887856e-06,
      "loss": 0.0376,
      "step": 54400
    },
    {
      "epoch": 1.6657992223616938,
      "grad_norm": 0.017443934455513954,
      "learning_rate": 8.89487595546439e-06,
      "loss": 0.0015,
      "step": 54410
    },
    {
      "epoch": 1.6661053791752134,
      "grad_norm": 0.054706212133169174,
      "learning_rate": 8.892834910040923e-06,
      "loss": 0.0033,
      "step": 54420
    },
    {
      "epoch": 1.6664115359887335,
      "grad_norm": 0.01126715075224638,
      "learning_rate": 8.890793864617457e-06,
      "loss": 0.0019,
      "step": 54430
    },
    {
      "epoch": 1.6667176928022533,
      "grad_norm": 0.029560551047325134,
      "learning_rate": 8.888752819193992e-06,
      "loss": 0.0014,
      "step": 54440
    },
    {
      "epoch": 1.6670238496157732,
      "grad_norm": 0.012619048357009888,
      "learning_rate": 8.886711773770526e-06,
      "loss": 0.0019,
      "step": 54450
    },
    {
      "epoch": 1.667330006429293,
      "grad_norm": 0.060895808041095734,
      "learning_rate": 8.88467072834706e-06,
      "loss": 0.0016,
      "step": 54460
    },
    {
      "epoch": 1.667636163242813,
      "grad_norm": 0.03894714638590813,
      "learning_rate": 8.882629682923595e-06,
      "loss": 0.0318,
      "step": 54470
    },
    {
      "epoch": 1.6679423200563328,
      "grad_norm": 0.13916970789432526,
      "learning_rate": 8.880588637500128e-06,
      "loss": 0.0034,
      "step": 54480
    },
    {
      "epoch": 1.6682484768698527,
      "grad_norm": 0.017035802826285362,
      "learning_rate": 8.878547592076662e-06,
      "loss": 0.0298,
      "step": 54490
    },
    {
      "epoch": 1.6685546336833728,
      "grad_norm": 1.8150737285614014,
      "learning_rate": 8.876506546653196e-06,
      "loss": 0.0386,
      "step": 54500
    },
    {
      "epoch": 1.6688607904968924,
      "grad_norm": 0.23142312467098236,
      "learning_rate": 8.874465501229731e-06,
      "loss": 0.0019,
      "step": 54510
    },
    {
      "epoch": 1.6691669473104125,
      "grad_norm": 0.01088059600442648,
      "learning_rate": 8.872424455806265e-06,
      "loss": 0.0011,
      "step": 54520
    },
    {
      "epoch": 1.6694731041239321,
      "grad_norm": 0.04207676649093628,
      "learning_rate": 8.870383410382798e-06,
      "loss": 0.0018,
      "step": 54530
    },
    {
      "epoch": 1.6697792609374522,
      "grad_norm": 0.05298130586743355,
      "learning_rate": 8.868342364959332e-06,
      "loss": 0.0021,
      "step": 54540
    },
    {
      "epoch": 1.670085417750972,
      "grad_norm": 0.022878268733620644,
      "learning_rate": 8.866301319535867e-06,
      "loss": 0.0275,
      "step": 54550
    },
    {
      "epoch": 1.670391574564492,
      "grad_norm": 0.013285527005791664,
      "learning_rate": 8.864260274112401e-06,
      "loss": 0.0302,
      "step": 54560
    },
    {
      "epoch": 1.6706977313780118,
      "grad_norm": 0.01115304697304964,
      "learning_rate": 8.862219228688935e-06,
      "loss": 0.0017,
      "step": 54570
    },
    {
      "epoch": 1.6710038881915317,
      "grad_norm": 0.016857728362083435,
      "learning_rate": 8.860178183265468e-06,
      "loss": 0.0017,
      "step": 54580
    },
    {
      "epoch": 1.6713100450050515,
      "grad_norm": 0.061452656984329224,
      "learning_rate": 8.858137137842004e-06,
      "loss": 0.0708,
      "step": 54590
    },
    {
      "epoch": 1.6716162018185714,
      "grad_norm": 0.013437922112643719,
      "learning_rate": 8.856096092418537e-06,
      "loss": 0.0086,
      "step": 54600
    },
    {
      "epoch": 1.6719223586320915,
      "grad_norm": 0.03556307405233383,
      "learning_rate": 8.854055046995071e-06,
      "loss": 0.0021,
      "step": 54610
    },
    {
      "epoch": 1.6722285154456111,
      "grad_norm": 0.04631274566054344,
      "learning_rate": 8.852014001571606e-06,
      "loss": 0.0019,
      "step": 54620
    },
    {
      "epoch": 1.6725346722591312,
      "grad_norm": 0.03794235363602638,
      "learning_rate": 8.84997295614814e-06,
      "loss": 0.0339,
      "step": 54630
    },
    {
      "epoch": 1.6728408290726509,
      "grad_norm": 0.03264450654387474,
      "learning_rate": 8.847931910724673e-06,
      "loss": 0.0017,
      "step": 54640
    },
    {
      "epoch": 1.673146985886171,
      "grad_norm": 0.0678606629371643,
      "learning_rate": 8.845890865301207e-06,
      "loss": 0.0016,
      "step": 54650
    },
    {
      "epoch": 1.6734531426996908,
      "grad_norm": 0.050646569579839706,
      "learning_rate": 8.843849819877742e-06,
      "loss": 0.0016,
      "step": 54660
    },
    {
      "epoch": 1.6737592995132107,
      "grad_norm": 0.030489683151245117,
      "learning_rate": 8.841808774454276e-06,
      "loss": 0.0292,
      "step": 54670
    },
    {
      "epoch": 1.6740654563267305,
      "grad_norm": 0.06365321576595306,
      "learning_rate": 8.83976772903081e-06,
      "loss": 0.0019,
      "step": 54680
    },
    {
      "epoch": 1.6743716131402504,
      "grad_norm": 0.016015373170375824,
      "learning_rate": 8.837726683607343e-06,
      "loss": 0.0403,
      "step": 54690
    },
    {
      "epoch": 1.6746777699537703,
      "grad_norm": 0.04124937206506729,
      "learning_rate": 8.835685638183879e-06,
      "loss": 0.0013,
      "step": 54700
    },
    {
      "epoch": 1.6749839267672901,
      "grad_norm": 0.029739292338490486,
      "learning_rate": 8.833644592760412e-06,
      "loss": 0.0012,
      "step": 54710
    },
    {
      "epoch": 1.6752900835808102,
      "grad_norm": 0.014949328266084194,
      "learning_rate": 8.831603547336946e-06,
      "loss": 0.0391,
      "step": 54720
    },
    {
      "epoch": 1.6755962403943299,
      "grad_norm": 0.017421673983335495,
      "learning_rate": 8.829562501913481e-06,
      "loss": 0.0029,
      "step": 54730
    },
    {
      "epoch": 1.67590239720785,
      "grad_norm": 0.14239297807216644,
      "learning_rate": 8.827521456490015e-06,
      "loss": 0.0018,
      "step": 54740
    },
    {
      "epoch": 1.6762085540213696,
      "grad_norm": 0.04108208790421486,
      "learning_rate": 8.825480411066549e-06,
      "loss": 0.0014,
      "step": 54750
    },
    {
      "epoch": 1.6765147108348897,
      "grad_norm": 0.031170139089226723,
      "learning_rate": 8.823439365643082e-06,
      "loss": 0.0012,
      "step": 54760
    },
    {
      "epoch": 1.6768208676484095,
      "grad_norm": 0.02533370442688465,
      "learning_rate": 8.821398320219618e-06,
      "loss": 0.001,
      "step": 54770
    },
    {
      "epoch": 1.6771270244619294,
      "grad_norm": 0.0416681244969368,
      "learning_rate": 8.819357274796151e-06,
      "loss": 0.0308,
      "step": 54780
    },
    {
      "epoch": 1.6774331812754493,
      "grad_norm": 0.009174629114568233,
      "learning_rate": 8.817316229372685e-06,
      "loss": 0.0012,
      "step": 54790
    },
    {
      "epoch": 1.6777393380889691,
      "grad_norm": 0.038286175578832626,
      "learning_rate": 8.815275183949219e-06,
      "loss": 0.0319,
      "step": 54800
    },
    {
      "epoch": 1.6780454949024892,
      "grad_norm": 0.010914867743849754,
      "learning_rate": 8.813234138525754e-06,
      "loss": 0.0023,
      "step": 54810
    },
    {
      "epoch": 1.6783516517160089,
      "grad_norm": 0.01396770216524601,
      "learning_rate": 8.811193093102288e-06,
      "loss": 0.0012,
      "step": 54820
    },
    {
      "epoch": 1.678657808529529,
      "grad_norm": 0.015746112912893295,
      "learning_rate": 8.809152047678821e-06,
      "loss": 0.0008,
      "step": 54830
    },
    {
      "epoch": 1.6789639653430486,
      "grad_norm": 0.060445480048656464,
      "learning_rate": 8.807111002255357e-06,
      "loss": 0.0456,
      "step": 54840
    },
    {
      "epoch": 1.6792701221565687,
      "grad_norm": 0.01072363555431366,
      "learning_rate": 8.80506995683189e-06,
      "loss": 0.0013,
      "step": 54850
    },
    {
      "epoch": 1.6795762789700883,
      "grad_norm": 0.06131770461797714,
      "learning_rate": 8.803028911408424e-06,
      "loss": 0.0084,
      "step": 54860
    },
    {
      "epoch": 1.6798824357836084,
      "grad_norm": 0.037289589643478394,
      "learning_rate": 8.800987865984957e-06,
      "loss": 0.0014,
      "step": 54870
    },
    {
      "epoch": 1.6801885925971283,
      "grad_norm": 0.0435466393828392,
      "learning_rate": 8.798946820561493e-06,
      "loss": 0.014,
      "step": 54880
    },
    {
      "epoch": 1.6804947494106481,
      "grad_norm": 0.02500053122639656,
      "learning_rate": 8.796905775138026e-06,
      "loss": 0.0011,
      "step": 54890
    },
    {
      "epoch": 1.680800906224168,
      "grad_norm": 0.019281458109617233,
      "learning_rate": 8.79486472971456e-06,
      "loss": 0.0009,
      "step": 54900
    },
    {
      "epoch": 1.6811070630376879,
      "grad_norm": 0.013424287550151348,
      "learning_rate": 8.792823684291094e-06,
      "loss": 0.0379,
      "step": 54910
    },
    {
      "epoch": 1.681413219851208,
      "grad_norm": 0.02697736956179142,
      "learning_rate": 8.790782638867629e-06,
      "loss": 0.0036,
      "step": 54920
    },
    {
      "epoch": 1.6817193766647276,
      "grad_norm": 0.02660052292048931,
      "learning_rate": 8.788741593444163e-06,
      "loss": 0.001,
      "step": 54930
    },
    {
      "epoch": 1.6820255334782477,
      "grad_norm": 0.04446634277701378,
      "learning_rate": 8.786700548020696e-06,
      "loss": 0.0008,
      "step": 54940
    },
    {
      "epoch": 1.6823316902917673,
      "grad_norm": 0.023638354614377022,
      "learning_rate": 8.784659502597232e-06,
      "loss": 0.0009,
      "step": 54950
    },
    {
      "epoch": 1.6826378471052874,
      "grad_norm": 0.01668098196387291,
      "learning_rate": 8.782618457173765e-06,
      "loss": 0.0011,
      "step": 54960
    },
    {
      "epoch": 1.682944003918807,
      "grad_norm": 0.014486929401755333,
      "learning_rate": 8.780577411750299e-06,
      "loss": 0.0326,
      "step": 54970
    },
    {
      "epoch": 1.6832501607323271,
      "grad_norm": 0.02921866625547409,
      "learning_rate": 8.778536366326833e-06,
      "loss": 0.0012,
      "step": 54980
    },
    {
      "epoch": 1.683556317545847,
      "grad_norm": 0.019870217889547348,
      "learning_rate": 8.776495320903368e-06,
      "loss": 0.0377,
      "step": 54990
    },
    {
      "epoch": 1.6838624743593669,
      "grad_norm": 0.02116052806377411,
      "learning_rate": 8.774454275479902e-06,
      "loss": 0.0265,
      "step": 55000
    },
    {
      "epoch": 1.6841686311728867,
      "grad_norm": 0.026195986196398735,
      "learning_rate": 8.772413230056435e-06,
      "loss": 0.0017,
      "step": 55010
    },
    {
      "epoch": 1.6844747879864066,
      "grad_norm": 0.00694352388381958,
      "learning_rate": 8.770372184632969e-06,
      "loss": 0.0011,
      "step": 55020
    },
    {
      "epoch": 1.6847809447999267,
      "grad_norm": 0.022268695756793022,
      "learning_rate": 8.768331139209504e-06,
      "loss": 0.0008,
      "step": 55030
    },
    {
      "epoch": 1.6850871016134463,
      "grad_norm": 1.6863765716552734,
      "learning_rate": 8.766290093786038e-06,
      "loss": 0.0342,
      "step": 55040
    },
    {
      "epoch": 1.6853932584269664,
      "grad_norm": 0.015293421223759651,
      "learning_rate": 8.764249048362572e-06,
      "loss": 0.0009,
      "step": 55050
    },
    {
      "epoch": 1.685699415240486,
      "grad_norm": 0.011960534378886223,
      "learning_rate": 8.762208002939107e-06,
      "loss": 0.0008,
      "step": 55060
    },
    {
      "epoch": 1.6860055720540061,
      "grad_norm": 0.024035319685935974,
      "learning_rate": 8.76016695751564e-06,
      "loss": 0.0066,
      "step": 55070
    },
    {
      "epoch": 1.6863117288675258,
      "grad_norm": 0.07119524478912354,
      "learning_rate": 8.758125912092174e-06,
      "loss": 0.0014,
      "step": 55080
    },
    {
      "epoch": 1.6866178856810459,
      "grad_norm": 0.014293924905359745,
      "learning_rate": 8.756084866668708e-06,
      "loss": 0.0016,
      "step": 55090
    },
    {
      "epoch": 1.6869240424945657,
      "grad_norm": 0.028619730845093727,
      "learning_rate": 8.754043821245243e-06,
      "loss": 0.0393,
      "step": 55100
    },
    {
      "epoch": 1.6872301993080856,
      "grad_norm": 0.025073667988181114,
      "learning_rate": 8.752002775821777e-06,
      "loss": 0.0012,
      "step": 55110
    },
    {
      "epoch": 1.6875363561216055,
      "grad_norm": 0.026734666898846626,
      "learning_rate": 8.74996173039831e-06,
      "loss": 0.002,
      "step": 55120
    },
    {
      "epoch": 1.6878425129351253,
      "grad_norm": 0.006924359127879143,
      "learning_rate": 8.747920684974844e-06,
      "loss": 0.0013,
      "step": 55130
    },
    {
      "epoch": 1.6881486697486454,
      "grad_norm": 0.00694566685706377,
      "learning_rate": 8.74587963955138e-06,
      "loss": 0.0008,
      "step": 55140
    },
    {
      "epoch": 1.688454826562165,
      "grad_norm": 0.025936001911759377,
      "learning_rate": 8.743838594127913e-06,
      "loss": 0.0011,
      "step": 55150
    },
    {
      "epoch": 1.6887609833756851,
      "grad_norm": 0.017198994755744934,
      "learning_rate": 8.741797548704447e-06,
      "loss": 0.0007,
      "step": 55160
    },
    {
      "epoch": 1.6890671401892048,
      "grad_norm": 0.024633437395095825,
      "learning_rate": 8.739756503280982e-06,
      "loss": 0.001,
      "step": 55170
    },
    {
      "epoch": 1.6893732970027249,
      "grad_norm": 0.016345608979463577,
      "learning_rate": 8.737715457857516e-06,
      "loss": 0.0009,
      "step": 55180
    },
    {
      "epoch": 1.6896794538162445,
      "grad_norm": 0.003336622379720211,
      "learning_rate": 8.73567441243405e-06,
      "loss": 0.0083,
      "step": 55190
    },
    {
      "epoch": 1.6899856106297646,
      "grad_norm": 0.017650455236434937,
      "learning_rate": 8.733633367010583e-06,
      "loss": 0.0009,
      "step": 55200
    },
    {
      "epoch": 1.6902917674432845,
      "grad_norm": 0.014311463572084904,
      "learning_rate": 8.731592321587118e-06,
      "loss": 0.0363,
      "step": 55210
    },
    {
      "epoch": 1.6905979242568043,
      "grad_norm": 0.026976963505148888,
      "learning_rate": 8.729551276163652e-06,
      "loss": 0.0042,
      "step": 55220
    },
    {
      "epoch": 1.6909040810703242,
      "grad_norm": 0.020679745823144913,
      "learning_rate": 8.727510230740186e-06,
      "loss": 0.0007,
      "step": 55230
    },
    {
      "epoch": 1.691210237883844,
      "grad_norm": 0.046223144978284836,
      "learning_rate": 8.72546918531672e-06,
      "loss": 0.0367,
      "step": 55240
    },
    {
      "epoch": 1.6915163946973641,
      "grad_norm": 0.004462564364075661,
      "learning_rate": 8.723428139893255e-06,
      "loss": 0.0007,
      "step": 55250
    },
    {
      "epoch": 1.6918225515108838,
      "grad_norm": 0.01631067506968975,
      "learning_rate": 8.721387094469788e-06,
      "loss": 0.0006,
      "step": 55260
    },
    {
      "epoch": 1.6921287083244039,
      "grad_norm": 0.014493427239358425,
      "learning_rate": 8.719346049046322e-06,
      "loss": 0.0346,
      "step": 55270
    },
    {
      "epoch": 1.6924348651379235,
      "grad_norm": 0.016599539667367935,
      "learning_rate": 8.717305003622857e-06,
      "loss": 0.0006,
      "step": 55280
    },
    {
      "epoch": 1.6927410219514436,
      "grad_norm": 0.01604350656270981,
      "learning_rate": 8.715263958199391e-06,
      "loss": 0.0009,
      "step": 55290
    },
    {
      "epoch": 1.6930471787649635,
      "grad_norm": 0.024600788950920105,
      "learning_rate": 8.713222912775924e-06,
      "loss": 0.037,
      "step": 55300
    },
    {
      "epoch": 1.6933533355784833,
      "grad_norm": 2.1852707862854004,
      "learning_rate": 8.711181867352458e-06,
      "loss": 0.027,
      "step": 55310
    },
    {
      "epoch": 1.6936594923920032,
      "grad_norm": 0.02285170555114746,
      "learning_rate": 8.709140821928993e-06,
      "loss": 0.0011,
      "step": 55320
    },
    {
      "epoch": 1.693965649205523,
      "grad_norm": 0.006726158317178488,
      "learning_rate": 8.707099776505527e-06,
      "loss": 0.0351,
      "step": 55330
    },
    {
      "epoch": 1.694271806019043,
      "grad_norm": 0.03538442403078079,
      "learning_rate": 8.70505873108206e-06,
      "loss": 0.0009,
      "step": 55340
    },
    {
      "epoch": 1.6945779628325628,
      "grad_norm": 0.026245368644595146,
      "learning_rate": 8.703017685658594e-06,
      "loss": 0.0312,
      "step": 55350
    },
    {
      "epoch": 1.6948841196460829,
      "grad_norm": 0.014799782074987888,
      "learning_rate": 8.70097664023513e-06,
      "loss": 0.0363,
      "step": 55360
    },
    {
      "epoch": 1.6951902764596025,
      "grad_norm": 0.017738107591867447,
      "learning_rate": 8.698935594811663e-06,
      "loss": 0.0011,
      "step": 55370
    },
    {
      "epoch": 1.6954964332731226,
      "grad_norm": 0.014662169851362705,
      "learning_rate": 8.696894549388197e-06,
      "loss": 0.0364,
      "step": 55380
    },
    {
      "epoch": 1.6958025900866422,
      "grad_norm": 0.007433133665472269,
      "learning_rate": 8.694853503964732e-06,
      "loss": 0.0348,
      "step": 55390
    },
    {
      "epoch": 1.6961087469001623,
      "grad_norm": 0.00798031222075224,
      "learning_rate": 8.692812458541266e-06,
      "loss": 0.001,
      "step": 55400
    },
    {
      "epoch": 1.6964149037136822,
      "grad_norm": 0.02063017524778843,
      "learning_rate": 8.6907714131178e-06,
      "loss": 0.001,
      "step": 55410
    },
    {
      "epoch": 1.696721060527202,
      "grad_norm": 0.04349961131811142,
      "learning_rate": 8.688730367694333e-06,
      "loss": 0.0011,
      "step": 55420
    },
    {
      "epoch": 1.697027217340722,
      "grad_norm": 1.677114486694336,
      "learning_rate": 8.686689322270869e-06,
      "loss": 0.0318,
      "step": 55430
    },
    {
      "epoch": 1.6973333741542418,
      "grad_norm": 0.021352311596274376,
      "learning_rate": 8.684648276847402e-06,
      "loss": 0.0014,
      "step": 55440
    },
    {
      "epoch": 1.6976395309677617,
      "grad_norm": 0.03974296525120735,
      "learning_rate": 8.682607231423936e-06,
      "loss": 0.001,
      "step": 55450
    },
    {
      "epoch": 1.6979456877812815,
      "grad_norm": 0.028989139944314957,
      "learning_rate": 8.68056618600047e-06,
      "loss": 0.0009,
      "step": 55460
    },
    {
      "epoch": 1.6982518445948016,
      "grad_norm": 0.006010240875184536,
      "learning_rate": 8.678525140577005e-06,
      "loss": 0.0016,
      "step": 55470
    },
    {
      "epoch": 1.6985580014083212,
      "grad_norm": 0.04032386466860771,
      "learning_rate": 8.676484095153539e-06,
      "loss": 0.0021,
      "step": 55480
    },
    {
      "epoch": 1.6988641582218413,
      "grad_norm": 0.024408766999840736,
      "learning_rate": 8.674443049730072e-06,
      "loss": 0.0011,
      "step": 55490
    },
    {
      "epoch": 1.699170315035361,
      "grad_norm": 0.01470449473708868,
      "learning_rate": 8.672402004306608e-06,
      "loss": 0.001,
      "step": 55500
    },
    {
      "epoch": 1.699476471848881,
      "grad_norm": 0.005372599698603153,
      "learning_rate": 8.670360958883141e-06,
      "loss": 0.0009,
      "step": 55510
    },
    {
      "epoch": 1.699782628662401,
      "grad_norm": 0.02991199865937233,
      "learning_rate": 8.668319913459675e-06,
      "loss": 0.0284,
      "step": 55520
    },
    {
      "epoch": 1.7000887854759208,
      "grad_norm": 0.025333009660243988,
      "learning_rate": 8.666278868036208e-06,
      "loss": 0.001,
      "step": 55530
    },
    {
      "epoch": 1.7003949422894407,
      "grad_norm": 0.02301730029284954,
      "learning_rate": 8.664237822612744e-06,
      "loss": 0.0012,
      "step": 55540
    },
    {
      "epoch": 1.7007010991029605,
      "grad_norm": 0.03536190465092659,
      "learning_rate": 8.662196777189277e-06,
      "loss": 0.0356,
      "step": 55550
    },
    {
      "epoch": 1.7010072559164804,
      "grad_norm": 0.021612802520394325,
      "learning_rate": 8.660155731765811e-06,
      "loss": 0.0368,
      "step": 55560
    },
    {
      "epoch": 1.7013134127300003,
      "grad_norm": 0.018852833658456802,
      "learning_rate": 8.658114686342345e-06,
      "loss": 0.0634,
      "step": 55570
    },
    {
      "epoch": 1.7016195695435203,
      "grad_norm": 0.056449923664331436,
      "learning_rate": 8.65607364091888e-06,
      "loss": 0.002,
      "step": 55580
    },
    {
      "epoch": 1.70192572635704,
      "grad_norm": 0.053096529096364975,
      "learning_rate": 8.654032595495414e-06,
      "loss": 0.0184,
      "step": 55590
    },
    {
      "epoch": 1.70223188317056,
      "grad_norm": 0.01910935342311859,
      "learning_rate": 8.651991550071947e-06,
      "loss": 0.0413,
      "step": 55600
    },
    {
      "epoch": 1.7025380399840797,
      "grad_norm": 0.022729530930519104,
      "learning_rate": 8.649950504648483e-06,
      "loss": 0.0386,
      "step": 55610
    },
    {
      "epoch": 1.7028441967975998,
      "grad_norm": 0.067656010389328,
      "learning_rate": 8.647909459225016e-06,
      "loss": 0.0071,
      "step": 55620
    },
    {
      "epoch": 1.7031503536111197,
      "grad_norm": 0.020977435633540154,
      "learning_rate": 8.64586841380155e-06,
      "loss": 0.0333,
      "step": 55630
    },
    {
      "epoch": 1.7034565104246395,
      "grad_norm": 0.03567332774400711,
      "learning_rate": 8.643827368378084e-06,
      "loss": 0.0031,
      "step": 55640
    },
    {
      "epoch": 1.7037626672381594,
      "grad_norm": 0.05104311555624008,
      "learning_rate": 8.641786322954619e-06,
      "loss": 0.002,
      "step": 55650
    },
    {
      "epoch": 1.7040688240516793,
      "grad_norm": 1.724379062652588,
      "learning_rate": 8.639745277531153e-06,
      "loss": 0.0376,
      "step": 55660
    },
    {
      "epoch": 1.7043749808651991,
      "grad_norm": 0.041812263429164886,
      "learning_rate": 8.637704232107686e-06,
      "loss": 0.0013,
      "step": 55670
    },
    {
      "epoch": 1.704681137678719,
      "grad_norm": 0.023405877873301506,
      "learning_rate": 8.63566318668422e-06,
      "loss": 0.0013,
      "step": 55680
    },
    {
      "epoch": 1.704987294492239,
      "grad_norm": 0.04576388746500015,
      "learning_rate": 8.633622141260755e-06,
      "loss": 0.0013,
      "step": 55690
    },
    {
      "epoch": 1.7052934513057587,
      "grad_norm": 0.029836077243089676,
      "learning_rate": 8.631581095837289e-06,
      "loss": 0.0013,
      "step": 55700
    },
    {
      "epoch": 1.7055996081192788,
      "grad_norm": 0.012389118783175945,
      "learning_rate": 8.629540050413823e-06,
      "loss": 0.0014,
      "step": 55710
    },
    {
      "epoch": 1.7059057649327984,
      "grad_norm": 0.1394745260477066,
      "learning_rate": 8.627499004990358e-06,
      "loss": 0.0396,
      "step": 55720
    },
    {
      "epoch": 1.7062119217463185,
      "grad_norm": 0.3061196506023407,
      "learning_rate": 8.625457959566892e-06,
      "loss": 0.1039,
      "step": 55730
    },
    {
      "epoch": 1.7065180785598384,
      "grad_norm": 0.018864667043089867,
      "learning_rate": 8.623416914143425e-06,
      "loss": 0.0014,
      "step": 55740
    },
    {
      "epoch": 1.7068242353733583,
      "grad_norm": 0.0428040437400341,
      "learning_rate": 8.621375868719959e-06,
      "loss": 0.0444,
      "step": 55750
    },
    {
      "epoch": 1.7071303921868781,
      "grad_norm": 0.004714768845587969,
      "learning_rate": 8.619334823296494e-06,
      "loss": 0.0014,
      "step": 55760
    },
    {
      "epoch": 1.707436549000398,
      "grad_norm": 0.04333662986755371,
      "learning_rate": 8.617293777873028e-06,
      "loss": 0.0018,
      "step": 55770
    },
    {
      "epoch": 1.7077427058139178,
      "grad_norm": 0.0370185486972332,
      "learning_rate": 8.615252732449561e-06,
      "loss": 0.0025,
      "step": 55780
    },
    {
      "epoch": 1.7080488626274377,
      "grad_norm": 0.030699681490659714,
      "learning_rate": 8.613211687026095e-06,
      "loss": 0.0014,
      "step": 55790
    },
    {
      "epoch": 1.7083550194409578,
      "grad_norm": 0.03162338212132454,
      "learning_rate": 8.61117064160263e-06,
      "loss": 0.0015,
      "step": 55800
    },
    {
      "epoch": 1.7086611762544774,
      "grad_norm": 0.04364573955535889,
      "learning_rate": 8.609129596179162e-06,
      "loss": 0.0331,
      "step": 55810
    },
    {
      "epoch": 1.7089673330679975,
      "grad_norm": 0.03915735334157944,
      "learning_rate": 8.607088550755698e-06,
      "loss": 0.001,
      "step": 55820
    },
    {
      "epoch": 1.7092734898815172,
      "grad_norm": 0.004911357536911964,
      "learning_rate": 8.605047505332231e-06,
      "loss": 0.0014,
      "step": 55830
    },
    {
      "epoch": 1.7095796466950373,
      "grad_norm": 0.02632281556725502,
      "learning_rate": 8.603006459908767e-06,
      "loss": 0.0013,
      "step": 55840
    },
    {
      "epoch": 1.7098858035085571,
      "grad_norm": 0.038687143474817276,
      "learning_rate": 8.6009654144853e-06,
      "loss": 0.001,
      "step": 55850
    },
    {
      "epoch": 1.710191960322077,
      "grad_norm": 0.01558036170899868,
      "learning_rate": 8.598924369061834e-06,
      "loss": 0.0459,
      "step": 55860
    },
    {
      "epoch": 1.7104981171355969,
      "grad_norm": 0.03453747555613518,
      "learning_rate": 8.59688332363837e-06,
      "loss": 0.0247,
      "step": 55870
    },
    {
      "epoch": 1.7108042739491167,
      "grad_norm": 0.03545430675148964,
      "learning_rate": 8.594842278214903e-06,
      "loss": 0.0015,
      "step": 55880
    },
    {
      "epoch": 1.7111104307626366,
      "grad_norm": 0.023156538605690002,
      "learning_rate": 8.592801232791437e-06,
      "loss": 0.0339,
      "step": 55890
    },
    {
      "epoch": 1.7114165875761564,
      "grad_norm": 0.0933055430650711,
      "learning_rate": 8.59076018736797e-06,
      "loss": 0.0274,
      "step": 55900
    },
    {
      "epoch": 1.7117227443896765,
      "grad_norm": 0.030755046755075455,
      "learning_rate": 8.588719141944506e-06,
      "loss": 0.0016,
      "step": 55910
    },
    {
      "epoch": 1.7120289012031962,
      "grad_norm": 0.014778731390833855,
      "learning_rate": 8.586678096521038e-06,
      "loss": 0.0304,
      "step": 55920
    },
    {
      "epoch": 1.7123350580167163,
      "grad_norm": 0.08402931690216064,
      "learning_rate": 8.584637051097573e-06,
      "loss": 0.0029,
      "step": 55930
    },
    {
      "epoch": 1.712641214830236,
      "grad_norm": 0.02501814253628254,
      "learning_rate": 8.582596005674107e-06,
      "loss": 0.0298,
      "step": 55940
    },
    {
      "epoch": 1.712947371643756,
      "grad_norm": 0.053243182599544525,
      "learning_rate": 8.580554960250642e-06,
      "loss": 0.0079,
      "step": 55950
    },
    {
      "epoch": 1.7132535284572759,
      "grad_norm": 0.061665065586566925,
      "learning_rate": 8.578513914827176e-06,
      "loss": 0.0018,
      "step": 55960
    },
    {
      "epoch": 1.7135596852707957,
      "grad_norm": 0.043514225631952286,
      "learning_rate": 8.576472869403709e-06,
      "loss": 0.0735,
      "step": 55970
    },
    {
      "epoch": 1.7138658420843156,
      "grad_norm": 0.02821309305727482,
      "learning_rate": 8.574431823980244e-06,
      "loss": 0.002,
      "step": 55980
    },
    {
      "epoch": 1.7141719988978354,
      "grad_norm": 0.03621004521846771,
      "learning_rate": 8.572390778556776e-06,
      "loss": 0.0813,
      "step": 55990
    },
    {
      "epoch": 1.7144781557113553,
      "grad_norm": 0.0426216647028923,
      "learning_rate": 8.570349733133312e-06,
      "loss": 0.0013,
      "step": 56000
    },
    {
      "epoch": 1.7147843125248752,
      "grad_norm": 0.07706758379936218,
      "learning_rate": 8.568308687709845e-06,
      "loss": 0.0527,
      "step": 56010
    },
    {
      "epoch": 1.7150904693383953,
      "grad_norm": 0.04539743810892105,
      "learning_rate": 8.56626764228638e-06,
      "loss": 0.0039,
      "step": 56020
    },
    {
      "epoch": 1.715396626151915,
      "grad_norm": 0.03181380406022072,
      "learning_rate": 8.564226596862913e-06,
      "loss": 0.0018,
      "step": 56030
    },
    {
      "epoch": 1.715702782965435,
      "grad_norm": 0.07690095156431198,
      "learning_rate": 8.562185551439448e-06,
      "loss": 0.0575,
      "step": 56040
    },
    {
      "epoch": 1.7160089397789546,
      "grad_norm": 0.03456009551882744,
      "learning_rate": 8.560144506015982e-06,
      "loss": 0.0269,
      "step": 56050
    },
    {
      "epoch": 1.7163150965924747,
      "grad_norm": 0.06915445625782013,
      "learning_rate": 8.558103460592515e-06,
      "loss": 0.0276,
      "step": 56060
    },
    {
      "epoch": 1.7166212534059946,
      "grad_norm": 0.06071087718009949,
      "learning_rate": 8.55606241516905e-06,
      "loss": 0.0523,
      "step": 56070
    },
    {
      "epoch": 1.7169274102195144,
      "grad_norm": 0.0598120391368866,
      "learning_rate": 8.554021369745584e-06,
      "loss": 0.0031,
      "step": 56080
    },
    {
      "epoch": 1.7172335670330343,
      "grad_norm": 0.032956644892692566,
      "learning_rate": 8.55198032432212e-06,
      "loss": 0.0026,
      "step": 56090
    },
    {
      "epoch": 1.7175397238465542,
      "grad_norm": 0.10228800028562546,
      "learning_rate": 8.549939278898652e-06,
      "loss": 0.0023,
      "step": 56100
    },
    {
      "epoch": 1.717845880660074,
      "grad_norm": 0.031099285930395126,
      "learning_rate": 8.547898233475187e-06,
      "loss": 0.0025,
      "step": 56110
    },
    {
      "epoch": 1.718152037473594,
      "grad_norm": 0.04997952654957771,
      "learning_rate": 8.54585718805172e-06,
      "loss": 0.0163,
      "step": 56120
    },
    {
      "epoch": 1.718458194287114,
      "grad_norm": 3.2118453979492188,
      "learning_rate": 8.543816142628256e-06,
      "loss": 0.009,
      "step": 56130
    },
    {
      "epoch": 1.7187643511006336,
      "grad_norm": 0.07470913231372833,
      "learning_rate": 8.541775097204788e-06,
      "loss": 0.0477,
      "step": 56140
    },
    {
      "epoch": 1.7190705079141537,
      "grad_norm": 0.048716410994529724,
      "learning_rate": 8.539734051781323e-06,
      "loss": 0.0018,
      "step": 56150
    },
    {
      "epoch": 1.7193766647276734,
      "grad_norm": 0.02938888594508171,
      "learning_rate": 8.537693006357857e-06,
      "loss": 0.0075,
      "step": 56160
    },
    {
      "epoch": 1.7196828215411935,
      "grad_norm": 0.018129700794816017,
      "learning_rate": 8.53565196093439e-06,
      "loss": 0.0015,
      "step": 56170
    },
    {
      "epoch": 1.7199889783547133,
      "grad_norm": 0.032667126506567,
      "learning_rate": 8.533610915510926e-06,
      "loss": 0.0016,
      "step": 56180
    },
    {
      "epoch": 1.7202951351682332,
      "grad_norm": 0.04833338037133217,
      "learning_rate": 8.53156987008746e-06,
      "loss": 0.0012,
      "step": 56190
    },
    {
      "epoch": 1.720601291981753,
      "grad_norm": 0.0279634278267622,
      "learning_rate": 8.529528824663995e-06,
      "loss": 0.0016,
      "step": 56200
    },
    {
      "epoch": 1.720907448795273,
      "grad_norm": 0.015082334168255329,
      "learning_rate": 8.527487779240527e-06,
      "loss": 0.0012,
      "step": 56210
    },
    {
      "epoch": 1.7212136056087928,
      "grad_norm": 0.026385407894849777,
      "learning_rate": 8.525446733817062e-06,
      "loss": 0.0401,
      "step": 56220
    },
    {
      "epoch": 1.7215197624223126,
      "grad_norm": 0.030043667182326317,
      "learning_rate": 8.523405688393596e-06,
      "loss": 0.0009,
      "step": 56230
    },
    {
      "epoch": 1.7218259192358327,
      "grad_norm": 0.044392578303813934,
      "learning_rate": 8.52136464297013e-06,
      "loss": 0.0011,
      "step": 56240
    },
    {
      "epoch": 1.7221320760493524,
      "grad_norm": 0.03127976506948471,
      "learning_rate": 8.519323597546663e-06,
      "loss": 0.0728,
      "step": 56250
    },
    {
      "epoch": 1.7224382328628725,
      "grad_norm": 0.04224644973874092,
      "learning_rate": 8.517282552123198e-06,
      "loss": 0.0013,
      "step": 56260
    },
    {
      "epoch": 1.722744389676392,
      "grad_norm": 0.02077341079711914,
      "learning_rate": 8.515241506699732e-06,
      "loss": 0.0014,
      "step": 56270
    },
    {
      "epoch": 1.7230505464899122,
      "grad_norm": 0.01867389678955078,
      "learning_rate": 8.513200461276266e-06,
      "loss": 0.0011,
      "step": 56280
    },
    {
      "epoch": 1.723356703303432,
      "grad_norm": 0.045235514640808105,
      "learning_rate": 8.511159415852801e-06,
      "loss": 0.0309,
      "step": 56290
    },
    {
      "epoch": 1.723662860116952,
      "grad_norm": 0.04377361387014389,
      "learning_rate": 8.509118370429335e-06,
      "loss": 0.002,
      "step": 56300
    },
    {
      "epoch": 1.7239690169304718,
      "grad_norm": 0.044894732534885406,
      "learning_rate": 8.507077325005868e-06,
      "loss": 0.0372,
      "step": 56310
    },
    {
      "epoch": 1.7242751737439916,
      "grad_norm": 0.04928349331021309,
      "learning_rate": 8.505036279582402e-06,
      "loss": 0.0014,
      "step": 56320
    },
    {
      "epoch": 1.7245813305575115,
      "grad_norm": 0.016695404425263405,
      "learning_rate": 8.502995234158937e-06,
      "loss": 0.0727,
      "step": 56330
    },
    {
      "epoch": 1.7248874873710314,
      "grad_norm": 0.019268155097961426,
      "learning_rate": 8.500954188735471e-06,
      "loss": 0.002,
      "step": 56340
    },
    {
      "epoch": 1.7251936441845515,
      "grad_norm": 0.0393332801759243,
      "learning_rate": 8.498913143312005e-06,
      "loss": 0.0014,
      "step": 56350
    },
    {
      "epoch": 1.725499800998071,
      "grad_norm": 0.12772531807422638,
      "learning_rate": 8.496872097888538e-06,
      "loss": 0.0308,
      "step": 56360
    },
    {
      "epoch": 1.7258059578115912,
      "grad_norm": 0.006241200491786003,
      "learning_rate": 8.494831052465074e-06,
      "loss": 0.0012,
      "step": 56370
    },
    {
      "epoch": 1.7261121146251108,
      "grad_norm": 0.055923786014318466,
      "learning_rate": 8.492790007041607e-06,
      "loss": 0.0015,
      "step": 56380
    },
    {
      "epoch": 1.726418271438631,
      "grad_norm": 0.04822434484958649,
      "learning_rate": 8.49074896161814e-06,
      "loss": 0.0012,
      "step": 56390
    },
    {
      "epoch": 1.7267244282521508,
      "grad_norm": 0.020619692280888557,
      "learning_rate": 8.488707916194676e-06,
      "loss": 0.0033,
      "step": 56400
    },
    {
      "epoch": 1.7270305850656706,
      "grad_norm": 0.010287655517458916,
      "learning_rate": 8.48666687077121e-06,
      "loss": 0.0021,
      "step": 56410
    },
    {
      "epoch": 1.7273367418791905,
      "grad_norm": 0.020706133916974068,
      "learning_rate": 8.484625825347743e-06,
      "loss": 0.0012,
      "step": 56420
    },
    {
      "epoch": 1.7276428986927104,
      "grad_norm": 0.004124122206121683,
      "learning_rate": 8.482584779924277e-06,
      "loss": 0.0014,
      "step": 56430
    },
    {
      "epoch": 1.7279490555062302,
      "grad_norm": 0.030782803893089294,
      "learning_rate": 8.480543734500812e-06,
      "loss": 0.1005,
      "step": 56440
    },
    {
      "epoch": 1.72825521231975,
      "grad_norm": 0.019100643694400787,
      "learning_rate": 8.478502689077346e-06,
      "loss": 0.0019,
      "step": 56450
    },
    {
      "epoch": 1.7285613691332702,
      "grad_norm": 1.6453092098236084,
      "learning_rate": 8.47646164365388e-06,
      "loss": 0.0325,
      "step": 56460
    },
    {
      "epoch": 1.7288675259467898,
      "grad_norm": 0.034070614725351334,
      "learning_rate": 8.474420598230413e-06,
      "loss": 0.0096,
      "step": 56470
    },
    {
      "epoch": 1.72917368276031,
      "grad_norm": 0.022126128897070885,
      "learning_rate": 8.472379552806949e-06,
      "loss": 0.0015,
      "step": 56480
    },
    {
      "epoch": 1.7294798395738296,
      "grad_norm": 0.023982495069503784,
      "learning_rate": 8.470338507383482e-06,
      "loss": 0.0273,
      "step": 56490
    },
    {
      "epoch": 1.7297859963873496,
      "grad_norm": 0.059290505945682526,
      "learning_rate": 8.468297461960016e-06,
      "loss": 0.0299,
      "step": 56500
    },
    {
      "epoch": 1.7300921532008695,
      "grad_norm": 0.022631511092185974,
      "learning_rate": 8.46625641653655e-06,
      "loss": 0.0305,
      "step": 56510
    },
    {
      "epoch": 1.7303983100143894,
      "grad_norm": 0.08172217756509781,
      "learning_rate": 8.464215371113085e-06,
      "loss": 0.0695,
      "step": 56520
    },
    {
      "epoch": 1.7307044668279092,
      "grad_norm": 0.03593543544411659,
      "learning_rate": 8.462174325689619e-06,
      "loss": 0.0254,
      "step": 56530
    },
    {
      "epoch": 1.731010623641429,
      "grad_norm": 0.037712059915065765,
      "learning_rate": 8.460133280266152e-06,
      "loss": 0.0024,
      "step": 56540
    },
    {
      "epoch": 1.7313167804549492,
      "grad_norm": 0.043290894478559494,
      "learning_rate": 8.458092234842688e-06,
      "loss": 0.0026,
      "step": 56550
    },
    {
      "epoch": 1.7316229372684688,
      "grad_norm": 1.6027809381484985,
      "learning_rate": 8.456051189419221e-06,
      "loss": 0.0615,
      "step": 56560
    },
    {
      "epoch": 1.731929094081989,
      "grad_norm": 0.030031414702534676,
      "learning_rate": 8.454010143995755e-06,
      "loss": 0.0016,
      "step": 56570
    },
    {
      "epoch": 1.7322352508955086,
      "grad_norm": 0.06840085238218307,
      "learning_rate": 8.451969098572289e-06,
      "loss": 0.0027,
      "step": 56580
    },
    {
      "epoch": 1.7325414077090286,
      "grad_norm": 0.033800914883613586,
      "learning_rate": 8.449928053148824e-06,
      "loss": 0.0354,
      "step": 56590
    },
    {
      "epoch": 1.7328475645225483,
      "grad_norm": 0.02424544095993042,
      "learning_rate": 8.447887007725358e-06,
      "loss": 0.0031,
      "step": 56600
    },
    {
      "epoch": 1.7331537213360684,
      "grad_norm": 0.03688938170671463,
      "learning_rate": 8.445845962301891e-06,
      "loss": 0.002,
      "step": 56610
    },
    {
      "epoch": 1.7334598781495882,
      "grad_norm": 0.046246517449617386,
      "learning_rate": 8.443804916878425e-06,
      "loss": 0.0023,
      "step": 56620
    },
    {
      "epoch": 1.733766034963108,
      "grad_norm": 0.07397709041833878,
      "learning_rate": 8.44176387145496e-06,
      "loss": 0.0016,
      "step": 56630
    },
    {
      "epoch": 1.734072191776628,
      "grad_norm": 0.040890954434871674,
      "learning_rate": 8.439722826031494e-06,
      "loss": 0.0029,
      "step": 56640
    },
    {
      "epoch": 1.7343783485901478,
      "grad_norm": 0.05434729903936386,
      "learning_rate": 8.437681780608027e-06,
      "loss": 0.0019,
      "step": 56650
    },
    {
      "epoch": 1.734684505403668,
      "grad_norm": 0.021879516541957855,
      "learning_rate": 8.435640735184563e-06,
      "loss": 0.0014,
      "step": 56660
    },
    {
      "epoch": 1.7349906622171876,
      "grad_norm": 0.07415296137332916,
      "learning_rate": 8.433599689761096e-06,
      "loss": 0.0013,
      "step": 56670
    },
    {
      "epoch": 1.7352968190307076,
      "grad_norm": 0.0279404129832983,
      "learning_rate": 8.43155864433763e-06,
      "loss": 0.0011,
      "step": 56680
    },
    {
      "epoch": 1.7356029758442273,
      "grad_norm": 0.02962217666208744,
      "learning_rate": 8.429517598914164e-06,
      "loss": 0.0393,
      "step": 56690
    },
    {
      "epoch": 1.7359091326577474,
      "grad_norm": 0.0038471154402941465,
      "learning_rate": 8.427476553490699e-06,
      "loss": 0.0018,
      "step": 56700
    },
    {
      "epoch": 1.736215289471267,
      "grad_norm": 0.005142598412930965,
      "learning_rate": 8.425435508067233e-06,
      "loss": 0.0012,
      "step": 56710
    },
    {
      "epoch": 1.736521446284787,
      "grad_norm": 0.03622109070420265,
      "learning_rate": 8.423394462643766e-06,
      "loss": 0.0667,
      "step": 56720
    },
    {
      "epoch": 1.736827603098307,
      "grad_norm": 0.07399832457304001,
      "learning_rate": 8.4213534172203e-06,
      "loss": 0.0019,
      "step": 56730
    },
    {
      "epoch": 1.7371337599118268,
      "grad_norm": 0.021298283711075783,
      "learning_rate": 8.419312371796835e-06,
      "loss": 0.0015,
      "step": 56740
    },
    {
      "epoch": 1.7374399167253467,
      "grad_norm": 0.04095200076699257,
      "learning_rate": 8.417271326373369e-06,
      "loss": 0.0341,
      "step": 56750
    },
    {
      "epoch": 1.7377460735388666,
      "grad_norm": 0.08502846956253052,
      "learning_rate": 8.415230280949903e-06,
      "loss": 0.0589,
      "step": 56760
    },
    {
      "epoch": 1.7380522303523867,
      "grad_norm": 0.04186229407787323,
      "learning_rate": 8.413189235526438e-06,
      "loss": 0.0019,
      "step": 56770
    },
    {
      "epoch": 1.7383583871659063,
      "grad_norm": 0.0738794133067131,
      "learning_rate": 8.411148190102972e-06,
      "loss": 0.0026,
      "step": 56780
    },
    {
      "epoch": 1.7386645439794264,
      "grad_norm": 1.8422175645828247,
      "learning_rate": 8.409107144679505e-06,
      "loss": 0.0385,
      "step": 56790
    },
    {
      "epoch": 1.738970700792946,
      "grad_norm": 0.04670516774058342,
      "learning_rate": 8.407066099256039e-06,
      "loss": 0.0134,
      "step": 56800
    },
    {
      "epoch": 1.739276857606466,
      "grad_norm": 0.039051733911037445,
      "learning_rate": 8.405025053832574e-06,
      "loss": 0.0022,
      "step": 56810
    },
    {
      "epoch": 1.7395830144199858,
      "grad_norm": 0.035198841243982315,
      "learning_rate": 8.402984008409108e-06,
      "loss": 0.002,
      "step": 56820
    },
    {
      "epoch": 1.7398891712335058,
      "grad_norm": 1.9137243032455444,
      "learning_rate": 8.400942962985642e-06,
      "loss": 0.1373,
      "step": 56830
    },
    {
      "epoch": 1.7401953280470257,
      "grad_norm": 0.05013693869113922,
      "learning_rate": 8.398901917562175e-06,
      "loss": 0.0025,
      "step": 56840
    },
    {
      "epoch": 1.7405014848605456,
      "grad_norm": 0.07359229773283005,
      "learning_rate": 8.39686087213871e-06,
      "loss": 0.0016,
      "step": 56850
    },
    {
      "epoch": 1.7408076416740654,
      "grad_norm": 0.00792495533823967,
      "learning_rate": 8.394819826715244e-06,
      "loss": 0.0018,
      "step": 56860
    },
    {
      "epoch": 1.7411137984875853,
      "grad_norm": 0.0113381864503026,
      "learning_rate": 8.392778781291778e-06,
      "loss": 0.002,
      "step": 56870
    },
    {
      "epoch": 1.7414199553011054,
      "grad_norm": 0.015617123804986477,
      "learning_rate": 8.390737735868313e-06,
      "loss": 0.0015,
      "step": 56880
    },
    {
      "epoch": 1.741726112114625,
      "grad_norm": 0.05352840945124626,
      "learning_rate": 8.388696690444847e-06,
      "loss": 0.0358,
      "step": 56890
    },
    {
      "epoch": 1.7420322689281451,
      "grad_norm": 0.04486783966422081,
      "learning_rate": 8.38665564502138e-06,
      "loss": 0.0014,
      "step": 56900
    },
    {
      "epoch": 1.7423384257416648,
      "grad_norm": 0.012115484103560448,
      "learning_rate": 8.384614599597914e-06,
      "loss": 0.035,
      "step": 56910
    },
    {
      "epoch": 1.7426445825551848,
      "grad_norm": 0.040130432695150375,
      "learning_rate": 8.38257355417445e-06,
      "loss": 0.0014,
      "step": 56920
    },
    {
      "epoch": 1.7429507393687047,
      "grad_norm": 0.018277572467923164,
      "learning_rate": 8.380532508750983e-06,
      "loss": 0.0018,
      "step": 56930
    },
    {
      "epoch": 1.7432568961822246,
      "grad_norm": 0.022516904398798943,
      "learning_rate": 8.378491463327517e-06,
      "loss": 0.0477,
      "step": 56940
    },
    {
      "epoch": 1.7435630529957444,
      "grad_norm": 0.0336991511285305,
      "learning_rate": 8.37645041790405e-06,
      "loss": 0.0019,
      "step": 56950
    },
    {
      "epoch": 1.7438692098092643,
      "grad_norm": 0.041820723563432693,
      "learning_rate": 8.374409372480586e-06,
      "loss": 0.0015,
      "step": 56960
    },
    {
      "epoch": 1.7441753666227842,
      "grad_norm": 0.056200772523880005,
      "learning_rate": 8.37236832705712e-06,
      "loss": 0.033,
      "step": 56970
    },
    {
      "epoch": 1.744481523436304,
      "grad_norm": 1.6205164194107056,
      "learning_rate": 8.370327281633653e-06,
      "loss": 0.0661,
      "step": 56980
    },
    {
      "epoch": 1.7447876802498241,
      "grad_norm": 0.05129944533109665,
      "learning_rate": 8.368286236210188e-06,
      "loss": 0.002,
      "step": 56990
    },
    {
      "epoch": 1.7450938370633438,
      "grad_norm": 0.033913753926754,
      "learning_rate": 8.366245190786722e-06,
      "loss": 0.0021,
      "step": 57000
    },
    {
      "epoch": 1.7453999938768638,
      "grad_norm": 0.04464214667677879,
      "learning_rate": 8.364204145363256e-06,
      "loss": 0.0249,
      "step": 57010
    },
    {
      "epoch": 1.7457061506903835,
      "grad_norm": 0.038685835897922516,
      "learning_rate": 8.36216309993979e-06,
      "loss": 0.0012,
      "step": 57020
    },
    {
      "epoch": 1.7460123075039036,
      "grad_norm": 0.03295785188674927,
      "learning_rate": 8.360122054516325e-06,
      "loss": 0.0023,
      "step": 57030
    },
    {
      "epoch": 1.7463184643174234,
      "grad_norm": 0.07089883834123611,
      "learning_rate": 8.358081009092858e-06,
      "loss": 0.0666,
      "step": 57040
    },
    {
      "epoch": 1.7466246211309433,
      "grad_norm": 0.08070237934589386,
      "learning_rate": 8.356039963669392e-06,
      "loss": 0.0023,
      "step": 57050
    },
    {
      "epoch": 1.7469307779444632,
      "grad_norm": 1.8922712802886963,
      "learning_rate": 8.353998918245926e-06,
      "loss": 0.0344,
      "step": 57060
    },
    {
      "epoch": 1.747236934757983,
      "grad_norm": 0.07974083721637726,
      "learning_rate": 8.35195787282246e-06,
      "loss": 0.0018,
      "step": 57070
    },
    {
      "epoch": 1.747543091571503,
      "grad_norm": 0.06243539974093437,
      "learning_rate": 8.349916827398994e-06,
      "loss": 0.0293,
      "step": 57080
    },
    {
      "epoch": 1.7478492483850228,
      "grad_norm": 0.026450112462043762,
      "learning_rate": 8.347875781975528e-06,
      "loss": 0.0014,
      "step": 57090
    },
    {
      "epoch": 1.7481554051985428,
      "grad_norm": 0.033809877932071686,
      "learning_rate": 8.345834736552063e-06,
      "loss": 0.0012,
      "step": 57100
    },
    {
      "epoch": 1.7484615620120625,
      "grad_norm": 0.08088228106498718,
      "learning_rate": 8.343793691128597e-06,
      "loss": 0.0339,
      "step": 57110
    },
    {
      "epoch": 1.7487677188255826,
      "grad_norm": 0.047985564917325974,
      "learning_rate": 8.34175264570513e-06,
      "loss": 0.0015,
      "step": 57120
    },
    {
      "epoch": 1.7490738756391022,
      "grad_norm": 0.06173425912857056,
      "learning_rate": 8.339711600281664e-06,
      "loss": 0.0604,
      "step": 57130
    },
    {
      "epoch": 1.7493800324526223,
      "grad_norm": 0.013882235623896122,
      "learning_rate": 8.3376705548582e-06,
      "loss": 0.0024,
      "step": 57140
    },
    {
      "epoch": 1.7496861892661422,
      "grad_norm": 0.1462383270263672,
      "learning_rate": 8.335629509434733e-06,
      "loss": 0.0291,
      "step": 57150
    },
    {
      "epoch": 1.749992346079662,
      "grad_norm": 0.06563542783260345,
      "learning_rate": 8.333588464011267e-06,
      "loss": 0.0698,
      "step": 57160
    },
    {
      "epoch": 1.750298502893182,
      "grad_norm": 2.4607303142547607,
      "learning_rate": 8.3315474185878e-06,
      "loss": 0.0404,
      "step": 57170
    },
    {
      "epoch": 1.7506046597067018,
      "grad_norm": 0.19562382996082306,
      "learning_rate": 8.329506373164336e-06,
      "loss": 0.0015,
      "step": 57180
    },
    {
      "epoch": 1.7509108165202216,
      "grad_norm": 0.02985808253288269,
      "learning_rate": 8.32746532774087e-06,
      "loss": 0.0049,
      "step": 57190
    },
    {
      "epoch": 1.7512169733337415,
      "grad_norm": 0.08556847274303436,
      "learning_rate": 8.325424282317403e-06,
      "loss": 0.0319,
      "step": 57200
    },
    {
      "epoch": 1.7515231301472616,
      "grad_norm": 0.04124586284160614,
      "learning_rate": 8.323383236893939e-06,
      "loss": 0.0239,
      "step": 57210
    },
    {
      "epoch": 1.7518292869607812,
      "grad_norm": 0.030281495302915573,
      "learning_rate": 8.321342191470472e-06,
      "loss": 0.0019,
      "step": 57220
    },
    {
      "epoch": 1.7521354437743013,
      "grad_norm": 0.09741660952568054,
      "learning_rate": 8.319301146047006e-06,
      "loss": 0.0027,
      "step": 57230
    },
    {
      "epoch": 1.752441600587821,
      "grad_norm": 0.05664980784058571,
      "learning_rate": 8.31726010062354e-06,
      "loss": 0.0286,
      "step": 57240
    },
    {
      "epoch": 1.752747757401341,
      "grad_norm": 0.05829506739974022,
      "learning_rate": 8.315219055200075e-06,
      "loss": 0.0019,
      "step": 57250
    },
    {
      "epoch": 1.753053914214861,
      "grad_norm": 3.0954275131225586,
      "learning_rate": 8.313178009776609e-06,
      "loss": 0.0618,
      "step": 57260
    },
    {
      "epoch": 1.7533600710283808,
      "grad_norm": 0.02054578810930252,
      "learning_rate": 8.311136964353142e-06,
      "loss": 0.0021,
      "step": 57270
    },
    {
      "epoch": 1.7536662278419006,
      "grad_norm": 0.07268816232681274,
      "learning_rate": 8.309095918929676e-06,
      "loss": 0.0685,
      "step": 57280
    },
    {
      "epoch": 1.7539723846554205,
      "grad_norm": 0.05343163385987282,
      "learning_rate": 8.307054873506211e-06,
      "loss": 0.0035,
      "step": 57290
    },
    {
      "epoch": 1.7542785414689404,
      "grad_norm": 0.0375857949256897,
      "learning_rate": 8.305013828082745e-06,
      "loss": 0.0013,
      "step": 57300
    },
    {
      "epoch": 1.7545846982824602,
      "grad_norm": 0.027427036315202713,
      "learning_rate": 8.302972782659278e-06,
      "loss": 0.0023,
      "step": 57310
    },
    {
      "epoch": 1.7548908550959803,
      "grad_norm": 0.0785282775759697,
      "learning_rate": 8.300931737235814e-06,
      "loss": 0.0013,
      "step": 57320
    },
    {
      "epoch": 1.7551970119095,
      "grad_norm": 0.05452638864517212,
      "learning_rate": 8.298890691812347e-06,
      "loss": 0.0022,
      "step": 57330
    },
    {
      "epoch": 1.75550316872302,
      "grad_norm": 0.026177575811743736,
      "learning_rate": 8.296849646388881e-06,
      "loss": 0.0012,
      "step": 57340
    },
    {
      "epoch": 1.7558093255365397,
      "grad_norm": 0.05733848735690117,
      "learning_rate": 8.294808600965415e-06,
      "loss": 0.0311,
      "step": 57350
    },
    {
      "epoch": 1.7561154823500598,
      "grad_norm": 0.0002177166606998071,
      "learning_rate": 8.29276755554195e-06,
      "loss": 0.0019,
      "step": 57360
    },
    {
      "epoch": 1.7564216391635796,
      "grad_norm": 0.016468005254864693,
      "learning_rate": 8.290726510118484e-06,
      "loss": 0.0017,
      "step": 57370
    },
    {
      "epoch": 1.7567277959770995,
      "grad_norm": 0.05504894629120827,
      "learning_rate": 8.288685464695017e-06,
      "loss": 0.0015,
      "step": 57380
    },
    {
      "epoch": 1.7570339527906194,
      "grad_norm": 0.04663749784231186,
      "learning_rate": 8.286644419271551e-06,
      "loss": 0.0023,
      "step": 57390
    },
    {
      "epoch": 1.7573401096041392,
      "grad_norm": 0.020590508356690407,
      "learning_rate": 8.284603373848086e-06,
      "loss": 0.0012,
      "step": 57400
    },
    {
      "epoch": 1.757646266417659,
      "grad_norm": 0.0486430823802948,
      "learning_rate": 8.28256232842462e-06,
      "loss": 0.0013,
      "step": 57410
    },
    {
      "epoch": 1.757952423231179,
      "grad_norm": 0.040343016386032104,
      "learning_rate": 8.280521283001154e-06,
      "loss": 0.0012,
      "step": 57420
    },
    {
      "epoch": 1.758258580044699,
      "grad_norm": 0.02205214835703373,
      "learning_rate": 8.278480237577689e-06,
      "loss": 0.001,
      "step": 57430
    },
    {
      "epoch": 1.7585647368582187,
      "grad_norm": 0.056817326694726944,
      "learning_rate": 8.276439192154223e-06,
      "loss": 0.0377,
      "step": 57440
    },
    {
      "epoch": 1.7588708936717388,
      "grad_norm": 0.013139253482222557,
      "learning_rate": 8.274398146730756e-06,
      "loss": 0.0014,
      "step": 57450
    },
    {
      "epoch": 1.7591770504852584,
      "grad_norm": 0.021703623235225677,
      "learning_rate": 8.27235710130729e-06,
      "loss": 0.001,
      "step": 57460
    },
    {
      "epoch": 1.7594832072987785,
      "grad_norm": 0.0351729616522789,
      "learning_rate": 8.270316055883825e-06,
      "loss": 0.0011,
      "step": 57470
    },
    {
      "epoch": 1.7597893641122984,
      "grad_norm": 0.033708084374666214,
      "learning_rate": 8.268275010460359e-06,
      "loss": 0.0405,
      "step": 57480
    },
    {
      "epoch": 1.7600955209258182,
      "grad_norm": 0.018291393294930458,
      "learning_rate": 8.266233965036893e-06,
      "loss": 0.0008,
      "step": 57490
    },
    {
      "epoch": 1.760401677739338,
      "grad_norm": 0.03661474213004112,
      "learning_rate": 8.264192919613426e-06,
      "loss": 0.001,
      "step": 57500
    },
    {
      "epoch": 1.760707834552858,
      "grad_norm": 0.32421237230300903,
      "learning_rate": 8.262151874189962e-06,
      "loss": 0.0012,
      "step": 57510
    },
    {
      "epoch": 1.7610139913663778,
      "grad_norm": 0.019811995327472687,
      "learning_rate": 8.260110828766495e-06,
      "loss": 0.0237,
      "step": 57520
    },
    {
      "epoch": 1.7613201481798977,
      "grad_norm": 0.018362363800406456,
      "learning_rate": 8.258069783343029e-06,
      "loss": 0.0009,
      "step": 57530
    },
    {
      "epoch": 1.7616263049934178,
      "grad_norm": 0.044880211353302,
      "learning_rate": 8.256028737919564e-06,
      "loss": 0.0453,
      "step": 57540
    },
    {
      "epoch": 1.7619324618069374,
      "grad_norm": 0.012620795518159866,
      "learning_rate": 8.253987692496098e-06,
      "loss": 0.0032,
      "step": 57550
    },
    {
      "epoch": 1.7622386186204575,
      "grad_norm": 0.06110629439353943,
      "learning_rate": 8.251946647072631e-06,
      "loss": 0.0012,
      "step": 57560
    },
    {
      "epoch": 1.7625447754339771,
      "grad_norm": 0.009689990431070328,
      "learning_rate": 8.249905601649165e-06,
      "loss": 0.0009,
      "step": 57570
    },
    {
      "epoch": 1.7628509322474972,
      "grad_norm": 0.026393482461571693,
      "learning_rate": 8.2478645562257e-06,
      "loss": 0.0013,
      "step": 57580
    },
    {
      "epoch": 1.763157089061017,
      "grad_norm": 0.017659803852438927,
      "learning_rate": 8.245823510802234e-06,
      "loss": 0.0008,
      "step": 57590
    },
    {
      "epoch": 1.763463245874537,
      "grad_norm": 0.030898960307240486,
      "learning_rate": 8.243782465378768e-06,
      "loss": 0.0008,
      "step": 57600
    },
    {
      "epoch": 1.7637694026880568,
      "grad_norm": 6.857985496520996,
      "learning_rate": 8.241741419955301e-06,
      "loss": 0.043,
      "step": 57610
    },
    {
      "epoch": 1.7640755595015767,
      "grad_norm": 0.02722359634935856,
      "learning_rate": 8.239700374531837e-06,
      "loss": 0.001,
      "step": 57620
    },
    {
      "epoch": 1.7643817163150965,
      "grad_norm": 0.013376484625041485,
      "learning_rate": 8.23765932910837e-06,
      "loss": 0.0012,
      "step": 57630
    },
    {
      "epoch": 1.7646878731286164,
      "grad_norm": 0.029572859406471252,
      "learning_rate": 8.235618283684904e-06,
      "loss": 0.0797,
      "step": 57640
    },
    {
      "epoch": 1.7649940299421365,
      "grad_norm": 0.012399867177009583,
      "learning_rate": 8.23357723826144e-06,
      "loss": 0.0008,
      "step": 57650
    },
    {
      "epoch": 1.7653001867556561,
      "grad_norm": 0.02010982297360897,
      "learning_rate": 8.231536192837973e-06,
      "loss": 0.0285,
      "step": 57660
    },
    {
      "epoch": 1.7656063435691762,
      "grad_norm": 0.03459583595395088,
      "learning_rate": 8.229495147414507e-06,
      "loss": 0.0011,
      "step": 57670
    },
    {
      "epoch": 1.7659125003826959,
      "grad_norm": 0.0508086197078228,
      "learning_rate": 8.22745410199104e-06,
      "loss": 0.0011,
      "step": 57680
    },
    {
      "epoch": 1.766218657196216,
      "grad_norm": 0.012402658350765705,
      "learning_rate": 8.225413056567576e-06,
      "loss": 0.0461,
      "step": 57690
    },
    {
      "epoch": 1.7665248140097358,
      "grad_norm": 0.5484016537666321,
      "learning_rate": 8.22337201114411e-06,
      "loss": 0.0011,
      "step": 57700
    },
    {
      "epoch": 1.7668309708232557,
      "grad_norm": 0.003850415349006653,
      "learning_rate": 8.221330965720643e-06,
      "loss": 0.0006,
      "step": 57710
    },
    {
      "epoch": 1.7671371276367756,
      "grad_norm": 0.024149097502231598,
      "learning_rate": 8.219289920297177e-06,
      "loss": 0.0058,
      "step": 57720
    },
    {
      "epoch": 1.7674432844502954,
      "grad_norm": 0.03323785215616226,
      "learning_rate": 8.217248874873712e-06,
      "loss": 0.0033,
      "step": 57730
    },
    {
      "epoch": 1.7677494412638153,
      "grad_norm": 0.009081939235329628,
      "learning_rate": 8.215207829450244e-06,
      "loss": 0.0006,
      "step": 57740
    },
    {
      "epoch": 1.7680555980773351,
      "grad_norm": 0.009308933280408382,
      "learning_rate": 8.213166784026779e-06,
      "loss": 0.001,
      "step": 57750
    },
    {
      "epoch": 1.7683617548908552,
      "grad_norm": 0.016940081492066383,
      "learning_rate": 8.211125738603313e-06,
      "loss": 0.0011,
      "step": 57760
    },
    {
      "epoch": 1.7686679117043749,
      "grad_norm": 0.016989629715681076,
      "learning_rate": 8.209084693179848e-06,
      "loss": 0.0005,
      "step": 57770
    },
    {
      "epoch": 1.768974068517895,
      "grad_norm": 0.008716345764696598,
      "learning_rate": 8.207043647756382e-06,
      "loss": 0.0009,
      "step": 57780
    },
    {
      "epoch": 1.7692802253314146,
      "grad_norm": 0.013714801520109177,
      "learning_rate": 8.205002602332915e-06,
      "loss": 0.0005,
      "step": 57790
    },
    {
      "epoch": 1.7695863821449347,
      "grad_norm": 0.014239495620131493,
      "learning_rate": 8.20296155690945e-06,
      "loss": 0.0008,
      "step": 57800
    },
    {
      "epoch": 1.7698925389584546,
      "grad_norm": 0.005411618389189243,
      "learning_rate": 8.200920511485984e-06,
      "loss": 0.0005,
      "step": 57810
    },
    {
      "epoch": 1.7701986957719744,
      "grad_norm": 0.013016984798014164,
      "learning_rate": 8.198879466062518e-06,
      "loss": 0.0006,
      "step": 57820
    },
    {
      "epoch": 1.7705048525854943,
      "grad_norm": 0.024234674870967865,
      "learning_rate": 8.196838420639052e-06,
      "loss": 0.0007,
      "step": 57830
    },
    {
      "epoch": 1.7708110093990141,
      "grad_norm": 0.02192959561944008,
      "learning_rate": 8.194797375215587e-06,
      "loss": 0.0006,
      "step": 57840
    },
    {
      "epoch": 1.771117166212534,
      "grad_norm": 0.017474133521318436,
      "learning_rate": 8.192756329792119e-06,
      "loss": 0.0004,
      "step": 57850
    },
    {
      "epoch": 1.7714233230260539,
      "grad_norm": 0.02202390506863594,
      "learning_rate": 8.190715284368654e-06,
      "loss": 0.0006,
      "step": 57860
    },
    {
      "epoch": 1.771729479839574,
      "grad_norm": 0.0022655928041785955,
      "learning_rate": 8.188674238945188e-06,
      "loss": 0.0005,
      "step": 57870
    },
    {
      "epoch": 1.7720356366530936,
      "grad_norm": 0.0064976997673511505,
      "learning_rate": 8.186633193521723e-06,
      "loss": 0.0317,
      "step": 57880
    },
    {
      "epoch": 1.7723417934666137,
      "grad_norm": 3.380201578140259,
      "learning_rate": 8.184592148098257e-06,
      "loss": 0.0075,
      "step": 57890
    },
    {
      "epoch": 1.7726479502801333,
      "grad_norm": 0.016955671831965446,
      "learning_rate": 8.18255110267479e-06,
      "loss": 0.0418,
      "step": 57900
    },
    {
      "epoch": 1.7729541070936534,
      "grad_norm": 0.009564472362399101,
      "learning_rate": 8.180510057251326e-06,
      "loss": 0.0052,
      "step": 57910
    },
    {
      "epoch": 1.7732602639071733,
      "grad_norm": 0.0051794713363051414,
      "learning_rate": 8.178469011827858e-06,
      "loss": 0.0006,
      "step": 57920
    },
    {
      "epoch": 1.7735664207206931,
      "grad_norm": 0.01446518674492836,
      "learning_rate": 8.176427966404393e-06,
      "loss": 0.0006,
      "step": 57930
    },
    {
      "epoch": 1.773872577534213,
      "grad_norm": 0.01793803460896015,
      "learning_rate": 8.174386920980927e-06,
      "loss": 0.0005,
      "step": 57940
    },
    {
      "epoch": 1.7741787343477329,
      "grad_norm": 0.013270624913275242,
      "learning_rate": 8.172345875557462e-06,
      "loss": 0.0007,
      "step": 57950
    },
    {
      "epoch": 1.7744848911612527,
      "grad_norm": 2.2246932983398438,
      "learning_rate": 8.170304830133994e-06,
      "loss": 0.0086,
      "step": 57960
    },
    {
      "epoch": 1.7747910479747726,
      "grad_norm": 0.010384729132056236,
      "learning_rate": 8.16826378471053e-06,
      "loss": 0.0006,
      "step": 57970
    },
    {
      "epoch": 1.7750972047882927,
      "grad_norm": 0.014831439591944218,
      "learning_rate": 8.166222739287063e-06,
      "loss": 0.04,
      "step": 57980
    },
    {
      "epoch": 1.7754033616018123,
      "grad_norm": 0.007611945737153292,
      "learning_rate": 8.164181693863597e-06,
      "loss": 0.0007,
      "step": 57990
    },
    {
      "epoch": 1.7757095184153324,
      "grad_norm": 0.02454940788447857,
      "learning_rate": 8.162140648440132e-06,
      "loss": 0.0007,
      "step": 58000
    },
    {
      "epoch": 1.776015675228852,
      "grad_norm": 0.03701924905180931,
      "learning_rate": 8.160099603016666e-06,
      "loss": 0.0369,
      "step": 58010
    },
    {
      "epoch": 1.7763218320423722,
      "grad_norm": 0.021180763840675354,
      "learning_rate": 8.158058557593201e-06,
      "loss": 0.0322,
      "step": 58020
    },
    {
      "epoch": 1.776627988855892,
      "grad_norm": 0.0492720752954483,
      "learning_rate": 8.156017512169733e-06,
      "loss": 0.0344,
      "step": 58030
    },
    {
      "epoch": 1.7769341456694119,
      "grad_norm": 0.007854863069951534,
      "learning_rate": 8.153976466746268e-06,
      "loss": 0.0007,
      "step": 58040
    },
    {
      "epoch": 1.7772403024829317,
      "grad_norm": 0.011330608278512955,
      "learning_rate": 8.151935421322802e-06,
      "loss": 0.0007,
      "step": 58050
    },
    {
      "epoch": 1.7775464592964516,
      "grad_norm": 0.018042732030153275,
      "learning_rate": 8.149894375899337e-06,
      "loss": 0.0012,
      "step": 58060
    },
    {
      "epoch": 1.7778526161099715,
      "grad_norm": 0.011149974539875984,
      "learning_rate": 8.14785333047587e-06,
      "loss": 0.002,
      "step": 58070
    },
    {
      "epoch": 1.7781587729234913,
      "grad_norm": 0.013896186836063862,
      "learning_rate": 8.145812285052405e-06,
      "loss": 0.0007,
      "step": 58080
    },
    {
      "epoch": 1.7784649297370114,
      "grad_norm": 0.0111109409481287,
      "learning_rate": 8.143771239628938e-06,
      "loss": 0.0007,
      "step": 58090
    },
    {
      "epoch": 1.778771086550531,
      "grad_norm": 0.03563566133379936,
      "learning_rate": 8.141730194205472e-06,
      "loss": 0.0007,
      "step": 58100
    },
    {
      "epoch": 1.7790772433640512,
      "grad_norm": 0.016498476266860962,
      "learning_rate": 8.139689148782007e-06,
      "loss": 0.0008,
      "step": 58110
    },
    {
      "epoch": 1.7793834001775708,
      "grad_norm": 0.0408487543463707,
      "learning_rate": 8.137648103358541e-06,
      "loss": 0.0006,
      "step": 58120
    },
    {
      "epoch": 1.7796895569910909,
      "grad_norm": 0.004523931071162224,
      "learning_rate": 8.135607057935076e-06,
      "loss": 0.0008,
      "step": 58130
    },
    {
      "epoch": 1.7799957138046107,
      "grad_norm": 0.012858141213655472,
      "learning_rate": 8.133566012511608e-06,
      "loss": 0.0471,
      "step": 58140
    },
    {
      "epoch": 1.7803018706181306,
      "grad_norm": 0.011859516613185406,
      "learning_rate": 8.131524967088144e-06,
      "loss": 0.0005,
      "step": 58150
    },
    {
      "epoch": 1.7806080274316505,
      "grad_norm": 0.04348469525575638,
      "learning_rate": 8.129483921664677e-06,
      "loss": 0.0009,
      "step": 58160
    },
    {
      "epoch": 1.7809141842451703,
      "grad_norm": 0.012941156513988972,
      "learning_rate": 8.12744287624121e-06,
      "loss": 0.0007,
      "step": 58170
    },
    {
      "epoch": 1.7812203410586904,
      "grad_norm": 0.013578972779214382,
      "learning_rate": 8.125401830817744e-06,
      "loss": 0.0005,
      "step": 58180
    },
    {
      "epoch": 1.78152649787221,
      "grad_norm": 1.9348868131637573,
      "learning_rate": 8.12336078539428e-06,
      "loss": 0.0404,
      "step": 58190
    },
    {
      "epoch": 1.7818326546857302,
      "grad_norm": 0.028245847672224045,
      "learning_rate": 8.121319739970813e-06,
      "loss": 0.0007,
      "step": 58200
    },
    {
      "epoch": 1.7821388114992498,
      "grad_norm": 0.018372872844338417,
      "learning_rate": 8.119278694547347e-06,
      "loss": 0.0004,
      "step": 58210
    },
    {
      "epoch": 1.7824449683127699,
      "grad_norm": 0.015530558302998543,
      "learning_rate": 8.117237649123882e-06,
      "loss": 0.0006,
      "step": 58220
    },
    {
      "epoch": 1.7827511251262895,
      "grad_norm": 0.02662123367190361,
      "learning_rate": 8.115196603700416e-06,
      "loss": 0.0014,
      "step": 58230
    },
    {
      "epoch": 1.7830572819398096,
      "grad_norm": 0.008272952400147915,
      "learning_rate": 8.11315555827695e-06,
      "loss": 0.0407,
      "step": 58240
    },
    {
      "epoch": 1.7833634387533295,
      "grad_norm": 0.035646140575408936,
      "learning_rate": 8.111114512853483e-06,
      "loss": 0.0008,
      "step": 58250
    },
    {
      "epoch": 1.7836695955668493,
      "grad_norm": 0.015442339703440666,
      "learning_rate": 8.109073467430019e-06,
      "loss": 0.0011,
      "step": 58260
    },
    {
      "epoch": 1.7839757523803692,
      "grad_norm": 0.014917334541678429,
      "learning_rate": 8.107032422006552e-06,
      "loss": 0.0006,
      "step": 58270
    },
    {
      "epoch": 1.784281909193889,
      "grad_norm": 0.01139079499989748,
      "learning_rate": 8.104991376583086e-06,
      "loss": 0.034,
      "step": 58280
    },
    {
      "epoch": 1.7845880660074092,
      "grad_norm": 0.010508231818675995,
      "learning_rate": 8.10295033115962e-06,
      "loss": 0.0145,
      "step": 58290
    },
    {
      "epoch": 1.7848942228209288,
      "grad_norm": 0.02605189010500908,
      "learning_rate": 8.100909285736155e-06,
      "loss": 0.0047,
      "step": 58300
    },
    {
      "epoch": 1.7852003796344489,
      "grad_norm": 0.4439866542816162,
      "learning_rate": 8.098868240312689e-06,
      "loss": 0.0011,
      "step": 58310
    },
    {
      "epoch": 1.7855065364479685,
      "grad_norm": 0.008427816443145275,
      "learning_rate": 8.096827194889222e-06,
      "loss": 0.0397,
      "step": 58320
    },
    {
      "epoch": 1.7858126932614886,
      "grad_norm": 0.037354014813899994,
      "learning_rate": 8.094786149465756e-06,
      "loss": 0.0009,
      "step": 58330
    },
    {
      "epoch": 1.7861188500750083,
      "grad_norm": 0.012146804481744766,
      "learning_rate": 8.092745104042291e-06,
      "loss": 0.0389,
      "step": 58340
    },
    {
      "epoch": 1.7864250068885283,
      "grad_norm": 0.013522625900804996,
      "learning_rate": 8.090704058618825e-06,
      "loss": 0.0011,
      "step": 58350
    },
    {
      "epoch": 1.7867311637020482,
      "grad_norm": 0.007277092430740595,
      "learning_rate": 8.088663013195359e-06,
      "loss": 0.0007,
      "step": 58360
    },
    {
      "epoch": 1.787037320515568,
      "grad_norm": 0.023595653474330902,
      "learning_rate": 8.086621967771894e-06,
      "loss": 0.001,
      "step": 58370
    },
    {
      "epoch": 1.787343477329088,
      "grad_norm": 0.029671836644411087,
      "learning_rate": 8.084580922348428e-06,
      "loss": 0.0414,
      "step": 58380
    },
    {
      "epoch": 1.7876496341426078,
      "grad_norm": 1.5924878120422363,
      "learning_rate": 8.082539876924961e-06,
      "loss": 0.0627,
      "step": 58390
    },
    {
      "epoch": 1.7879557909561279,
      "grad_norm": 0.010933543555438519,
      "learning_rate": 8.080498831501495e-06,
      "loss": 0.0008,
      "step": 58400
    },
    {
      "epoch": 1.7882619477696475,
      "grad_norm": 0.018849411979317665,
      "learning_rate": 8.07845778607803e-06,
      "loss": 0.0381,
      "step": 58410
    },
    {
      "epoch": 1.7885681045831676,
      "grad_norm": 0.03845621272921562,
      "learning_rate": 8.076416740654564e-06,
      "loss": 0.0019,
      "step": 58420
    },
    {
      "epoch": 1.7888742613966873,
      "grad_norm": 0.022028451785445213,
      "learning_rate": 8.074375695231097e-06,
      "loss": 0.001,
      "step": 58430
    },
    {
      "epoch": 1.7891804182102073,
      "grad_norm": 0.06522085517644882,
      "learning_rate": 8.072334649807631e-06,
      "loss": 0.0749,
      "step": 58440
    },
    {
      "epoch": 1.789486575023727,
      "grad_norm": 0.014662078581750393,
      "learning_rate": 8.070293604384166e-06,
      "loss": 0.0801,
      "step": 58450
    },
    {
      "epoch": 1.789792731837247,
      "grad_norm": 0.04205958545207977,
      "learning_rate": 8.0682525589607e-06,
      "loss": 0.001,
      "step": 58460
    },
    {
      "epoch": 1.790098888650767,
      "grad_norm": 0.020505014806985855,
      "learning_rate": 8.066211513537234e-06,
      "loss": 0.0013,
      "step": 58470
    },
    {
      "epoch": 1.7904050454642868,
      "grad_norm": 0.03454165905714035,
      "learning_rate": 8.064170468113769e-06,
      "loss": 0.0019,
      "step": 58480
    },
    {
      "epoch": 1.7907112022778067,
      "grad_norm": 0.03222142532467842,
      "learning_rate": 8.062129422690303e-06,
      "loss": 0.0354,
      "step": 58490
    },
    {
      "epoch": 1.7910173590913265,
      "grad_norm": 0.02308112196624279,
      "learning_rate": 8.060088377266836e-06,
      "loss": 0.0317,
      "step": 58500
    },
    {
      "epoch": 1.7913235159048466,
      "grad_norm": 0.026839246973395348,
      "learning_rate": 8.05804733184337e-06,
      "loss": 0.0014,
      "step": 58510
    },
    {
      "epoch": 1.7916296727183663,
      "grad_norm": 0.023966090753674507,
      "learning_rate": 8.056006286419905e-06,
      "loss": 0.0014,
      "step": 58520
    },
    {
      "epoch": 1.7919358295318863,
      "grad_norm": 0.00016458792379125953,
      "learning_rate": 8.053965240996439e-06,
      "loss": 0.0373,
      "step": 58530
    },
    {
      "epoch": 1.792241986345406,
      "grad_norm": 0.030291907489299774,
      "learning_rate": 8.051924195572973e-06,
      "loss": 0.0037,
      "step": 58540
    },
    {
      "epoch": 1.792548143158926,
      "grad_norm": 0.026622816920280457,
      "learning_rate": 8.049883150149506e-06,
      "loss": 0.034,
      "step": 58550
    },
    {
      "epoch": 1.792854299972446,
      "grad_norm": 0.014588146470487118,
      "learning_rate": 8.047842104726042e-06,
      "loss": 0.0014,
      "step": 58560
    },
    {
      "epoch": 1.7931604567859658,
      "grad_norm": 0.026206888258457184,
      "learning_rate": 8.045801059302575e-06,
      "loss": 0.0015,
      "step": 58570
    },
    {
      "epoch": 1.7934666135994857,
      "grad_norm": 0.02767893485724926,
      "learning_rate": 8.043760013879109e-06,
      "loss": 0.0015,
      "step": 58580
    },
    {
      "epoch": 1.7937727704130055,
      "grad_norm": 0.001604078453965485,
      "learning_rate": 8.041718968455644e-06,
      "loss": 0.0012,
      "step": 58590
    },
    {
      "epoch": 1.7940789272265254,
      "grad_norm": 0.05672154575586319,
      "learning_rate": 8.039677923032178e-06,
      "loss": 0.0018,
      "step": 58600
    },
    {
      "epoch": 1.7943850840400453,
      "grad_norm": 0.015819353982806206,
      "learning_rate": 8.037636877608712e-06,
      "loss": 0.0012,
      "step": 58610
    },
    {
      "epoch": 1.7946912408535654,
      "grad_norm": 1.8770827054977417,
      "learning_rate": 8.035595832185245e-06,
      "loss": 0.0702,
      "step": 58620
    },
    {
      "epoch": 1.794997397667085,
      "grad_norm": 0.02775544673204422,
      "learning_rate": 8.03355478676178e-06,
      "loss": 0.0016,
      "step": 58630
    },
    {
      "epoch": 1.795303554480605,
      "grad_norm": 0.019570395350456238,
      "learning_rate": 8.031513741338314e-06,
      "loss": 0.0873,
      "step": 58640
    },
    {
      "epoch": 1.7956097112941247,
      "grad_norm": 0.05944881960749626,
      "learning_rate": 8.029472695914848e-06,
      "loss": 0.0295,
      "step": 58650
    },
    {
      "epoch": 1.7959158681076448,
      "grad_norm": 0.033599913120269775,
      "learning_rate": 8.027431650491381e-06,
      "loss": 0.0014,
      "step": 58660
    },
    {
      "epoch": 1.7962220249211647,
      "grad_norm": 0.023451417684555054,
      "learning_rate": 8.025390605067917e-06,
      "loss": 0.0008,
      "step": 58670
    },
    {
      "epoch": 1.7965281817346845,
      "grad_norm": 1.7849855422973633,
      "learning_rate": 8.02334955964445e-06,
      "loss": 0.0337,
      "step": 58680
    },
    {
      "epoch": 1.7968343385482044,
      "grad_norm": 0.05263950675725937,
      "learning_rate": 8.021308514220984e-06,
      "loss": 0.0298,
      "step": 58690
    },
    {
      "epoch": 1.7971404953617243,
      "grad_norm": 0.03179500997066498,
      "learning_rate": 8.01926746879752e-06,
      "loss": 0.0317,
      "step": 58700
    },
    {
      "epoch": 1.7974466521752441,
      "grad_norm": 0.05115403234958649,
      "learning_rate": 8.017226423374053e-06,
      "loss": 0.0015,
      "step": 58710
    },
    {
      "epoch": 1.797752808988764,
      "grad_norm": 1.8705365657806396,
      "learning_rate": 8.015185377950587e-06,
      "loss": 0.0383,
      "step": 58720
    },
    {
      "epoch": 1.798058965802284,
      "grad_norm": 0.012165798805654049,
      "learning_rate": 8.01314433252712e-06,
      "loss": 0.0013,
      "step": 58730
    },
    {
      "epoch": 1.7983651226158037,
      "grad_norm": 0.030208097770810127,
      "learning_rate": 8.011103287103656e-06,
      "loss": 0.0015,
      "step": 58740
    },
    {
      "epoch": 1.7986712794293238,
      "grad_norm": 0.02611616812646389,
      "learning_rate": 8.00906224168019e-06,
      "loss": 0.0302,
      "step": 58750
    },
    {
      "epoch": 1.7989774362428435,
      "grad_norm": 0.021029861643910408,
      "learning_rate": 8.007021196256723e-06,
      "loss": 0.0017,
      "step": 58760
    },
    {
      "epoch": 1.7992835930563635,
      "grad_norm": 0.15323804318904877,
      "learning_rate": 8.004980150833257e-06,
      "loss": 0.0015,
      "step": 58770
    },
    {
      "epoch": 1.7995897498698834,
      "grad_norm": 0.02408795803785324,
      "learning_rate": 8.002939105409792e-06,
      "loss": 0.0019,
      "step": 58780
    },
    {
      "epoch": 1.7998959066834033,
      "grad_norm": 0.03897630795836449,
      "learning_rate": 8.000898059986326e-06,
      "loss": 0.002,
      "step": 58790
    },
    {
      "epoch": 1.8002020634969231,
      "grad_norm": 0.016568955034017563,
      "learning_rate": 7.99885701456286e-06,
      "loss": 0.0013,
      "step": 58800
    },
    {
      "epoch": 1.800508220310443,
      "grad_norm": 0.020613227039575577,
      "learning_rate": 7.996815969139395e-06,
      "loss": 0.0265,
      "step": 58810
    },
    {
      "epoch": 1.8008143771239629,
      "grad_norm": 0.03039052151143551,
      "learning_rate": 7.994774923715928e-06,
      "loss": 0.0011,
      "step": 58820
    },
    {
      "epoch": 1.8011205339374827,
      "grad_norm": 0.03190741315484047,
      "learning_rate": 7.992733878292462e-06,
      "loss": 0.036,
      "step": 58830
    },
    {
      "epoch": 1.8014266907510028,
      "grad_norm": 0.03108719363808632,
      "learning_rate": 7.990692832868995e-06,
      "loss": 0.0012,
      "step": 58840
    },
    {
      "epoch": 1.8017328475645225,
      "grad_norm": 0.05503065884113312,
      "learning_rate": 7.98865178744553e-06,
      "loss": 0.0271,
      "step": 58850
    },
    {
      "epoch": 1.8020390043780425,
      "grad_norm": 0.02042287401854992,
      "learning_rate": 7.986610742022064e-06,
      "loss": 0.0015,
      "step": 58860
    },
    {
      "epoch": 1.8023451611915622,
      "grad_norm": 0.7259153723716736,
      "learning_rate": 7.984569696598598e-06,
      "loss": 0.0024,
      "step": 58870
    },
    {
      "epoch": 1.8026513180050823,
      "grad_norm": 0.022561464458703995,
      "learning_rate": 7.982528651175132e-06,
      "loss": 0.0316,
      "step": 58880
    },
    {
      "epoch": 1.8029574748186021,
      "grad_norm": 0.04368029162287712,
      "learning_rate": 7.980487605751667e-06,
      "loss": 0.0016,
      "step": 58890
    },
    {
      "epoch": 1.803263631632122,
      "grad_norm": 0.022401802241802216,
      "learning_rate": 7.9784465603282e-06,
      "loss": 0.0009,
      "step": 58900
    },
    {
      "epoch": 1.8035697884456419,
      "grad_norm": 0.017037713900208473,
      "learning_rate": 7.976405514904734e-06,
      "loss": 0.0017,
      "step": 58910
    },
    {
      "epoch": 1.8038759452591617,
      "grad_norm": 0.021473869681358337,
      "learning_rate": 7.97436446948127e-06,
      "loss": 0.0012,
      "step": 58920
    },
    {
      "epoch": 1.8041821020726816,
      "grad_norm": 0.03490632772445679,
      "learning_rate": 7.972323424057803e-06,
      "loss": 0.0666,
      "step": 58930
    },
    {
      "epoch": 1.8044882588862015,
      "grad_norm": 0.02746500074863434,
      "learning_rate": 7.970282378634337e-06,
      "loss": 0.0008,
      "step": 58940
    },
    {
      "epoch": 1.8047944156997215,
      "grad_norm": 0.023458348587155342,
      "learning_rate": 7.96824133321087e-06,
      "loss": 0.0012,
      "step": 58950
    },
    {
      "epoch": 1.8051005725132412,
      "grad_norm": 0.02861349657177925,
      "learning_rate": 7.966200287787406e-06,
      "loss": 0.0015,
      "step": 58960
    },
    {
      "epoch": 1.8054067293267613,
      "grad_norm": 0.02964189276099205,
      "learning_rate": 7.96415924236394e-06,
      "loss": 0.0014,
      "step": 58970
    },
    {
      "epoch": 1.805712886140281,
      "grad_norm": 0.0637589618563652,
      "learning_rate": 7.962118196940473e-06,
      "loss": 0.0013,
      "step": 58980
    },
    {
      "epoch": 1.806019042953801,
      "grad_norm": 0.045159123837947845,
      "learning_rate": 7.960077151517007e-06,
      "loss": 0.0325,
      "step": 58990
    },
    {
      "epoch": 1.8063251997673209,
      "grad_norm": 0.030412819236516953,
      "learning_rate": 7.958036106093542e-06,
      "loss": 0.0009,
      "step": 59000
    },
    {
      "epoch": 1.8066313565808407,
      "grad_norm": 0.012191887013614178,
      "learning_rate": 7.955995060670076e-06,
      "loss": 0.0372,
      "step": 59010
    },
    {
      "epoch": 1.8069375133943606,
      "grad_norm": 0.004989512264728546,
      "learning_rate": 7.95395401524661e-06,
      "loss": 0.0033,
      "step": 59020
    },
    {
      "epoch": 1.8072436702078805,
      "grad_norm": 0.022626284509897232,
      "learning_rate": 7.951912969823145e-06,
      "loss": 0.0303,
      "step": 59030
    },
    {
      "epoch": 1.8075498270214003,
      "grad_norm": 0.0062909503467381,
      "learning_rate": 7.949871924399679e-06,
      "loss": 0.0012,
      "step": 59040
    },
    {
      "epoch": 1.8078559838349202,
      "grad_norm": 0.026054544374346733,
      "learning_rate": 7.947830878976212e-06,
      "loss": 0.0014,
      "step": 59050
    },
    {
      "epoch": 1.8081621406484403,
      "grad_norm": 0.04690563678741455,
      "learning_rate": 7.945789833552746e-06,
      "loss": 0.0075,
      "step": 59060
    },
    {
      "epoch": 1.80846829746196,
      "grad_norm": 0.052879828959703445,
      "learning_rate": 7.943748788129281e-06,
      "loss": 0.001,
      "step": 59070
    },
    {
      "epoch": 1.80877445427548,
      "grad_norm": 0.03894051909446716,
      "learning_rate": 7.941707742705815e-06,
      "loss": 0.0012,
      "step": 59080
    },
    {
      "epoch": 1.8090806110889996,
      "grad_norm": 0.028542302548885345,
      "learning_rate": 7.939666697282348e-06,
      "loss": 0.0713,
      "step": 59090
    },
    {
      "epoch": 1.8093867679025197,
      "grad_norm": 0.023899054154753685,
      "learning_rate": 7.937625651858882e-06,
      "loss": 0.0015,
      "step": 59100
    },
    {
      "epoch": 1.8096929247160396,
      "grad_norm": 0.027632856741547585,
      "learning_rate": 7.935584606435417e-06,
      "loss": 0.0274,
      "step": 59110
    },
    {
      "epoch": 1.8099990815295595,
      "grad_norm": 0.0005156468832865357,
      "learning_rate": 7.933543561011951e-06,
      "loss": 0.0013,
      "step": 59120
    },
    {
      "epoch": 1.8103052383430793,
      "grad_norm": 0.005405985750257969,
      "learning_rate": 7.931502515588485e-06,
      "loss": 0.0553,
      "step": 59130
    },
    {
      "epoch": 1.8106113951565992,
      "grad_norm": 0.04257460683584213,
      "learning_rate": 7.92946147016502e-06,
      "loss": 0.002,
      "step": 59140
    },
    {
      "epoch": 1.810917551970119,
      "grad_norm": 0.06106710433959961,
      "learning_rate": 7.927420424741554e-06,
      "loss": 0.0015,
      "step": 59150
    },
    {
      "epoch": 1.811223708783639,
      "grad_norm": 0.006346963346004486,
      "learning_rate": 7.925379379318087e-06,
      "loss": 0.0104,
      "step": 59160
    },
    {
      "epoch": 1.811529865597159,
      "grad_norm": 0.015670377761125565,
      "learning_rate": 7.923338333894621e-06,
      "loss": 0.0305,
      "step": 59170
    },
    {
      "epoch": 1.8118360224106786,
      "grad_norm": 0.07183437049388885,
      "learning_rate": 7.921297288471156e-06,
      "loss": 0.071,
      "step": 59180
    },
    {
      "epoch": 1.8121421792241987,
      "grad_norm": 0.03408466652035713,
      "learning_rate": 7.91925624304769e-06,
      "loss": 0.0016,
      "step": 59190
    },
    {
      "epoch": 1.8124483360377184,
      "grad_norm": 0.06898988783359528,
      "learning_rate": 7.917215197624224e-06,
      "loss": 0.0157,
      "step": 59200
    },
    {
      "epoch": 1.8127544928512385,
      "grad_norm": 0.03615504503250122,
      "learning_rate": 7.915174152200757e-06,
      "loss": 0.0016,
      "step": 59210
    },
    {
      "epoch": 1.8130606496647583,
      "grad_norm": 0.017244309186935425,
      "learning_rate": 7.913133106777293e-06,
      "loss": 0.0017,
      "step": 59220
    },
    {
      "epoch": 1.8133668064782782,
      "grad_norm": 0.02951609157025814,
      "learning_rate": 7.911092061353826e-06,
      "loss": 0.0017,
      "step": 59230
    },
    {
      "epoch": 1.813672963291798,
      "grad_norm": 0.004201870411634445,
      "learning_rate": 7.90905101593036e-06,
      "loss": 0.0016,
      "step": 59240
    },
    {
      "epoch": 1.813979120105318,
      "grad_norm": 0.0036992018576711416,
      "learning_rate": 7.907009970506895e-06,
      "loss": 0.0011,
      "step": 59250
    },
    {
      "epoch": 1.8142852769188378,
      "grad_norm": 0.05926062539219856,
      "learning_rate": 7.904968925083429e-06,
      "loss": 0.0333,
      "step": 59260
    },
    {
      "epoch": 1.8145914337323577,
      "grad_norm": 0.0314377136528492,
      "learning_rate": 7.902927879659963e-06,
      "loss": 0.0013,
      "step": 59270
    },
    {
      "epoch": 1.8148975905458777,
      "grad_norm": 0.06419295072555542,
      "learning_rate": 7.900886834236496e-06,
      "loss": 0.0008,
      "step": 59280
    },
    {
      "epoch": 1.8152037473593974,
      "grad_norm": 0.011191721074283123,
      "learning_rate": 7.898845788813032e-06,
      "loss": 0.0013,
      "step": 59290
    },
    {
      "epoch": 1.8155099041729175,
      "grad_norm": 2.0947046279907227,
      "learning_rate": 7.896804743389565e-06,
      "loss": 0.0445,
      "step": 59300
    },
    {
      "epoch": 1.815816060986437,
      "grad_norm": 0.038283806294202805,
      "learning_rate": 7.894763697966099e-06,
      "loss": 0.0013,
      "step": 59310
    },
    {
      "epoch": 1.8161222177999572,
      "grad_norm": 0.03859090805053711,
      "learning_rate": 7.892722652542632e-06,
      "loss": 0.0031,
      "step": 59320
    },
    {
      "epoch": 1.816428374613477,
      "grad_norm": 0.05222375690937042,
      "learning_rate": 7.890681607119168e-06,
      "loss": 0.0013,
      "step": 59330
    },
    {
      "epoch": 1.816734531426997,
      "grad_norm": 0.020929675549268723,
      "learning_rate": 7.888640561695701e-06,
      "loss": 0.0013,
      "step": 59340
    },
    {
      "epoch": 1.8170406882405168,
      "grad_norm": 0.021727215498685837,
      "learning_rate": 7.886599516272235e-06,
      "loss": 0.0012,
      "step": 59350
    },
    {
      "epoch": 1.8173468450540367,
      "grad_norm": 0.026570763438940048,
      "learning_rate": 7.88455847084877e-06,
      "loss": 0.0008,
      "step": 59360
    },
    {
      "epoch": 1.8176530018675565,
      "grad_norm": 0.012470155954360962,
      "learning_rate": 7.882517425425304e-06,
      "loss": 0.0353,
      "step": 59370
    },
    {
      "epoch": 1.8179591586810764,
      "grad_norm": 0.007966762408614159,
      "learning_rate": 7.880476380001838e-06,
      "loss": 0.001,
      "step": 59380
    },
    {
      "epoch": 1.8182653154945965,
      "grad_norm": 0.016840659081935883,
      "learning_rate": 7.878435334578371e-06,
      "loss": 0.028,
      "step": 59390
    },
    {
      "epoch": 1.818571472308116,
      "grad_norm": 0.05795641615986824,
      "learning_rate": 7.876394289154907e-06,
      "loss": 0.0012,
      "step": 59400
    },
    {
      "epoch": 1.8188776291216362,
      "grad_norm": 0.022689398378133774,
      "learning_rate": 7.87435324373144e-06,
      "loss": 0.0009,
      "step": 59410
    },
    {
      "epoch": 1.8191837859351558,
      "grad_norm": 0.007489623036235571,
      "learning_rate": 7.872312198307974e-06,
      "loss": 0.0009,
      "step": 59420
    },
    {
      "epoch": 1.819489942748676,
      "grad_norm": 0.03455819934606552,
      "learning_rate": 7.870271152884508e-06,
      "loss": 0.0011,
      "step": 59430
    },
    {
      "epoch": 1.8197960995621958,
      "grad_norm": 0.019538354128599167,
      "learning_rate": 7.868230107461043e-06,
      "loss": 0.0011,
      "step": 59440
    },
    {
      "epoch": 1.8201022563757157,
      "grad_norm": 0.016629904508590698,
      "learning_rate": 7.866189062037577e-06,
      "loss": 0.033,
      "step": 59450
    },
    {
      "epoch": 1.8204084131892355,
      "grad_norm": 0.027860132977366447,
      "learning_rate": 7.86414801661411e-06,
      "loss": 0.0009,
      "step": 59460
    },
    {
      "epoch": 1.8207145700027554,
      "grad_norm": 0.023687027394771576,
      "learning_rate": 7.862106971190646e-06,
      "loss": 0.0305,
      "step": 59470
    },
    {
      "epoch": 1.8210207268162752,
      "grad_norm": 0.0334443524479866,
      "learning_rate": 7.86006592576718e-06,
      "loss": 0.0008,
      "step": 59480
    },
    {
      "epoch": 1.8213268836297951,
      "grad_norm": 0.015726439654827118,
      "learning_rate": 7.858024880343713e-06,
      "loss": 0.0006,
      "step": 59490
    },
    {
      "epoch": 1.8216330404433152,
      "grad_norm": 0.006704938597977161,
      "learning_rate": 7.855983834920247e-06,
      "loss": 0.0024,
      "step": 59500
    },
    {
      "epoch": 1.8219391972568348,
      "grad_norm": 0.030270587652921677,
      "learning_rate": 7.853942789496782e-06,
      "loss": 0.0239,
      "step": 59510
    },
    {
      "epoch": 1.822245354070355,
      "grad_norm": 0.030350051820278168,
      "learning_rate": 7.851901744073315e-06,
      "loss": 0.0316,
      "step": 59520
    },
    {
      "epoch": 1.8225515108838746,
      "grad_norm": 0.017789943143725395,
      "learning_rate": 7.849860698649849e-06,
      "loss": 0.0226,
      "step": 59530
    },
    {
      "epoch": 1.8228576676973947,
      "grad_norm": 0.04147886112332344,
      "learning_rate": 7.847819653226383e-06,
      "loss": 0.0383,
      "step": 59540
    },
    {
      "epoch": 1.8231638245109145,
      "grad_norm": 0.018677258864045143,
      "learning_rate": 7.845778607802918e-06,
      "loss": 0.0016,
      "step": 59550
    },
    {
      "epoch": 1.8234699813244344,
      "grad_norm": 0.07399427890777588,
      "learning_rate": 7.843737562379452e-06,
      "loss": 0.034,
      "step": 59560
    },
    {
      "epoch": 1.8237761381379543,
      "grad_norm": 0.04049009457230568,
      "learning_rate": 7.841696516955985e-06,
      "loss": 0.0021,
      "step": 59570
    },
    {
      "epoch": 1.8240822949514741,
      "grad_norm": 0.04918765649199486,
      "learning_rate": 7.839655471532519e-06,
      "loss": 0.0013,
      "step": 59580
    },
    {
      "epoch": 1.824388451764994,
      "grad_norm": 0.014403793029487133,
      "learning_rate": 7.837614426109054e-06,
      "loss": 0.0314,
      "step": 59590
    },
    {
      "epoch": 1.8246946085785138,
      "grad_norm": 4.516565799713135,
      "learning_rate": 7.835573380685588e-06,
      "loss": 0.051,
      "step": 59600
    },
    {
      "epoch": 1.825000765392034,
      "grad_norm": 1.8786112070083618,
      "learning_rate": 7.833532335262122e-06,
      "loss": 0.0375,
      "step": 59610
    },
    {
      "epoch": 1.8253069222055536,
      "grad_norm": 0.03954879939556122,
      "learning_rate": 7.831491289838657e-06,
      "loss": 0.0017,
      "step": 59620
    },
    {
      "epoch": 1.8256130790190737,
      "grad_norm": 0.038155317306518555,
      "learning_rate": 7.82945024441519e-06,
      "loss": 0.0019,
      "step": 59630
    },
    {
      "epoch": 1.8259192358325933,
      "grad_norm": 0.095573790371418,
      "learning_rate": 7.827409198991724e-06,
      "loss": 0.0017,
      "step": 59640
    },
    {
      "epoch": 1.8262253926461134,
      "grad_norm": 0.019835269078612328,
      "learning_rate": 7.825368153568258e-06,
      "loss": 0.0288,
      "step": 59650
    },
    {
      "epoch": 1.8265315494596333,
      "grad_norm": 0.020441574975848198,
      "learning_rate": 7.823327108144793e-06,
      "loss": 0.0288,
      "step": 59660
    },
    {
      "epoch": 1.8268377062731531,
      "grad_norm": 0.0284262802451849,
      "learning_rate": 7.821286062721325e-06,
      "loss": 0.0101,
      "step": 59670
    },
    {
      "epoch": 1.827143863086673,
      "grad_norm": 0.04537832364439964,
      "learning_rate": 7.81924501729786e-06,
      "loss": 0.0325,
      "step": 59680
    },
    {
      "epoch": 1.8274500199001928,
      "grad_norm": 0.03921588510274887,
      "learning_rate": 7.817203971874394e-06,
      "loss": 0.0359,
      "step": 59690
    },
    {
      "epoch": 1.8277561767137127,
      "grad_norm": 0.04215485230088234,
      "learning_rate": 7.81516292645093e-06,
      "loss": 0.0019,
      "step": 59700
    },
    {
      "epoch": 1.8280623335272326,
      "grad_norm": 0.013225805945694447,
      "learning_rate": 7.813121881027463e-06,
      "loss": 0.0019,
      "step": 59710
    },
    {
      "epoch": 1.8283684903407527,
      "grad_norm": 0.012523237615823746,
      "learning_rate": 7.811080835603997e-06,
      "loss": 0.002,
      "step": 59720
    },
    {
      "epoch": 1.8286746471542723,
      "grad_norm": 0.019242532551288605,
      "learning_rate": 7.809039790180532e-06,
      "loss": 0.0039,
      "step": 59730
    },
    {
      "epoch": 1.8289808039677924,
      "grad_norm": 0.06882806867361069,
      "learning_rate": 7.806998744757066e-06,
      "loss": 0.0014,
      "step": 59740
    },
    {
      "epoch": 1.829286960781312,
      "grad_norm": 1.3953256607055664,
      "learning_rate": 7.8049576993336e-06,
      "loss": 0.0031,
      "step": 59750
    },
    {
      "epoch": 1.8295931175948321,
      "grad_norm": 0.06629211455583572,
      "learning_rate": 7.802916653910133e-06,
      "loss": 0.0365,
      "step": 59760
    },
    {
      "epoch": 1.829899274408352,
      "grad_norm": 0.05036873742938042,
      "learning_rate": 7.800875608486668e-06,
      "loss": 0.0016,
      "step": 59770
    },
    {
      "epoch": 1.8302054312218718,
      "grad_norm": 0.034567516297101974,
      "learning_rate": 7.7988345630632e-06,
      "loss": 0.0012,
      "step": 59780
    },
    {
      "epoch": 1.8305115880353917,
      "grad_norm": 0.029002061113715172,
      "learning_rate": 7.796793517639736e-06,
      "loss": 0.0019,
      "step": 59790
    },
    {
      "epoch": 1.8308177448489116,
      "grad_norm": 0.0399915985763073,
      "learning_rate": 7.79475247221627e-06,
      "loss": 0.0419,
      "step": 59800
    },
    {
      "epoch": 1.8311239016624317,
      "grad_norm": 0.03444541618227959,
      "learning_rate": 7.792711426792805e-06,
      "loss": 0.0637,
      "step": 59810
    },
    {
      "epoch": 1.8314300584759513,
      "grad_norm": 0.013928274624049664,
      "learning_rate": 7.790670381369338e-06,
      "loss": 0.0016,
      "step": 59820
    },
    {
      "epoch": 1.8317362152894714,
      "grad_norm": 0.0385885052382946,
      "learning_rate": 7.788629335945872e-06,
      "loss": 0.0013,
      "step": 59830
    },
    {
      "epoch": 1.832042372102991,
      "grad_norm": 0.029392987489700317,
      "learning_rate": 7.786588290522407e-06,
      "loss": 0.0011,
      "step": 59840
    },
    {
      "epoch": 1.8323485289165111,
      "grad_norm": 0.029173320159316063,
      "learning_rate": 7.78454724509894e-06,
      "loss": 0.0011,
      "step": 59850
    },
    {
      "epoch": 1.8326546857300308,
      "grad_norm": 0.01969599351286888,
      "learning_rate": 7.782506199675475e-06,
      "loss": 0.0012,
      "step": 59860
    },
    {
      "epoch": 1.8329608425435509,
      "grad_norm": 0.04128493741154671,
      "learning_rate": 7.780465154252008e-06,
      "loss": 0.0019,
      "step": 59870
    },
    {
      "epoch": 1.8332669993570707,
      "grad_norm": 0.012418788857758045,
      "learning_rate": 7.778424108828544e-06,
      "loss": 0.0011,
      "step": 59880
    },
    {
      "epoch": 1.8335731561705906,
      "grad_norm": 0.013749372214078903,
      "learning_rate": 7.776383063405076e-06,
      "loss": 0.0336,
      "step": 59890
    },
    {
      "epoch": 1.8338793129841104,
      "grad_norm": 0.03809979557991028,
      "learning_rate": 7.774342017981611e-06,
      "loss": 0.0405,
      "step": 59900
    },
    {
      "epoch": 1.8341854697976303,
      "grad_norm": 0.02673661895096302,
      "learning_rate": 7.772300972558145e-06,
      "loss": 0.0024,
      "step": 59910
    },
    {
      "epoch": 1.8344916266111504,
      "grad_norm": 0.04715839773416519,
      "learning_rate": 7.770259927134678e-06,
      "loss": 0.002,
      "step": 59920
    },
    {
      "epoch": 1.83479778342467,
      "grad_norm": 0.012440214864909649,
      "learning_rate": 7.768218881711214e-06,
      "loss": 0.0429,
      "step": 59930
    },
    {
      "epoch": 1.8351039402381901,
      "grad_norm": 0.02986665442585945,
      "learning_rate": 7.766177836287747e-06,
      "loss": 0.0011,
      "step": 59940
    },
    {
      "epoch": 1.8354100970517098,
      "grad_norm": 0.04572577029466629,
      "learning_rate": 7.764136790864283e-06,
      "loss": 0.0337,
      "step": 59950
    },
    {
      "epoch": 1.8357162538652299,
      "grad_norm": 0.03239067643880844,
      "learning_rate": 7.762095745440814e-06,
      "loss": 0.0012,
      "step": 59960
    },
    {
      "epoch": 1.8360224106787495,
      "grad_norm": 0.02896689996123314,
      "learning_rate": 7.76005470001735e-06,
      "loss": 0.0243,
      "step": 59970
    },
    {
      "epoch": 1.8363285674922696,
      "grad_norm": 0.030937837436795235,
      "learning_rate": 7.758013654593883e-06,
      "loss": 0.0009,
      "step": 59980
    },
    {
      "epoch": 1.8366347243057894,
      "grad_norm": 0.014679527841508389,
      "learning_rate": 7.755972609170417e-06,
      "loss": 0.0331,
      "step": 59990
    },
    {
      "epoch": 1.8369408811193093,
      "grad_norm": 0.035456229001283646,
      "learning_rate": 7.75393156374695e-06,
      "loss": 0.0019,
      "step": 60000
    },
    {
      "epoch": 1.8372470379328292,
      "grad_norm": 0.022471075877547264,
      "learning_rate": 7.751890518323486e-06,
      "loss": 0.0416,
      "step": 60010
    },
    {
      "epoch": 1.837553194746349,
      "grad_norm": 1.678794264793396,
      "learning_rate": 7.74984947290002e-06,
      "loss": 0.0303,
      "step": 60020
    },
    {
      "epoch": 1.8378593515598691,
      "grad_norm": 0.07188713550567627,
      "learning_rate": 7.747808427476553e-06,
      "loss": 0.0021,
      "step": 60030
    },
    {
      "epoch": 1.8381655083733888,
      "grad_norm": 0.09383641183376312,
      "learning_rate": 7.745767382053089e-06,
      "loss": 0.0016,
      "step": 60040
    },
    {
      "epoch": 1.8384716651869089,
      "grad_norm": 0.009351802989840508,
      "learning_rate": 7.743726336629622e-06,
      "loss": 0.0017,
      "step": 60050
    },
    {
      "epoch": 1.8387778220004285,
      "grad_norm": 0.03724951669573784,
      "learning_rate": 7.741685291206158e-06,
      "loss": 0.0397,
      "step": 60060
    },
    {
      "epoch": 1.8390839788139486,
      "grad_norm": 0.03613576665520668,
      "learning_rate": 7.73964424578269e-06,
      "loss": 0.0304,
      "step": 60070
    },
    {
      "epoch": 1.8393901356274682,
      "grad_norm": 0.017028365284204483,
      "learning_rate": 7.737603200359225e-06,
      "loss": 0.0352,
      "step": 60080
    },
    {
      "epoch": 1.8396962924409883,
      "grad_norm": 0.03682209551334381,
      "learning_rate": 7.735562154935759e-06,
      "loss": 0.0057,
      "step": 60090
    },
    {
      "epoch": 1.8400024492545082,
      "grad_norm": 0.013767091557383537,
      "learning_rate": 7.733521109512292e-06,
      "loss": 0.002,
      "step": 60100
    },
    {
      "epoch": 1.840308606068028,
      "grad_norm": 0.02317783795297146,
      "learning_rate": 7.731480064088826e-06,
      "loss": 0.0013,
      "step": 60110
    },
    {
      "epoch": 1.840614762881548,
      "grad_norm": 0.06655910611152649,
      "learning_rate": 7.729439018665361e-06,
      "loss": 0.0016,
      "step": 60120
    },
    {
      "epoch": 1.8409209196950678,
      "grad_norm": 0.04270339384675026,
      "learning_rate": 7.727397973241895e-06,
      "loss": 0.0019,
      "step": 60130
    },
    {
      "epoch": 1.8412270765085879,
      "grad_norm": 0.032603196799755096,
      "learning_rate": 7.725356927818429e-06,
      "loss": 0.069,
      "step": 60140
    },
    {
      "epoch": 1.8415332333221075,
      "grad_norm": 0.01276603527367115,
      "learning_rate": 7.723315882394964e-06,
      "loss": 0.0013,
      "step": 60150
    },
    {
      "epoch": 1.8418393901356276,
      "grad_norm": 0.0473393052816391,
      "learning_rate": 7.721274836971498e-06,
      "loss": 0.0046,
      "step": 60160
    },
    {
      "epoch": 1.8421455469491472,
      "grad_norm": 0.005232417024672031,
      "learning_rate": 7.719233791548031e-06,
      "loss": 0.0012,
      "step": 60170
    },
    {
      "epoch": 1.8424517037626673,
      "grad_norm": 0.028042787685990334,
      "learning_rate": 7.717192746124565e-06,
      "loss": 0.0012,
      "step": 60180
    },
    {
      "epoch": 1.842757860576187,
      "grad_norm": 0.025350531563162804,
      "learning_rate": 7.7151517007011e-06,
      "loss": 0.036,
      "step": 60190
    },
    {
      "epoch": 1.843064017389707,
      "grad_norm": 0.029527973383665085,
      "learning_rate": 7.713110655277634e-06,
      "loss": 0.0299,
      "step": 60200
    },
    {
      "epoch": 1.843370174203227,
      "grad_norm": 2.4583005905151367,
      "learning_rate": 7.711069609854167e-06,
      "loss": 0.0407,
      "step": 60210
    },
    {
      "epoch": 1.8436763310167468,
      "grad_norm": 0.026100875809788704,
      "learning_rate": 7.709028564430701e-06,
      "loss": 0.005,
      "step": 60220
    },
    {
      "epoch": 1.8439824878302666,
      "grad_norm": 0.03729293867945671,
      "learning_rate": 7.706987519007236e-06,
      "loss": 0.0561,
      "step": 60230
    },
    {
      "epoch": 1.8442886446437865,
      "grad_norm": 0.024508362635970116,
      "learning_rate": 7.70494647358377e-06,
      "loss": 0.0014,
      "step": 60240
    },
    {
      "epoch": 1.8445948014573066,
      "grad_norm": 0.03153271973133087,
      "learning_rate": 7.702905428160304e-06,
      "loss": 0.0014,
      "step": 60250
    },
    {
      "epoch": 1.8449009582708262,
      "grad_norm": 0.028276408091187477,
      "learning_rate": 7.700864382736837e-06,
      "loss": 0.0027,
      "step": 60260
    },
    {
      "epoch": 1.8452071150843463,
      "grad_norm": 0.05192023143172264,
      "learning_rate": 7.698823337313373e-06,
      "loss": 0.0019,
      "step": 60270
    },
    {
      "epoch": 1.845513271897866,
      "grad_norm": 0.05543338134884834,
      "learning_rate": 7.696782291889906e-06,
      "loss": 0.0018,
      "step": 60280
    },
    {
      "epoch": 1.845819428711386,
      "grad_norm": 0.013471119105815887,
      "learning_rate": 7.69474124646644e-06,
      "loss": 0.0057,
      "step": 60290
    },
    {
      "epoch": 1.846125585524906,
      "grad_norm": 0.04453177750110626,
      "learning_rate": 7.692700201042975e-06,
      "loss": 0.0013,
      "step": 60300
    },
    {
      "epoch": 1.8464317423384258,
      "grad_norm": 0.03191700577735901,
      "learning_rate": 7.690659155619509e-06,
      "loss": 0.029,
      "step": 60310
    },
    {
      "epoch": 1.8467378991519456,
      "grad_norm": 0.02519986405968666,
      "learning_rate": 7.688618110196043e-06,
      "loss": 0.0015,
      "step": 60320
    },
    {
      "epoch": 1.8470440559654655,
      "grad_norm": 0.005840682424604893,
      "learning_rate": 7.686577064772576e-06,
      "loss": 0.0056,
      "step": 60330
    },
    {
      "epoch": 1.8473502127789854,
      "grad_norm": 0.032277341932058334,
      "learning_rate": 7.684536019349112e-06,
      "loss": 0.0011,
      "step": 60340
    },
    {
      "epoch": 1.8476563695925052,
      "grad_norm": 0.04303620755672455,
      "learning_rate": 7.682494973925645e-06,
      "loss": 0.0019,
      "step": 60350
    },
    {
      "epoch": 1.8479625264060253,
      "grad_norm": 0.03411693498492241,
      "learning_rate": 7.680453928502179e-06,
      "loss": 0.0012,
      "step": 60360
    },
    {
      "epoch": 1.848268683219545,
      "grad_norm": 0.013019072823226452,
      "learning_rate": 7.678412883078713e-06,
      "loss": 0.0015,
      "step": 60370
    },
    {
      "epoch": 1.848574840033065,
      "grad_norm": 0.013844442553818226,
      "learning_rate": 7.676371837655248e-06,
      "loss": 0.0667,
      "step": 60380
    },
    {
      "epoch": 1.8488809968465847,
      "grad_norm": 0.02796718291938305,
      "learning_rate": 7.674330792231782e-06,
      "loss": 0.0011,
      "step": 60390
    },
    {
      "epoch": 1.8491871536601048,
      "grad_norm": 0.06975577771663666,
      "learning_rate": 7.672289746808315e-06,
      "loss": 0.0014,
      "step": 60400
    },
    {
      "epoch": 1.8494933104736246,
      "grad_norm": 0.04475468769669533,
      "learning_rate": 7.67024870138485e-06,
      "loss": 0.0012,
      "step": 60410
    },
    {
      "epoch": 1.8497994672871445,
      "grad_norm": 0.007584280334413052,
      "learning_rate": 7.668207655961384e-06,
      "loss": 0.0012,
      "step": 60420
    },
    {
      "epoch": 1.8501056241006644,
      "grad_norm": 0.03978867828845978,
      "learning_rate": 7.666166610537918e-06,
      "loss": 0.0042,
      "step": 60430
    },
    {
      "epoch": 1.8504117809141842,
      "grad_norm": 0.009089427068829536,
      "learning_rate": 7.664125565114451e-06,
      "loss": 0.0138,
      "step": 60440
    },
    {
      "epoch": 1.850717937727704,
      "grad_norm": 0.02829316072165966,
      "learning_rate": 7.662084519690987e-06,
      "loss": 0.001,
      "step": 60450
    },
    {
      "epoch": 1.851024094541224,
      "grad_norm": 0.027087347581982613,
      "learning_rate": 7.66004347426752e-06,
      "loss": 0.0014,
      "step": 60460
    },
    {
      "epoch": 1.851330251354744,
      "grad_norm": 0.06129668653011322,
      "learning_rate": 7.658002428844054e-06,
      "loss": 0.0519,
      "step": 60470
    },
    {
      "epoch": 1.8516364081682637,
      "grad_norm": 0.02428872138261795,
      "learning_rate": 7.655961383420588e-06,
      "loss": 0.0008,
      "step": 60480
    },
    {
      "epoch": 1.8519425649817838,
      "grad_norm": 0.015304148197174072,
      "learning_rate": 7.653920337997123e-06,
      "loss": 0.0006,
      "step": 60490
    },
    {
      "epoch": 1.8522487217953034,
      "grad_norm": 2.315262794494629,
      "learning_rate": 7.651879292573657e-06,
      "loss": 0.1247,
      "step": 60500
    },
    {
      "epoch": 1.8525548786088235,
      "grad_norm": 0.01754143461585045,
      "learning_rate": 7.64983824715019e-06,
      "loss": 0.001,
      "step": 60510
    },
    {
      "epoch": 1.8528610354223434,
      "grad_norm": 0.019561566412448883,
      "learning_rate": 7.647797201726726e-06,
      "loss": 0.0012,
      "step": 60520
    },
    {
      "epoch": 1.8531671922358632,
      "grad_norm": 0.023781126365065575,
      "learning_rate": 7.64575615630326e-06,
      "loss": 0.0191,
      "step": 60530
    },
    {
      "epoch": 1.853473349049383,
      "grad_norm": 0.039945587515830994,
      "learning_rate": 7.643715110879793e-06,
      "loss": 0.0011,
      "step": 60540
    },
    {
      "epoch": 1.853779505862903,
      "grad_norm": 0.020521188154816628,
      "learning_rate": 7.641674065456327e-06,
      "loss": 0.0008,
      "step": 60550
    },
    {
      "epoch": 1.8540856626764228,
      "grad_norm": 0.025373117998242378,
      "learning_rate": 7.639633020032862e-06,
      "loss": 0.0043,
      "step": 60560
    },
    {
      "epoch": 1.8543918194899427,
      "grad_norm": 0.00945250689983368,
      "learning_rate": 7.637591974609396e-06,
      "loss": 0.001,
      "step": 60570
    },
    {
      "epoch": 1.8546979763034628,
      "grad_norm": 0.02590395137667656,
      "learning_rate": 7.63555092918593e-06,
      "loss": 0.0009,
      "step": 60580
    },
    {
      "epoch": 1.8550041331169824,
      "grad_norm": 0.02281336672604084,
      "learning_rate": 7.633509883762463e-06,
      "loss": 0.0284,
      "step": 60590
    },
    {
      "epoch": 1.8553102899305025,
      "grad_norm": 0.004431391600519419,
      "learning_rate": 7.631468838338998e-06,
      "loss": 0.0012,
      "step": 60600
    },
    {
      "epoch": 1.8556164467440222,
      "grad_norm": 0.02608356811106205,
      "learning_rate": 7.629427792915532e-06,
      "loss": 0.0009,
      "step": 60610
    },
    {
      "epoch": 1.8559226035575422,
      "grad_norm": 0.040567606687545776,
      "learning_rate": 7.627386747492066e-06,
      "loss": 0.0339,
      "step": 60620
    },
    {
      "epoch": 1.856228760371062,
      "grad_norm": 1.7122538089752197,
      "learning_rate": 7.625345702068601e-06,
      "loss": 0.0321,
      "step": 60630
    },
    {
      "epoch": 1.856534917184582,
      "grad_norm": 0.023058883845806122,
      "learning_rate": 7.6233046566451345e-06,
      "loss": 0.0009,
      "step": 60640
    },
    {
      "epoch": 1.8568410739981018,
      "grad_norm": 0.025696467608213425,
      "learning_rate": 7.621263611221669e-06,
      "loss": 0.0008,
      "step": 60650
    },
    {
      "epoch": 1.8571472308116217,
      "grad_norm": 0.018531326204538345,
      "learning_rate": 7.619222565798203e-06,
      "loss": 0.0008,
      "step": 60660
    },
    {
      "epoch": 1.8574533876251416,
      "grad_norm": 0.045747943222522736,
      "learning_rate": 7.617181520374737e-06,
      "loss": 0.0013,
      "step": 60670
    },
    {
      "epoch": 1.8577595444386614,
      "grad_norm": 0.02305162511765957,
      "learning_rate": 7.61514047495127e-06,
      "loss": 0.0009,
      "step": 60680
    },
    {
      "epoch": 1.8580657012521815,
      "grad_norm": 0.040406983345746994,
      "learning_rate": 7.613099429527805e-06,
      "loss": 0.0008,
      "step": 60690
    },
    {
      "epoch": 1.8583718580657012,
      "grad_norm": 0.01969752460718155,
      "learning_rate": 7.611058384104338e-06,
      "loss": 0.0009,
      "step": 60700
    },
    {
      "epoch": 1.8586780148792212,
      "grad_norm": 0.06279526650905609,
      "learning_rate": 7.609017338680873e-06,
      "loss": 0.0354,
      "step": 60710
    },
    {
      "epoch": 1.8589841716927409,
      "grad_norm": 0.013879531063139439,
      "learning_rate": 7.606976293257408e-06,
      "loss": 0.0007,
      "step": 60720
    },
    {
      "epoch": 1.859290328506261,
      "grad_norm": 1.9242600202560425,
      "learning_rate": 7.6049352478339415e-06,
      "loss": 0.043,
      "step": 60730
    },
    {
      "epoch": 1.8595964853197808,
      "grad_norm": 0.023677874356508255,
      "learning_rate": 7.602894202410476e-06,
      "loss": 0.0006,
      "step": 60740
    },
    {
      "epoch": 1.8599026421333007,
      "grad_norm": 0.04180862009525299,
      "learning_rate": 7.600853156987009e-06,
      "loss": 0.0377,
      "step": 60750
    },
    {
      "epoch": 1.8602087989468206,
      "grad_norm": 0.029002968221902847,
      "learning_rate": 7.598812111563544e-06,
      "loss": 0.0008,
      "step": 60760
    },
    {
      "epoch": 1.8605149557603404,
      "grad_norm": 0.0290131326764822,
      "learning_rate": 7.596771066140077e-06,
      "loss": 0.0243,
      "step": 60770
    },
    {
      "epoch": 1.8608211125738603,
      "grad_norm": 0.016305601224303246,
      "learning_rate": 7.594730020716612e-06,
      "loss": 0.0013,
      "step": 60780
    },
    {
      "epoch": 1.8611272693873802,
      "grad_norm": 0.01885959319770336,
      "learning_rate": 7.592688975293145e-06,
      "loss": 0.0006,
      "step": 60790
    },
    {
      "epoch": 1.8614334262009002,
      "grad_norm": 0.032796330749988556,
      "learning_rate": 7.59064792986968e-06,
      "loss": 0.0011,
      "step": 60800
    },
    {
      "epoch": 1.8617395830144199,
      "grad_norm": 0.015417811460793018,
      "learning_rate": 7.588606884446213e-06,
      "loss": 0.0011,
      "step": 60810
    },
    {
      "epoch": 1.86204573982794,
      "grad_norm": 0.016497045755386353,
      "learning_rate": 7.5865658390227485e-06,
      "loss": 0.0648,
      "step": 60820
    },
    {
      "epoch": 1.8623518966414596,
      "grad_norm": 0.01972281187772751,
      "learning_rate": 7.584524793599281e-06,
      "loss": 0.0009,
      "step": 60830
    },
    {
      "epoch": 1.8626580534549797,
      "grad_norm": 0.02853407897055149,
      "learning_rate": 7.582483748175816e-06,
      "loss": 0.0011,
      "step": 60840
    },
    {
      "epoch": 1.8629642102684996,
      "grad_norm": 0.018757035955786705,
      "learning_rate": 7.580442702752351e-06,
      "loss": 0.001,
      "step": 60850
    },
    {
      "epoch": 1.8632703670820194,
      "grad_norm": 0.028836097568273544,
      "learning_rate": 7.578401657328884e-06,
      "loss": 0.0533,
      "step": 60860
    },
    {
      "epoch": 1.8635765238955393,
      "grad_norm": 0.012327703647315502,
      "learning_rate": 7.576360611905419e-06,
      "loss": 0.0012,
      "step": 60870
    },
    {
      "epoch": 1.8638826807090592,
      "grad_norm": 0.07143814116716385,
      "learning_rate": 7.574319566481952e-06,
      "loss": 0.0014,
      "step": 60880
    },
    {
      "epoch": 1.864188837522579,
      "grad_norm": 1.8177595138549805,
      "learning_rate": 7.5722785210584874e-06,
      "loss": 0.0354,
      "step": 60890
    },
    {
      "epoch": 1.8644949943360989,
      "grad_norm": 0.018550347536802292,
      "learning_rate": 7.57023747563502e-06,
      "loss": 0.0358,
      "step": 60900
    },
    {
      "epoch": 1.864801151149619,
      "grad_norm": 0.03207944333553314,
      "learning_rate": 7.568196430211555e-06,
      "loss": 0.0015,
      "step": 60910
    },
    {
      "epoch": 1.8651073079631386,
      "grad_norm": 0.018519116565585136,
      "learning_rate": 7.566155384788088e-06,
      "loss": 0.0194,
      "step": 60920
    },
    {
      "epoch": 1.8654134647766587,
      "grad_norm": 0.04544169455766678,
      "learning_rate": 7.564114339364623e-06,
      "loss": 0.0013,
      "step": 60930
    },
    {
      "epoch": 1.8657196215901783,
      "grad_norm": 0.01694934256374836,
      "learning_rate": 7.5620732939411565e-06,
      "loss": 0.0012,
      "step": 60940
    },
    {
      "epoch": 1.8660257784036984,
      "grad_norm": 0.05214279890060425,
      "learning_rate": 7.560032248517691e-06,
      "loss": 0.0275,
      "step": 60950
    },
    {
      "epoch": 1.8663319352172183,
      "grad_norm": 0.036427173763513565,
      "learning_rate": 7.557991203094226e-06,
      "loss": 0.0016,
      "step": 60960
    },
    {
      "epoch": 1.8666380920307382,
      "grad_norm": 0.04378695413470268,
      "learning_rate": 7.555950157670759e-06,
      "loss": 0.0014,
      "step": 60970
    },
    {
      "epoch": 1.866944248844258,
      "grad_norm": 0.0178991612046957,
      "learning_rate": 7.5539091122472945e-06,
      "loss": 0.0012,
      "step": 60980
    },
    {
      "epoch": 1.867250405657778,
      "grad_norm": 0.021748075261712074,
      "learning_rate": 7.551868066823827e-06,
      "loss": 0.0011,
      "step": 60990
    },
    {
      "epoch": 1.8675565624712978,
      "grad_norm": 0.012618186883628368,
      "learning_rate": 7.549827021400362e-06,
      "loss": 0.0007,
      "step": 61000
    },
    {
      "epoch": 1.8678627192848176,
      "grad_norm": 0.02794490195810795,
      "learning_rate": 7.547785975976895e-06,
      "loss": 0.0446,
      "step": 61010
    },
    {
      "epoch": 1.8681688760983377,
      "grad_norm": 1.9068689346313477,
      "learning_rate": 7.54574493055343e-06,
      "loss": 0.0349,
      "step": 61020
    },
    {
      "epoch": 1.8684750329118573,
      "grad_norm": 0.02548549510538578,
      "learning_rate": 7.5437038851299635e-06,
      "loss": 0.001,
      "step": 61030
    },
    {
      "epoch": 1.8687811897253774,
      "grad_norm": 0.03173753619194031,
      "learning_rate": 7.541662839706498e-06,
      "loss": 0.01,
      "step": 61040
    },
    {
      "epoch": 1.869087346538897,
      "grad_norm": 0.01766645908355713,
      "learning_rate": 7.539621794283032e-06,
      "loss": 0.0009,
      "step": 61050
    },
    {
      "epoch": 1.8693935033524172,
      "grad_norm": 0.023712942376732826,
      "learning_rate": 7.537580748859566e-06,
      "loss": 0.0354,
      "step": 61060
    },
    {
      "epoch": 1.869699660165937,
      "grad_norm": 0.04873986914753914,
      "learning_rate": 7.5355397034361015e-06,
      "loss": 0.0016,
      "step": 61070
    },
    {
      "epoch": 1.870005816979457,
      "grad_norm": 0.008977638557553291,
      "learning_rate": 7.533498658012634e-06,
      "loss": 0.0011,
      "step": 61080
    },
    {
      "epoch": 1.8703119737929768,
      "grad_norm": 0.040578145533800125,
      "learning_rate": 7.531457612589169e-06,
      "loss": 0.0016,
      "step": 61090
    },
    {
      "epoch": 1.8706181306064966,
      "grad_norm": 0.0355306901037693,
      "learning_rate": 7.5294165671657024e-06,
      "loss": 0.0017,
      "step": 61100
    },
    {
      "epoch": 1.8709242874200165,
      "grad_norm": 0.037217509001493454,
      "learning_rate": 7.527375521742237e-06,
      "loss": 0.0016,
      "step": 61110
    },
    {
      "epoch": 1.8712304442335363,
      "grad_norm": 0.04161149635910988,
      "learning_rate": 7.5253344763187706e-06,
      "loss": 0.0348,
      "step": 61120
    },
    {
      "epoch": 1.8715366010470564,
      "grad_norm": 1.8852959871292114,
      "learning_rate": 7.523293430895305e-06,
      "loss": 0.0363,
      "step": 61130
    },
    {
      "epoch": 1.871842757860576,
      "grad_norm": 0.027924340218305588,
      "learning_rate": 7.521252385471839e-06,
      "loss": 0.001,
      "step": 61140
    },
    {
      "epoch": 1.8721489146740962,
      "grad_norm": 0.01798875816166401,
      "learning_rate": 7.519211340048373e-06,
      "loss": 0.0344,
      "step": 61150
    },
    {
      "epoch": 1.8724550714876158,
      "grad_norm": 0.030517231673002243,
      "learning_rate": 7.517170294624907e-06,
      "loss": 0.0597,
      "step": 61160
    },
    {
      "epoch": 1.872761228301136,
      "grad_norm": 0.048290546983480453,
      "learning_rate": 7.515129249201441e-06,
      "loss": 0.0014,
      "step": 61170
    },
    {
      "epoch": 1.8730673851146558,
      "grad_norm": 0.021589238196611404,
      "learning_rate": 7.513088203777976e-06,
      "loss": 0.0012,
      "step": 61180
    },
    {
      "epoch": 1.8733735419281756,
      "grad_norm": 0.02821187674999237,
      "learning_rate": 7.5110471583545095e-06,
      "loss": 0.0015,
      "step": 61190
    },
    {
      "epoch": 1.8736796987416955,
      "grad_norm": 0.013636939227581024,
      "learning_rate": 7.509006112931044e-06,
      "loss": 0.0014,
      "step": 61200
    },
    {
      "epoch": 1.8739858555552154,
      "grad_norm": 0.053538911044597626,
      "learning_rate": 7.506965067507578e-06,
      "loss": 0.0033,
      "step": 61210
    },
    {
      "epoch": 1.8742920123687352,
      "grad_norm": 0.03825385123491287,
      "learning_rate": 7.504924022084112e-06,
      "loss": 0.0334,
      "step": 61220
    },
    {
      "epoch": 1.874598169182255,
      "grad_norm": 0.028362318873405457,
      "learning_rate": 7.502882976660646e-06,
      "loss": 0.0014,
      "step": 61230
    },
    {
      "epoch": 1.8749043259957752,
      "grad_norm": 0.06523523479700089,
      "learning_rate": 7.50084193123718e-06,
      "loss": 0.0015,
      "step": 61240
    },
    {
      "epoch": 1.8752104828092948,
      "grad_norm": 0.03257136046886444,
      "learning_rate": 7.498800885813714e-06,
      "loss": 0.0357,
      "step": 61250
    },
    {
      "epoch": 1.875516639622815,
      "grad_norm": 0.022506466135382652,
      "learning_rate": 7.496759840390248e-06,
      "loss": 0.0393,
      "step": 61260
    },
    {
      "epoch": 1.8758227964363345,
      "grad_norm": 0.04257519170641899,
      "learning_rate": 7.494718794966782e-06,
      "loss": 0.0368,
      "step": 61270
    },
    {
      "epoch": 1.8761289532498546,
      "grad_norm": 0.009525159373879433,
      "learning_rate": 7.4926777495433165e-06,
      "loss": 0.0426,
      "step": 61280
    },
    {
      "epoch": 1.8764351100633745,
      "grad_norm": 0.04451208561658859,
      "learning_rate": 7.490636704119851e-06,
      "loss": 0.0339,
      "step": 61290
    },
    {
      "epoch": 1.8767412668768944,
      "grad_norm": 0.03966263309121132,
      "learning_rate": 7.488595658696385e-06,
      "loss": 0.002,
      "step": 61300
    },
    {
      "epoch": 1.8770474236904142,
      "grad_norm": 0.05344442278146744,
      "learning_rate": 7.486554613272919e-06,
      "loss": 0.0399,
      "step": 61310
    },
    {
      "epoch": 1.877353580503934,
      "grad_norm": 0.0720595046877861,
      "learning_rate": 7.484513567849453e-06,
      "loss": 0.0023,
      "step": 61320
    },
    {
      "epoch": 1.877659737317454,
      "grad_norm": 0.032810840755701065,
      "learning_rate": 7.482472522425987e-06,
      "loss": 0.0309,
      "step": 61330
    },
    {
      "epoch": 1.8779658941309738,
      "grad_norm": 0.012120909988880157,
      "learning_rate": 7.480431477002521e-06,
      "loss": 0.0019,
      "step": 61340
    },
    {
      "epoch": 1.878272050944494,
      "grad_norm": 0.024861108511686325,
      "learning_rate": 7.478390431579055e-06,
      "loss": 0.0064,
      "step": 61350
    },
    {
      "epoch": 1.8785782077580135,
      "grad_norm": 1.4690923690795898,
      "learning_rate": 7.476349386155589e-06,
      "loss": 0.0574,
      "step": 61360
    },
    {
      "epoch": 1.8788843645715336,
      "grad_norm": 0.026567591354250908,
      "learning_rate": 7.4743083407321235e-06,
      "loss": 0.0018,
      "step": 61370
    },
    {
      "epoch": 1.8791905213850533,
      "grad_norm": 0.06409779191017151,
      "learning_rate": 7.472267295308657e-06,
      "loss": 0.0018,
      "step": 61380
    },
    {
      "epoch": 1.8794966781985734,
      "grad_norm": 0.03316352516412735,
      "learning_rate": 7.470226249885192e-06,
      "loss": 0.0019,
      "step": 61390
    },
    {
      "epoch": 1.8798028350120932,
      "grad_norm": 0.09796053916215897,
      "learning_rate": 7.468185204461726e-06,
      "loss": 0.0021,
      "step": 61400
    },
    {
      "epoch": 1.880108991825613,
      "grad_norm": 0.05293910950422287,
      "learning_rate": 7.46614415903826e-06,
      "loss": 0.0295,
      "step": 61410
    },
    {
      "epoch": 1.880415148639133,
      "grad_norm": 3.3465726375579834,
      "learning_rate": 7.464103113614794e-06,
      "loss": 0.0126,
      "step": 61420
    },
    {
      "epoch": 1.8807213054526528,
      "grad_norm": 0.05639743432402611,
      "learning_rate": 7.462062068191328e-06,
      "loss": 0.0022,
      "step": 61430
    },
    {
      "epoch": 1.8810274622661727,
      "grad_norm": 0.0564885176718235,
      "learning_rate": 7.4600210227678624e-06,
      "loss": 0.0021,
      "step": 61440
    },
    {
      "epoch": 1.8813336190796925,
      "grad_norm": 0.00998533796519041,
      "learning_rate": 7.457979977344396e-06,
      "loss": 0.0017,
      "step": 61450
    },
    {
      "epoch": 1.8816397758932126,
      "grad_norm": 0.03500784933567047,
      "learning_rate": 7.4559389319209306e-06,
      "loss": 0.0356,
      "step": 61460
    },
    {
      "epoch": 1.8819459327067323,
      "grad_norm": 0.019471557810902596,
      "learning_rate": 7.453897886497464e-06,
      "loss": 0.0014,
      "step": 61470
    },
    {
      "epoch": 1.8822520895202524,
      "grad_norm": 0.025269944220781326,
      "learning_rate": 7.451856841073999e-06,
      "loss": 0.0013,
      "step": 61480
    },
    {
      "epoch": 1.882558246333772,
      "grad_norm": 0.04964682087302208,
      "learning_rate": 7.449815795650532e-06,
      "loss": 0.001,
      "step": 61490
    },
    {
      "epoch": 1.882864403147292,
      "grad_norm": 1.1225188970565796,
      "learning_rate": 7.447774750227067e-06,
      "loss": 0.0022,
      "step": 61500
    },
    {
      "epoch": 1.883170559960812,
      "grad_norm": 0.01960155740380287,
      "learning_rate": 7.4457337048036005e-06,
      "loss": 0.001,
      "step": 61510
    },
    {
      "epoch": 1.8834767167743318,
      "grad_norm": 2.833136796951294,
      "learning_rate": 7.443692659380135e-06,
      "loss": 0.0292,
      "step": 61520
    },
    {
      "epoch": 1.8837828735878517,
      "grad_norm": 0.015014134347438812,
      "learning_rate": 7.4416516139566695e-06,
      "loss": 0.0011,
      "step": 61530
    },
    {
      "epoch": 1.8840890304013715,
      "grad_norm": 0.02429460547864437,
      "learning_rate": 7.439610568533203e-06,
      "loss": 0.0355,
      "step": 61540
    },
    {
      "epoch": 1.8843951872148916,
      "grad_norm": 0.014365951530635357,
      "learning_rate": 7.437569523109738e-06,
      "loss": 0.0009,
      "step": 61550
    },
    {
      "epoch": 1.8847013440284113,
      "grad_norm": 0.02817927859723568,
      "learning_rate": 7.435528477686271e-06,
      "loss": 0.0274,
      "step": 61560
    },
    {
      "epoch": 1.8850075008419314,
      "grad_norm": 0.04711426794528961,
      "learning_rate": 7.433487432262806e-06,
      "loss": 0.0012,
      "step": 61570
    },
    {
      "epoch": 1.885313657655451,
      "grad_norm": 0.02238992042839527,
      "learning_rate": 7.431446386839339e-06,
      "loss": 0.0319,
      "step": 61580
    },
    {
      "epoch": 1.885619814468971,
      "grad_norm": 0.011984915472567081,
      "learning_rate": 7.429405341415874e-06,
      "loss": 0.1169,
      "step": 61590
    },
    {
      "epoch": 1.8859259712824907,
      "grad_norm": 0.015177462249994278,
      "learning_rate": 7.4273642959924075e-06,
      "loss": 0.0042,
      "step": 61600
    },
    {
      "epoch": 1.8862321280960108,
      "grad_norm": 0.05436238646507263,
      "learning_rate": 7.425323250568942e-06,
      "loss": 0.0014,
      "step": 61610
    },
    {
      "epoch": 1.8865382849095307,
      "grad_norm": 0.050471141934394836,
      "learning_rate": 7.423282205145476e-06,
      "loss": 0.0015,
      "step": 61620
    },
    {
      "epoch": 1.8868444417230505,
      "grad_norm": 0.03563900664448738,
      "learning_rate": 7.42124115972201e-06,
      "loss": 0.0015,
      "step": 61630
    },
    {
      "epoch": 1.8871505985365704,
      "grad_norm": 0.07168910652399063,
      "learning_rate": 7.419200114298545e-06,
      "loss": 0.0636,
      "step": 61640
    },
    {
      "epoch": 1.8874567553500903,
      "grad_norm": 0.051520537585020065,
      "learning_rate": 7.417159068875078e-06,
      "loss": 0.0285,
      "step": 61650
    },
    {
      "epoch": 1.8877629121636104,
      "grad_norm": 0.07322186231613159,
      "learning_rate": 7.415118023451613e-06,
      "loss": 0.0661,
      "step": 61660
    },
    {
      "epoch": 1.88806906897713,
      "grad_norm": 0.061789341270923615,
      "learning_rate": 7.413076978028146e-06,
      "loss": 0.036,
      "step": 61670
    },
    {
      "epoch": 1.88837522579065,
      "grad_norm": 0.025641662999987602,
      "learning_rate": 7.411035932604681e-06,
      "loss": 0.0012,
      "step": 61680
    },
    {
      "epoch": 1.8886813826041697,
      "grad_norm": 0.06076795607805252,
      "learning_rate": 7.4089948871812146e-06,
      "loss": 0.0018,
      "step": 61690
    },
    {
      "epoch": 1.8889875394176898,
      "grad_norm": 0.04324980452656746,
      "learning_rate": 7.406953841757749e-06,
      "loss": 0.0016,
      "step": 61700
    },
    {
      "epoch": 1.8892936962312095,
      "grad_norm": 0.035527680069208145,
      "learning_rate": 7.404912796334283e-06,
      "loss": 0.0013,
      "step": 61710
    },
    {
      "epoch": 1.8895998530447295,
      "grad_norm": 0.007680546026676893,
      "learning_rate": 7.402871750910817e-06,
      "loss": 0.0117,
      "step": 61720
    },
    {
      "epoch": 1.8899060098582494,
      "grad_norm": 0.027989251539111137,
      "learning_rate": 7.400830705487351e-06,
      "loss": 0.001,
      "step": 61730
    },
    {
      "epoch": 1.8902121666717693,
      "grad_norm": 0.05202870815992355,
      "learning_rate": 7.398789660063885e-06,
      "loss": 0.001,
      "step": 61740
    },
    {
      "epoch": 1.8905183234852891,
      "grad_norm": 0.1197730302810669,
      "learning_rate": 7.39674861464042e-06,
      "loss": 0.0008,
      "step": 61750
    },
    {
      "epoch": 1.890824480298809,
      "grad_norm": 0.01725887507200241,
      "learning_rate": 7.3947075692169534e-06,
      "loss": 0.0344,
      "step": 61760
    },
    {
      "epoch": 1.891130637112329,
      "grad_norm": 0.026023460552096367,
      "learning_rate": 7.392666523793488e-06,
      "loss": 0.0012,
      "step": 61770
    },
    {
      "epoch": 1.8914367939258487,
      "grad_norm": 0.022279754281044006,
      "learning_rate": 7.390625478370022e-06,
      "loss": 0.0012,
      "step": 61780
    },
    {
      "epoch": 1.8917429507393688,
      "grad_norm": 0.06707868725061417,
      "learning_rate": 7.388584432946556e-06,
      "loss": 0.0188,
      "step": 61790
    },
    {
      "epoch": 1.8920491075528885,
      "grad_norm": 0.008342386223375797,
      "learning_rate": 7.38654338752309e-06,
      "loss": 0.0009,
      "step": 61800
    },
    {
      "epoch": 1.8923552643664086,
      "grad_norm": 0.014829435385763645,
      "learning_rate": 7.384502342099624e-06,
      "loss": 0.0009,
      "step": 61810
    },
    {
      "epoch": 1.8926614211799282,
      "grad_norm": 0.01896863803267479,
      "learning_rate": 7.382461296676158e-06,
      "loss": 0.001,
      "step": 61820
    },
    {
      "epoch": 1.8929675779934483,
      "grad_norm": 0.024146858602762222,
      "learning_rate": 7.380420251252692e-06,
      "loss": 0.0008,
      "step": 61830
    },
    {
      "epoch": 1.8932737348069681,
      "grad_norm": 0.022918833419680595,
      "learning_rate": 7.378379205829226e-06,
      "loss": 0.0402,
      "step": 61840
    },
    {
      "epoch": 1.893579891620488,
      "grad_norm": 0.03340710699558258,
      "learning_rate": 7.3763381604057605e-06,
      "loss": 0.0622,
      "step": 61850
    },
    {
      "epoch": 1.8938860484340079,
      "grad_norm": 0.013679192401468754,
      "learning_rate": 7.374297114982295e-06,
      "loss": 0.001,
      "step": 61860
    },
    {
      "epoch": 1.8941922052475277,
      "grad_norm": 0.010012454353272915,
      "learning_rate": 7.372256069558829e-06,
      "loss": 0.001,
      "step": 61870
    },
    {
      "epoch": 1.8944983620610478,
      "grad_norm": 0.023347139358520508,
      "learning_rate": 7.370215024135363e-06,
      "loss": 0.0009,
      "step": 61880
    },
    {
      "epoch": 1.8948045188745675,
      "grad_norm": 0.04223796725273132,
      "learning_rate": 7.368173978711897e-06,
      "loss": 0.001,
      "step": 61890
    },
    {
      "epoch": 1.8951106756880876,
      "grad_norm": 0.011242896318435669,
      "learning_rate": 7.366132933288431e-06,
      "loss": 0.0013,
      "step": 61900
    },
    {
      "epoch": 1.8954168325016072,
      "grad_norm": 0.005364669021219015,
      "learning_rate": 7.364091887864965e-06,
      "loss": 0.0011,
      "step": 61910
    },
    {
      "epoch": 1.8957229893151273,
      "grad_norm": 0.023250296711921692,
      "learning_rate": 7.362050842441499e-06,
      "loss": 0.0009,
      "step": 61920
    },
    {
      "epoch": 1.8960291461286471,
      "grad_norm": 0.00789005309343338,
      "learning_rate": 7.360009797018033e-06,
      "loss": 0.0007,
      "step": 61930
    },
    {
      "epoch": 1.896335302942167,
      "grad_norm": 0.028988119214773178,
      "learning_rate": 7.3579687515945675e-06,
      "loss": 0.0008,
      "step": 61940
    },
    {
      "epoch": 1.8966414597556869,
      "grad_norm": 0.009598626755177975,
      "learning_rate": 7.355927706171101e-06,
      "loss": 0.041,
      "step": 61950
    },
    {
      "epoch": 1.8969476165692067,
      "grad_norm": 0.06033683195710182,
      "learning_rate": 7.353886660747636e-06,
      "loss": 0.0009,
      "step": 61960
    },
    {
      "epoch": 1.8972537733827266,
      "grad_norm": 0.018713735044002533,
      "learning_rate": 7.35184561532417e-06,
      "loss": 0.001,
      "step": 61970
    },
    {
      "epoch": 1.8975599301962465,
      "grad_norm": 0.02244923822581768,
      "learning_rate": 7.349804569900704e-06,
      "loss": 0.0007,
      "step": 61980
    },
    {
      "epoch": 1.8978660870097666,
      "grad_norm": 0.02828637883067131,
      "learning_rate": 7.347763524477238e-06,
      "loss": 0.0014,
      "step": 61990
    },
    {
      "epoch": 1.8981722438232862,
      "grad_norm": 0.013333187438547611,
      "learning_rate": 7.345722479053772e-06,
      "loss": 0.0011,
      "step": 62000
    },
    {
      "epoch": 1.8984784006368063,
      "grad_norm": 0.02327979914844036,
      "learning_rate": 7.343681433630306e-06,
      "loss": 0.0324,
      "step": 62010
    },
    {
      "epoch": 1.898784557450326,
      "grad_norm": 0.005007569212466478,
      "learning_rate": 7.34164038820684e-06,
      "loss": 0.0402,
      "step": 62020
    },
    {
      "epoch": 1.899090714263846,
      "grad_norm": 0.011790727265179157,
      "learning_rate": 7.3395993427833745e-06,
      "loss": 0.0008,
      "step": 62030
    },
    {
      "epoch": 1.8993968710773659,
      "grad_norm": 0.03977193310856819,
      "learning_rate": 7.337558297359908e-06,
      "loss": 0.0012,
      "step": 62040
    },
    {
      "epoch": 1.8997030278908857,
      "grad_norm": 0.010094849392771721,
      "learning_rate": 7.335517251936443e-06,
      "loss": 0.031,
      "step": 62050
    },
    {
      "epoch": 1.9000091847044056,
      "grad_norm": 0.005432977806776762,
      "learning_rate": 7.333476206512976e-06,
      "loss": 0.0009,
      "step": 62060
    },
    {
      "epoch": 1.9003153415179255,
      "grad_norm": 0.027264196425676346,
      "learning_rate": 7.331435161089511e-06,
      "loss": 0.0008,
      "step": 62070
    },
    {
      "epoch": 1.9006214983314453,
      "grad_norm": 0.041280411183834076,
      "learning_rate": 7.3293941156660445e-06,
      "loss": 0.0044,
      "step": 62080
    },
    {
      "epoch": 1.9009276551449652,
      "grad_norm": 0.0035985398571938276,
      "learning_rate": 7.327353070242579e-06,
      "loss": 0.0008,
      "step": 62090
    },
    {
      "epoch": 1.9012338119584853,
      "grad_norm": 0.03546106070280075,
      "learning_rate": 7.3253120248191134e-06,
      "loss": 0.0009,
      "step": 62100
    },
    {
      "epoch": 1.901539968772005,
      "grad_norm": 0.038039430975914,
      "learning_rate": 7.323270979395647e-06,
      "loss": 0.0348,
      "step": 62110
    },
    {
      "epoch": 1.901846125585525,
      "grad_norm": 0.0350758358836174,
      "learning_rate": 7.321229933972182e-06,
      "loss": 0.0011,
      "step": 62120
    },
    {
      "epoch": 1.9021522823990447,
      "grad_norm": 0.014695684425532818,
      "learning_rate": 7.319188888548715e-06,
      "loss": 0.0008,
      "step": 62130
    },
    {
      "epoch": 1.9024584392125647,
      "grad_norm": 0.03681665286421776,
      "learning_rate": 7.31714784312525e-06,
      "loss": 0.001,
      "step": 62140
    },
    {
      "epoch": 1.9027645960260846,
      "grad_norm": 0.05536331608891487,
      "learning_rate": 7.315106797701783e-06,
      "loss": 0.0009,
      "step": 62150
    },
    {
      "epoch": 1.9030707528396045,
      "grad_norm": 0.01989397592842579,
      "learning_rate": 7.313065752278318e-06,
      "loss": 0.0011,
      "step": 62160
    },
    {
      "epoch": 1.9033769096531243,
      "grad_norm": 0.0025200059171766043,
      "learning_rate": 7.3110247068548515e-06,
      "loss": 0.0008,
      "step": 62170
    },
    {
      "epoch": 1.9036830664666442,
      "grad_norm": 0.01130390539765358,
      "learning_rate": 7.308983661431386e-06,
      "loss": 0.0008,
      "step": 62180
    },
    {
      "epoch": 1.903989223280164,
      "grad_norm": 0.01999167911708355,
      "learning_rate": 7.30694261600792e-06,
      "loss": 0.0009,
      "step": 62190
    },
    {
      "epoch": 1.904295380093684,
      "grad_norm": 0.0020686478819698095,
      "learning_rate": 7.304901570584454e-06,
      "loss": 0.0292,
      "step": 62200
    },
    {
      "epoch": 1.904601536907204,
      "grad_norm": 0.028482070192694664,
      "learning_rate": 7.302860525160989e-06,
      "loss": 0.001,
      "step": 62210
    },
    {
      "epoch": 1.9049076937207237,
      "grad_norm": 2.1388261318206787,
      "learning_rate": 7.300819479737522e-06,
      "loss": 0.0768,
      "step": 62220
    },
    {
      "epoch": 1.9052138505342437,
      "grad_norm": 0.01839574985206127,
      "learning_rate": 7.298778434314057e-06,
      "loss": 0.0409,
      "step": 62230
    },
    {
      "epoch": 1.9055200073477634,
      "grad_norm": 0.033085066825151443,
      "learning_rate": 7.29673738889059e-06,
      "loss": 0.0345,
      "step": 62240
    },
    {
      "epoch": 1.9058261641612835,
      "grad_norm": 0.024976151064038277,
      "learning_rate": 7.294696343467125e-06,
      "loss": 0.001,
      "step": 62250
    },
    {
      "epoch": 1.9061323209748033,
      "grad_norm": 0.034349482506513596,
      "learning_rate": 7.2926552980436585e-06,
      "loss": 0.0016,
      "step": 62260
    },
    {
      "epoch": 1.9064384777883232,
      "grad_norm": 0.04252098873257637,
      "learning_rate": 7.290614252620193e-06,
      "loss": 0.0016,
      "step": 62270
    },
    {
      "epoch": 1.906744634601843,
      "grad_norm": 0.019317813217639923,
      "learning_rate": 7.288573207196727e-06,
      "loss": 0.0008,
      "step": 62280
    },
    {
      "epoch": 1.907050791415363,
      "grad_norm": 0.005505087785422802,
      "learning_rate": 7.286532161773261e-06,
      "loss": 0.001,
      "step": 62290
    },
    {
      "epoch": 1.9073569482288828,
      "grad_norm": 0.03327227383852005,
      "learning_rate": 7.284491116349795e-06,
      "loss": 0.0009,
      "step": 62300
    },
    {
      "epoch": 1.9076631050424027,
      "grad_norm": 0.015014927834272385,
      "learning_rate": 7.282450070926329e-06,
      "loss": 0.0011,
      "step": 62310
    },
    {
      "epoch": 1.9079692618559227,
      "grad_norm": 0.015728818252682686,
      "learning_rate": 7.280409025502864e-06,
      "loss": 0.001,
      "step": 62320
    },
    {
      "epoch": 1.9082754186694424,
      "grad_norm": 0.022081436589360237,
      "learning_rate": 7.2783679800793974e-06,
      "loss": 0.0728,
      "step": 62330
    },
    {
      "epoch": 1.9085815754829625,
      "grad_norm": 0.02509157918393612,
      "learning_rate": 7.276326934655932e-06,
      "loss": 0.0399,
      "step": 62340
    },
    {
      "epoch": 1.9088877322964821,
      "grad_norm": 0.01153457723557949,
      "learning_rate": 7.2742858892324656e-06,
      "loss": 0.0294,
      "step": 62350
    },
    {
      "epoch": 1.9091938891100022,
      "grad_norm": 0.021733876317739487,
      "learning_rate": 7.272244843809e-06,
      "loss": 0.0018,
      "step": 62360
    },
    {
      "epoch": 1.909500045923522,
      "grad_norm": 0.02221483550965786,
      "learning_rate": 7.270203798385534e-06,
      "loss": 0.031,
      "step": 62370
    },
    {
      "epoch": 1.909806202737042,
      "grad_norm": 0.09568443149328232,
      "learning_rate": 7.268162752962068e-06,
      "loss": 0.0349,
      "step": 62380
    },
    {
      "epoch": 1.9101123595505618,
      "grad_norm": 0.032970938831567764,
      "learning_rate": 7.266121707538602e-06,
      "loss": 0.0016,
      "step": 62390
    },
    {
      "epoch": 1.9104185163640817,
      "grad_norm": 0.05285743251442909,
      "learning_rate": 7.264080662115136e-06,
      "loss": 0.0015,
      "step": 62400
    },
    {
      "epoch": 1.9107246731776015,
      "grad_norm": 0.04441438615322113,
      "learning_rate": 7.26203961669167e-06,
      "loss": 0.0017,
      "step": 62410
    },
    {
      "epoch": 1.9110308299911214,
      "grad_norm": 0.05327087640762329,
      "learning_rate": 7.2599985712682045e-06,
      "loss": 0.0328,
      "step": 62420
    },
    {
      "epoch": 1.9113369868046415,
      "grad_norm": 0.05235785245895386,
      "learning_rate": 7.257957525844739e-06,
      "loss": 0.0272,
      "step": 62430
    },
    {
      "epoch": 1.9116431436181611,
      "grad_norm": 0.022682299837470055,
      "learning_rate": 7.255916480421273e-06,
      "loss": 0.0013,
      "step": 62440
    },
    {
      "epoch": 1.9119493004316812,
      "grad_norm": 0.01926897093653679,
      "learning_rate": 7.253875434997807e-06,
      "loss": 0.0057,
      "step": 62450
    },
    {
      "epoch": 1.9122554572452009,
      "grad_norm": 0.013182653114199638,
      "learning_rate": 7.251834389574341e-06,
      "loss": 0.0392,
      "step": 62460
    },
    {
      "epoch": 1.912561614058721,
      "grad_norm": 0.05359242856502533,
      "learning_rate": 7.249793344150875e-06,
      "loss": 0.0018,
      "step": 62470
    },
    {
      "epoch": 1.9128677708722408,
      "grad_norm": 0.03887198120355606,
      "learning_rate": 7.247752298727409e-06,
      "loss": 0.0013,
      "step": 62480
    },
    {
      "epoch": 1.9131739276857607,
      "grad_norm": 0.051927659660577774,
      "learning_rate": 7.245711253303943e-06,
      "loss": 0.001,
      "step": 62490
    },
    {
      "epoch": 1.9134800844992805,
      "grad_norm": 0.008064544759690762,
      "learning_rate": 7.243670207880477e-06,
      "loss": 0.0012,
      "step": 62500
    },
    {
      "epoch": 1.9137862413128004,
      "grad_norm": 0.030427346006035805,
      "learning_rate": 7.2416291624570115e-06,
      "loss": 0.0015,
      "step": 62510
    },
    {
      "epoch": 1.9140923981263203,
      "grad_norm": 0.020727725699543953,
      "learning_rate": 7.239588117033544e-06,
      "loss": 0.0135,
      "step": 62520
    },
    {
      "epoch": 1.9143985549398401,
      "grad_norm": 0.01557744201272726,
      "learning_rate": 7.23754707161008e-06,
      "loss": 0.0009,
      "step": 62530
    },
    {
      "epoch": 1.9147047117533602,
      "grad_norm": 0.061039429157972336,
      "learning_rate": 7.235506026186614e-06,
      "loss": 0.0376,
      "step": 62540
    },
    {
      "epoch": 1.9150108685668799,
      "grad_norm": 0.027692725881934166,
      "learning_rate": 7.233464980763148e-06,
      "loss": 0.001,
      "step": 62550
    },
    {
      "epoch": 1.9153170253804,
      "grad_norm": 0.042938102036714554,
      "learning_rate": 7.231423935339682e-06,
      "loss": 0.0014,
      "step": 62560
    },
    {
      "epoch": 1.9156231821939196,
      "grad_norm": 0.00882258452475071,
      "learning_rate": 7.229382889916216e-06,
      "loss": 0.001,
      "step": 62570
    },
    {
      "epoch": 1.9159293390074397,
      "grad_norm": 0.026957593858242035,
      "learning_rate": 7.22734184449275e-06,
      "loss": 0.0007,
      "step": 62580
    },
    {
      "epoch": 1.9162354958209595,
      "grad_norm": 0.007961130701005459,
      "learning_rate": 7.225300799069283e-06,
      "loss": 0.001,
      "step": 62590
    },
    {
      "epoch": 1.9165416526344794,
      "grad_norm": 0.021912021562457085,
      "learning_rate": 7.2232597536458185e-06,
      "loss": 0.001,
      "step": 62600
    },
    {
      "epoch": 1.9168478094479993,
      "grad_norm": 0.021666960790753365,
      "learning_rate": 7.221218708222351e-06,
      "loss": 0.0475,
      "step": 62610
    },
    {
      "epoch": 1.9171539662615191,
      "grad_norm": 0.006382293999195099,
      "learning_rate": 7.219177662798887e-06,
      "loss": 0.0394,
      "step": 62620
    },
    {
      "epoch": 1.917460123075039,
      "grad_norm": 0.008071266114711761,
      "learning_rate": 7.2171366173754195e-06,
      "loss": 0.0013,
      "step": 62630
    },
    {
      "epoch": 1.9177662798885589,
      "grad_norm": 0.014242161065340042,
      "learning_rate": 7.215095571951955e-06,
      "loss": 0.0012,
      "step": 62640
    },
    {
      "epoch": 1.918072436702079,
      "grad_norm": 0.033144690096378326,
      "learning_rate": 7.213054526528489e-06,
      "loss": 0.0012,
      "step": 62650
    },
    {
      "epoch": 1.9183785935155986,
      "grad_norm": 0.028055626899003983,
      "learning_rate": 7.211013481105023e-06,
      "loss": 0.001,
      "step": 62660
    },
    {
      "epoch": 1.9186847503291187,
      "grad_norm": 0.031546786427497864,
      "learning_rate": 7.2089724356815574e-06,
      "loss": 0.0012,
      "step": 62670
    },
    {
      "epoch": 1.9189909071426383,
      "grad_norm": 0.029443128034472466,
      "learning_rate": 7.20693139025809e-06,
      "loss": 0.0011,
      "step": 62680
    },
    {
      "epoch": 1.9192970639561584,
      "grad_norm": 0.013998928479850292,
      "learning_rate": 7.2048903448346256e-06,
      "loss": 0.0011,
      "step": 62690
    },
    {
      "epoch": 1.9196032207696783,
      "grad_norm": 0.00038350350223481655,
      "learning_rate": 7.202849299411158e-06,
      "loss": 0.0006,
      "step": 62700
    },
    {
      "epoch": 1.9199093775831981,
      "grad_norm": 1.8792262077331543,
      "learning_rate": 7.200808253987694e-06,
      "loss": 0.0362,
      "step": 62710
    },
    {
      "epoch": 1.920215534396718,
      "grad_norm": 1.7303746938705444,
      "learning_rate": 7.1987672085642265e-06,
      "loss": 0.0304,
      "step": 62720
    },
    {
      "epoch": 1.9205216912102379,
      "grad_norm": 0.03922315686941147,
      "learning_rate": 7.196726163140762e-06,
      "loss": 0.0693,
      "step": 62730
    },
    {
      "epoch": 1.9208278480237577,
      "grad_norm": 0.026030169799923897,
      "learning_rate": 7.194685117717295e-06,
      "loss": 0.0018,
      "step": 62740
    },
    {
      "epoch": 1.9211340048372776,
      "grad_norm": 0.03394827991724014,
      "learning_rate": 7.19264407229383e-06,
      "loss": 0.0313,
      "step": 62750
    },
    {
      "epoch": 1.9214401616507977,
      "grad_norm": 0.03970636427402496,
      "learning_rate": 7.190603026870363e-06,
      "loss": 0.0011,
      "step": 62760
    },
    {
      "epoch": 1.9217463184643173,
      "grad_norm": 0.026899317279458046,
      "learning_rate": 7.188561981446897e-06,
      "loss": 0.0014,
      "step": 62770
    },
    {
      "epoch": 1.9220524752778374,
      "grad_norm": 0.011198509484529495,
      "learning_rate": 7.186520936023433e-06,
      "loss": 0.0014,
      "step": 62780
    },
    {
      "epoch": 1.922358632091357,
      "grad_norm": 0.09854082018136978,
      "learning_rate": 7.184479890599965e-06,
      "loss": 0.0604,
      "step": 62790
    },
    {
      "epoch": 1.9226647889048771,
      "grad_norm": 0.04674237221479416,
      "learning_rate": 7.182438845176501e-06,
      "loss": 0.0013,
      "step": 62800
    },
    {
      "epoch": 1.922970945718397,
      "grad_norm": 0.06330659985542297,
      "learning_rate": 7.1803977997530335e-06,
      "loss": 0.0016,
      "step": 62810
    },
    {
      "epoch": 1.9232771025319169,
      "grad_norm": 0.0232541486620903,
      "learning_rate": 7.178356754329569e-06,
      "loss": 0.0013,
      "step": 62820
    },
    {
      "epoch": 1.9235832593454367,
      "grad_norm": 0.025468114763498306,
      "learning_rate": 7.176315708906102e-06,
      "loss": 0.0326,
      "step": 62830
    },
    {
      "epoch": 1.9238894161589566,
      "grad_norm": 0.025014173239469528,
      "learning_rate": 7.174274663482636e-06,
      "loss": 0.0011,
      "step": 62840
    },
    {
      "epoch": 1.9241955729724765,
      "grad_norm": 0.03484523296356201,
      "learning_rate": 7.17223361805917e-06,
      "loss": 0.0011,
      "step": 62850
    },
    {
      "epoch": 1.9245017297859963,
      "grad_norm": 0.020269282162189484,
      "learning_rate": 7.170192572635704e-06,
      "loss": 0.035,
      "step": 62860
    },
    {
      "epoch": 1.9248078865995164,
      "grad_norm": 0.020155617967247963,
      "learning_rate": 7.168151527212238e-06,
      "loss": 0.0119,
      "step": 62870
    },
    {
      "epoch": 1.925114043413036,
      "grad_norm": 0.03479619324207306,
      "learning_rate": 7.1661104817887724e-06,
      "loss": 0.0017,
      "step": 62880
    },
    {
      "epoch": 1.9254202002265561,
      "grad_norm": 0.017309444025158882,
      "learning_rate": 7.164069436365308e-06,
      "loss": 0.0015,
      "step": 62890
    },
    {
      "epoch": 1.9257263570400758,
      "grad_norm": 0.02281012572348118,
      "learning_rate": 7.1620283909418406e-06,
      "loss": 0.0027,
      "step": 62900
    },
    {
      "epoch": 1.9260325138535959,
      "grad_norm": 0.012064032256603241,
      "learning_rate": 7.159987345518376e-06,
      "loss": 0.0355,
      "step": 62910
    },
    {
      "epoch": 1.9263386706671157,
      "grad_norm": 0.08452954888343811,
      "learning_rate": 7.157946300094909e-06,
      "loss": 0.0011,
      "step": 62920
    },
    {
      "epoch": 1.9266448274806356,
      "grad_norm": 0.05606096610426903,
      "learning_rate": 7.155905254671443e-06,
      "loss": 0.0017,
      "step": 62930
    },
    {
      "epoch": 1.9269509842941555,
      "grad_norm": 0.018144775182008743,
      "learning_rate": 7.153864209247977e-06,
      "loss": 0.0011,
      "step": 62940
    },
    {
      "epoch": 1.9272571411076753,
      "grad_norm": 0.023911209776997566,
      "learning_rate": 7.151823163824511e-06,
      "loss": 0.0009,
      "step": 62950
    },
    {
      "epoch": 1.9275632979211952,
      "grad_norm": 0.014464949257671833,
      "learning_rate": 7.149782118401045e-06,
      "loss": 0.001,
      "step": 62960
    },
    {
      "epoch": 1.927869454734715,
      "grad_norm": 0.01913166604936123,
      "learning_rate": 7.1477410729775795e-06,
      "loss": 0.0413,
      "step": 62970
    },
    {
      "epoch": 1.9281756115482351,
      "grad_norm": 0.034046854823827744,
      "learning_rate": 7.145700027554113e-06,
      "loss": 0.0012,
      "step": 62980
    },
    {
      "epoch": 1.9284817683617548,
      "grad_norm": 0.04357146471738815,
      "learning_rate": 7.143658982130648e-06,
      "loss": 0.0289,
      "step": 62990
    },
    {
      "epoch": 1.9287879251752749,
      "grad_norm": 0.02574945241212845,
      "learning_rate": 7.141617936707182e-06,
      "loss": 0.0016,
      "step": 63000
    },
    {
      "epoch": 1.9290940819887945,
      "grad_norm": 0.1297300159931183,
      "learning_rate": 7.139576891283716e-06,
      "loss": 0.0017,
      "step": 63010
    },
    {
      "epoch": 1.9294002388023146,
      "grad_norm": 0.021284624934196472,
      "learning_rate": 7.13753584586025e-06,
      "loss": 0.0295,
      "step": 63020
    },
    {
      "epoch": 1.9297063956158345,
      "grad_norm": 1.6897755861282349,
      "learning_rate": 7.135494800436784e-06,
      "loss": 0.0263,
      "step": 63030
    },
    {
      "epoch": 1.9300125524293543,
      "grad_norm": 0.008228451944887638,
      "learning_rate": 7.133453755013318e-06,
      "loss": 0.0728,
      "step": 63040
    },
    {
      "epoch": 1.9303187092428742,
      "grad_norm": 0.03554842993617058,
      "learning_rate": 7.131412709589852e-06,
      "loss": 0.0016,
      "step": 63050
    },
    {
      "epoch": 1.930624866056394,
      "grad_norm": 0.017399951815605164,
      "learning_rate": 7.1293716641663865e-06,
      "loss": 0.0016,
      "step": 63060
    },
    {
      "epoch": 1.930931022869914,
      "grad_norm": 0.021493948996067047,
      "learning_rate": 7.12733061874292e-06,
      "loss": 0.0015,
      "step": 63070
    },
    {
      "epoch": 1.9312371796834338,
      "grad_norm": 0.07187004387378693,
      "learning_rate": 7.125289573319455e-06,
      "loss": 0.0014,
      "step": 63080
    },
    {
      "epoch": 1.9315433364969539,
      "grad_norm": 0.10063312947750092,
      "learning_rate": 7.123248527895988e-06,
      "loss": 0.0018,
      "step": 63090
    },
    {
      "epoch": 1.9318494933104735,
      "grad_norm": 0.05017929524183273,
      "learning_rate": 7.121207482472523e-06,
      "loss": 0.0309,
      "step": 63100
    },
    {
      "epoch": 1.9321556501239936,
      "grad_norm": 0.02050703391432762,
      "learning_rate": 7.119166437049057e-06,
      "loss": 0.0019,
      "step": 63110
    },
    {
      "epoch": 1.9324618069375132,
      "grad_norm": 0.044769562780857086,
      "learning_rate": 7.117125391625591e-06,
      "loss": 0.0359,
      "step": 63120
    },
    {
      "epoch": 1.9327679637510333,
      "grad_norm": 0.0926550030708313,
      "learning_rate": 7.115084346202125e-06,
      "loss": 0.0017,
      "step": 63130
    },
    {
      "epoch": 1.9330741205645532,
      "grad_norm": 0.06109365448355675,
      "learning_rate": 7.113043300778659e-06,
      "loss": 0.0015,
      "step": 63140
    },
    {
      "epoch": 1.933380277378073,
      "grad_norm": 0.01500638946890831,
      "learning_rate": 7.1110022553551935e-06,
      "loss": 0.0012,
      "step": 63150
    },
    {
      "epoch": 1.933686434191593,
      "grad_norm": 0.028821676969528198,
      "learning_rate": 7.108961209931727e-06,
      "loss": 0.04,
      "step": 63160
    },
    {
      "epoch": 1.9339925910051128,
      "grad_norm": 0.017933283001184464,
      "learning_rate": 7.106920164508262e-06,
      "loss": 0.0014,
      "step": 63170
    },
    {
      "epoch": 1.9342987478186329,
      "grad_norm": 0.04111635684967041,
      "learning_rate": 7.104879119084795e-06,
      "loss": 0.0383,
      "step": 63180
    },
    {
      "epoch": 1.9346049046321525,
      "grad_norm": 0.02751448005437851,
      "learning_rate": 7.10283807366133e-06,
      "loss": 0.0013,
      "step": 63190
    },
    {
      "epoch": 1.9349110614456726,
      "grad_norm": 0.011194761842489243,
      "learning_rate": 7.1007970282378634e-06,
      "loss": 0.0016,
      "step": 63200
    },
    {
      "epoch": 1.9352172182591922,
      "grad_norm": 0.032337743788957596,
      "learning_rate": 7.098755982814398e-06,
      "loss": 0.0013,
      "step": 63210
    },
    {
      "epoch": 1.9355233750727123,
      "grad_norm": 0.02406594343483448,
      "learning_rate": 7.0967149373909324e-06,
      "loss": 0.0012,
      "step": 63220
    },
    {
      "epoch": 1.935829531886232,
      "grad_norm": 0.03968596085906029,
      "learning_rate": 7.094673891967466e-06,
      "loss": 0.0012,
      "step": 63230
    },
    {
      "epoch": 1.936135688699752,
      "grad_norm": 0.03909991309046745,
      "learning_rate": 7.0926328465440006e-06,
      "loss": 0.0009,
      "step": 63240
    },
    {
      "epoch": 1.936441845513272,
      "grad_norm": 0.019011490046977997,
      "learning_rate": 7.090591801120534e-06,
      "loss": 0.0019,
      "step": 63250
    },
    {
      "epoch": 1.9367480023267918,
      "grad_norm": 0.010283565148711205,
      "learning_rate": 7.088550755697069e-06,
      "loss": 0.0008,
      "step": 63260
    },
    {
      "epoch": 1.9370541591403116,
      "grad_norm": 0.0025769476778805256,
      "learning_rate": 7.086509710273602e-06,
      "loss": 0.0008,
      "step": 63270
    },
    {
      "epoch": 1.9373603159538315,
      "grad_norm": 0.04330527409911156,
      "learning_rate": 7.084468664850137e-06,
      "loss": 0.0009,
      "step": 63280
    },
    {
      "epoch": 1.9376664727673516,
      "grad_norm": 3.0398690700531006,
      "learning_rate": 7.0824276194266705e-06,
      "loss": 0.034,
      "step": 63290
    },
    {
      "epoch": 1.9379726295808712,
      "grad_norm": 0.05098782479763031,
      "learning_rate": 7.080386574003205e-06,
      "loss": 0.001,
      "step": 63300
    },
    {
      "epoch": 1.9382787863943913,
      "grad_norm": 0.028867999091744423,
      "learning_rate": 7.078345528579739e-06,
      "loss": 0.0009,
      "step": 63310
    },
    {
      "epoch": 1.938584943207911,
      "grad_norm": 0.02138243429362774,
      "learning_rate": 7.076304483156273e-06,
      "loss": 0.0008,
      "step": 63320
    },
    {
      "epoch": 1.938891100021431,
      "grad_norm": 0.018875816836953163,
      "learning_rate": 7.074263437732807e-06,
      "loss": 0.0647,
      "step": 63330
    },
    {
      "epoch": 1.9391972568349507,
      "grad_norm": 0.027308497577905655,
      "learning_rate": 7.072222392309341e-06,
      "loss": 0.0011,
      "step": 63340
    },
    {
      "epoch": 1.9395034136484708,
      "grad_norm": 0.022568656131625175,
      "learning_rate": 7.070181346885876e-06,
      "loss": 0.0007,
      "step": 63350
    },
    {
      "epoch": 1.9398095704619907,
      "grad_norm": 0.007440648972988129,
      "learning_rate": 7.068140301462409e-06,
      "loss": 0.0008,
      "step": 63360
    },
    {
      "epoch": 1.9401157272755105,
      "grad_norm": 0.0284061748534441,
      "learning_rate": 7.066099256038944e-06,
      "loss": 0.0009,
      "step": 63370
    },
    {
      "epoch": 1.9404218840890304,
      "grad_norm": 0.024422861635684967,
      "learning_rate": 7.0640582106154775e-06,
      "loss": 0.0009,
      "step": 63380
    },
    {
      "epoch": 1.9407280409025502,
      "grad_norm": 0.047917213290929794,
      "learning_rate": 7.062017165192012e-06,
      "loss": 0.0368,
      "step": 63390
    },
    {
      "epoch": 1.9410341977160703,
      "grad_norm": 0.014470965601503849,
      "learning_rate": 7.059976119768546e-06,
      "loss": 0.0008,
      "step": 63400
    },
    {
      "epoch": 1.94134035452959,
      "grad_norm": 0.0020105920266360044,
      "learning_rate": 7.05793507434508e-06,
      "loss": 0.0458,
      "step": 63410
    },
    {
      "epoch": 1.94164651134311,
      "grad_norm": 0.03776072338223457,
      "learning_rate": 7.055894028921614e-06,
      "loss": 0.0696,
      "step": 63420
    },
    {
      "epoch": 1.9419526681566297,
      "grad_norm": 0.04949743673205376,
      "learning_rate": 7.053852983498148e-06,
      "loss": 0.0817,
      "step": 63430
    },
    {
      "epoch": 1.9422588249701498,
      "grad_norm": 0.01483604684472084,
      "learning_rate": 7.051811938074682e-06,
      "loss": 0.0014,
      "step": 63440
    },
    {
      "epoch": 1.9425649817836694,
      "grad_norm": 1.1415959596633911,
      "learning_rate": 7.049770892651216e-06,
      "loss": 0.0025,
      "step": 63450
    },
    {
      "epoch": 1.9428711385971895,
      "grad_norm": 0.007883642800152302,
      "learning_rate": 7.047729847227751e-06,
      "loss": 0.0012,
      "step": 63460
    },
    {
      "epoch": 1.9431772954107094,
      "grad_norm": 1.5525521039962769,
      "learning_rate": 7.0456888018042845e-06,
      "loss": 0.0274,
      "step": 63470
    },
    {
      "epoch": 1.9434834522242292,
      "grad_norm": 0.014023598283529282,
      "learning_rate": 7.043647756380819e-06,
      "loss": 0.0363,
      "step": 63480
    },
    {
      "epoch": 1.943789609037749,
      "grad_norm": 0.030879542231559753,
      "learning_rate": 7.041606710957353e-06,
      "loss": 0.0644,
      "step": 63490
    },
    {
      "epoch": 1.944095765851269,
      "grad_norm": 0.032901581376791,
      "learning_rate": 7.039565665533887e-06,
      "loss": 0.0021,
      "step": 63500
    },
    {
      "epoch": 1.944401922664789,
      "grad_norm": 0.033899713307619095,
      "learning_rate": 7.037524620110421e-06,
      "loss": 0.0352,
      "step": 63510
    },
    {
      "epoch": 1.9447080794783087,
      "grad_norm": 0.023750264197587967,
      "learning_rate": 7.035483574686955e-06,
      "loss": 0.0029,
      "step": 63520
    },
    {
      "epoch": 1.9450142362918288,
      "grad_norm": 0.04046659544110298,
      "learning_rate": 7.033442529263489e-06,
      "loss": 0.004,
      "step": 63530
    },
    {
      "epoch": 1.9453203931053484,
      "grad_norm": 1.8218700885772705,
      "learning_rate": 7.0314014838400234e-06,
      "loss": 0.0353,
      "step": 63540
    },
    {
      "epoch": 1.9456265499188685,
      "grad_norm": 0.05410541966557503,
      "learning_rate": 7.029360438416557e-06,
      "loss": 0.0054,
      "step": 63550
    },
    {
      "epoch": 1.9459327067323884,
      "grad_norm": 0.026694774627685547,
      "learning_rate": 7.027319392993092e-06,
      "loss": 0.0019,
      "step": 63560
    },
    {
      "epoch": 1.9462388635459082,
      "grad_norm": 0.05021040886640549,
      "learning_rate": 7.025278347569626e-06,
      "loss": 0.0384,
      "step": 63570
    },
    {
      "epoch": 1.9465450203594281,
      "grad_norm": 0.0899844765663147,
      "learning_rate": 7.02323730214616e-06,
      "loss": 0.0012,
      "step": 63580
    },
    {
      "epoch": 1.946851177172948,
      "grad_norm": 0.025968074798583984,
      "learning_rate": 7.021196256722694e-06,
      "loss": 0.0012,
      "step": 63590
    },
    {
      "epoch": 1.9471573339864678,
      "grad_norm": 0.022555898874998093,
      "learning_rate": 7.019155211299228e-06,
      "loss": 0.0018,
      "step": 63600
    },
    {
      "epoch": 1.9474634907999877,
      "grad_norm": 0.04353807494044304,
      "learning_rate": 7.017114165875762e-06,
      "loss": 0.0012,
      "step": 63610
    },
    {
      "epoch": 1.9477696476135078,
      "grad_norm": 0.0362531840801239,
      "learning_rate": 7.015073120452296e-06,
      "loss": 0.037,
      "step": 63620
    },
    {
      "epoch": 1.9480758044270274,
      "grad_norm": 1.7346386909484863,
      "learning_rate": 7.0130320750288305e-06,
      "loss": 0.0292,
      "step": 63630
    },
    {
      "epoch": 1.9483819612405475,
      "grad_norm": 0.042911283671855927,
      "learning_rate": 7.010991029605364e-06,
      "loss": 0.0316,
      "step": 63640
    },
    {
      "epoch": 1.9486881180540672,
      "grad_norm": 0.0332731269299984,
      "learning_rate": 7.008949984181899e-06,
      "loss": 0.0025,
      "step": 63650
    },
    {
      "epoch": 1.9489942748675873,
      "grad_norm": 0.05890284478664398,
      "learning_rate": 7.006908938758432e-06,
      "loss": 0.0398,
      "step": 63660
    },
    {
      "epoch": 1.9493004316811071,
      "grad_norm": 0.068370521068573,
      "learning_rate": 7.004867893334967e-06,
      "loss": 0.0018,
      "step": 63670
    },
    {
      "epoch": 1.949606588494627,
      "grad_norm": 0.05842466652393341,
      "learning_rate": 7.002826847911501e-06,
      "loss": 0.0018,
      "step": 63680
    },
    {
      "epoch": 1.9499127453081468,
      "grad_norm": 0.05247914418578148,
      "learning_rate": 7.000785802488035e-06,
      "loss": 0.0022,
      "step": 63690
    },
    {
      "epoch": 1.9502189021216667,
      "grad_norm": 0.016037195920944214,
      "learning_rate": 6.998744757064569e-06,
      "loss": 0.0016,
      "step": 63700
    },
    {
      "epoch": 1.9505250589351866,
      "grad_norm": 0.04508672282099724,
      "learning_rate": 6.996703711641103e-06,
      "loss": 0.0038,
      "step": 63710
    },
    {
      "epoch": 1.9508312157487064,
      "grad_norm": 0.056532520800828934,
      "learning_rate": 6.9946626662176375e-06,
      "loss": 0.0332,
      "step": 63720
    },
    {
      "epoch": 1.9511373725622265,
      "grad_norm": 0.033676356077194214,
      "learning_rate": 6.992621620794171e-06,
      "loss": 0.0623,
      "step": 63730
    },
    {
      "epoch": 1.9514435293757462,
      "grad_norm": 0.04029688611626625,
      "learning_rate": 6.990580575370706e-06,
      "loss": 0.0014,
      "step": 63740
    },
    {
      "epoch": 1.9517496861892663,
      "grad_norm": 0.024444974958896637,
      "learning_rate": 6.988539529947239e-06,
      "loss": 0.0009,
      "step": 63750
    },
    {
      "epoch": 1.952055843002786,
      "grad_norm": 0.06817249953746796,
      "learning_rate": 6.986498484523774e-06,
      "loss": 0.0016,
      "step": 63760
    },
    {
      "epoch": 1.952361999816306,
      "grad_norm": 0.03687942773103714,
      "learning_rate": 6.9844574391003074e-06,
      "loss": 0.0013,
      "step": 63770
    },
    {
      "epoch": 1.9526681566298258,
      "grad_norm": 0.015882793813943863,
      "learning_rate": 6.982416393676842e-06,
      "loss": 0.0012,
      "step": 63780
    },
    {
      "epoch": 1.9529743134433457,
      "grad_norm": 0.018444890156388283,
      "learning_rate": 6.980375348253376e-06,
      "loss": 0.0013,
      "step": 63790
    },
    {
      "epoch": 1.9532804702568656,
      "grad_norm": 0.018226390704512596,
      "learning_rate": 6.97833430282991e-06,
      "loss": 0.0011,
      "step": 63800
    },
    {
      "epoch": 1.9535866270703854,
      "grad_norm": 0.03357972949743271,
      "learning_rate": 6.9762932574064445e-06,
      "loss": 0.0013,
      "step": 63810
    },
    {
      "epoch": 1.9538927838839053,
      "grad_norm": 0.050673745572566986,
      "learning_rate": 6.974252211982978e-06,
      "loss": 0.001,
      "step": 63820
    },
    {
      "epoch": 1.9541989406974252,
      "grad_norm": 0.032706256955862045,
      "learning_rate": 6.972211166559513e-06,
      "loss": 0.0361,
      "step": 63830
    },
    {
      "epoch": 1.9545050975109453,
      "grad_norm": 0.014482208527624607,
      "learning_rate": 6.970170121136046e-06,
      "loss": 0.001,
      "step": 63840
    },
    {
      "epoch": 1.954811254324465,
      "grad_norm": 1.5952593088150024,
      "learning_rate": 6.968129075712581e-06,
      "loss": 0.0324,
      "step": 63850
    },
    {
      "epoch": 1.955117411137985,
      "grad_norm": 0.04190723970532417,
      "learning_rate": 6.9660880302891145e-06,
      "loss": 0.0344,
      "step": 63860
    },
    {
      "epoch": 1.9554235679515046,
      "grad_norm": 0.02248764969408512,
      "learning_rate": 6.964046984865649e-06,
      "loss": 0.0011,
      "step": 63870
    },
    {
      "epoch": 1.9557297247650247,
      "grad_norm": 0.02240682952105999,
      "learning_rate": 6.962005939442183e-06,
      "loss": 0.0291,
      "step": 63880
    },
    {
      "epoch": 1.9560358815785446,
      "grad_norm": 0.04422038793563843,
      "learning_rate": 6.959964894018717e-06,
      "loss": 0.0013,
      "step": 63890
    },
    {
      "epoch": 1.9563420383920644,
      "grad_norm": 0.04214483126997948,
      "learning_rate": 6.9579238485952516e-06,
      "loss": 0.0012,
      "step": 63900
    },
    {
      "epoch": 1.9566481952055843,
      "grad_norm": 0.02080252580344677,
      "learning_rate": 6.955882803171785e-06,
      "loss": 0.0275,
      "step": 63910
    },
    {
      "epoch": 1.9569543520191042,
      "grad_norm": 0.04041987285017967,
      "learning_rate": 6.95384175774832e-06,
      "loss": 0.0011,
      "step": 63920
    },
    {
      "epoch": 1.957260508832624,
      "grad_norm": 0.043925732374191284,
      "learning_rate": 6.951800712324853e-06,
      "loss": 0.0011,
      "step": 63930
    },
    {
      "epoch": 1.957566665646144,
      "grad_norm": 0.010593615472316742,
      "learning_rate": 6.949759666901388e-06,
      "loss": 0.0012,
      "step": 63940
    },
    {
      "epoch": 1.957872822459664,
      "grad_norm": 0.022859755903482437,
      "learning_rate": 6.9477186214779215e-06,
      "loss": 0.0386,
      "step": 63950
    },
    {
      "epoch": 1.9581789792731836,
      "grad_norm": 0.011156284250319004,
      "learning_rate": 6.945677576054456e-06,
      "loss": 0.0013,
      "step": 63960
    },
    {
      "epoch": 1.9584851360867037,
      "grad_norm": 0.033063385635614395,
      "learning_rate": 6.94363653063099e-06,
      "loss": 0.0008,
      "step": 63970
    },
    {
      "epoch": 1.9587912929002234,
      "grad_norm": 0.033115487545728683,
      "learning_rate": 6.941595485207524e-06,
      "loss": 0.0014,
      "step": 63980
    },
    {
      "epoch": 1.9590974497137434,
      "grad_norm": 1.6458033323287964,
      "learning_rate": 6.939554439784058e-06,
      "loss": 0.0291,
      "step": 63990
    },
    {
      "epoch": 1.9594036065272633,
      "grad_norm": 0.029947549104690552,
      "learning_rate": 6.937513394360592e-06,
      "loss": 0.0307,
      "step": 64000
    },
    {
      "epoch": 1.9597097633407832,
      "grad_norm": 0.004346481524407864,
      "learning_rate": 6.935472348937126e-06,
      "loss": 0.0338,
      "step": 64010
    },
    {
      "epoch": 1.960015920154303,
      "grad_norm": 0.02596660517156124,
      "learning_rate": 6.93343130351366e-06,
      "loss": 0.0014,
      "step": 64020
    },
    {
      "epoch": 1.960322076967823,
      "grad_norm": 0.08431585878133774,
      "learning_rate": 6.931390258090195e-06,
      "loss": 0.0017,
      "step": 64030
    },
    {
      "epoch": 1.9606282337813428,
      "grad_norm": 0.03435872122645378,
      "learning_rate": 6.9293492126667285e-06,
      "loss": 0.0012,
      "step": 64040
    },
    {
      "epoch": 1.9609343905948626,
      "grad_norm": 0.032268475741147995,
      "learning_rate": 6.927308167243263e-06,
      "loss": 0.0412,
      "step": 64050
    },
    {
      "epoch": 1.9612405474083827,
      "grad_norm": 1.815085768699646,
      "learning_rate": 6.925267121819797e-06,
      "loss": 0.037,
      "step": 64060
    },
    {
      "epoch": 1.9615467042219024,
      "grad_norm": 0.006089076865464449,
      "learning_rate": 6.923226076396331e-06,
      "loss": 0.0365,
      "step": 64070
    },
    {
      "epoch": 1.9618528610354224,
      "grad_norm": 0.046248260885477066,
      "learning_rate": 6.921185030972865e-06,
      "loss": 0.0265,
      "step": 64080
    },
    {
      "epoch": 1.962159017848942,
      "grad_norm": 0.04132326692342758,
      "learning_rate": 6.919143985549399e-06,
      "loss": 0.0017,
      "step": 64090
    },
    {
      "epoch": 1.9624651746624622,
      "grad_norm": 0.04611870273947716,
      "learning_rate": 6.917102940125933e-06,
      "loss": 0.0314,
      "step": 64100
    },
    {
      "epoch": 1.962771331475982,
      "grad_norm": 0.08682646602392197,
      "learning_rate": 6.915061894702467e-06,
      "loss": 0.0321,
      "step": 64110
    },
    {
      "epoch": 1.963077488289502,
      "grad_norm": 0.019889511168003082,
      "learning_rate": 6.913020849279001e-06,
      "loss": 0.0019,
      "step": 64120
    },
    {
      "epoch": 1.9633836451030218,
      "grad_norm": 1.6946220397949219,
      "learning_rate": 6.9109798038555356e-06,
      "loss": 0.0304,
      "step": 64130
    },
    {
      "epoch": 1.9636898019165416,
      "grad_norm": 0.05281834304332733,
      "learning_rate": 6.90893875843207e-06,
      "loss": 0.0016,
      "step": 64140
    },
    {
      "epoch": 1.9639959587300615,
      "grad_norm": 0.014973814599215984,
      "learning_rate": 6.906897713008604e-06,
      "loss": 0.0023,
      "step": 64150
    },
    {
      "epoch": 1.9643021155435814,
      "grad_norm": 0.028106553480029106,
      "learning_rate": 6.904856667585138e-06,
      "loss": 0.001,
      "step": 64160
    },
    {
      "epoch": 1.9646082723571014,
      "grad_norm": 0.02539351023733616,
      "learning_rate": 6.902815622161672e-06,
      "loss": 0.0314,
      "step": 64170
    },
    {
      "epoch": 1.964914429170621,
      "grad_norm": 0.014267709106206894,
      "learning_rate": 6.900774576738206e-06,
      "loss": 0.03,
      "step": 64180
    },
    {
      "epoch": 1.9652205859841412,
      "grad_norm": 0.05344163998961449,
      "learning_rate": 6.89873353131474e-06,
      "loss": 0.0016,
      "step": 64190
    },
    {
      "epoch": 1.9655267427976608,
      "grad_norm": 0.00023766199592500925,
      "learning_rate": 6.8966924858912745e-06,
      "loss": 0.0011,
      "step": 64200
    },
    {
      "epoch": 1.965832899611181,
      "grad_norm": 0.02329336293041706,
      "learning_rate": 6.894651440467808e-06,
      "loss": 0.0012,
      "step": 64210
    },
    {
      "epoch": 1.9661390564247008,
      "grad_norm": 0.010755111463367939,
      "learning_rate": 6.892610395044343e-06,
      "loss": 0.0306,
      "step": 64220
    },
    {
      "epoch": 1.9664452132382206,
      "grad_norm": 0.03445341810584068,
      "learning_rate": 6.890569349620876e-06,
      "loss": 0.0023,
      "step": 64230
    },
    {
      "epoch": 1.9667513700517405,
      "grad_norm": 0.02514580450952053,
      "learning_rate": 6.888528304197411e-06,
      "loss": 0.001,
      "step": 64240
    },
    {
      "epoch": 1.9670575268652604,
      "grad_norm": 0.030537281185388565,
      "learning_rate": 6.886487258773945e-06,
      "loss": 0.0014,
      "step": 64250
    },
    {
      "epoch": 1.9673636836787802,
      "grad_norm": 0.029188040643930435,
      "learning_rate": 6.884446213350479e-06,
      "loss": 0.0012,
      "step": 64260
    },
    {
      "epoch": 1.9676698404923,
      "grad_norm": 0.02280385047197342,
      "learning_rate": 6.882405167927013e-06,
      "loss": 0.029,
      "step": 64270
    },
    {
      "epoch": 1.9679759973058202,
      "grad_norm": 0.03649584949016571,
      "learning_rate": 6.880364122503547e-06,
      "loss": 0.0009,
      "step": 64280
    },
    {
      "epoch": 1.9682821541193398,
      "grad_norm": 0.05059444531798363,
      "learning_rate": 6.8783230770800815e-06,
      "loss": 0.0014,
      "step": 64290
    },
    {
      "epoch": 1.96858831093286,
      "grad_norm": 0.07136749476194382,
      "learning_rate": 6.876282031656615e-06,
      "loss": 0.0027,
      "step": 64300
    },
    {
      "epoch": 1.9688944677463796,
      "grad_norm": 0.017714038491249084,
      "learning_rate": 6.87424098623315e-06,
      "loss": 0.0014,
      "step": 64310
    },
    {
      "epoch": 1.9692006245598996,
      "grad_norm": 0.021781589835882187,
      "learning_rate": 6.872199940809683e-06,
      "loss": 0.0009,
      "step": 64320
    },
    {
      "epoch": 1.9695067813734195,
      "grad_norm": 0.029526052996516228,
      "learning_rate": 6.870158895386218e-06,
      "loss": 0.0394,
      "step": 64330
    },
    {
      "epoch": 1.9698129381869394,
      "grad_norm": 0.02369089238345623,
      "learning_rate": 6.868117849962751e-06,
      "loss": 0.0408,
      "step": 64340
    },
    {
      "epoch": 1.9701190950004592,
      "grad_norm": 0.013291678391397,
      "learning_rate": 6.866076804539286e-06,
      "loss": 0.0008,
      "step": 64350
    },
    {
      "epoch": 1.970425251813979,
      "grad_norm": 0.051422327756881714,
      "learning_rate": 6.86403575911582e-06,
      "loss": 0.0012,
      "step": 64360
    },
    {
      "epoch": 1.970731408627499,
      "grad_norm": 0.043990202248096466,
      "learning_rate": 6.861994713692354e-06,
      "loss": 0.0014,
      "step": 64370
    },
    {
      "epoch": 1.9710375654410188,
      "grad_norm": 0.05490365996956825,
      "learning_rate": 6.8599536682688885e-06,
      "loss": 0.0015,
      "step": 64380
    },
    {
      "epoch": 1.971343722254539,
      "grad_norm": 0.01673278398811817,
      "learning_rate": 6.857912622845422e-06,
      "loss": 0.001,
      "step": 64390
    },
    {
      "epoch": 1.9716498790680586,
      "grad_norm": 0.03533893823623657,
      "learning_rate": 6.855871577421957e-06,
      "loss": 0.0684,
      "step": 64400
    },
    {
      "epoch": 1.9719560358815786,
      "grad_norm": 0.02103244699537754,
      "learning_rate": 6.85383053199849e-06,
      "loss": 0.0011,
      "step": 64410
    },
    {
      "epoch": 1.9722621926950983,
      "grad_norm": 0.032394275069236755,
      "learning_rate": 6.851789486575025e-06,
      "loss": 0.0012,
      "step": 64420
    },
    {
      "epoch": 1.9725683495086184,
      "grad_norm": 0.018921783193945885,
      "learning_rate": 6.849748441151558e-06,
      "loss": 0.0011,
      "step": 64430
    },
    {
      "epoch": 1.9728745063221382,
      "grad_norm": 0.03553837910294533,
      "learning_rate": 6.847707395728093e-06,
      "loss": 0.0012,
      "step": 64440
    },
    {
      "epoch": 1.973180663135658,
      "grad_norm": 0.017375215888023376,
      "learning_rate": 6.845666350304626e-06,
      "loss": 0.0011,
      "step": 64450
    },
    {
      "epoch": 1.973486819949178,
      "grad_norm": 0.011671053245663643,
      "learning_rate": 6.843625304881161e-06,
      "loss": 0.0356,
      "step": 64460
    },
    {
      "epoch": 1.9737929767626978,
      "grad_norm": 0.03253878280520439,
      "learning_rate": 6.8415842594576956e-06,
      "loss": 0.0377,
      "step": 64470
    },
    {
      "epoch": 1.9740991335762177,
      "grad_norm": 0.020826099440455437,
      "learning_rate": 6.839543214034229e-06,
      "loss": 0.0499,
      "step": 64480
    },
    {
      "epoch": 1.9744052903897376,
      "grad_norm": 0.010706278495490551,
      "learning_rate": 6.837502168610764e-06,
      "loss": 0.0011,
      "step": 64490
    },
    {
      "epoch": 1.9747114472032576,
      "grad_norm": 0.033279601484537125,
      "learning_rate": 6.835461123187297e-06,
      "loss": 0.0373,
      "step": 64500
    },
    {
      "epoch": 1.9750176040167773,
      "grad_norm": 0.05004969984292984,
      "learning_rate": 6.833420077763832e-06,
      "loss": 0.0351,
      "step": 64510
    },
    {
      "epoch": 1.9753237608302974,
      "grad_norm": 0.029179399833083153,
      "learning_rate": 6.831379032340365e-06,
      "loss": 0.0094,
      "step": 64520
    },
    {
      "epoch": 1.975629917643817,
      "grad_norm": 0.027225222438573837,
      "learning_rate": 6.8293379869169e-06,
      "loss": 0.0333,
      "step": 64530
    },
    {
      "epoch": 1.975936074457337,
      "grad_norm": 0.019352253526449203,
      "learning_rate": 6.827296941493433e-06,
      "loss": 0.0024,
      "step": 64540
    },
    {
      "epoch": 1.976242231270857,
      "grad_norm": 3.8667802810668945,
      "learning_rate": 6.825255896069968e-06,
      "loss": 0.0438,
      "step": 64550
    },
    {
      "epoch": 1.9765483880843768,
      "grad_norm": 0.024757491424679756,
      "learning_rate": 6.823214850646501e-06,
      "loss": 0.0683,
      "step": 64560
    },
    {
      "epoch": 1.9768545448978967,
      "grad_norm": 0.035826969891786575,
      "learning_rate": 6.821173805223036e-06,
      "loss": 0.0015,
      "step": 64570
    },
    {
      "epoch": 1.9771607017114166,
      "grad_norm": 0.08956238627433777,
      "learning_rate": 6.819132759799569e-06,
      "loss": 0.0022,
      "step": 64580
    },
    {
      "epoch": 1.9774668585249364,
      "grad_norm": 0.03325141966342926,
      "learning_rate": 6.817091714376104e-06,
      "loss": 0.0014,
      "step": 64590
    },
    {
      "epoch": 1.9777730153384563,
      "grad_norm": 0.07311373203992844,
      "learning_rate": 6.815050668952639e-06,
      "loss": 0.0019,
      "step": 64600
    },
    {
      "epoch": 1.9780791721519764,
      "grad_norm": 0.0417931005358696,
      "learning_rate": 6.813009623529172e-06,
      "loss": 0.0022,
      "step": 64610
    },
    {
      "epoch": 1.978385328965496,
      "grad_norm": 0.014693857170641422,
      "learning_rate": 6.810968578105707e-06,
      "loss": 0.0014,
      "step": 64620
    },
    {
      "epoch": 1.978691485779016,
      "grad_norm": 0.023997634649276733,
      "learning_rate": 6.80892753268224e-06,
      "loss": 0.0019,
      "step": 64630
    },
    {
      "epoch": 1.9789976425925357,
      "grad_norm": 0.03213908523321152,
      "learning_rate": 6.806886487258775e-06,
      "loss": 0.0042,
      "step": 64640
    },
    {
      "epoch": 1.9793037994060558,
      "grad_norm": 0.05633022263646126,
      "learning_rate": 6.804845441835308e-06,
      "loss": 0.0014,
      "step": 64650
    },
    {
      "epoch": 1.9796099562195757,
      "grad_norm": 0.01364061702042818,
      "learning_rate": 6.802804396411843e-06,
      "loss": 0.0011,
      "step": 64660
    },
    {
      "epoch": 1.9799161130330956,
      "grad_norm": 0.06282723695039749,
      "learning_rate": 6.800763350988376e-06,
      "loss": 0.038,
      "step": 64670
    },
    {
      "epoch": 1.9802222698466154,
      "grad_norm": 0.016805659979581833,
      "learning_rate": 6.7987223055649106e-06,
      "loss": 0.0009,
      "step": 64680
    },
    {
      "epoch": 1.9805284266601353,
      "grad_norm": 0.023594342172145844,
      "learning_rate": 6.796681260141444e-06,
      "loss": 0.0329,
      "step": 64690
    },
    {
      "epoch": 1.9808345834736552,
      "grad_norm": 0.027816038578748703,
      "learning_rate": 6.794640214717979e-06,
      "loss": 0.0014,
      "step": 64700
    },
    {
      "epoch": 1.981140740287175,
      "grad_norm": 0.02206987887620926,
      "learning_rate": 6.792599169294514e-06,
      "loss": 0.0013,
      "step": 64710
    },
    {
      "epoch": 1.981446897100695,
      "grad_norm": 0.021137025207281113,
      "learning_rate": 6.790558123871047e-06,
      "loss": 0.001,
      "step": 64720
    },
    {
      "epoch": 1.9817530539142147,
      "grad_norm": 0.03488972410559654,
      "learning_rate": 6.788517078447582e-06,
      "loss": 0.0016,
      "step": 64730
    },
    {
      "epoch": 1.9820592107277348,
      "grad_norm": 0.013490828685462475,
      "learning_rate": 6.786476033024115e-06,
      "loss": 0.001,
      "step": 64740
    },
    {
      "epoch": 1.9823653675412545,
      "grad_norm": 0.03070087917149067,
      "learning_rate": 6.78443498760065e-06,
      "loss": 0.0351,
      "step": 64750
    },
    {
      "epoch": 1.9826715243547746,
      "grad_norm": 0.0431295782327652,
      "learning_rate": 6.782393942177183e-06,
      "loss": 0.001,
      "step": 64760
    },
    {
      "epoch": 1.9829776811682944,
      "grad_norm": 0.026091791689395905,
      "learning_rate": 6.780352896753718e-06,
      "loss": 0.0013,
      "step": 64770
    },
    {
      "epoch": 1.9832838379818143,
      "grad_norm": 0.019106166437268257,
      "learning_rate": 6.778311851330251e-06,
      "loss": 0.0011,
      "step": 64780
    },
    {
      "epoch": 1.9835899947953342,
      "grad_norm": 0.02260722406208515,
      "learning_rate": 6.776270805906786e-06,
      "loss": 0.0013,
      "step": 64790
    },
    {
      "epoch": 1.983896151608854,
      "grad_norm": 0.040119655430316925,
      "learning_rate": 6.774229760483319e-06,
      "loss": 0.0358,
      "step": 64800
    },
    {
      "epoch": 1.984202308422374,
      "grad_norm": 0.012965323403477669,
      "learning_rate": 6.772188715059854e-06,
      "loss": 0.1149,
      "step": 64810
    },
    {
      "epoch": 1.9845084652358937,
      "grad_norm": 0.05338943377137184,
      "learning_rate": 6.770147669636389e-06,
      "loss": 0.0022,
      "step": 64820
    },
    {
      "epoch": 1.9848146220494138,
      "grad_norm": 0.07539194077253342,
      "learning_rate": 6.768106624212922e-06,
      "loss": 0.0013,
      "step": 64830
    },
    {
      "epoch": 1.9851207788629335,
      "grad_norm": 0.051094718277454376,
      "learning_rate": 6.766065578789457e-06,
      "loss": 0.0015,
      "step": 64840
    },
    {
      "epoch": 1.9854269356764536,
      "grad_norm": 0.013797910884022713,
      "learning_rate": 6.76402453336599e-06,
      "loss": 0.03,
      "step": 64850
    },
    {
      "epoch": 1.9857330924899732,
      "grad_norm": 0.05090610682964325,
      "learning_rate": 6.761983487942525e-06,
      "loss": 0.0012,
      "step": 64860
    },
    {
      "epoch": 1.9860392493034933,
      "grad_norm": 0.028411641716957092,
      "learning_rate": 6.759942442519058e-06,
      "loss": 0.0014,
      "step": 64870
    },
    {
      "epoch": 1.9863454061170132,
      "grad_norm": 0.04121902957558632,
      "learning_rate": 6.757901397095593e-06,
      "loss": 0.0013,
      "step": 64880
    },
    {
      "epoch": 1.986651562930533,
      "grad_norm": 1.751298427581787,
      "learning_rate": 6.755860351672126e-06,
      "loss": 0.0673,
      "step": 64890
    },
    {
      "epoch": 1.9869577197440529,
      "grad_norm": 0.026274802163243294,
      "learning_rate": 6.753819306248661e-06,
      "loss": 0.0015,
      "step": 64900
    },
    {
      "epoch": 1.9872638765575728,
      "grad_norm": 0.03936769813299179,
      "learning_rate": 6.7517782608251945e-06,
      "loss": 0.001,
      "step": 64910
    },
    {
      "epoch": 1.9875700333710928,
      "grad_norm": 0.04390978068113327,
      "learning_rate": 6.749737215401729e-06,
      "loss": 0.001,
      "step": 64920
    },
    {
      "epoch": 1.9878761901846125,
      "grad_norm": 0.03490721434354782,
      "learning_rate": 6.7476961699782635e-06,
      "loss": 0.0622,
      "step": 64930
    },
    {
      "epoch": 1.9881823469981326,
      "grad_norm": 0.03145383670926094,
      "learning_rate": 6.745655124554797e-06,
      "loss": 0.0019,
      "step": 64940
    },
    {
      "epoch": 1.9884885038116522,
      "grad_norm": 0.038275137543678284,
      "learning_rate": 6.743614079131332e-06,
      "loss": 0.0024,
      "step": 64950
    },
    {
      "epoch": 1.9887946606251723,
      "grad_norm": 0.021861817687749863,
      "learning_rate": 6.741573033707865e-06,
      "loss": 0.0019,
      "step": 64960
    },
    {
      "epoch": 1.989100817438692,
      "grad_norm": 0.032714564353227615,
      "learning_rate": 6.7395319882844e-06,
      "loss": 0.0391,
      "step": 64970
    },
    {
      "epoch": 1.989406974252212,
      "grad_norm": 0.06592639535665512,
      "learning_rate": 6.7374909428609334e-06,
      "loss": 0.0013,
      "step": 64980
    },
    {
      "epoch": 1.9897131310657319,
      "grad_norm": 0.01637869141995907,
      "learning_rate": 6.735449897437468e-06,
      "loss": 0.0747,
      "step": 64990
    },
    {
      "epoch": 1.9900192878792518,
      "grad_norm": 0.0393686406314373,
      "learning_rate": 6.7334088520140016e-06,
      "loss": 0.0015,
      "step": 65000
    },
    {
      "epoch": 1.9903254446927716,
      "grad_norm": 0.017545392736792564,
      "learning_rate": 6.731367806590536e-06,
      "loss": 0.0013,
      "step": 65010
    },
    {
      "epoch": 1.9906316015062915,
      "grad_norm": 0.12404954433441162,
      "learning_rate": 6.72932676116707e-06,
      "loss": 0.0019,
      "step": 65020
    },
    {
      "epoch": 1.9909377583198116,
      "grad_norm": 0.010085063055157661,
      "learning_rate": 6.727285715743604e-06,
      "loss": 0.0366,
      "step": 65030
    },
    {
      "epoch": 1.9912439151333312,
      "grad_norm": 0.0169466994702816,
      "learning_rate": 6.725244670320139e-06,
      "loss": 0.0372,
      "step": 65040
    },
    {
      "epoch": 1.9915500719468513,
      "grad_norm": 0.013642788864672184,
      "learning_rate": 6.723203624896672e-06,
      "loss": 0.0031,
      "step": 65050
    },
    {
      "epoch": 1.991856228760371,
      "grad_norm": 0.034912243485450745,
      "learning_rate": 6.721162579473207e-06,
      "loss": 0.0011,
      "step": 65060
    },
    {
      "epoch": 1.992162385573891,
      "grad_norm": 0.011912105605006218,
      "learning_rate": 6.7191215340497405e-06,
      "loss": 0.0012,
      "step": 65070
    },
    {
      "epoch": 1.9924685423874107,
      "grad_norm": 0.039185188710689545,
      "learning_rate": 6.717080488626275e-06,
      "loss": 0.0012,
      "step": 65080
    },
    {
      "epoch": 1.9927746992009308,
      "grad_norm": 4.432614803314209,
      "learning_rate": 6.715039443202809e-06,
      "loss": 0.0101,
      "step": 65090
    },
    {
      "epoch": 1.9930808560144506,
      "grad_norm": 1.7450693845748901,
      "learning_rate": 6.712998397779343e-06,
      "loss": 0.0318,
      "step": 65100
    },
    {
      "epoch": 1.9933870128279705,
      "grad_norm": 0.029522927477955818,
      "learning_rate": 6.710957352355877e-06,
      "loss": 0.0011,
      "step": 65110
    },
    {
      "epoch": 1.9936931696414903,
      "grad_norm": 0.02751927822828293,
      "learning_rate": 6.708916306932411e-06,
      "loss": 0.0009,
      "step": 65120
    },
    {
      "epoch": 1.9939993264550102,
      "grad_norm": 0.052137743681669235,
      "learning_rate": 6.706875261508945e-06,
      "loss": 0.0366,
      "step": 65130
    },
    {
      "epoch": 1.9943054832685303,
      "grad_norm": 0.03881094232201576,
      "learning_rate": 6.704834216085479e-06,
      "loss": 0.0009,
      "step": 65140
    },
    {
      "epoch": 1.99461164008205,
      "grad_norm": 0.03028622269630432,
      "learning_rate": 6.702793170662014e-06,
      "loss": 0.0012,
      "step": 65150
    },
    {
      "epoch": 1.99491779689557,
      "grad_norm": 0.027785005047917366,
      "learning_rate": 6.7007521252385475e-06,
      "loss": 0.002,
      "step": 65160
    },
    {
      "epoch": 1.9952239537090897,
      "grad_norm": 0.022381873801350594,
      "learning_rate": 6.698711079815082e-06,
      "loss": 0.0376,
      "step": 65170
    },
    {
      "epoch": 1.9955301105226098,
      "grad_norm": 0.014459051191806793,
      "learning_rate": 6.696670034391616e-06,
      "loss": 0.0013,
      "step": 65180
    },
    {
      "epoch": 1.9958362673361294,
      "grad_norm": 0.08777692168951035,
      "learning_rate": 6.69462898896815e-06,
      "loss": 0.001,
      "step": 65190
    },
    {
      "epoch": 1.9961424241496495,
      "grad_norm": 0.007722690235823393,
      "learning_rate": 6.692587943544684e-06,
      "loss": 0.001,
      "step": 65200
    },
    {
      "epoch": 1.9964485809631694,
      "grad_norm": 0.013689366169273853,
      "learning_rate": 6.690546898121218e-06,
      "loss": 0.0345,
      "step": 65210
    },
    {
      "epoch": 1.9967547377766892,
      "grad_norm": 2.110137939453125,
      "learning_rate": 6.688505852697752e-06,
      "loss": 0.0773,
      "step": 65220
    },
    {
      "epoch": 1.997060894590209,
      "grad_norm": 0.04513107240200043,
      "learning_rate": 6.686464807274286e-06,
      "loss": 0.0466,
      "step": 65230
    },
    {
      "epoch": 1.997367051403729,
      "grad_norm": 0.03672531247138977,
      "learning_rate": 6.68442376185082e-06,
      "loss": 0.0014,
      "step": 65240
    },
    {
      "epoch": 1.997673208217249,
      "grad_norm": 0.028514446690678596,
      "learning_rate": 6.6823827164273545e-06,
      "loss": 0.0013,
      "step": 65250
    },
    {
      "epoch": 1.9979793650307687,
      "grad_norm": 0.04607534408569336,
      "learning_rate": 6.680341671003888e-06,
      "loss": 0.0111,
      "step": 65260
    },
    {
      "epoch": 1.9982855218442888,
      "grad_norm": 0.01830245740711689,
      "learning_rate": 6.678300625580423e-06,
      "loss": 0.0432,
      "step": 65270
    },
    {
      "epoch": 1.9985916786578084,
      "grad_norm": 0.02218829095363617,
      "learning_rate": 6.676259580156957e-06,
      "loss": 0.063,
      "step": 65280
    },
    {
      "epoch": 1.9988978354713285,
      "grad_norm": 0.058899931609630585,
      "learning_rate": 6.674218534733491e-06,
      "loss": 0.0027,
      "step": 65290
    },
    {
      "epoch": 1.9992039922848484,
      "grad_norm": 0.05057626590132713,
      "learning_rate": 6.672177489310025e-06,
      "loss": 0.0018,
      "step": 65300
    },
    {
      "epoch": 1.9995101490983682,
      "grad_norm": 0.005477477330714464,
      "learning_rate": 6.670136443886559e-06,
      "loss": 0.0361,
      "step": 65310
    },
    {
      "epoch": 1.999816305911888,
      "grad_norm": 0.024000776931643486,
      "learning_rate": 6.6680953984630934e-06,
      "loss": 0.0015,
      "step": 65320
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9973287409108305,
      "eval_f1": 0.9973287283773383,
      "eval_loss": 0.014448104426264763,
      "eval_precision": 0.9973380748666987,
      "eval_recall": 0.9973287409108305,
      "eval_runtime": 1686.58,
      "eval_samples_per_second": 77.464,
      "eval_steps_per_second": 4.842,
      "step": 65326
    }
  ],
  "logging_steps": 10,
  "max_steps": 97989,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.0313518421412096e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
